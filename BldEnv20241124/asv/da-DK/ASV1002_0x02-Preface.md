# Forord

Velkommen til Artificial Intelligence Security Verification Standard (AISVS) version 1.0!

## Introduktion

Etableret i 2025 gennem en fælles indsats fra samfundet definerer AISVS sikkerhedskravene, der skal overvejes ved design, udvikling, implementering og drift af moderne AI-modeller, databehandlingspipelines og AI-aktiverede tjenester.

AISVS v1.0 repræsenterer det samlede arbejde fra dets projektledere, arbejdsgruppe og bredere fællesskabsbidragydere for at skabe en pragmatisk, testbar grundlinje for sikring af AI-systemer.

Vores mål med denne udgivelse er at gøre AISVS let at tage i brug, samtidig med at vi forbliver skarpt fokuserede på dets definerede omfang og adresserer det hurtigt udviklende risikolandskab, der er unikt for AI.

## Nøglemål for AISVS Version 1.0

Version 1.0 vil blive oprettet med flere vejledende principper.

### Veldefineret omfang

Hvert krav skal være i overensstemmelse med AISVS’s navn og mission:

* Kunstig intelligens – Kontroller fungerer på AI/ML-laget (data, model, pipeline eller inferens) og er ansvaret for AI-praktikere.
* Sikkerhed – Kravene afbøder direkte identificerede sikkerheds-, privatlivs- eller sikkerhedsrisici.
* Verifikation – Sproget er skrevet, så overensstemmelse kan valideres objektivt.
* Standard – Sektioner følger en konsekvent struktur og terminologi for at danne en sammenhængende reference.
  ​
---

Ved at følge AISVS kan organisationer systematisk evaluere og styrke sikkerhedspositionen for deres AI-løsninger og fremme en kultur af sikker AI-udvikling.

