# Frontispice

## Om standarden

Artificial Intelligence Security Verification Standard (AISVS) er en fællesskabsdrevet katalog over sikkerhedskrav, som dataforskere, MLOps-ingeniører, softwarearkitekter, udviklere, testere, sikkerhedsprofessionelle, værktøjsleverandører, regulatorer og brugere kan anvende til at designe, opbygge, teste og verificere pålidelige AI-aktiverede systemer og applikationer. Den giver et fælles sprog til at specificere sikkerhedskontroller på tværs af AI-livscyklussen — fra dataindsamling og modeludvikling til implementering og løbende overvågning — så organisationer kan måle og forbedre robusthed, privatliv og sikkerhed i deres AI-løsninger.

## Ophavsret og licens

Version 0.1 (Første offentlige udkast - Arbejde i gang), 2025  

![license](../images/license.png)

Ophavsret © 2025 The AISVS-projektet.  

Udgivet under the[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
For enhver genbrug eller distribution skal du tydeligt kommunikere licensbetingelserne for dette værk til andre.

## Projektledere

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bidragydere og anmeldere

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS er en helt ny standard, der er skabt specifikt til at håndtere de unikke sikkerhedsudfordringer ved kunstige intelligenssystemer. Selvom den henter inspiration fra bredere sikkerhedspraksis, er hvert krav i AISVS udviklet fra bunden for at afspejle AI-trusselslandskabet og hjælpe organisationer med at opbygge sikkerere, mere modstandsdygtige AI-løsninger.

