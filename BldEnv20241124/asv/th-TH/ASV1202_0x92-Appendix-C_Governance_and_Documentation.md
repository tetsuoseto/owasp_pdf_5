# ภาคผนวก ซี: การกำกับดูแลและเอกสารด้านความมั่นคงปลอดภัยของปัญญาประดิษฐ์

## วัตถุประสงค์

ภาคผนวกนี้จัดเตรียมข้อกำหนดพื้นฐานสำหรับการจัดตั้งโครงสร้างองค์กร นโยบาย และกระบวนการเพื่อควบคุมความปลอดภัยของ AI ตลอดวงจรชีวิตของระบบ

---

## การนำกรอบการจัดการความเสี่ยงของปัญญาประดิษฐ์ (AI Risk Management Framework) มาใช้

จัดทำกรอบงานอย่างเป็นทางการเพื่อระบุ ประเมิน และลดความเสี่ยงเฉพาะของปัญญาประดิษฐ์ตลอดวงจรชีวิตของระบบ

|   #    | Description                                                                                                     | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.1.1 | ตรวจสอบให้แน่ใจว่าวิธีการประเมินความเสี่ยงเฉพาะสำหรับ AI ได้รับการจัดทำเป็นเอกสารและนำไปใช้แล้ว                 |   1   | D/V  |
| AC.1.2 | ตรวจสอบให้แน่ใจว่าการประเมินความเสี่ยงถูกดำเนินการในจุดสำคัญของวงจรชีวิต AI และก่อนการเปลี่ยนแปลงที่มีความสำคัญ |   2   |  D   |
| AC.1.3 | ตรวจสอบให้แน่ใจว่าโครงสร้างการจัดการความเสี่ยงสอดคล้องกับมาตรฐานที่กำหนดไว้ (เช่น NIST AI RMF)                  |   3   | D/V  |

---

## นโยบายและขั้นตอนความปลอดภัยของปัญญาประดิษฐ์ (AI) AC.2

กำหนดและบังคับใช้มาตรฐานองค์กรสำหรับการพัฒนา การปรับใช้งาน และการดำเนินงาน AI อย่างปลอดภัย

|   #    | Description                                                                                                           | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.2.1 | ตรวจสอบให้แน่ใจว่านโยบายความปลอดภัยของ AI ที่บันทึกไว้มีอยู่จริง                                                      |   1   | D/V  |
| AC.2.2 | ตรวจสอบให้แน่ใจว่านโยบายได้รับการทบทวนและปรับปรุงอย่างน้อยทุกปีและหลังจากมีการเปลี่ยนแปลงที่สำคัญในภูมิทัศน์ภัยคุกคาม |   2   |  D   |
| AC.2.3 | ตรวจสอบให้แน่ใจว่านโยบายครอบคลุมทุกหมวดหมู่ของ AISVS และข้อกำหนดทางกฎระเบียบที่เกี่ยวข้อง                             |   3   | D/V  |

---

## AC.3 บทบาทและความรับผิดชอบสำหรับความมั่นคงปลอดภัยของปัญญาประดิษฐ์

กำหนดความรับผิดชอบที่ชัดเจนสำหรับความมั่นคงปลอดภัยของ AI ทั่วทั้งองค์กร

|   #    | Description                                                                                                         | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.3.1 | ตรวจสอบให้แน่ใจว่าได้บันทึกบทบาทและความรับผิดชอบด้านความปลอดภัยของปัญญาประดิษฐ์ไว้แล้ว                              |   1   | D/V  |
| AC.3.2 | ตรวจสอบให้แน่ใจว่าบุคคลที่รับผิดชอบมีความเชี่ยวชาญด้านความปลอดภัยที่เหมาะสม                                         |   2   |  D   |
| AC.3.3 | ตรวจสอบให้แน่ใจว่าคณะกรรมการจริยธรรม AI หรือคณะกรรมการกำกับดูแลได้รับการจัดตั้งขึ้นสำหรับระบบ AI ที่มีความเสี่ยงสูง |   3   | D/V  |

---

## การบังคับใช้แนวทางจริยธรรมของปัญญาประดิษฐ์ (AI)

ตรวจสอบให้แน่ใจว่าระบบปัญญาประดิษฐ์ทำงานตามหลักจริยธรรมที่กำหนดไว้

|   #    | Description                                                                                | Level | Role |
| :----: | ------------------------------------------------------------------------------------------ | :---: | :--: |
| AC.4.1 | ตรวจสอบให้แน่ใจว่ามีแนวทางจริยธรรมสำหรับการพัฒนาและการนำ AI ไปใช้                          |   1   | D/V  |
| AC.4.2 | ตรวจสอบให้แน่ใจว่ามีมาตรการในการตรวจจับและรายงานการละเมิดทางจริยธรรมอยู่ในระบบแล้ว         |   2   |  D   |
| AC.4.3 | ตรวจสอบให้แน่ใจว่ามีการทบทวนด้านจริยธรรมอย่างสม่ำเสมอของระบบปัญญาประดิษฐ์ที่นำไปใช้งานแล้ว |   3   | D/V  |

---

## AC.5 การติดตามความสอดคล้องด้านกฎระเบียบของปัญญาประดิษฐ์

รักษาการรับรู้และการปฏิบัติตามกฎระเบียบปัญญาประดิษฐ์ที่เปลี่ยนแปลงอยู่เสมอ

|   #    | Description                                                                                                                | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.5.1 | ตรวจสอบให้แน่ใจว่ามีกระบวนการในการระบุข้อกำหนดทางกฎระเบียบของปัญญาประดิษฐ์ที่ใช้บังคับอยู่                                 |   1   | D/V  |
| AC.5.2 | ตรวจสอบให้แน่ใจว่าการปฏิบัติตามข้อกำหนดทางกฎหมายทั้งหมดได้รับการประเมินแล้ว                                                |   2   |  D   |
| AC.5.3 | ตรวจสอบให้แน่ใจว่าการเปลี่ยนแปลงด้านข้อกำหนดกฎระเบียบเป็นตัวกระตุ้นให้มีการทบทวนและปรับปรุงระบบปัญญาประดิษฐ์อย่างทันท่วงที |   3   | D/V  |

### เอกสารอ้างอิง

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)

