# 10 ความทนทานของระบบต่อการโจมตีและการป้องกันความเป็นส่วนตัว

## วัตถุประสงค์ของการควบคุม

ตรวจสอบให้แน่ใจว่าโมเดลปัญญาประดิษฐ์ยังคงเชื่อถือได้ รักษาความเป็นส่วนตัว และต้านทานการละเมิดได้เมื่อเผชิญกับการโจมตีประเภทหลีกเลี่ยง การสืบค้นข้อมูล การดึงข้อมูล หรือการปลอมปนข้อมูล

---

## 10.1 การปรับแนวแบบจำลองและความปลอดภัย

ป้องกันผลลัพธ์ที่เป็นอันตรายหรือขัดต่อข้อกำหนดนโยบาย

|   #    | Description                                                                                                                               | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.1.1 | ตรวจสอบให้แน่ใจว่าชุดทดสอบความสอดคล้อง (คำสั่งทีมแดง, การสอดแนมเจลเบรก, เนื้อหาที่ห้าม) ถูกควบคุมเวอร์ชันและรันในทุกการปล่อยโมเดลทุกครั้ง |   1   | D/V  |
| 10.1.2 | ตรวจสอบให้แน่ใจว่าการปฏิเสธและการป้องกันการทำงานที่ปลอดภัยถูกบังคับใช้อย่างเคร่งครัด                                                      |   1   |  D   |
| 10.1.3 | ตรวจสอบให้แน่ใจว่าตัวประเมินอัตโนมัติวัดอัตราของเนื้อหาที่เป็นอันตรายและแจ้งเตือนเมื่อเกิดการเสื่อมคุณภาพเกินกว่าค่าขีดจำกัดที่กำหนดไว้   |   2   | D/V  |
| 10.1.4 | ยืนยันว่าการฝึก counter-jailbreak มีการบันทึกและสามารถทำซ้ำได้                                                                            |   2   |  D   |
| 10.1.5 | ตรวจสอบให้แน่ใจว่าหลักฐานการปฏิบัติตามนโยบายอย่างเป็นทางการหรือการตรวจสอบที่ได้รับการรับรองครอบคลุมโดเมนที่สำคัญ                          |   3   |  V   |

---

## 10.2 การเสริมความแข็งแกร่งต่อการโจมตีด้วยตัวอย่างที่หลอกลวง

เพิ่มความทนทานต่อข้อมูลนำเข้าที่ถูกดัดแปลง การฝึกอบรมแบบต้านการโจมตีอย่างเข้มแข็งและการประเมินผลมาตรฐานเป็นแนวปฏิบัติที่ดีที่สุดในปัจจุบัน

|   #    | Description                                                                                                                                                | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.2.1 | ตรวจสอบให้แน่ใจว่ารีโพสิโทรีโครงการมีการกำหนดค่าการฝึกอบรมแบบต่อต้าน (adversarial-training) พร้อมกับเมล็ดพันธุ์ที่ทำให้สามารถทำซ้ำได้ (reproducible seeds) |   1   |  D   |
| 10.2.2 | ตรวจสอบให้แน่ใจว่าการตรวจจับตัวอย่างโจมตีสร้างการแจ้งเตือนบล็อกในสายงานการผลิต                                                                             |   2   | D/V  |
| 10.2.4 | ตรวจสอบให้แน่ใจว่าหลักฐานความมั่นคงที่ได้รับการรับรองหรือใบรับรองขอบเขตช่วงครอบคลุมอย่างน้อยคลาสที่สำคัญอันดับต้น ๆ                                        |   3   |  V   |
| 10.2.5 | ตรวจสอบให้แน่ใจว่าการทดสอบรีเกรสชันใช้การโจมตีแบบปรับตัวเพื่อยืนยันว่าไม่มีการสูญเสียความทนทานที่วัดได้                                                    |   3   |  V   |

---

## 10.3 การลดความเสี่ยงจากการสืบค้นสมาชิก

จำกัดความสามารถในการตัดสินใจว่าข้อมูลใดเป็นส่วนหนึ่งของชุดข้อมูลฝึกฝนหรือไม่ ความเป็นส่วนตัวแบบต่าง (Differential privacy) และการปกปิดคะแนนความเชื่อมั่น (confidence-score masking) ยังคงเป็นการป้องกันที่มีประสิทธิภาพที่สุดที่เป็นที่รู้จักอยู่ในปัจจุบัน

|   #    | Description                                                                                                              | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 10.3.1 | ยืนยันว่าการทำปกติเอนโทรปีแบบต่อคำถามหรือการปรับอุณหภูมิช่วยลดการพยากรณ์ที่มั่นใจเกินไปได้                               |   1   |  D   |
| 10.3.2 | ตรวจสอบให้แน่ใจว่าการฝึกอบรมใช้การเพิ่มประสิทธิภาพแบบต่างially-private ที่มีขอบเขต ε สำหรับชุดข้อมูลที่มีความละเอียดอ่อน |   2   |  D   |
| 10.3.3 | ตรวจสอบให้แน่ใจว่าการจำลองการโจมตี (แบบแฝงเงาหรือแบบกล่องดำ) แสดงค่า AUC การโจมตี ≤ 0.60 บนข้อมูลที่แยกเก็บไว้           |   2   |  V   |

---

## 10.4 ความต้านทานต่อการย้อนกลับของโมเดล

ป้องกันการสร้างข้อมูลแอตทริบิวต์ส่วนตัวขึ้นใหม่ งานสำรวจล่าสุดเน้นการตัดข้อความผลลัพธ์และการรับประกันความเป็นส่วนตัวแบบ DP เป็นวิธีป้องกันที่ใช้ได้จริง

|   #    | Description                                                                                               | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.4.1 | ตรวจสอบให้แน่ใจว่าสมบัติที่อ่อนไหวไม่ถูกส่งออกโดยตรง; ในกรณีที่จำเป็นให้ใช้การจัดกลุ่มหรือการแปลงทางเดียว |   1   |  D   |
| 10.4.2 | ตรวจสอบให้แน่ใจว่าข้อจำกัดอัตราการสอบถามจำกัดการสอบถามแบบปรับตัวซ้ำจากเจ้าของหลักเดียวกัน                 |   1   | D/V  |
| 10.4.3 | ตรวจสอบให้แน่ใจว่าโมเดลได้รับการฝึกด้วยเสียงรบกวนที่ปกป้องความเป็นส่วนตัว                                 |   2   |  D   |

---

## 10.5 การป้องกันการสกัดแบบจำลอง

ตรวจจับและป้องกันการทำสำเนาที่ไม่ได้รับอนุญาต ควรใช้การประทับลายน้ำและการวิเคราะห์รูปแบบคำค้นค้น

|   #    | Description                                                                                                                       | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.5.1 | ตรวจสอบให้แน่ใจว่าเกตเวย์การอนุมานบังคับใช้ขีดจำกัดอัตราทั่วโลกและแต่ละคีย์ API ที่ปรับแต่งให้สอดคล้องกับเกณฑ์การจดจำของโมเดล     |   1   |  D   |
| 10.5.2 | ตรวจสอบให้แน่ใจว่าสถิติ query-entropy และ input-plurality ส่งข้อมูลไปยังตัวตรวจจับการสกัดแบบอัตโนมัติ                             |   2   | D/V  |
| 10.5.3 | ยืนยันว่าเครื่องหมายลายน้ำแบบเปราะบางหรือแบบน่าจะเป็นสามารถพิสูจน์ได้ด้วย p < 0.01 ในการทำสอบไม่เกิน 1,000 คำสั่งกับสำเนาที่สงสัย |   2   |  V   |
| 10.5.4 | ตรวจสอบให้แน่ใจว่ากุญแจลายน้ำและชุดทริกเกอร์ถูกจัดเก็บในโมดูลความปลอดภัยฮาร์ดแวร์และมีการหมุนเวียนทุกปี                           |   3   |  D   |
| 10.5.5 | ตรวจสอบให้แน่ใจว่าเหตุการณ์แจ้งเตือนการสกัดข้อมูลรวมถึงคำสั่งค้นหาที่เป็นปัญหาและถูกผนวกรวมกับคู่มือการตอบสนองเหตุการณ์แล้ว       |   3   |  V   |

---

## 10.6 การตรวจจับข้อมูลถูกวางยาพิษในช่วงเวลาสรุปผล

ระบุและทำให้ข้อมูลนำเข้าที่มีประตูหลังหรือพิษเป็นกลาง

|   #    | Description                                                                                                                                             | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.6.1 | ตรวจสอบให้แน่ใจว่าสัญญาณอินพุตผ่านตัวตรวจจับความผิดปกติ (เช่น STRIP, การให้คะแนนความสอดคล้อง) ก่อนการอนุมานของโมเดล                                     |   1   |  D   |
| 10.6.2 | ตรวจสอบให้แน่ใจว่าการปรับแต่งเกณฑ์ตรวจจับ (detector thresholds) บนชุดข้อมูลตรวจสอบ (validation sets) ที่สะอาด/ปนเปื้อน เพื่อให้เกิดผลบวกเท็จน้อยกว่า 5% |   1   |  V   |
| 10.6.3 | ตรวจสอบให้แน่ใจว่าข้อมูลนำเข้าที่ถูกระบุว่าเป็นพิษทำให้เกิดการบล็อกแบบนุ่มนวลและกระบวนการตรวจสอบโดยมนุษย์                                               |   2   |  D   |
| 10.6.4 | ตรวจสอบให้แน่ใจว่าตัวตรวจจับได้รับการทดสอบความเครียดด้วยการโจมตีประตูหลังแบบไม่มีตัวกระตุ้นและปรับตัวได้                                                |   2   |  V   |
| 10.6.5 | ตรวจสอบให้แน่ใจว่ามาตรวัดประสิทธิภาพการตรวจจับถูกบันทึกไว้และมีการประเมินซ้ำเป็นระยะด้วยข้อมูลข่าวกรองภัยคุกคามที่ทันสมัย                               |   3   |  D   |

---

## 10.7 การปรับนโยบายความปลอดภัยแบบไดนามิก

การอัปเดตนโยบายความปลอดภัยแบบเรียลไทม์โดยอ้างอิงจากความรู้ด้านภัยคุกคามและการวิเคราะห์พฤติกรรม

|   #    | Description                                                                                                                                     | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.7.1 | ตรวจสอบให้แน่ใจว่านโยบายความปลอดภัยสามารถอัปเดตได้แบบไดนามิกโดยไม่ต้องรีสตาร์ทเอเจนต์พร้อมทั้งรักษาความสมบูรณ์ของเวอร์ชันนโยบายไว้              |   1   | D/V  |
| 10.7.2 | ตรวจสอบให้นโยบายที่อัปเดตได้รับการลงนามทางคริปโตกราฟีโดยเจ้าหน้าที่ด้านความปลอดภัยที่ได้รับอนุญาตและได้รับการตรวจสอบก่อนนำไปใช้                 |   2   | D/V  |
| 10.7.3 | ตรวจสอบให้แน่ใจว่าการเปลี่ยนนโยบายแบบไดนามิกถูกบันทึกด้วยเส้นทางการตรวจสอบอย่างครบถ้วน รวมถึงการให้เหตุผล ลำดับการอนุมัติ และขั้นตอนการย้อนกลับ |   2   | D/V  |
| 10.7.4 | ตรวจสอบให้แน่ใจว่า กลไกความปลอดภัยแบบปรับตัวจะปรับระดับความไวในการตรวจจับภัยคุกคามตามบริบทความเสี่ยงและรูปแบบพฤติกรรม                           |   3   | D/V  |
| 10.7.5 | ตรวจสอบให้มั่นใจว่าการตัดสินใจปรับนโยบายสามารถอธิบายได้และมีหลักฐานแสดงกระบวนการเพื่อตรวจสอบโดยทีมรักษาความปลอดภัย                              |   3   | D/V  |

---

## 10.8 การวิเคราะห์ความปลอดภัยแบบอิงการสะท้อน

การตรวจสอบความปลอดภัยผ่านการสะท้อนตนเองของเอเย่นต์และการวิเคราะห์เมตา-คอกนิทีฟ

|   #    | Description                                                                                                                                         | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.8.1 | ตรวจสอบให้แน่ใจว่ากลไกการสะท้อนความคิดของเอเจนต์รวมถึงการประเมินตนเองที่มุ่งเน้นด้านความปลอดภัยของการตัดสินใจและการกระทำด้วย                        |   1   | D/V  |
| 10.8.2 | ตรวจสอบให้แน่ใจว่าผลลัพธ์จากการสะท้อนได้รับการตรวจสอบความถูกต้องเพื่อป้องกันการปลอมแปลงกลไกการประเมินตนเองโดยข้อมูลป้อนเข้าที่เป็นการโจมตี          |   2   | D/V  |
| 10.8.3 | ยืนยันว่าการวิเคราะห์ความปลอดภัยแบบเมตา-คอกนิทีฟสามารถระบุอคติ การบิดเบือน หรือการถูกโจมตีในกระบวนการวิเคราะห์เหตุผลของเอเยนต์ได้                   |   2   | D/V  |
| 10.8.4 | ยืนยันว่าคำเตือนด้านความปลอดภัยที่ใช้การสะท้อนทำให้เกิดการตรวจสอบที่เพิ่มขึ้นและกระบวนการแทรกแซงโดยมนุษย์ที่เป็นไปได้                               |   3   | D/V  |
| 10.8.5 | ตรวจสอบให้แน่ใจว่าการเรียนรู้อย่างต่อเนื่องจากการสะท้อนด้านความปลอดภัยช่วยปรับปรุงการตรวจจับภัยคุกคามโดยไม่ส่งผลกระทบต่อฟังก์ชันที่ถูกต้องตามกฎหมาย |   3   | D/V  |

---

## 10.9 ความปลอดภัยด้านวิวัฒนาการและการพัฒนาตนเอง

การควบคุมความปลอดภัยสำหรับระบบตัวแทนที่สามารถปรับเปลี่ยนและวิวัฒนาการด้วยตนเองได้

|   #    | Description                                                                                                                      | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.9.1 | ตรวจสอบให้แน่ใจว่าความสามารถในการแก้ไขตนเองถูกจำกัดให้อยู่ในพื้นที่ปลอดภัยที่กำหนดไว้เท่านั้นโดยมีขอบเขตการยืนยันอย่างเป็นทางการ |   1   | D/V  |
| 10.9.2 | ตรวจสอบให้แน่ใจว่าข้อเสนอการพัฒนาผ่านกระบวนการประเมินผลกระทบด้านความปลอดภัยก่อนการนำไปใช้                                        |   2   | D/V  |
| 10.9.3 | ตรวจสอบให้แน่ใจว่า กลไกการปรับปรุงตัวเองรวมถึงความสามารถในการย้อนกลับ พร้อมการตรวจสอบความสมบูรณ์ของข้อมูลด้วย                    |   2   | D/V  |
| 10.9.4 | ตรวจสอบให้แน่ใจว่าความปลอดภัยของการเรียนรู้แบบเมตาป้องกันการโจมตีโดยศัตรูต่ออัลกอริทึมการปรับปรุง                                |   3   | D/V  |
| 10.9.5 | ยืนยันว่าการปรับปรุงตนเองแบบเรียกซ้ำถูกจำกัดโดยข้อจำกัดด้านความปลอดภัยทางรูปแบบพร้อมหลักฐานทางคณิตศาสตร์ของความลู่เข้า           |   3   | D/V  |

---

### บรรณานุกรม

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

