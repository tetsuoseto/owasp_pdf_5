# การใช้ AISVS

มาตรฐานการตรวจสอบความปลอดภัยปัญญาประดิษฐ์ (AISVS) กำหนดข้อกำหนดด้านความปลอดภัยสำหรับแอปพลิเคชันและบริการ AI สมัยใหม่ โดยเน้นที่ด้านที่อยู่ในความควบคุมของนักพัฒนาแอปพลิเคชัน

AISVS มีวัตถุประสงค์สำหรับผู้ที่พัฒนาหรือประเมินความปลอดภัยของแอปพลิเคชัน AI รวมถึงนักพัฒนา สถาปนิก วิศวกรความปลอดภัย และผู้ตรวจสอบ บทนี้จะแนะนำโครงสร้างและการใช้ AISVS รวมถึงระดับการตรวจสอบและกรณีการใช้งานที่ตั้งใจไว้

## ระดับการตรวจสอบความปลอดภัยของปัญญาประดิษฐ์

AISVS กำหนดระดับการตรวจสอบความปลอดภัยขึ้นสามระดับโดยเพิ่มความลึกและความซับซ้อนในแต่ละระดับ ช่วยให้องค์กรสามารถปรับแต่งมาตรการรักษาความปลอดภัยให้สอดคล้องกับระดับความเสี่ยงของระบบปัญญาประดิษฐ์ของตนได้

องค์กรอาจเริ่มต้นที่ระดับ 1 และนำระดับที่สูงขึ้นมาใช้โดยค่อยๆ เพิ่มขึ้นเมื่อความสมบูรณ์ของความปลอดภัยและความเสี่ยงจากภัยคุกคามเพิ่มขึ้น

### คำจำกัดความของระดับต่าง ๆ

แต่ละข้อกำหนดใน AISVS v1.0 จะถูกกำหนดให้อยู่ในระดับหนึ่งของต่อไปนี้:

#### ข้อกำหนดระดับ 1

ระดับ 1 รวมข้อกำหนดด้านความปลอดภัยที่สำคัญและเป็นพื้นฐานที่สุด ซึ่งเน้นไปที่การป้องกันการโจมตีทั่วไปที่ไม่ขึ้นอยู่กับเงื่อนไขหรือช่องโหว่อื่นๆ การควบคุมส่วนใหญ่ในระดับ 1 นั้นดำเนินการได้ง่ายหรือมีความสำคัญมากพอที่ควรจะลงมือทำ

#### ข้อกำหนดระดับ 2

ระดับ 2 ครอบคลุมการโจมตีที่ซับซ้อนมากขึ้นหรือน้อยครั้งกว่า รวมถึงการป้องกันแบบหลายชั้นต่อภัยคุกคามที่แพร่หลาย ข้อกำหนดเหล่านี้อาจเกี่ยวข้องกับตรรกะที่ซับซ้อนมากขึ้นหรือมุ่งเป้าไปที่เงื่อนไขเบื้องต้นของการโจมตีเฉพาะเจาะจง

#### ข้อกำหนดระดับ 3

ระดับ 3 รวมถึงการควบคุมที่โดยทั่วไปยากต่อการนำไปใช้หรือใช้ได้ในสถานการณ์เฉพาะ ซึ่งมักเป็นกลไกการป้องกันเชิงลึกหรือการลดผลกระทบจากการโจมตีที่มีความเฉพาะเจาะจง เป้าหมาย หรือมีความซับซ้อนสูง

### บทบาท (D/V)

ความต้องการแต่ละข้อของ AISVS ถูกทำเครื่องหมายตามกลุ่มเป้าหมายหลัก:

* D – ข้อกำหนดที่มุ่งเน้นสำหรับนักพัฒนา
* วี – ข้อกำหนดที่เน้นผู้ตรวจสอบ/ผู้ตรวจสอบบัญชี
* D/V – เกี่ยวข้องกับทั้งนักพัฒนาและผู้ตรวจสอบ

