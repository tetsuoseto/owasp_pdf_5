# คำนำ

ยินดีต้อนรับสู่มาตรฐานการตรวจสอบความปลอดภัยปัญญาประดิษฐ์ (AISVS) เวอร์ชัน 1.0!

## บทนำ

ก่อตั้งขึ้นในปี 2025 ผ่านความร่วมมือของชุมชน AISVS กำหนดข้อกำหนดด้านความปลอดภัยที่ต้องพิจารณาเมื่อออกแบบ พัฒนา นำไปใช้ และดำเนินงานโมเดล AI สมัยใหม่ ท่อทางข้อมูล และบริการที่รองรับ AI

AISVS v1.0 แสดงถึงผลงานร่วมกันของผู้นำโครงการ กลุ่มทำงาน และผู้ร่วมชุมชนที่กว้างขึ้น เพื่อสร้างฐานข้อมูลที่ใช้งานได้จริงและสามารถทดสอบได้สำหรับการรักษาความปลอดภัยระบบปัญญาประดิษฐ์ (AI)

เป้าหมายของเรากับการเปิดตัวนี้คือทำให้ AISVS ง่ายต่อการนำไปใช้ ในขณะเดียวกันก็ยังมุ่งเน้นอย่างเข้มข้นในขอบเขตที่กำหนดไว้และตอบสนองต่อภูมิทัศน์ความเสี่ยงที่เปลี่ยนแปลงอย่างรวดเร็วซึ่งเป็นเอกลักษณ์เฉพาะของ AI

## วัตถุประสงค์หลักสำหรับ AISVS เวอร์ชัน 1.0

เวอร์ชัน 1.0 จะถูกสร้างขึ้นด้วยหลักการชี้นำหลายประการ

### ขอบเขตที่กำหนดไว้อย่างชัดเจน

ข้อกำหนดแต่ละข้อจะต้องสอดคล้องกับชื่อและพันธกิจของ AISVS:

* ปัญญาประดิษฐ์ – การควบคุมทำงานที่ชั้น AI/ML (ข้อมูล, แบบจำลอง, ท่อส่ง, หรือการอนุมาน) และเป็นความรับผิดชอบของผู้ปฏิบัติงานด้าน AI
* ความปลอดภัย – ข้อกำหนดจะช่วยลดความเสี่ยงด้านความปลอดภัย ความเป็นส่วนตัว หรือความปลอดภัยที่ระบุไว้โดยตรง
* การตรวจสอบ – ภาษาเขียนเพื่อให้สามารถตรวจสอบความสอดคล้องอย่างมีวัตถุประสงค์ได้
* มาตรฐาน – ส่วนต่างๆ มีโครงสร้างและคำศัพท์ที่สอดคล้องกันเพื่อสร้างเอกสารอ้างอิงที่เป็นระบบเดียวกัน
  ​
---

โดยการปฏิบัติตาม AISVS องค์กรสามารถประเมินและเสริมสร้างสถานะความปลอดภัยของโซลูชัน AI ของตนอย่างเป็นระบบ ส่งเสริมวัฒนธรรมด้านวิศวกรรม AI ที่ปลอดภัย

