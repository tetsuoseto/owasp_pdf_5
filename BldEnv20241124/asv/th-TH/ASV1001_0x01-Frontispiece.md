# ปกหน้า

## เกี่ยวกับมาตรฐาน

มาตรฐานการตรวจสอบความปลอดภัยปัญญาประดิษฐ์ (AISVS) เป็นแคตตาล็อกข้อกำหนดด้านความปลอดภัยที่ขับเคลื่อนโดยชุมชน ซึ่งนักวิทยาศาสตร์ข้อมูล, วิศวกร MLOps, สถาปนิกซอฟต์แวร์, นักพัฒนา, ผู้ทดสอบ, ผู้เชี่ยวชาญด้านความปลอดภัย, ผู้จัดจำหน่ายเครื่องมือ, หน่วยงานกำกับดูแล และผู้บริโภค สามารถใช้ในการออกแบบ สร้าง ทดสอบ และตรวจสอบระบบและแอปพลิเคชันที่เปิดใช้งานด้วย AI ที่น่าเชื่อถือ มาตรฐานนี้ให้ภาษากลางในการระบุการควบคุมความปลอดภัยตลอดวงจรชีวิตของ AI ตั้งแต่การเก็บข้อมูลและการพัฒนาแบบจำลองไปจนถึงการติดตั้งใช้งานและการเฝ้าติดตามอย่างต่อเนื่อง เพื่อให้องค์กรสามารถวัดและปรับปรุงความทนทาน ความเป็นส่วนตัว และความปลอดภัยของโซลูชัน AI ของตนได้อย่างมีประสิทธิภาพ

## ลิขสิทธิ์และใบอนุญาต

รุ่น 0.1 (ร่างสาธารณะแรก - กำลังดำเนินการ), 2025  

![license](../images/license.png)

ลิขสิทธิ์ © 2025 โครงการ AISVS  

เผยแพร่ภายใต้เงื่อนไขของ[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
สำหรับการใช้งานซ้ำหรือแจกจ่าย คุณต้องสื่อสารเงื่อนไขการอนุญาตของงานนี้ให้ผู้อื่นทราบอย่างชัดเจน

## หัวหน้าโครงการ

|            |                           |
| ---------- | ------------------------- |
| จิม มานิโก | อะราส “รัสส์” เมมิซยาอิซี |

## ผู้ร่วมเขียนและผู้ตรวจทาน

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS เป็นมาตรฐานใหม่ทั้งหมดที่สร้างขึ้นเพื่อแก้ไขความท้าทายด้านความปลอดภัยเฉพาะของระบบปัญญาประดิษฐ์ ในขณะที่ได้รับแรงบันดาลใจจากแนวปฏิบัติความปลอดภัยที่ดีที่สุดทั่วไป ทุกข้อกำหนดใน AISVS ได้รับการพัฒนาขึ้นตั้งแต่ต้นเพื่อสะท้อนภูมิทัศน์ภัยคุกคามของ AI และช่วยให้องค์กรสร้างโซลูชัน AI ที่ปลอดภัยและมีความยืดหยุ่นมากขึ้น

