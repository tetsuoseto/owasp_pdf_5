# পরিশিষ্ট A: পরিভাষা তালিকা

> এই বিস্তৃত শব্দকোষটি AISVS-এ ব্যবহৃত প্রধান AI, ML এবং সিকিউরিটি শব্দগুলির সংজ্ঞা প্রদান করে যাতে স্পষ্টতা ও সাধারণ বোঝাপড়া নিশ্চিত করা যায়।
> ​
* প্রতিপক্ষের উদাহরণ: একটি ইনপুট যা ইচ্ছাকৃতভাবে একটি AI মডেলকে ভুল করতে তৈরি করা হয়, প্রায়ই মানবদের দ্বারা অনুভূতিহীন সূক্ষ্ম পরিবর্তন যোগ করে।
  ​
* প্রতিরক্ষামূলক স্থায়িত্ব – AI-এ প্রতিরক্ষামূলক স্থায়িত্ব বলতে এমন একটি মডেলের ক্ষমতাকে বোঝায় যা তার কর্মক্ষমতা বজায় রাখতে পারে এবং ইন্দ্রিয়ের মাধ্যমে তৈরি করা হয় এমন পরিকল্পিত, ক্ষতিকর ইনপুট দ্বারা বিভ্রান্ত বা প্রতারণা প্রতিরোধ করতে সক্ষম।
  ​
* এজেন্ট – এআই এজেন্টগুলি এমন সফটওয়্যার সিস্টেম যা ব্যবহারকারীদের পক্ষ থেকে লক্ষ্য অর্জন ও কাজ সম্পন্ন করার জন্য কৃত্রিম বুদ্ধিমত্তা ব্যবহার করে। তারা যুক্তি, পরিকল্পনা এবং স্মৃতিধারণ প্রদর্শন করে এবং সিদ্ধান্ত গ্রহণ, শেখার ও মানিয়ে নেওয়ার একটি নির্দিষ্ট মাত্রার স্বায়ত্তশাসন রয়েছে।
  ​
* এজেন্টিক এআই: এমন এআই সিস্টেম যা কিছু পরিমাণ স্বায়ত্তশাসনের সঙ্গে কাজ করতে পারে লক্ষ্য অর্জনের জন্য, প্রায়ই সরাসরি মানুষের হস্তক্ষেপ ছাড়া সিদ্ধান্ত নেয় এবং পদক্ষেপ গ্রহণ করে।
  ​
* অ্যাট্রিবিউট-ভিত্তিক অ্যাক্সেস নিয়ন্ত্রণ (ABAC): একটি অ্যাক্সেস নিয়ন্ত্রণ প্যারাডাইম যেখানে অনুমোদনের সিদ্ধান্ত ব্যবহারকারী, সম্পদ, ক্রিয়া এবং পরিবেশের অ্যাট্রিবিউটের উপর ভিত্তি করে নেওয়া হয়, যা প্রশ্নের সময় মূল্যায়ন করা হয়।
  ​
* ব্যাকডোর আক্রমণ: ডেটা পয়জনিং আক্রমণের একটি ধরন যেখানে মডেলটি নির্দিষ্ট ট্রিগারগুলির প্রতি বিশেষভাবে প্রতিক্রিয়া জানাতে প্রশিক্ষিত হয়, অন্য সময় সাধারণভাবে আচরণ করে।
  ​
* পক্ষে পক্ষপাত: AI মডেলের আউটপুটে সিস্টেম্যাটিক ত্রুটি যা নির্দিষ্ট গোষ্ঠী বা নির্দিষ্ট প্রেক্ষাপটে অন্যায্য বা বৈষম্যমূলক ফলাফল আনতে পারে।
  ​
* বায়াস শোষণ: একটি আক্রমণ কৌশল যা এআই মডেলগুলিতে পরিচিত পক্ষপাতগুলির সুবিধা নিয়ে আউটপুট বা ফলাফল নিয়ন্ত্রণ করে।
  ​
* সিডার: অ্যামাজনের নীতি ভাষা এবং ইঞ্জিন যা AI সিস্টেমের জন্য ABAC বাস্তবায়নে সূক্ষ্ম-গ্রেড পারমিশনের জন্য ব্যবহৃত হয়।
  ​
* চেইন অফ থট: ভাষার মডেলগুলিতে বিচার দক্ষতা উন্নত করার একটি কৌশল, যেখানে চূড়ান্ত উত্তর প্রদানের আগে মধ্যবর্তী বিচার ধাপগুলি তৈরি করা হয়।
  ​
* সার্কিট ব্রেকার: যন্ত্রণা যা স্বয়ংক্রিয়ভাবে AI সিস্টেমের কার্যক্রম বন্ধ করে দেয় যখন নির্দিষ্ট ঝুঁকির সীমা অতিক্রম করা হয়।
  ​
* ডেটা লিকেজ: AI মডেলের আউটপুট বা আচরণের মাধ্যমে সংবেদনশীল তথ্যের অনিচ্ছাকৃত প্রকাশ।
  ​
* ডেটা পয়জনিং: মডেলের অখণ্ডতা ক্ষুণ্ন করার উদ্দেশ্যে প্রশিক্ষণ ডেটা ইচ্ছাকৃতভাবে দুর্নীতিগ্রস্ত করা, প্রায়শই ব্যাকডোর ইনস্টল করা বা কর্মক্ষমতা হ্রাস করার জন্য।
  ​
* ডিফারেনশিয়াল প্রাইভেসি – ডিফারেনশিয়াল প্রাইভেসি হল একটি গাণিতিকভাবে কঠোর কাঠামো যা ডেটাসেট সম্পর্কিত পরিসংখ্যানমূলক তথ্য প্রকাশের সময় ব্যক্তিগত তথ্য বিষয়দের গোপনীয়তা রক্ষা করে। এটি একটি ডেটা রাখার সংস্থাকে গোষ্ঠীর সামগ্রিক প্যাটার্ন শেয়ার করার অনুমতি দেয়, পাশাপাশি নির্দিষ্ট ব্যক্তিদের সম্পর্কে ফাঁস হওয়া তথ্য সীমাবদ্ধ করে।
  ​
* এম্বেডিংস: ডেটার (টেক্সট, ছবি, ইত্যাদি) ঘন ভেক্টর উপস্থাপনা যা উচ্চ-মাত্রিক স্থানেএ সেমান্টিক অর্থ ধারণ করে।
  ​
* ব্যাখ্যাযোগ্যতা – কৃত্রিম বুদ্ধিমত্তায় ব্যাখ্যাযোগ্যতা হলো এমন একটি ক্ষমতা যা একটি এআই সিস্টেমকে তার সিদ্ধান্ত এবং পূর্বাভাসের জন্য মানুষের বোঝার উপযোগী কারণ প্রদান করতে সক্ষম করে, যা তার অভ্যন্তরীণ কার্যপ্রণালী সম্পর্কে অন্তর্দৃষ্টি দেয়।
  ​
* ব্যাখ্যাযোগ্য এআই (XAI): এমন এআই সিস্টেম যা তাদের সিদ্ধান্ত এবং আচরণের জন্য মানুষের বোঝার মতো ব্যাখ্যা প্রদান করতে বিভিন্ন প্রযুক্তি এবং কাঠামোর মাধ্যমে ডিজাইন করা হয়েছে।
  ​
* ফেডারেটেড লার্নিং: একটি মেশিন লার্নিং পদ্ধতি যেখানে মডেলগুলি একাধিক বিকেন্দ্রীকৃত ডিভাইসে প্রশিক্ষিত হয়, যা স্থানীয় ডেটা নমুনা ধারণ করে, ডেটা নিজেই বিনিময় না করে।
  ​
* গার্ডরেলস: এমন নিষেধাজ্ঞা বা সীমাবদ্ধতা যা কৃত্রিম বুদ্ধিমত্তা (এআই) সিস্টেমগুলোকে ক্ষতিকারক, পক্ষপাতমূলক বা অন্যান্য অনাকাংক্ষিত আউটপুট তৈরি করা থেকে বিরত রাখতে ব্যবহার করা হয়।
  ​
* হ্যালুসিনেশন – একটি এআই হ্যালুসিনেশন এমন একটি ঘটনা বোঝায় যেখানে একটি এআই মডেল তার প্রশিক্ষণ ডেটা বা বাস্তব তথ্যের ভিত্তিতে নয় এমন ভুল বা বিভ্রান্তিকর তথ্য তৈরি করে।
  ​
* মানব-ইন-দ্য-লুপ (HITL): এমন সিস্টেমগুলি যা গুরুত্বপূর্ণ সিদ্ধান্ত গ্রহণের সময়ে মানব তত্ত্বাবধান, যাচাই, বা হস্তক্ষেপ প্রয়োজন এমনভাবে ডিজাইন করা হয়েছে।
  ​
* ইনফ্রাস্ট্রাকচার অ্যাজ কোড (IaC): ম্যানুয়াল প্রক্রিয়ার পরিবর্তে কোডের মাধ্যমে ইনফ্রাস্ট্রাকচার পরিচালনা এবং প্রভিশনিং, যা সিকিউরিটি স্ক্যানিং এবং সঙ্গতিপূর্ণ ডিপ্লয়মেন্ট সক্ষম করে।
  ​
* জেলব্রেক: কৌশল যা AI সিস্টেমগুলিতে, বিশেষ করে বড় ভাষার মডেলগুলিতে, নিরাপত্তা রক্ষা ব্যবস্থাগুলো অতিক্রম করার জন্য ব্যবহৃত হয়, যাতে নিষিদ্ধ বিষয়বস্তু তৈরি করা যায়।
  ​
* সর্বনিম্ন বিশেষাধিকার: ব্যবহারকারী এবং প্রক্রিয়াগুলির জন্য শুধুমাত্র সর্বনিম্ন প্রয়োজনীয় অ্যাক্সেস অধিকার প্রদান করার নিরাপত্তা নীতি।
  ​
* LIME (লোকাল ইন্টারপ্রেটেবল মডেল-এগনিস্টিক এক্সপ্লানেশন): যেকোনো মেশিন লার্নিং ক্লাসিফায়ারের পূর্বাভাস ব্যাখ্যা করার একটি কৌশল যা স্থানীয়ভাবে একটি ব্যাখ্যাযোগ্য মডেল দিয়ে এটিকে আনুমানিক করে।
  ​
* সদস্যতা অনুমান আক্রমণ: একটি আক্রমণ যা নির্ধারণ করার উদ্দেশ্যে যে একটি নির্দিষ্ট তথ্য বিন্দু মেশিন লার্নিং মডেল প্রশিক্ষণের জন্য ব্যবহৃত হয়েছে কিনা।
  ​
* MITRE ATLAS: কৃত্রিম বুদ্ধিমত্তা সিস্টেমের জন্য শত্রুত্বপূর্ণ হুমকি পরিমণ্ডল; AI সিস্টেমের বিরুদ্ধে শত্রুতাপূর্ণ কৌশল এবং প্রযুক্তির একটি জ্ঞানভিত্তিক ডাটাবেস।
  ​
* মডেল কার্ড – একটি মডেল কার্ড একটি ডকুমেন্ট যা একটি AI মডেলের পারফরম্যান্স, সীমাবদ্ধতা, উদ্দেশ্যকৃত ব্যবহার এবং নৈতিক বিবেচনা সম্পর্কিত মানক তথ্য প্রদান করে, যা স্বচ্ছতা এবং দায়িত্বশীল AI উন্নয়নকে উৎসাহিত করে।
  ​
* মডেল নিষ্কাশন: একটি আক্রমণ যেখানে একটি প্রতিপক্ষ অনুমোদন ছাড়াই লক্ষ্যমাত্রা মডেলটিকে বারবার প্রশ্ন করে কার্যকরভাবে সমান একটি অনুলিপি তৈরি করে।
  ​
* মডেল ইনভার্শন: একটি আক্রমণ যা মডেল আউটপুট বিশ্লেষণ করে প্রশিক্ষণ ডেটা পুনর্গঠন করার চেষ্টা করে।
  ​
* মডেল জীবনচক্র ব্যবস্থাপনা – এআই মডেল জীবনচক্র ব্যবস্থাপনা হলো একটি এআই মডেলের প্রতিটি পর্যায়ের তত্ত্বাবধানের প্রক্রিয়া, যার মধ্যে রয়েছে এর ডিজাইন, উন্নয়ন, প্রবর্তন, পর্যবেক্ষণ, রক্ষণাবেক্ষণ এবং চূড়ান্ত অবসর, যাতে এটি কার্যকর এবং উদ্দেশ্যের সাথে সঙ্গতিপূর্ণ থাকে।
  ​
* মডেল পয়জনিং: প্রশিক্ষণ প্রক্রিয়ার সময় সরাসরি একটি মডেলে দুর্বলতা বা ব্যাকডোর সংযোজন।
  ​
* মডেল চুরি/গোপনীয়তা লঙ্ঘন: পুনরাবৃত্তি প্রশ্নের মাধ্যমে একটি মালিকানা মডেলের একটি নকল বা সন্নিকট অনুকরণ তৈরি করা।
  ​
* মাল্টি-এজেন্ট সিস্টেম: একটি সিস্টেম যা একাধিক ইন্টারঅ্যাক্টিভ AI এজেন্ট দ্বারা গঠিত, প্রতিটির ভিন্ন ক্ষমতা এবং লক্ষ্য থাকতে পারে।
  ​
* OPA (ওপেন পলিসি এজেন্ট): একটি ওপেন সোর্স পলিসি ইঞ্জিন যা স্ট্যাক জুড়ে ঐক্যবদ্ধ পলিসি প্রয়োগ সক্ষম করে।
  ​
* গোপনীয়তা সংরক্ষণকারী মেশিন লার্নিং (PPML): প্রশিক্ষণ ডেটার গোপনীয়তা সংরক্ষণ করে এমএল মডেলগুলি প্রশিক্ষণ ও বাস্তবায়নের কৌশল এবং পদ্ধতিসমূহ।
  ​
* প্রম্পট ইনজেকশন: একটি আক্রমণ যেখানে ক্ষতিকর নির্দেশাবলী ইনপুটে সংযুক্ত করা হয় মডেলের উদ্দেশ্যমূলক আচরণকে ওভাররাইড করার জন্য।
  ​
* RAG (রিট্রিভাল-অগমেন্টেড জেনারেশন): একটি কৌশল যা বড় ভাষার মডেলগুলিকে উন্নত করে প্রাসঙ্গিক তথ্য বাহ্যিক জ্ঞান উৎস থেকে পুনরুদ্ধার করে উত্তর তৈরি করার আগে।
  ​
* রেড-টিমিং: AI সিস্টেমগুলিকে সক্রিয়ভাবে পরীক্ষা করার অনুশীলন যা বিরোধী আক্রমণের অনুকরণ করে দুর্বলতা সনাক্ত করে।
  ​
* SBOM (সফটওয়্যার বিল অফ ম্যাটেরিয়ালস): সফটওয়্যার বা এআই মডেল তৈরি করার জন্য ব্যবহৃত বিভিন্ন উপাদানের বিবরণ এবং সাপ্লাই চেইন সম্পর্কসমূহ অন্তর্ভুক্ত একটি আনুষ্ঠানিক রেকর্ড।
  ​
* SHAP (শ্যাপলি অ্যাডিটিভ এক্সপ্লানেশন): যেকোনো মেশিন লার্নিং মডেলের আউটপুট ব্যাখ্যার জন্য একটি গেম থিওরেটিক পদ্ধতি যা প্রত্যেক বৈশিষ্ট্যের পূর্বাভাসে অবদানের পরিমাণ হিসাব করে।
  ​
* সরবরাহ চেইন আক্রমণ: সিস্টেমের সরবরাহ চেইনের কম সুরক্ষিত উপাদানগুলোতে লক্ষ্য করে, যেমন তৃতীয়- পক্ষের লাইব্রেরি, ডেটাসেট, বা পূর্ব-প্রশিক্ষিত মডেল, সিস্টেমকে অননুমোদিতভাবে প্রবেশ করানো।
  ​
* ট্রান্সফার লার্নিং: একটি পদ্ধতি যেখানে একটি মডেল যা একটি কাজের জন্য তৈরি করা হয়েছে, সেটি দ্বিতীয় কাজের জন্য মডেলের শুরুর বিন্দু হিসেবে পুনর্ব্যবহার করা হয়।
  ​
* ভেক্টর ডাটাবেস: একটি বিশেষায়িত ডাটাবেস যা উচ্চ-মাত্রিক ভেক্টর (এম্বেডিং) সংরক্ষণ করতে এবং দক্ষ মিল অনুসন্ধান সম্পাদন করতে ডিজাইন করা হয়েছে।
  ​
* অ্যাপ্লিকেশন দুর্বলতা স্ক্যানিং: স্বয়ংক্রিয় টুলগুলি যা সফ্টওয়্যার কম্পোনেন্ট, যার মধ্যে AI ফ্রেমওয়ার্ক এবং নির্ভরশীলতাগুলির পরিচিত নিরাপত্তা দুর্বলতাগুলি সনাক্ত করে।
  ​
* ওয়াটারমার্কিং: AI-উৎপাদিত সামগ্রীতে অদৃশ্য চিহ্ন এমবেড করার কৌশল যা এর উৎস ট্র্যাক করতে বা AI উৎপত্তি সনাক্ত করতে ব্যবহৃত হয়।
  ​
* জিরো-ডে দুর্বলতা: একটি পূর্বে অজানা দুর্বলতা যা আক্রমণকারীরা প্যাচ তৈরি এবং প্রয়োগ করার আগে শোষণ করতে পারে।

