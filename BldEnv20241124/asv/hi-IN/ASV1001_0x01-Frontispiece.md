# मुखपृष्ठ

## मानक के बारे में

कृत्रिम बुद्धिमत्ता सुरक्षा सत्यापन मानक (AISVS) एक समुदाय-संचालित सुरक्षा आवश्यकताओं की सूची है जिसका उपयोग डेटा वैज्ञानिक, MLOps इंजीनियर, सॉफ़्टवेयर आर्किटेक्ट, डेवलपर्स, परीक्षक, सुरक्षा विशेषज्ञ, टूल विक्रेता, नियामक, और उपभोक्ता विश्वसनीय AI-संचालित प्रणालियों और अनुप्रयोगों को डिजाइन, निर्माण, परीक्षण, और सत्यापित करने के लिए कर सकते हैं। यह AI जीवनचक्र के दौरान सुरक्षा नियंत्रणों को निर्दिष्ट करने के लिए एक सामान्य भाषा प्रदान करता है—डेटा संग्रह और मॉडल विकास से लेकर तैनाती और निरंतर निगरानी तक—ताकि संगठन अपनी AI समाधानों की लचीलापन, गोपनीयता, और सुरक्षा को माप सकें और सुधार सकें।

## कॉपीराइट और लाइसेंस

संस्करण 0.1 (प्रथम सार्वजनिक ड्राफ्ट - कार्य प्रगति पर), 2025  

![license](../images/license.png)

कॉपीराइट © 2025 द AISVS प्रोजेक्ट।  

के तहत जारी किया गया[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
किसी भी पुनः उपयोग या वितरण के लिए, आपको इस कार्य के लाइसेंस शर्तों को स्पष्ट रूप से दूसरों तक संप्रेषित करना होगा।

## परियोजना प्रमुख

|            |                        |
| ---------- | ---------------------- |
| जिम मैनिको | अरास "रस" मेमिस्याजिची |

## योगदानकर्ता और समीक्षक

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS एक बिल्कुल नया मानक है जो विशेष रूप से कृत्रिम बुद्धिमत्ता प्रणालियों की अद्वितीय सुरक्षा चुनौतियों को संबोधित करने के लिए बनाया गया है। जब कि यह व्यापक सुरक्षा सर्वोत्तम प्रथाओं से प्रेरणा लेता है, AISVS में हर एक आवश्यकताल AI खतरा परिदृश्य को प्रतिबिंबित करने और संगठनों को अधिक सुरक्षित, अधिक मजबूत AI समाधान बनाने में सहायता करने के लिए आधार से विकसित की गई है।

