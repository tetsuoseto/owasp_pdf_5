# C13 मानव निगरानी, उत्तरदायित्व और शासन

## नियंत्रण उद्देश्य

यह अध्याय AI प्रणालियों में मानव निरीक्षण और स्पष्ट उत्तरदायित्व श्रृंखलाओं को बनाए रखने के लिए आवश्यकताओं को प्रदान करता है, जो AI जीवनचक्र के दौरान व्याख्यात्मकता, पारदर्शिता और नैतिक प्रबंधन सुनिश्चित करता है।

---

## C13.1 किल-स्विच और अधिलेखित तंत्र

जब AI सिस्टम के असुरक्षित व्यवहार का पता चले तो शटडाउन या रोलबैक पथ प्रदान करें।

|   #    | Description                                                                                                  | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 13.1.1 | पुष्टि करें कि एक मैनुअल किल-स्वीच तंत्र मौजूद है जो तुरंत AI मॉडल की अनुमान प्रक्रिया और आउटपुट को रोक सके। |   1   | D/V  |
| 13.1.2 | सुनिश्चित करें कि ओवरराइड नियंत्रण केवल अधिकृत कर्मियों के लिए सुलभ हों।                                     |   1   |  D   |
| 13.1.3 | सत्यापित करें कि रोलबैक प्रक्रियाएं पिछली मॉडल संस्करणों या सुरक्षित-मोड ऑपरेशनों पर वापस जा सकती हैं।       |   3   | D/V  |
| 13.1.4 | सुनिश्चित करें कि ओवरराइड तंत्र नियमित रूप से परीक्षण किए जाते हैं।                                          |   3   |  V   |

---

## C13.2 ह्यूमन-इन-द-लूप निर्णय जांच बिंदु

जब जोखिम पूर्वनिर्धारित सीमा से अधिक हो तो मानव अनुमोदन आवश्यक करें।

|   #    | Description                                                                                                                                     | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.2.1 | सुनिश्चित करें कि उच्च-जोखिम वाली AI निर्णयों को क्रियान्वयन से पहले स्पष्ट मानव अनुमोदन की आवश्यकता हो।                                        |   1   | D/V  |
| 13.2.2 | सुनिश्चित करें कि जोखिम स्तर स्पष्ट रूप से परिभाषित हैं और स्वचालित रूप से मानव समीक्षा कार्यप्रवाह चालू करते हैं।                              |   1   |  D   |
| 13.2.3 | सत्यापित करें कि समय-सम्बंधित निर्णयों के लिए वैकल्पिक प्रक्रियाएं मौजूद हैं जब आवश्यक समय सीमा के भीतर मानव अनुमोदन प्राप्त नहीं किया जा सकता। |   2   |  D   |
| 13.2.4 | पुष्टि करें कि वृद्धि प्रक्रिया विभिन्न निर्णय प्रकारों या जोखिम श्रेणियों के लिए स्पष्ट अधिकार स्तर निर्दिष्ट करती है, यदि लागू हो।            |   3   | D/V  |

---

## C13.3 जिम्मेदारी की श्रृंखला और लेखा परीक्षा योग्यता

ऑपरेटर क्रियाओं और मॉडल निर्णयों का लॉग रखें।

|   #    | Description                                                                                                                      | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.3.1 | सुनिश्चित करें कि सभी एआई सिस्टम के निर्णय और मानव हस्तक्षेप समय-सीमा, उपयोगकर्ता पहचान और निर्णय के कारण के साथ लॉग किए गए हैं। |   1   | D/V  |
| 13.3.2 | पुष्टि करें कि ऑडिट लॉग्स को छेड़ा नहीं जा सकता है और उनमें अखंडता सत्यापन तंत्र शामिल हैं।                                      |   2   |  D   |

---

## C13.4 व्याख्यायोग्य-एआई तकनीकें

सतही फीचर महत्व, प्रतिलोम तथ्य, और स्थानीय व्याख्याएं।

|   #    | Description                                                                                                                                                             | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.4.1 | सुनिश्चित करें कि एआई सिस्टम अपने निर्णयों के लिए मानवीय पठनीय प्रारूप में मूलभूत स्पष्टीकरण प्रदान करते हैं।                                                           |   1   | D/V  |
| 13.4.2 | पुष्टि करें कि व्याख्या की गुणवत्ता मानव मूल्यांकन अध्ययन और मेट्रिक्स के माध्यम से सत्यापित की गई है।                                                                  |   2   |  V   |
| 13.4.3 | सुनिश्चित करें कि महत्वपूर्ण निर्णयों के लिए फीचर महत्व स्कोर या अट्रीब्यूशन मेथड्स (SHAP, LIME, आदि) उपलब्ध हों।                                                       |   3   | D/V  |
| 13.4.4 | सत्यापित करें कि काउंटरफैक्चुअल व्याख्याएं दिखाती हैं कि इनपुट्स को कैसे संशोधित किया जा सकता है ताकि परिणामों को बदला जा सके, यदि उपयोग के मामले और डोमेन में लागू हो। |   3   |  V   |

---

## C13.5 मॉडल कार्ड और उपयोग प्रकटीकरण

इच्छित उपयोग, प्रदर्शन मीट्रिक, और नैतिक विचारों के लिए मॉडल कार्ड बनाए रखें।

|   #    | Description                                                                                                                                                                         | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.5.1 | सत्यापित करें कि मॉडल कार्ड्स में लक्षित उपयोग मामलों, सीमाओं, और ज्ञात विफलता मोड्स का दस्तावेजीकरण किया गया है।                                                                   |   1   |  D   |
| 13.5.2 | सुनिश्चित करें कि विभिन्न लागू उपयोग मामलों में प्रदर्शन मेट्रिक्स का प्रकटीकरण किया गया हो।                                                                                        |   1   | D/V  |
| 13.5.3 | सुनिश्चित करें कि नैतिक विचार, पक्षपात आकलन, निष्पक्षता मूल्यांकन, प्रशिक्षण डेटा की विशेषताएं, और ज्ञात प्रशिक्षण डेटा की सीमाएँ दस्तावेजीकृत हों और नियमित रूप से अपडेट किए जाएं। |   2   |  D   |
| 13.5.4 | सुनिश्चित करें कि मॉडल कार्ड संस्करण-नियंत्रित हों और मॉडल जीवनचक्र के दौरान परिवर्तन ट्रैकिंग के साथ बनाए रखे जाएं।                                                                |   2   | D/V  |

---

## C13.6 अनिश्चितता मात्राङ्कन

प्रतिक्रियाओं में आत्मविश्वास स्कोर या एंट्रॉपी मापन को प्रसारित करें।

|   #    | Description                                                                                                   | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.6.1 | सुनिश्चित करें कि एआई सिस्टम अपनी आउटपुट के साथ विश्वास स्कोर या अनिश्चितता माप प्रदान करते हैं।              |   1   |  D   |
| 13.6.2 | सुनिश्चित करें कि अनिश्चितता सीमा अतिरिक्त मानवीय समीक्षा या वैकल्पिक निर्णय मार्गों को सक्रिय करती है।       |   2   | D/V  |
| 13.6.3 | सुनिश्चित करें कि अनिश्चितता मात्रांकन विधियाँ ग्राउंड ट्रूथ डेटा के आधार पर कैलिब्रेट और सत्यापित की गई हैं। |   2   |  V   |
| 13.6.4 | पता लगाएं कि असमर्थता संचरण कई-चरण AI वर्कफ़्लोज़ के माध्यम से बनाए रखा गया है।                               |   3   | D/V  |

---

## C13.7 उपयोगकर्ता-सामना पारदर्शिता रिपोर्ट्स

घटनाओं, ड्रीफ़्ट और डेटा उपयोग पर आवधिक प्रकटीकरण प्रदान करें।

|   #    | Description                                                                                                                                  | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.7.1 | सुनिश्चित करें कि डेटा उपयोग नीतियाँ और उपयोगकर्ता सहमति प्रबंधन प्रथाएँ हितधारकों को स्पष्ट रूप से संप्रेषित की गई हैं।                     |   1   | D/V  |
| 13.7.2 | सुनिश्चित करें कि एआई प्रभाव मूल्यांकन किए गए हैं और परिणाम रिपोर्टिंग में शामिल हैं।                                                        |   2   | D/V  |
| 13.7.3 | सुनिश्चित करें कि नियमित रूप से प्रकाशित पारदर्शिता रिपोर्टों में AI घटनाओं और संचालन संबंधी मेट्रिक्स को उचित विस्तार से प्रकट किया गया हो। |   2   | D/V  |

### सन्दर्भ

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX%3A32016R0679)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

