# Préface

Bienvenue dans la norme de vérification de la sécurité de l'intelligence artificielle (AISVS) version 1.0 !

## Introduction

Créée en 2025 grâce à un effort collaboratif de la communauté, AISVS définit les exigences de sécurité à prendre en compte lors de la conception, du développement, du déploiement et de l’exploitation des modèles d’IA modernes, des pipelines et des services activés par l’IA.

AISVS v1.0 représente le travail combiné de ses chefs de projet, du groupe de travail et des contributeurs de la communauté élargie pour produire une base pragmatique et testable pour sécuriser les systèmes d'IA.

Notre objectif avec cette version est de rendre AISVS facile à adopter tout en restant strictement concentré sur son périmètre défini et en répondant au paysage de risques en rapide évolution, propre à l'IA.

## Objectifs clés pour AISVS Version 1.0

La version 1.0 sera créée selon plusieurs principes directeurs.

### Portée bien définie

Chaque exigence doit être conforme au nom et à la mission d’AISVS :

* Intelligence artificielle – Les contrôles fonctionnent au niveau de la couche IA/ML (données, modèle, pipeline ou inférence) et sont de la responsabilité des praticiens de l'IA.
* Sécurité – Les exigences atténuent directement les risques identifiés en matière de sécurité, de confidentialité ou de sécurité.
* Vérification – Le langage est rédigé de manière à ce que la conformité puisse être validée objectivement.
* Norme – Les sections suivent une structure et une terminologie cohérentes pour former une référence uniforme.
  ​
---

En suivant AISVS, les organisations peuvent évaluer systématiquement et renforcer la posture de sécurité de leurs solutions d'IA, favorisant ainsi une culture d'ingénierie de l'IA sécurisée.

