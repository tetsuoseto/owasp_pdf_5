# Įžanga

Sveiki atvykę į dirbtinio intelekto saugumo patvirtinimo standartą (AISVS) 1.0 versija!

## Įvadas

AISVS, įkurta 2025 m. bendruomenės bendradarbiavimo pastangomis, apibrėžia saugumo reikalavimus, kuriuos reikia atsižvelgti projektuojant, kuriant, diegiant ir valdant modernius dirbtinio intelekto modelius, srautus ir dirbtiniu intelektu pagrįstas paslaugas.

AISVS v1.0 atspindi savo projekto vadovų, darbo grupės ir plačiosios bendruomenės narių bendrą darbą, siekiant sukurti pragmatišką, išbandomą AI sistemų saugumo pagrindą.

Mūsų tikslas su šiuo leidimu yra padaryti AISVS paprastą priimti, tuo pačiu išlaikant griežtą dėmesį jos apibrėžtam veikimo srities ribojimui ir sprendžiant sparčiai kintančią unikalią AI rizikos aplinką.

## Pagrindiniai AISVS 1.0 versijos tikslai

1.0 versija bus sukurta remiantis keliais pagrindiniais principais.

### Aiškiai apibrėžtas taikymo sritis

Kiekviena reikalavimas turi atitikti AISVS pavadinimą ir misiją:

* Dirbtinis intelektas – valdikliai veikia AI/ML sluoksnyje (duomenys, modelis, duomenų apdorojimo grandinė arba išvedimas) ir yra AI specialistų atsakomybė.
* Sauga – Reikalavimai tiesiogiai mažina nustatytas saugumo, privatumo ar saugos rizikas.
* Verifikavimas – kalba parašyta taip, kad atitiktis būtų galima objektyviai patikrinti.
* Standartas – skyriai laikosi nuoseklios struktūros ir terminologijos, kad sudarytų nuoseklią nuorodą.
  ​
---

Laikydamosi AISVS, organizacijos gali sistemingai įvertinti ir sustiprinti savo DI sprendimų saugumo lygį, skatinant saugios DI inžinerijos kultūrą.

