# Seguridad en la Cadena de Suministro para Modelos, Frameworks y Datos

## Objetivo de Control

Los ataques a la cadena de suministro de IA explotan modelos, frameworks o conjuntos de datos de terceros para incrustar puertas traseras, sesgos o código explotable. Estos controles proporcionan trazabilidad de principio a fin, gestión de vulnerabilidades y monitoreo para proteger todo el ciclo de vida del modelo.

---

## C6.1 Evaluación y Procedencia del Modelo Preentrenado

Evalúe y autentique los orígenes, licencias y comportamientos ocultos de modelos de terceros antes de cualquier ajuste fino o despliegue.

|   #   | Description                                                                                                                                                                   | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.1.1 | Verifique que cada artefacto de modelo de terceros incluya un registro de procedencia firmado que identifique el repositorio fuente y el hash del commit.                     |   1   | D/V  |
| 6.1.2 | Verifique que los modelos sean escaneados en busca de capas maliciosas o activadores tipo troyano utilizando herramientas automatizadas antes de la importación.              |   1   | D/V  |
| 6.1.3 | Verifique que el aprendizaje por transferencia ajustado pase la evaluación adversarial para detectar comportamientos ocultos.                                                 |   2   |  D   |
| 6.1.4 | Verifique que las licencias del modelo, las etiquetas de control de exportación y las declaraciones de origen de datos estén registradas en una entrada de ML-BOM.            |   2   |  V   |
| 6.1.5 | Verifique que los modelos de alto riesgo (pesos subidos públicamente, creadores no verificados) permanezcan en cuarentena hasta que sean revisados y aprobados por un humano. |   3   | D/V  |

---

## C6.2 Escaneo de Frameworks y Bibliotecas

Escanee continuamente los marcos y bibliotecas de aprendizaje automático (ML) para detectar CVEs y código malicioso y mantener segura la pila de ejecución.

|   #   | Description                                                                                                                                                    | Level | Role |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.2.1 | Verifique que las canalizaciones de integración continua ejecuten escáneres de dependencias en los marcos de IA y las bibliotecas críticas.                    |   1   | D/V  |
| 6.2.2 | Verifique que las vulnerabilidades críticas (CVSS ≥ 7.0) bloqueen la promoción a imágenes de producción.                                                       |   1   | D/V  |
| 6.2.3 | Verifique que el análisis estático de código se ejecute en bibliotecas de aprendizaje automático bifurcadas o empaquetadas.                                    |   2   |  D   |
| 6.2.4 | Verifique que las propuestas de actualización del framework incluyan una evaluación del impacto en la seguridad que haga referencia a fuentes públicas de CVE. |   2   |  V   |
| 6.2.5 | Verifique que los sensores en tiempo de ejecución alerten sobre cargas inesperadas de bibliotecas dinámicas que se desvíen del SBOM firmado.                   |   3   |  V   |

---

## C6.3 Fijación y Verificación de Dependencias

Fije cada dependencia a sumas inmutables y reproduzca las compilaciones para garantizar artefactos idénticos y libres de manipulaciones.

|   #   | Description                                                                                                                                  | Level | Role |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.3.1 | Verifique que todos los gestores de paquetes apliquen la fijación de versiones mediante archivos de bloqueo.                                 |   1   | D/V  |
| 6.3.2 | Verifique que se usen resúmenes inmutables en lugar de etiquetas mutables en las referencias de contenedores.                                |   1   | D/V  |
| 6.3.3 | Verifique que las comprobaciones de compilaciones reproducibles comparen los hashes entre ejecuciones de CI para asegurar salidas idénticas. |   2   |  D   |
| 6.3.4 | Verifique que las atestaciones de compilación se almacenen durante 18 meses para la trazabilidad de auditoría.                               |   2   |  V   |
| 6.3.5 | Verifique que las dependencias expiradas desencadenen solicitudes de extracción automatizadas para actualizar o bifurcar versiones fijadas.  |   3   |  D   |

---

## C6.4 Aplicación de Fuentes Confiables

Permitir descargas de artefactos solo desde fuentes aprobadas por la organización y verificadas criptográficamente, y bloquear todo lo demás.

|   #   | Description                                                                                                                                           | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.4.1 | Verifique que los pesos del modelo, los conjuntos de datos y los contenedores se descarguen únicamente de dominios aprobados o registros internos.    |   1   | D/V  |
| 6.4.2 | Verifique que las firmas de Sigstore/Cosign validen la identidad del editor antes de que los artefactos se almacenen en caché localmente.             |   1   | D/V  |
| 6.4.3 | Verifique que los proxies de salida bloqueen las descargas de artefactos no autenticadas para hacer cumplir la política de fuentes confiables.        |   2   |  D   |
| 6.4.4 | Verifique que las listas blancas del repositorio se revisen trimestralmente con evidencia de justificación comercial para cada entrada.               |   2   |  V   |
| 6.4.5 | Verifique que las violaciones de políticas desencadenen la cuarentena de artefactos y la reversión de las ejecuciones de canalizaciones dependientes. |   3   |  V   |

---

## C6.5 Evaluación de Riesgos de Conjuntos de Datos de Terceros

Evaluar los conjuntos de datos externos en busca de envenenamiento, sesgo y cumplimiento legal, y supervisarlos durante todo su ciclo de vida.

|   #   | Description                                                                                                                                                                         | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.5.1 | Verifique que los conjuntos de datos externos sean sometidos a una puntuación de riesgo de envenenamiento (por ejemplo, huellas digitales de datos, detección de valores atípicos). |   1   | D/V  |
| 6.5.2 | Verifique que las métricas de sesgo (paridad demográfica, igualdad de oportunidades) se calculen antes de la aprobación del conjunto de datos.                                      |   1   |  D   |
| 6.5.3 | Verifique que la procedencia y los términos de licencia de los conjuntos de datos estén registrados en las entradas del ML‑BOM.                                                     |   2   |  V   |
| 6.5.4 | Verifique que la supervisión periódica detecte desviaciones o corrupción en los conjuntos de datos alojados.                                                                        |   2   |  V   |
| 6.5.5 | Verifique que el contenido no permitido (derechos de autor, información personal identificable) sea eliminado mediante un proceso automático de depuración antes del entrenamiento. |   3   |  D   |

---

## C6.6 Monitoreo de Ataques a la Cadena de Suministro

Detecte amenazas en la cadena de suministro temprano mediante fuentes CVE, análisis de registros de auditoría y simulaciones de equipos rojos.

|   #   | Description                                                                                                                                                                   | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.6.1 | Verifique que los registros de auditoría de CI/CD se transmitan a SIEM para detectar extracciones de paquetes anómalas o pasos de compilación manipulados.                    |   1   |  V   |
| 6.6.2 | Verifique que los manuales de respuesta a incidentes incluyan procedimientos de reversión para modelos o bibliotecas comprometidos.                                           |   2   |  D   |
| 6.6.3 | Verifique que el enriquecimiento de inteligencia de amenazas etiquete indicadores específicos de ML (por ejemplo, IoCs de envenenamiento de modelos) en la triaje de alertas. |   3   |  V   |

---

## C6.7 ML‑BOM para Artefactos de Modelo

Genere y firme SBOMs específicos para ML detallados (ML-BOMs) para que los consumidores posteriores puedan verificar la integridad de los componentes en el momento del despliegue.

|   #   | Description                                                                                                                                              | Level | Role |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.7.1 | Verifique que cada artefacto de modelo publique un ML-BOM que liste conjuntos de datos, pesos, hiperparámetros y licencias.                              |   1   | D/V  |
| 6.7.2 | Verifique que la generación de ML-BOM y la firma con Cosign estén automatizadas en CI y sean obligatorias para la fusión.                                |   1   | D/V  |
| 6.7.3 | Verifique que las comprobaciones de integridad de ML-BOM fallen la compilación si falta algún metadato del componente (hash, licencia).                  |   2   |  D   |
| 6.7.4 | Verifique que los consumidores posteriores puedan consultar ML-BOMs a través de la API para validar los modelos importados en el momento del despliegue. |   2   |  V   |
| 6.7.5 | Verifique que las ML-BOMs estén controladas por versiones y se comparen para detectar modificaciones no autorizadas.                                     |   3   |  V   |

---

## Referencias

* [ML Supply Chain Compromise – MITRE ATLAS](https://misp-galaxy.org/mitre-atlas-attack-pattern/)
* [Supply‑chain Levels for Software Artifacts (SLSA)](https://slsa.dev/)
* [CycloneDX – Machine Learning Bill of Materials](https://cyclonedx.org/capabilities/mlbom/)
* [What is Data Poisoning? – SentinelOne](https://www.sentinelone.com/cybersecurity-101/cybersecurity/data-poisoning/)
* [Transfer Learning Attack – OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML07_2023-Transfer_Learning_Attack)
* [AI Data Security Best Practices – CISA](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [Secure CI/CD Supply Chain – Sumo Logic](https://www.sumologic.com/blog/secure-azure-devops-github-supply-chain-attacks)
* [AI & Transparency: Protect ML Models – ReversingLabs](https://www.reversinglabs.com/blog/ai-and-transparency-how-ml-model-creators-can-protect-against-supply-chain-attacks)
* [SBOM Overview – CISA](https://www.cisa.gov/sbom)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [Dependency Pinning for Reproducible Python – Medium](https://medium.com/data-science-collective/guarantee-a-locked-reproducible-environment-with-every-python-run-c0e2bf19fb53)

