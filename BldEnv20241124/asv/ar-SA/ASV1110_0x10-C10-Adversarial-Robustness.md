# 10 المتانة العدائية ودفاع الخصوصية

## هدف التحكم

ضمان بقاء نماذج الذكاء الاصطناعي موثوقة، محافظة على الخصوصية، ومقاومة للاستخدام السيء عند مواجهة هجمات التهرب، الاستنتاج، الاستخراج، أو التسميم.

---

## 10.1 محاذاة النموذج والسلامة

الحماية من المخرجات الضارة أو التي تنتهك السياسات.

|   #    | Description                                                                                                                                                    | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.1.1 | تحقق من أن مجموعة اختبار المحاذاة (مطالبات الفريق الأحمر، فحوصات كسر الحماية، المحتوى غير المسموح به) تخضع للتحكم في الإصدارات وتُجرى على كل إصدار من النماذج. |   1   | D/V  |
| 10.1.2 | التحقق من تطبيق ضوابط الرفض وإنهاء الأمان بشكل صارم.                                                                                                           |   1   |  D   |
| 10.1.3 | تحقق من أن المقيم الآلي يقيس معدل المحتوى الضار ويحدد التراجعات التي تتجاوز العتبة المحددة.                                                                    |   2   | D/V  |
| 10.1.4 | تحقق من توثيق تدريب مقاومة الاختراق العكسي وأنه يمكن إعادة إنتاجه.                                                                                             |   2   |  D   |
| 10.1.5 | تحقق من أن إثباتات الامتثال الرسمية للسياسات أو المراقبة المعتمدة تغطي المجالات الحرجة.                                                                        |   3   |  V   |

---

## 10.2 تعزيز مقاومة الأمثلة العدائية

زيادة الصلابة أمام المدخلات المُعدلة. التدريب العدائي القوي وتقييم المعايير المرجعية هما أفضل الممارسات الحالية.

|   #    | Description                                                                                       | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.2.1 | تحقق من أن مستودعات المشروع تتضمن إعدادات التدريب المتعارضة مع بذور قابلة لإعادة الإنتاج.         |   1   |  D   |
| 10.2.2 | تحقق من أن كشف الأمثلة الهجومية يطلق تنبيهات الحجب في خطوط إنتاج الإنتاج.                         |   2   | D/V  |
| 10.2.4 | تحقق من أن إثباتات الصلابة المعتمدة أو شهادات حدود الفاصل تغطي على الأقل الفئات الحرجة العلوية.   |   3   |  V   |
| 10.2.5 | تحقق من أن اختبارات الانحدار تستخدم هجمات تكيفية للتأكد من عدم وجود فقدان قابل للقياس في المتانة. |   3   |  V   |

---

## 10.3 التخفيف من استنتاج العضوية

تحديد القدرة على معرفة ما إذا كانت السجلات موجودة في بيانات التدريب. تبقى الخصوصية التفاضلية وإخفاء درجة الثقة من أكثر طرق الدفاع فعالية المعروفة.

|   #    | Description                                                                                                                         | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.3.1 | تحقق من أن تنظيم الانتروبيا لكل استعلام أو تعديل درجة الحرارة يقلل من التنبؤات المفرطة الثقة.                                       |   1   |  D   |
| 10.3.2 | تحقق من أن التدريب يستخدم تحسين الخصوصية التفاضلية المحصور بـ ε للمجموعات البيانية الحساسة.                                         |   2   |  D   |
| 10.3.3 | تحقق من أن محاكيات الهجوم (نموذج الظل أو الصندوق الأسود) تظهر مساحة تحت منحنى الاستقبال الهجومي (AUC) ≤ 0.60 على البيانات المحتجزة. |   2   |  V   |

---

## 10.4 مقاومة عكس النموذج

منع إعادة بناء السمات الخاصة. تؤكد الدراسات الاستقصائية الحديثة على تقليم المخرجات وضمانات الخصوصية التفاضلية كدفاعات عملية.

|   #    | Description                                                                                                    | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.4.1 | تأكد من عدم إخراج السمات الحساسة مباشرةً أبدًا؛ وعند الحاجة، استخدم التكتيلات أو التحويلات ذات الاتجاه الواحد. |   1   |  D   |
| 10.4.2 | تحقق من أن حدود معدل الاستعلامات تحد من الاستعلامات التكيفية المتكررة من نفس الجهة الأساسية.                   |   1   | D/V  |
| 10.4.3 | تحقق من أن النموذج تم تدريبه باستخدام ضوضاء تحافظ على الخصوصية.                                                |   2   |  D   |

---

## 10.5 الدفاع ضد استخراج النماذج

اكتشاف وردع النسخ غير المصرح به. يُنصح باستخدام العلامات المائية وتحليل نمط الاستعلام.

|   #    | Description                                                                                                      | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.5.1 | تحقق من أن بوابات الاستدلال تفرض حدود معدّل عامة وخاصّة بكل مفتاح API تم ضبطها وفقًا لعتبة الحفظ في النموذج.     |   1   |  D   |
| 10.5.2 | تحقق من أن إحصائيات تشتت الاستعلام وتعددية الإدخال تغذي كاشف الاستخراج الآلي.                                    |   2   | D/V  |
| 10.5.3 | تحقق من أن العلامات المائية الهشة أو الاحتمالية يمكن إثباتها بقيمة p < 0.01 في ≤ 1000 استعلام ضد نسخة مشتبه بها. |   2   |  V   |
| 10.5.4 | تحقق من أن مفاتيح العلامات المائية ومجموعات الزناد مخزنة في وحدة أمان الأجهزة ويتم تدويرها سنويًا.               |   3   |  D   |
| 10.5.5 | تحقق من أن أحداث التنبيه بالاستخراج تتضمن الاستعلامات المخالفة ومتكاملة مع كتب إجراءات الاستجابة للحوادث.        |   3   |  V   |

---

## 10.6 كشف البيانات المسممة أثناء وقت الاستدلال

تحديد وإزالة الخوادم الخلفية أو المدخلات المسمومة.

|   #    | Description                                                                                         | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.6.1 | تحقق من أن المدخلات تمر عبر كاشف الشذوذ (مثل STRIP، تقييم الاتساق) قبل استنتاج النموذج.             |   1   |  D   |
| 10.6.2 | تحقق من ضبط عتبات الكاشف على مجموعات تحقق نظيفة/مسمومة لتحقيق معدل أقل من 5٪ من الإيجابيات الكاذبة. |   1   |  V   |
| 10.6.3 | تحقق من أن المدخلات التي تم تمييزها كمسمومة تؤدي إلى تفعيل الحظر الناعم وسير عمل المراجعة البشرية.  |   2   |  D   |
| 10.6.4 | تحقق من أن الكاشفات قد خضعت لاختبارات إجهاد باستخدام هجمات الباب الخلفي التكيفية دون مشغل.          |   2   |  V   |
| 10.6.5 | تحقق من تسجيل مقاييس فعالية الكشف وإعادة تقييمها دورياً باستخدام معلومات تهديد حديثة.               |   3   |  D   |

---

## 10.7 التكيف الديناميكي لسياسة الأمان

تحديثات سياسة الأمان في الوقت الحقيقي بناءً على استخبارات التهديدات والتحليل السلوكي.

|   #    | Description                                                                                                             | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.7.1 | تحقق من إمكانية تحديث سياسات الأمان ديناميكيًا دون إعادة تشغيل الوكيل مع الحفاظ على سلامة نسخة السياسة.                 |   1   | D/V  |
| 10.7.2 | تحقق من أن تحديثات السياسة موقعة تشفيرياً من قبل أفراد الأمان المخولين ويتم التحقق منها قبل التطبيق.                    |   2   | D/V  |
| 10.7.3 | تحقق من أن تغييرات السياسات الديناميكية تُسجّل مع مسارات تدقيق كاملة تشمل المبررات، وسلاسل الموافقات، وإجراءات التراجع. |   2   | D/V  |
| 10.7.4 | تحقق من أن آليات الأمان التكيفية تضبط حساسية كشف التهديدات بناءً على سياق المخاطر وأنماط السلوك.                        |   3   | D/V  |
| 10.7.5 | تحقق من أن قرارات تعديل السياسات قابلة للتفسير وتتضمن مسارات أدلة لمراجعة فريق الأمان.                                  |   3   | D/V  |

---

## 10.8 التحليل الأمني القائم على الانعكاس

التحقق من الأمان من خلال تأمل الوكيل الذاتي والتحليل الميتامعرفي.

|   #    | Description                                                                                                     | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.8.1 | تحقق من أن آليات انعكاس الوكيل تتضمن تقييمًا ذاتيًا يركز على الأمان للقرارات والإجراءات.                        |   1   | D/V  |
| 10.8.2 | تحقق من أن مخرجات الانعكاس قد تم التحقق من صحتها لمنع التلاعب بآليات التقييم الذاتي من خلال المدخلات العدائية.  |   2   | D/V  |
| 10.8.3 | تحقق من أن تحليل الأمان الميتامعرفي يحدد الانحياز المحتمل أو التلاعب أو الاختراق في عمليات تفكير الوكيل.        |   2   | D/V  |
| 10.8.4 | تحقق من أن تحذيرات الأمان القائمة على الانعكاس تُفعّل المراقبة المُعزّزة وإمكانيات تدخل بشري محتملة.            |   3   | D/V  |
| 10.8.5 | تحقق من أن التعلم المستمر من الانعكاسات الأمنية يحسن من اكتشاف التهديدات دون التأثير سلبًا على الوظائف الشرعية. |   3   | D/V  |

---

## 10.9 الأمان في التطور والتحسين الذاتي

ضوابط الأمان لأنظمة الوكلاء القادرة على التعديل الذاتي والتطور.

|   #    | Description                                                                                  | Level | Role |
| :----: | -------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.9.1 | تحقق من أن قدرات التعديل الذاتي مقيدة بالمناطق الآمنة المحددة مع وجود حدود تحقق رسمية.       |   1   | D/V  |
| 10.9.2 | تحقق من أن مقترحات التطوير تخضع لتقييم تأثير الأمان قبل التنفيذ.                             |   2   | D/V  |
| 10.9.3 | تحقق من أن آليات تحسين الذات تتضمن قدرات التراجع مع التحقق من السلامة.                       |   2   | D/V  |
| 10.9.4 | تحقق من أن أمان التعلم الفوقي يمنع التلاعب العدائي بخوارزميات التحسين.                       |   3   | D/V  |
| 10.9.5 | تحقق من أن التحسين الذاتي التكراري محدود بقيود السلامة الرسمية مع براهين رياضية على التقارب. |   3   | D/V  |

---

### المراجع

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

