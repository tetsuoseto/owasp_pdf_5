# الصفحة الافتتاحية

## حول المعيار

معيار التحقق من أمان الذكاء الاصطناعي (AISVS) هو كتالوج مدفوع بالمجتمع لمتطلبات الأمان يمكن لعلماء البيانات، مهندسي عمليات تعلم الآلة (MLOps)، مهندسي البرمجيات، المطورين، المختبرين، محترفي الأمن، بائعي الأدوات، الجهات التنظيمية، والمستهلكين استخدامه لتصميم، وبناء، واختبار، والتحقق من أنظمة وتطبيقات الذكاء الاصطناعي الموثوقة. يوفر هذا المعيار لغة مشتركة لتحديد ضوابط الأمان عبر دورة حياة الذكاء الاصطناعي—بدءًا من جمع البيانات وتطوير النماذج وحتى النشر والمراقبة المستمرة—لتمكين المؤسسات من قياس وتحسين الصلابة والخصوصية والسلامة لحلول الذكاء الاصطناعي الخاصة بها.

## حقوق النشر والترخيص

الإصدار 0.1 (المسودة العامة الأولى - العمل جاري)، 2025  

![license](../images/license.png)

حقوق النشر © 2025 مشروع AISVS.  

تم الإصدار بموجب[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
لأي إعادة استخدام أو توزيع، يجب عليك توضيح شروط الترخيص الخاصة بهذا العمل للآخرين بوضوح.

## قادة المشروع

|            |                         |
| ---------- | ----------------------- |
| جيم مانيكو | آراس "روس" ميميسيازيتشي |

## المساهمون والمراجعون

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS هو معيار جديد تمامًا تم إنشاؤه خصيصًا لمواجهة التحديات الأمنية الفريدة لأنظمة الذكاء الاصطناعي. بينما يستلهم من أفضل الممارسات الأمنية العامة، تم تطوير كل متطلب في AISVS من الصفر ليعكس مشهد تهديدات الذكاء الاصطناعي ولمساعدة المؤسسات في بناء حلول ذكاء اصطناعي أكثر أمانًا ومرونة.

