# Előszó

Üdvözöljük a Mesterséges Intelligencia Biztonsági Ellenőrzési Szabvány (AISVS) 1.0 verziójában!

## Bevezetés

Az AISVS-t 2025-ben hozták létre egy együttműködő közösségi erőfeszítés eredményeként, és meghatározza a biztonsági követelményeket, amelyeket figyelembe kell venni modern AI modellek, folyamatok és AI-képességekkel rendelkező szolgáltatások tervezése, fejlesztése, telepítése és működtetése során.

Az AISVS v1.0 az AI rendszerek biztonságossá tételéhez szükséges pragmatikus, tesztelhető alapvonal előállítására irányuló projektvezetők, munkacsoport és szélesebb közösség hozzájárulóinak együttes munkáját képviseli.

E kiadással a célunk, hogy az AISVS könnyen alkalmazható legyen, miközben szigorúan a meghatározott hatókörére összpontosítunk, és kezeljük az AI-ra jellemző gyorsan változó kockázati környezetet.

## Az AISVS 1.0 verziójának fő céljai

Az 1.0 verzió több irányelv alapján készül majd.

### Jól meghatározott hatókör

Minden követelménynek összhangban kell állnia az AISVS nevével és küldetésével:

* Mesterséges Intelligencia – Az ellenőrzések az AI/ML rétegen (adat, modell, munkafolyamat vagy következtetés) működnek, és az AI szakemberek felelőssége.
* Biztonság – A követelmények közvetlenül enyhítik az azonosított biztonsági, adatvédelmi vagy biztonsági kockázatokat.
* Ellenőrzés – A nyelvezet olyan módon van megírva, hogy a megfelelőség objektíven igazolható legyen.
* Szabvány – A szakaszok következetes szerkezetet és terminológiát követnek, hogy koherens hivatkozást alkossanak.
  ​
---

Az AISVS követésével a szervezetek rendszerszerűen értékelhetik és erősíthetik mesterséges intelligencia megoldásaik biztonsági helyzetét, elősegítve a biztonságos MI mérnöki kultúra kialakulását.

