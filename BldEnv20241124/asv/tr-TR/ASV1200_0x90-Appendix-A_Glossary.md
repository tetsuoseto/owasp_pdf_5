# Ek A: Terimler Sözlüğü

> Bu kapsamlı sözlük, AISVS genelinde kullanılan önemli AI, ML ve güvenlik terimlerinin netlik ve ortak anlayışı sağlamak amacıyla tanımlarını sunar.
> ​
* Düşmanca Örnek: Genellikle insanlara fark edilmeyen ince bozulmalar eklenerek, bir yapay zeka modelinin hata yapmasına neden olmak amacıyla kasıtlı olarak oluşturulmuş bir giriş.
  ​
* Adversarial Dayanıklılık – AI'da adversarial dayanıklılık, bir modelin performansını koruyabilme ve hatalara yol açmak amacıyla kasıtlı olarak hazırlanmış kötü niyetli girdiler tarafından aldatılmaya veya manipüle edilmeye karşı dirençli olma yeteneğini ifade eder.
  ​
* Ajan – AI ajanları, kullanıcılar adına hedeflere ulaşmak ve görevleri tamamlamak için AI kullanan yazılım sistemleridir. Akıl yürütme, planlama ve hafıza gösterirler ve karar verme, öğrenme ve uyum sağlama konusunda belli bir özerkliğe sahiptirler.
  ​
* Agentik AI: Belirli bir dereceye kadar özerklikle hedeflere ulaşabilen, genellikle doğrudan insan müdahalesi olmadan kararlar alan ve eylemler gerçekleştiren AI sistemleri.
  ​
* Öznitelik Tabanlı Erişim Kontrolü (ABAC): Yetkilendirme kararlarının kullanıcı, kaynak, eylem ve ortamın özniteliklerine dayanarak, sorgu zamanında değerlendirildiği bir erişim kontrol paradigmasıdır.
  ​
* Arka Kapı Saldırısı: Modelin belirli tetikleyicilere karşı özel bir şekilde yanıt vermesi için eğitildiği, diğer durumlarda ise normal şekilde davrandığı bir veri zehirleme saldırısı türü.
  ​
* Önyargı: Belirli gruplar veya belirli bağlamlarda adaletsiz veya ayrımcı sonuçlara yol açabilecek AI modeli çıktılarındaki sistematik hatalar.
  ​
* Önyargı Sömürüsü: Yapay zeka modellerindeki bilinen önyargılardan faydalanarak çıktıları veya sonuçları manipüle etmeye yönelik bir saldırı tekniği.
  ​
* Cedar: AI sistemleri için ABAC uygulanmasında kullanılan, ince taneli izinler için Amazon'un politika dili ve motoru.
  ​
* Düşünce Zinciri: Sonucu üretmeden önce ara çıkarım adımları oluşturarak dil modellerinde akıl yürütmeyi geliştirmek için kullanılan bir tekniktir.
  ​
* Devre Kesiciler: Belirli risk eşiklerinin aşıldığı durumlarda yapay zeka sistemi işlemlerini otomatik olarak durduran mekanizmalar.
  ​
* Veri Sızıntısı: Yapay zeka model çıktıları veya davranışı aracılığıyla hassas bilgilerin istem dışı ifşası.
  ​
* Veri Zehirlemesi: Model bütünlüğünü tehlikeye atmak amacıyla eğitim verilerinin kasıtlı olarak bozulması, genellikle arka kapı kurulması veya performansın düşürülmesi için yapılır.
  ​
* Diferansiyel Gizlilik – Diferansiyel gizlilik, bireysel veri sahiplerinin gizliliğini korurken veri setleri hakkında istatistiksel bilgilerin paylaşılmasını sağlayan matematiksel olarak kesin bir çerçevedir. Bu yaklaşım, veri sahibi kişinin belirli bireyler hakkında sızıntı yapan bilgileri sınırlandırırken, grup genelindeki toplu örüntülerin paylaşılmasını mümkün kılar.
  ​
* Gömüntüler: Semantik anlamı yüksek boyutlu bir uzayda yakalayan, verilerin (metin, görüntüler vb.) yoğun vektör temsilleri.
  ​
* Açıklanabilirlik – Yapay zekada açıklanabilirlik, bir yapay zeka sisteminin kararları ve tahminleri için insan tarafından anlaşılabilir nedenler sunabilme yeteneği olup, iç işleyişine dair anlayış sağlar.
  ​
* Açıklanabilir Yapay Zeka (XAI): Kararları ve davranışları için insan tarafından anlaşılabilir açıklamalar sağlamak üzere çeşitli teknikler ve çerçeveler kullanarak tasarlanmış yapay zeka sistemleri.
  ​
* Federated Learning (Birleştirilmiş Öğrenme): Modellerin yerel veri örneklerine sahip çoklu merkezi olmayan cihazlarda, verilerin kendisi değiş tokuş edilmeden eğitildiği bir makine öğrenimi yaklaşımı.
  ​
* Koruyucu Önlemler: Yapay zeka sistemlerinin zararlı, önyargılı veya başka şekilde istenmeyen çıktılar üretmesini önlemek için uygulanan kısıtlamalar.
  ​
* Halüsinasyon – Bir yapay zeka halüsinasyonu, yapay zeka modelinin eğitim verilerine veya gerçeklik temel alınmaksızın yanlış veya yanıltıcı bilgi üretmesi durumunu ifade eder.
  ​
* İnsan-Dahil Döngü (HITL): Kritik karar noktalarında insan denetimi, doğrulaması veya müdahalesi gerektirecek şekilde tasarlanmış sistemler.
  ​
* Kod olarak Altyapı (IaC): Altyapıyı manuel işlemler yerine kod aracılığıyla yönetmek ve sağlamak, güvenlik taraması ve tutarlı dağıtımlara olanak tanır.
  ​
* Jailbreak: Yasaklanmış içerik üretmek amacıyla, özellikle büyük dil modellerinde, AI sistemlerindeki güvenlik korumalarını aşmak için kullanılan teknikler.
  ​
* En Az Ayrıcalık: Kullanıcılar ve süreçler için yalnızca gerekli olan en düşük erişim haklarının verilmesi güvenlik ilkesi.
  ​
* LIME (Yerel Yorumlanabilir Model-Agnostik Açıklamalar): Herhangi bir makine öğrenimi sınıflandırıcısının tahminlerini, yerel olarak yorumlanabilir bir modelle yaklaşık olarak açıklamak için kullanılan bir tekniktir.
  ​
* Üyelik Çıkarım Saldırısı: Belirli bir veri noktasının bir makine öğrenimi modelini eğitmek için kullanılıp kullanılmadığını belirlemeyi amaçlayan bir saldırı.
  ​
* MITRE ATLAS: Yapay Zeka Sistemlerine Yönelik Düşmanca Tehdit Manzarası; Yapay zeka sistemlerine karşı düşmanca taktikler ve tekniklerin bilgi tabanı.
  ​
* Model Kartı – Model kartı, bir yapay zeka modelinin performansı, sınırlamaları, hedef kullanımları ve etik değerlendirmeleri hakkında standart bilgi sağlayan ve şeffaflığı ile sorumlu yapay zeka geliştirmeyi teşvik eden bir belgedir.
  ​
* Model Çıkarma: Bir saldırı türü olup, bir düşmanın hedef modeli tekrar tekrar sorgulayarak yetkisiz şekilde işlevsel olarak benzer bir kopyasını oluşturmasıdır.
  ​
* Model Ters Çevirimi: Model çıktıları analiz edilerek eğitim verilerini yeniden oluşturmayı amaçlayan bir saldırı.
  ​
* Model Yaşam Döngüsü Yönetimi – AI Model Yaşam Döngüsü Yönetimi, bir yapay zeka modelinin tasarımı, geliştirilmesi, dağıtımı, izlenmesi, bakımı ve nihai emekliliği dahil olmak üzere tüm varlık aşamalarını denetleme sürecidir; bu süreç, modelin etkili kalmasını ve hedeflerle uyumlu olmasını sağlar.
  ​
* Model Zehirlemesi: Eğitim süreci sırasında doğrudan modele güvenlik açıkları veya arka kapılar ekleme.
  ​
* Model Hırsızlığı/Çalınması: Tekrarlanan sorgular yoluyla tescilli bir modelin kopyasını veya yaklaşık bir versiyonunu çıkarmak.
  ​
* Çok Ajanlı Sistem: Her biri potansiyel olarak farklı yeteneklere ve hedeflere sahip, birden fazla etkileşimli yapay zeka ajanından oluşan bir sistem.
  ​
* OPA (Open Policy Agent): Yığını kapsayan birleşik politika uygulamasını mümkün kılan açık kaynaklı bir politika motoru.
  ​
* Gizliliği Koruyan Makine Öğrenimi (PPML): Eğitim verilerinin gizliliğini korurken ML modellerini eğitmek ve dağıtmak için teknikler ve yöntemler.
  ​
* İstem Enjeksiyonu: Bir modelin amaçlanan davranışını geçersiz kılmak için kötü niyetli talimatların girdilere yerleştirildiği bir saldırı.
  ​
* RAG (Elde Edilmiş Üretim): Yanıt oluşturmadan önce ilgili bilgileri dış bilgi kaynaklarından alarak büyük dil modellerini geliştiren bir tekniktir.
  ​
* Red-Teaming: Yapay zeka sistemlerindeki zayıflıkları tespit etmek amacıyla düşmanca saldırıları simüle ederek aktif test yapma uygulaması.
  ​
* SBOM (Yazılım Malzeme Listesi): Yazılım veya AI modelleri oluşturulurken kullanılan çeşitli bileşenlerin detaylarını ve tedarik zinciri ilişkilerini içeren resmi kayıt.
  ​
* SHAP (SHapley Katkı Açıklamaları): Her bir özellikle tahmin arasındaki katkıyı hesaplayarak herhangi bir makine öğrenimi modelinin çıktısını açıklamak için oyun teorisine dayalı bir yaklaşım.
  ​
* Tedarik Zinciri Saldırısı: Üçüncü taraf kütüphaneler, veri setleri veya önceden eğitilmiş modeller gibi tedarik zincirindeki daha az güvenli unsurları hedefleyerek bir sistemi ele geçirme.
  ​
* Transfer Learning: Bir görev için geliştirilen bir modelin, ikinci bir görev için modelin başlangıç noktası olarak yeniden kullanıldığı bir tekniktir.
  ​
* Vektör Veritabanı: Yüksek boyutlu vektörleri (gömülü temsiller) depolamak ve etkili benzerlik aramaları gerçekleştirmek için tasarlanmış özelleşmiş bir veritabanı.
  ​
* Güvenlik Açığı Tarama: AI çerçeveleri ve bağımlılıklar dahil olmak üzere yazılım bileşenlerindeki bilinen güvenlik açıklarını otomatik olarak tanımlayan araçlar.
  ​
* Filigranlama: Kökenini takip etmek veya yapay zeka tarafından üretildiğini tespit etmek için yapay zeka tarafından oluşturulan içeriğe farkedilemez işaretler yerleştirme teknikleri.
  ​
* Sıfırıncı Gün Açığı: Geliştiriciler bir yama oluşturup dağıtmadan önce saldırganların kötüye kullanabileceği daha önce bilinmeyen bir güvenlik açığı.

