# Lampiran A: Glosari

> Glosari komprehensif ini menyediakan definisi istilah utama AI, ML, dan keselamatan yang digunakan sepanjang AISVS untuk memastikan kejelasan dan pemahaman bersama.
> ​
* Contoh Adversarial: Satu input yang sengaja direka untuk menyebabkan model AI membuat kesilapan, sering dengan menambah gangguan halus yang tidak dapat dikesan oleh manusia.
  ​
* Ketahanan Adversarial – Ketahanan adversarial dalam AI merujuk kepada keupayaan model untuk mengekalkan prestasinya dan menahan daripada diperdaya atau dimanipulasi oleh input jahat yang direka dengan sengaja untuk menyebabkan kesilapan.
  ​
* Ejen – Ejen AI adalah sistem perisian yang menggunakan AI untuk mencapai matlamat dan melengkapkan tugasan bagi pihak pengguna. Mereka menunjukkan kebolehan berfikir, merancang, dan mengingati serta mempunyai tahap autonomi untuk membuat keputusan, belajar, dan menyesuaikan diri.
  ​
* Agentic AI: Sistem AI yang boleh beroperasi dengan tahap autonomi tertentu untuk mencapai matlamat, sering membuat keputusan dan mengambil tindakan tanpa campur tangan manusia secara langsung.
  ​
* Kawalan Akses Berasaskan Atribut (ABAC): Paradigma kawalan akses di mana keputusan kebenaran berdasarkan atribut pengguna, sumber, tindakan, dan persekitaran, dinilai semasa masa pertanyaan.
  ​
* Serangan Pintu Belakang: Satu jenis serangan pencemaran data di mana model dilatih untuk bertindak balas dengan cara tertentu kepada pencetus tertentu sementara berkelakuan normal pada masa lain.
  ​
* Bias: Ralat sistematik dalam keluaran model AI yang boleh menyebabkan hasil yang tidak adil atau diskriminasi untuk kumpulan tertentu atau dalam konteks tertentu.
  ​
* Eksploitasi Bias: Satu teknik serangan yang mengambil kesempatan daripada bias yang diketahui dalam model AI untuk memanipulasi hasil atau keputusan.
  ​
* Cedar: Bahasa dasar dasar dasar dan enjin dasar Amazon untuk izin yang terperinci yang digunakan dalam melaksanakan ABAC untuk sistem AI.
  ​
* Rantaian Pemikiran: Satu teknik untuk meningkatkan penalaran dalam model bahasa dengan menghasilkan langkah penalaran perantaraan sebelum menghasilkan jawapan akhir.
  ​
* Pemutus Litar: Mekanisme yang secara automatik menghentikan operasi sistem AI apabila ambang risiko tertentu melebihi.
  ​
* Kebocoran Data: Pendedahan tidak disengajakan maklumat sensitif melalui output atau perilaku model AI.
  ​
* Pencemaran Data: Kerusakan sengaja pada data latihan untuk mengompromikan integritas model, sering kali untuk memasang pintu belakang atau merosakkan prestasi.
  ​
* Privasi Berbeza – Privasi Berbeza adalah kerangka kerja matematik yang ketat untuk mengeluarkan maklumat statistik mengenai set data sambil melindungi privasi subjek data individu. Ia membolehkan pemegang data berkongsi corak agregat kumpulan sambil mengehadkan maklumat yang bocor mengenai individu tertentu.
  ​
* Penempatan: Representasi vektor padat data (teks, imej, dan lain-lain) yang menangkap makna semantik dalam ruang berdimensi tinggi.
  ​
* Kebolehamanan – Kebolehamanan dalam AI adalah keupayaan sistem AI untuk memberikan alasan yang difahami oleh manusia bagi keputusan dan ramalannya, serta menawarkan wawasan mengenai cara kerjanya secara dalaman.
  ​
* AI Boleh Diterangkan (XAI): Sistem AI yang direka untuk memberikan penjelasan yang boleh difahami manusia bagi keputusan dan tingkah laku mereka melalui pelbagai teknik dan rangka kerja.
  ​
* Pembelajaran Bersekutu: Pendekatan pembelajaran mesin di mana model dilatih merentasi pelbagai peranti teragih yang memegang sampel data tempatan, tanpa bertukar data itu sendiri.
  ​
* Panduan keselamatan: Had yang dilaksanakan untuk mengelakkan sistem AI menghasilkan output yang berbahaya, berat sebelah, atau tidak diingini.
  ​
* Halusinasi – Halusinasi AI merujuk kepada fenomena di mana model AI menghasilkan maklumat yang salah atau mengelirukan yang tidak berasaskan pada data latihan atau realiti fakta.
  ​
* Manusia-dalam-Laluan (HITL): Sistem yang direka untuk memerlukan pengawasan, pengesahan, atau campur tangan manusia pada titik keputusan penting.
  ​
* Infrastruktur sebagai Kod (IaC): Mengurus dan menyediakan infrastruktur melalui kod dan bukannya proses manual, membolehkan imbasan keselamatan dan pengeluaran yang konsisten.
  ​
* Jailbreak: Teknik yang digunakan untuk mengelakkan penghad keselamatan dalam sistem AI, terutamanya dalam model bahasa besar, untuk menghasilkan kandungan yang dilarang.
  ​
* Hak Istimewa Minimum: Prinsip keselamatan yang memberikan hanya hak akses minimum yang diperlukan untuk pengguna dan proses.
  ​
* LIME (Penjelasan Model-Agnostik Tempatan yang Boleh Ditafsir): Teknik untuk menerangkan ramalan mana-mana pengklasifikasi pembelajaran mesin dengan mendekatinya secara tempatan menggunakan model yang boleh ditafsir.
  ​
* Serangan Inferens Keanggotaan: Serangan yang bertujuan untuk menentukan sama ada titik data tertentu telah digunakan untuk melatih model pembelajaran mesin.
  ​
* MITRE ATLAS: Lanskap Ancaman Adversarial untuk Sistem Kecerdasan Buatan; sebuah pangkalan pengetahuan mengenai taktik dan teknik adversarial terhadap sistem AI.
  ​
* Kad Model – Kad model adalah dokumen yang menyediakan maklumat piawai tentang prestasi model AI, hadnya, kegunaan yang dimaksudkan, dan pertimbangan etika untuk mempromosikan ketelusan dan pembangunan AI yang bertanggungjawab.
  ​
* Penyalinan Model: Serangan di mana penyerang mengulangi pertanyaan ke model sasaran untuk menghasilkan salinan yang fungsi serupa tanpa kebenaran.
  ​
* Model Inversion: Satu serangan yang cuba membina semula data latihan dengan menganalisis output model.
  ​
* Pengurusan Kitaran Hayat Model – Pengurusan Kitaran Hayat Model AI adalah proses mengawasi semua peringkat kewujudan model AI, termasuk reka bentuk, pembangunan, penyebaran, pemantauan, penyelenggaraan, dan penarikan balik akhirnya, untuk memastikan ia kekal berkesan dan selaras dengan objektif.
  ​
* Pencemaran Model: Memperkenalkan kelemahan atau pintu belakang secara langsung ke dalam model semasa proses latihan.
  ​
* Pencurian/Pengambilan Model: Mengekstrak salinan atau anggaran model proprietari melalui pertanyaan berulang.
  ​
* Sistem Multi-ejen: Sistem yang terdiri daripada pelbagai agen AI yang berinteraksi, masing-masing dengan keupayaan dan matlamat yang mungkin berbeza.
  ​
* OPA (Open Policy Agent): Enjin dasar sumber terbuka yang membolehkan penguatkuasaan dasar bersatu merentasi keseluruhan tumpukan.
  ​
* Pembelajaran Mesin Menjaga Privasi (PPML): Teknik dan kaedah untuk melatih dan menggunakan model ML sambil melindungi privasi data latihan.
  ​
* Suntikan Prompt: Serangan di mana arahan berniat jahat diselitkan dalam input untuk menggantikan tingkah laku model yang dimaksudkan.
  ​
* RAG (Generasi Diperkuat Pengambilan): Suatu teknik yang meningkatkan model bahasa besar dengan mengambil maklumat yang relevan daripada sumber pengetahuan luaran sebelum menjana jawapan.
  ​
* Red-Teaming: Amalan menguji sistem AI secara aktif dengan mensimulasikan serangan advesari untuk mengenal pasti kelemahan.
  ​
* SBOM (Senarai Bahan Perisian): Rekod rasmi yang mengandungi butiran dan hubungan rantaian bekalan bagi pelbagai komponen yang digunakan dalam membina perisian atau model AI.
  ​
* SHAP (Penjelasan Tambahan Shapley): Pendekatan teori permainan untuk menerangkan hasil mana-mana model pembelajaran mesin dengan mengira sumbangan setiap ciri kepada ramalan.
  ​
* Serangan Rantaian Bekalan: Mengkompromi sistem dengan menyasarkan elemen yang kurang selamat dalam rantaian bekalannya, seperti perpustakaan pihak ketiga, set data, atau model pra-latih.
  ​
* Pembelajaran Pindahan: Satu teknik di mana model yang dibangunkan untuk satu tugas digunakan semula sebagai titik permulaan untuk model dalam tugas kedua.
  ​
* Pangkalan Data Vektor: Pangkalan data khusus yang direka untuk menyimpan vektor berdimensi tinggi (penyulitan) dan melaksanakan carian kesamaan yang cekap.
  ​
* Imbasan Kelemahan: Alat automatik yang mengenal pasti kelemahan keselamatan yang diketahui dalam komponen perisian, termasuk rangka kerja AI dan pergantungan.
  ​
* Tandatanda Air: Teknik untuk menyematkan penanda yang tidak dapat dikesan dalam kandungan yang dihasilkan oleh AI untuk mengesan asal-usulnya atau mengesan penghasilan oleh AI.
  ​
* Kelemahan Zero-Day: Kelemahan yang sebelum ini tidak diketahui yang boleh dieksploitasi oleh penyerang sebelum pembangun mencipta dan mengedarkan tampalan.

