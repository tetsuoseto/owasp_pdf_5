# Frontyspis

## O standardzie

Standard Weryfikacji Bezpieczeństwa Sztucznej Inteligencji (AISVS) to społecznościowy katalog wymagań bezpieczeństwa, z którego mogą korzystać naukowcy danych, inżynierowie MLOps, architekci oprogramowania, programiści, testerzy, specjaliści ds. bezpieczeństwa, dostawcy narzędzi, regulatorzy i użytkownicy do projektowania, budowy, testowania oraz weryfikacji godnych zaufania systemów i aplikacji opartych na sztucznej inteligencji. Zapewnia on wspólny język do określania zabezpieczeń w całym cyklu życia AI — od zbierania danych i rozwijania modeli, po wdrożenie i bieżący monitoring — dzięki czemu organizacje mogą mierzyć i poprawiać odporność, prywatność oraz bezpieczeństwo swoich rozwiązań AI.

## Prawa autorskie i licencja

Wersja 0.1 (Pierwszy publiczny szkic – prace w toku), 2025  

![license](../images/license.png)

Prawa autorskie © 2025 Projekt AISVS.  

Wydane na podstawie[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
W przypadku ponownego użycia lub dystrybucji, musisz jasno przekazać innym warunki licencji tego dzieła.

## Kierownicy projektu

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras „Russ” Memisyazici |

## Współautorzy i Recenzenci

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS to zupełnie nowy standard stworzony specjalnie w celu rozwiązania unikalnych wyzwań związanych z bezpieczeństwem systemów sztucznej inteligencji. Chociaż czerpie inspirację z ogólnych najlepszych praktyk bezpieczeństwa, każdy wymóg w AISVS został opracowany od podstaw, aby odzwierciedlać krajobraz zagrożeń AI i pomagać organizacjom w tworzeniu bezpieczniejszych, bardziej odpornych rozwiązań AI.

