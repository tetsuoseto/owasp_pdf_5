# Przedmowa

Witamy w standardzie weryfikacji bezpieczeństwa sztucznej inteligencji (AISVS) wersja 1.0!

## Wprowadzenie

Ustanowiona w 2025 roku dzięki wspólnemu wysiłkowi społeczności, AISVS definiuje wymagania dotyczące bezpieczeństwa, które należy uwzględnić podczas projektowania, rozwoju, wdrażania i eksploatacji nowoczesnych modeli AI, pipeline'ów oraz usług wspomaganych AI.

AISVS w wersji 1.0 reprezentuje wspólną pracę liderów projektu, grupy roboczej oraz szerszej społeczności współtwórców, mającą na celu stworzenie pragmatycznej, testowalnej podstawy do zabezpieczania systemów sztucznej inteligencji.

Naszym celem przy tym wydaniu jest, aby AISVS było łatwe do wdrożenia, jednocześnie pozostając ściśle skoncentrowanym na określonym zakresie oraz reagując na szybko zmieniający się krajobraz ryzyka unikalny dla sztucznej inteligencji.

## Kluczowe cele wersji 1.0 AISVS

Wersja 1.0 zostanie opracowana zgodnie z kilkoma zasadniczymi wytycznymi.

### Dobrze zdefiniowany zakres

Każde wymaganie musi być zgodne z nazwą i misją AISVS:

* Sztuczna inteligencja – Kontrole działają na warstwie AI/ML (dane, model, pipeline lub inferencja) i są odpowiedzialnością specjalistów AI.
* Bezpieczeństwo – Wymagania bezpośrednio niwelują zidentyfikowane ryzyka związane z bezpieczeństwem, prywatnością lub bezpieczeństwem użytkowania.
* Weryfikacja – Język jest napisany tak, aby zgodność mogła być obiektywnie zweryfikowana.
* Standard – Sekcje mają spójną strukturę i terminologię, tworząc spójny wzorzec odniesienia.
  ​
---

Stosując AISVS, organizacje mogą systematycznie oceniać i wzmacniać poziom bezpieczeństwa swoich rozwiązań AI, promując kulturę bezpiecznego inżynierowania AI.

