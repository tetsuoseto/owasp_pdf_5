# Παράρτημα Α: Γλωσσάριο

> Αυτό το ολοκληρωμένο γλωσσάριο παρέχει ορισμούς βασικών όρων ΤΝ, ΜΜ και ασφάλειας που χρησιμοποιούνται σε όλο το AISVS για να διασφαλίσει σαφήνεια και κοινή κατανόηση.
> ​
* Εχθρικό Παράδειγμα: Μια είσοδος που έχει κατασκευαστεί επιδέξια με σκοπό να προκαλέσει ένα μοντέλο Τεχνητής Νοημοσύνης να κάνει λάθος, συχνά προσθέτοντας διακριτικές παρεμβολές οι οποίες είναι ανεπαίσθητες για τον ανθρώπινο παρατηρητή.
  ​
* Αντιμετώπιση Εχθρικών Επιθέσεων – Η αντιμετώπιση εχθρικών επιθέσεων στην τεχνητή νοημοσύνη αναφέρεται στην ικανότητα ενός μοντέλου να διατηρεί την απόδοσή του και να αντιστέκεται στην εξαπάτηση ή παραπλάνηση από επίτηδες σχεδιασμένες, κακόβουλες εισόδους που έχουν ως στόχο να προκαλέσουν σφάλματα.
  ​
* Πράκτορας – Οι πράκτορες τεχνητής νοημοσύνης είναι συστήματα λογισμικού που χρησιμοποιούν την τεχνητή νοημοσύνη για την επίτευξη στόχων και την ολοκλήρωση εργασιών εκ μέρους των χρηστών. Εμφανίζουν ικανότητες συλλογισμού, σχεδιασμού και μνήμης και διαθέτουν επίπεδο αυτονομίας για τη λήψη αποφάσεων, την εκμάθηση και την προσαρμογή.
  ​
* Agentic AI: Τα συστήματα ΤΝ που μπορούν να λειτουργούν με κάποιο βαθμό αυτονομίας για να επιτύχουν στόχους, συχνά παίρνοντας αποφάσεις και αναλαμβάνοντας ενέργειες χωρίς άμεση ανθρώπινη παρέμβαση.
  ​
* Έλεγχος Πρόσβασης Βασισμένος σε Χαρακτηριστικά (ABAC): Ένα παράδειγμα ελέγχου πρόσβασης όπου οι αποφάσεις εξουσιοδότησης βασίζονται σε χαρακτηριστικά του χρήστη, του πόρου, της ενέργειας και του περιβάλλοντος, τα οποία αξιολογούνται κατά το χρόνο του ερωτήματος.
  ​
* Επίθεση Πίσω Πόρτας: Ένας τύπος επίθεσης δηλητηρίασης δεδομένων όπου το μοντέλο εκπαιδεύεται να ανταποκρίνεται με συγκεκριμένο τρόπο σε ορισμένα ερεθίσματα, ενώ συμπεριφέρεται κανονικά διαφορετικά.
  ​
* Προκατάληψη: Συστηματικά σφάλματα στις εξόδους μοντέλων τεχνητής νοημοσύνης που μπορούν να οδηγήσουν σε άδικα ή διακριτικά αποτελέσματα για ορισμένες ομάδες ή σε συγκεκριμένα πλαίσια.
  ​
* Εκμετάλλευση μεροληψίας: Μια τεχνική επίθεσης που εκμεταλλεύεται γνωστές μεροληψίες σε μοντέλα Τεχνητής Νοημοσύνης για να χειραγωγήσει τα αποτελέσματα ή τις εξόδους.
  ​
* Cedar: Η γλώσσα πολιτικής και η μηχανή της Amazon για λεπτομερείς άδειες που χρησιμοποιούνται στην υλοποίηση ABAC για συστήματα ΤΝ.
  ​
* Αλυσίδα Σκέψης: Μια τεχνική για τη βελτίωση της λογικής στα γλωσσικά μοντέλα μέσω της δημιουργίας ενδιάμεσων βημάτων συλλογισμού πριν από την παραγωγή μιας τελικής απάντησης.
  ​
* Διακόπτες Κυκλώματος: Μηχανισμοί που σταματούν αυτόματα τις λειτουργίες του συστήματος AI όταν ξεπεραστούν συγκεκριμένα όρια κινδύνου.
  ​
* Διαρροή Δεδομένων: Ακούσια αποκάλυψη ευαίσθητων πληροφοριών μέσω των αποτελεσμάτων ή της συμπεριφοράς μοντέλων τεχνητής νοημοσύνης.
  ​
* Δηλητηρίαση Δεδομένων: Η εκούσια αλλοίωση των δεδομένων εκπαίδευσης για να παραβιαστεί η ακεραιότητα του μοντέλου, συχνά με σκοπό την εγκατάσταση παραθύρων πίσω ή τη χειροτέρευση της απόδοσης.
  ​
* Διαφορική Ιδιωτικότητα – Η διαφορική ιδιωτικότητα είναι ένα μαθηματικά αυστηρό πλαίσιο για την παροχή στατιστικών πληροφοριών σχετικά με σύνολα δεδομένων, προστατεύοντας παράλληλα την ιδιωτικότητα των ατομικών υποκειμένων δεδομένων. Επιτρέπει σε έναν κάτοχο δεδομένων να μοιράζεται συνολικά μοτίβα της ομάδας, περιορίζοντας ταυτόχρονα τις πληροφορίες που αποκαλύπτονται για συγκεκριμένα άτομα.
  ​
* Ενσωματώσεις: Πυκνές αναπαραστάσεις διανυσμάτων δεδομένων (κείμενα, εικόνες, κ.ά.) που αποτυπώνουν το σημασιολογικό νόημα σε έναν πολυδιάστατο χώρο.
  ​
* Επεξηγησιμότητα – Η επεξηγησιμότητα στην Τεχνητή Νοημοσύνη είναι η ικανότητα ενός συστήματος ΤΝ να παρέχει λόγους κατανοητούς από τον άνθρωπο για τις αποφάσεις και τις προβλέψεις του, προσφέροντας εμβάθυνση στη λειτουργία του.
  ​
* Επεξηγηματική Τεχνητή Νοημοσύνη (XAI): Συγκροτήματα τεχνητής νοημοσύνης που έχουν σχεδιαστεί για να παρέχουν εξηγήσεις κατανοητές από τον άνθρωπο για τις αποφάσεις και τις συμπεριφορές τους μέσω διαφόρων τεχνικών και πλαισίων.
  ​
* Federated Learning: Μια προσέγγιση μηχανικής μάθησης όπου τα μοντέλα εκπαιδεύονται σε πολλαπλές αποκεντρωμένες συσκευές που κατέχουν τοπικά δείγματα δεδομένων, χωρίς να ανταλλάσσεται η ίδια η πληροφορία.
  ​
* Φράγματα ασφαλείας: Περιορισμοί που εφαρμόζονται για να αποτρέψουν τα συστήματα τεχνητής νοημοσύνης από την παραγωγή επιβλαβών, μεροληπτικών ή άλλως ανεπιθύμητων αποτελεσμάτων.
  ​
* Παράληψη – Η παράληψη σε τεχνητή νοημοσύνη αναφέρεται σε ένα φαινόμενο όπου ένα μοντέλο ΤΝ δημιουργεί λανθασμένες ή παραπλανητικές πληροφορίες που δεν βασίζονται στα δεδομένα εκπαίδευσής του ή στην πραγματικότητα.
  ​
* Άνθρωπος-στο-Βρόχο (HITL): Συστήματα σχεδιασμένα να απαιτούν ανθρώπινη επίβλεψη, επαλήθευση ή παρέμβαση σε κρίσιμα σημεία λήψης αποφάσεων.
  ​
* Υποδομή ως Κώδικας (IaC): Διαχείριση και προμήθεια υποδομής μέσω κώδικα αντί για χειροκίνητες διαδικασίες, επιτρέποντας τον έλεγχο ασφάλειας και συνεπείς αναπτύξεις.
  ​
* Jailbreak: Τεχνικές που χρησιμοποιούνται για την παράκαμψη των προστατευτικών περιορισμών σε συστήματα τεχνητής νοημοσύνης, ιδιαίτερα σε μεγάλα γλωσσικά μοντέλα, για την παραγωγή απαγορευμένου περιεχομένου.
  ​
* Ελάχιστα Δικαιώματα: Η αρχή ασφαλείας που αφορά την παροχή μόνο των ελάχιστων απαραίτητων δικαιωμάτων πρόσβασης για χρήστες και διαδικασίες.
  ​
* LIME (Τοπικές Ερμηνεύσιμες Εξηγήσεις Ανεξάρτητες από το Μοντέλο): Μια τεχνική για την εξήγηση των προβλέψεων οποιουδήποτε ταξινομητή μηχανικής μάθησης, προσεγγίζοντάς τον τοπικά με ένα ερμηνεύσιμο μοντέλο.
  ​
* Επίθεση Εξαγωγής Μέλους: Μια επίθεση που αποσκοπεί στον καθορισμό του εάν ένα συγκεκριμένο δεδομένο χρησιμοποιήθηκε για την εκπαίδευση ενός μοντέλου μηχανικής μάθησης.
  ​
* MITRE ATLAS: Το Τοπίο Απειλών Αντιπάλων για Συστήματα Τεχνητής Νοημοσύνης· μια βάση γνώσεων τακτικών και τεχνικών αντιπάλων κατά των συστημάτων ΤΝ.
  ​
* Κάρτα Μοντέλου – Μία κάρτα μοντέλου είναι ένα έγγραφο που παρέχει τυποποιημένες πληροφορίες για την απόδοση ενός μοντέλου τεχνητής νοημοσύνης, τους περιορισμούς του, τις προγραμματισμένες χρήσεις και τις ηθικές εκτιμήσεις, με στόχο την προώθηση της διαφάνειας και της υπεύθυνης ανάπτυξης τεχνητής νοημοσύνης.
  ​
* Εξαγωγή Μοντέλου: Μια επίθεση όπου ένας αντίπαλος επανειλημμένα κάνει ερωτήματα σε ένα στόχο μοντέλο για να δημιουργήσει ένα λειτουργικά παρόμοιο αντίγραφο χωρίς άδεια.
  ​
* Αντιστροφή Μοντέλου: Μια επίθεση που προσπαθεί να ανακατασκευάσει τα δεδομένα εκπαίδευσης αναλύοντας τις εξόδους του μοντέλου.
  ​
* Διαχείριση Κύκλου Ζωής Μοντέλου – Η Διαχείριση Κύκλου Ζωής Μοντέλου Τεχνητής Νοημοσύνης είναι η διαδικασία επίβλεψης όλων των σταδίων της ύπαρξης ενός μοντέλου ΤΝ, συμπεριλαμβανομένου του σχεδιασμού, της ανάπτυξης, της ανάπτυξης στο περιβάλλον παραγωγής, της παρακολούθησης, της συντήρησης και της τελικής αποχώρησης, προκειμένου να διασφαλιστεί ότι παραμένει αποτελεσματικό και ευθυγραμμισμένο με τους στόχους.
  ​
* Μόλυνση Μοντέλου: Εισαγωγή ευπαθειών ή κρυφών θυρών απευθείας σε ένα μοντέλο κατά τη διάρκεια της διαδικασίας εκπαίδευσης.
  ​
* Κλοπή/Αποκόμιση Μοντέλου: Εξαγωγή ενός αντιγράφου ή προσέγγισης ενός ιδιοκτησιακού μοντέλου μέσω επανειλημμένων αιτημάτων.
  ​
* Πολυ-πρακτόρων Σύστημα: Ένα σύστημα αποτελούμενο από πολλαπλούς αλληλεπιδρώντες πράκτορες ΤΝ, καθένας με ενδεχομένως διαφορετικές ικανότητες και στόχους.
  ​
* OPA (Open Policy Agent): Μηχανή πολιτικής ανοιχτού κώδικα που επιτρέπει την ενοποιημένη επιβολή πολιτικών σε όλο το στοίβο.
  ​
* Μηχανική μάθηση με διατήρηση της ιδιωτικότητας (Privacy-Preserving Machine Learning - PPML): Τεχνικές και μέθοδοι για την εκπαίδευση και ανάπτυξη μοντέλων μηχανικής μάθησης με προστασία της ιδιωτικότητας των δεδομένων εκπαίδευσης.
  ​
* Εισαγωγή Εντολών (Prompt Injection): Μια επίθεση όπου κακόβουλες εντολές ενσωματώνονται στις εισόδους για να υπερισχύσουν της προβλεπόμενης συμπεριφοράς ενός μοντέλου.
  ​
* RAG (Ανάκτηση-Ενισχυμένη Γεννήτρια): Μια τεχνική που ενισχύει τα μεγάλα μοντέλα γλώσσας ανακτώντας σχετικές πληροφορίες από εξωτερικές πηγές γνώσης πριν από την παραγωγή μιας απάντησης.
  ​
* Red-Teaming: Η πρακτική της ενεργητικής δοκιμής συστημάτων ΤΝ μέσω προσομοίωσης εχθρικών επιθέσεων για την αναγνώριση ευπαθειών.
  ​
* SBOM (Κατάσταση Υλικών Λογισμικού): Μια επίσημη καταγραφή που περιλαμβάνει τις λεπτομέρειες και τις σχέσεις της αλυσίδας εφοδιασμού διαφόρων στοιχείων που χρησιμοποιούνται στην κατασκευή λογισμικού ή μοντέλων τεχνητής νοημοσύνης.
  ​
* SHAP (Προσαρμογές επεξηγήσεων Shapley): Μια θεωρητική προσέγγιση παιχνιδιών για την εξήγηση της εξόδου οποιουδήποτε μοντέλου μηχανικής μάθησης, υπολογίζοντας τη συμβολή κάθε χαρακτηριστικού στην πρόβλεψη.
  ​
* Επίθεση στην Αλυσίδα Εφοδιασμού: Διασφάλιση ενός συστήματος στοχεύοντας λιγότερο ασφαλή στοιχεία στην αλυσίδα εφοδιασμού του, όπως βιβλιοθήκες τρίτων, σύνολα δεδομένων ή προκαταρκτικά εκπαιδευμένα μοντέλα.
  ​
* Μεταφορά Μάθησης: Μια τεχνική όπου ένα μοντέλο που έχει αναπτυχθεί για μία εργασία επαναχρησιμοποιείται ως σημείο εκκίνησης για ένα μοντέλο σε μια δεύτερη εργασία.
  ​
* Βάση Δεδομένων Διανυσμάτων: Μια εξειδικευμένη βάση δεδομένων σχεδιασμένη για την αποθήκευση υψηλής διάστασης διανυσμάτων (ενσωματώσεων) και την εκτέλεση αποδοτικών αναζητήσεων ομοιότητας.
  ​
* Σάρωση Ευπαθειών: Αυτοματοποιημένα εργαλεία που εντοπίζουν γνωστές ευπάθειες ασφαλείας σε στοιχεία λογισμικού, συμπεριλαμβανομένων των πλαισίων τεχνητής νοημοσύνης και των εξαρτήσεων.
  ​
* Υδατοσήμανση: Τεχνικές για την ενσωμάτωση ανεπαίσθητων δεικτών στο περιεχόμενο που δημιουργείται από τεχνητή νοημοσύνη, προκειμένου να παρακολουθείται η προέλευσή του ή να ανιχνεύεται η δημιουργία από AI.
  ​
* Ευπάθεια μηδενικής ημέρας: Μια προγενέστερα άγνωστη ευπάθεια που μπορούν να εκμεταλλευτούν οι επιτιθέμενοι πριν οι προγραμματιστές δημιουργήσουν και υλοποιήσουν ένα ενημερωτικό πακέτο ασφαλείας.

