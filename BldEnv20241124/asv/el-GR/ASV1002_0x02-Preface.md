# Πρόλογος

Καλώς ήρθατε στο Πρότυπο Επαλήθευσης Ασφάλειας Τεχνητής Νοημοσύνης (AISVS) έκδοση 1.0!

## Εισαγωγή

Ιδρύθηκε το 2025 μέσω μιας συνεργατικής προσπάθειας της κοινότητας, το AISVS ορίζει τις απαιτήσεις ασφάλειας που πρέπει να λαμβάνονται υπόψη κατά το σχεδιασμό, την ανάπτυξη, την ανάπτυξη και τη λειτουργία σύγχρονων μοντέλων AI, ροών εργασίας και υπηρεσιών που υποστηρίζονται από AI.

Το AISVS v1.0 αντιπροσωπεύει το συνδυασμένο έργο των υπευθύνων του έργου, της ομάδας εργασίας και των ευρύτερων συνεισφερόντων της κοινότητας, με στόχο την παραγωγή μιας πραγματιστικής, ελεγξιμης βάσης για την ασφάλεια των συστημάτων τεχνητής νοημοσύνης.

Ο στόχος μας με αυτήν την έκδοση είναι να κάνουμε το AISVS εύκολο στην υιοθέτηση, παραμένοντας ταυτόχρονα απόλυτα επικεντρωμένοι στο καθορισμένο πεδίο εφαρμογής του και αντιμετωπίζοντας το ταχέως εξελισσόμενο τοπίο κινδύνου που είναι μοναδικό για την Τεχνητή Νοημοσύνη.

## Κύριοι στόχοι για την έκδοση AISVS 1.0

Η Έκδοση 1.0 θα δημιουργηθεί με αρκετές βασικές αρχές καθοδήγησης.

### Καλά Ορισμένο Πεδίο Εφαρμογής

Κάθε απαίτηση πρέπει να ευθυγραμμίζεται με το όνομα και την αποστολή της AISVS:

* Τεχνητή Νοημοσύνη – Οι έλεγχοι λειτουργούν στο στρώμα AI/ML (δεδομένα, μοντέλο, ροή εργασίας ή συμπερασματολογία) και είναι ευθύνη των ειδικών AI.
* Ασφάλεια – Οι απαιτήσεις αντιμετωπίζουν άμεσα τους ταυτοποιημένους κινδύνους ασφάλειας, ιδιωτικότητας ή ασφάλειας.
* Επαλήθευση – Η γλώσσα είναι γραμμένη ώστε η συμμόρφωση να μπορεί να επιβεβαιωθεί αντικειμενικά.
* Πρότυπο – Τμήματα ακολουθούν μια συνεπή δομή και ορολογία για τη δημιουργία ενός συνεκτικού αναφοράς.
  ​
---

Ακολουθώντας το AISVS, οι οργανισμοί μπορούν να αξιολογούν συστηματικά και να ενισχύουν τη στάση ασφάλειας των λύσεων ΤΝ τους, προάγοντας μια κουλτούρα ασφαλούς μηχανικής τεχνητής νοημοσύνης.

