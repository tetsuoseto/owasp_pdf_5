# C13 Ανθρώπινη Επιτήρηση, Λογοδοσία και Διακυβέρνηση

## Στόχος Ελέγχου

Αυτό το κεφάλαιο παρέχει απαιτήσεις για τη διατήρηση της ανθρώπινης επίβλεψης και σαφών αλυσίδων λογοδοσίας στα συστήματα τεχνητής νοημοσύνης, διασφαλίζοντας την επεξηγησιμότητα, τη διαφάνεια και τη δεοντολογική διαχείριση σε όλο τον κύκλο ζωής της τεχνητής νοημοσύνης.

---

## C13.1 Μηχανισμοί Απενεργοποίησης (Kill-Switch) και Υπέρβασης (Override)

Παρέχετε διαδρομές τερματισμού ή επαναφοράς όταν παρατηρηθεί μη ασφαλής συμπεριφορά του συστήματος τεχνητής νοημοσύνης.

|   #    | Description                                                                                                                                                    | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.1.1 | Επαληθεύστε ότι υπάρχει μηχανισμός χειροκίνητου διακόπτη ασφαλείας για την άμεση διακοπή της εκτέλεσης και των αποτελεσμάτων του μοντέλου τεχνητής νοημοσύνης. |   1   | D/V  |
| 13.1.2 | Επαληθεύστε ότι οι έλεγχοι παράκαμψης είναι προσβάσιμοι μόνο σε εξουσιοδοτημένο προσωπικό.                                                                     |   1   |  D   |
| 13.1.3 | Επαληθεύστε ότι οι διαδικασίες επαναφοράς μπορούν να επαναφέρουν σε προηγούμενες εκδόσεις μοντέλων ή σε λειτουργίες ασφαλούς λειτουργίας.                      |   3   | D/V  |
| 13.1.4 | Επαληθεύστε ότι οι μηχανισμοί παράκαμψης δοκιμάζονται τακτικά.                                                                                                 |   3   |  V   |

---

## C13.2 Σημεία Ελέγχου Αποφάσεων με Ανθρώπινη Παρέμβαση

Απαιτούνται ανθρώπινες εγκρίσεις όταν τα στοιχήματα υπερβαίνουν προκαθορισμένα όρια κινδύνου.

|   #    | Description                                                                                                                                                                   | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.2.1 | Επαληθεύστε ότι οι αποφάσεις τεχνητής νοημοσύνης υψηλού κινδύνου απαιτούν ρητή έγκριση από ανθρώπινο παράγοντα πριν από την εκτέλεση.                                         |   1   | D/V  |
| 13.2.2 | Επαληθεύστε ότι τα όρια κινδύνου είναι σαφώς ορισμένα και ενεργοποιούν αυτόματα ροές εργασίας για ανθρώπινη αξιολόγηση.                                                       |   1   |  D   |
| 13.2.3 | Επαληθεύστε ότι οι αποφάσεις με χρονική ευαισθησία διαθέτουν εναλλακτικές διαδικασίες όταν η ανθρώπινη έγκριση δεν μπορεί να ληφθεί εντός των απαιτούμενων χρονικών πλαισίων. |   2   |  D   |
| 13.2.4 | Επαληθεύστε ότι οι διαδικασίες κλιμάκωσης ορίζουν σαφείς επίπεδα αρμοδιότητας για διαφορετικούς τύπους αποφάσεων ή κατηγορίες κινδύνου, εφόσον εφαρμόζεται.                   |   3   | D/V  |

---

## C13.3 Αλυσίδα Ευθύνης και Ελεγχος Ιχνών

Καταγράψτε τις ενέργειες του χειριστή και τις αποφάσεις του μοντέλου.

|   #    | Description                                                                                                                                                                               | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.3.1 | Επαληθεύστε ότι όλες οι αποφάσεις του συστήματος τεχνητής νοημοσύνης και οι ανθρώπινες παρεμβάσεις καταγράφονται με χρονικές σημάνσεις, ταυτότητες χρηστών και αιτιολόγηση των αποφάσεων. |   1   | D/V  |
| 13.3.2 | Επαληθεύστε ότι τα αρχεία καταγραφής ελέγχου δεν μπορούν να αλλοιωθούν και περιλαμβάνουν μηχανισμούς επαλήθευσης ακεραιότητας.                                                            |   2   |  D   |

---

## C13.4 Τεχνικές Εξηγήσιμης Τεχνητής Νοημοσύνης

Σημαντικότητα επιφανειακών χαρακτηριστικών, αντι-παράδοξα και τοπικές εξηγήσεις.

|   #    | Description                                                                                                                                                                   | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.4.1 | Επαληθεύστε ότι τα συστήματα τεχνητής νοημοσύνης παρέχουν βασικές εξηγήσεις για τις αποφάσεις τους σε μορφή κατανοητή από τον άνθρωπο.                                        |   1   | D/V  |
| 13.4.2 | Επαληθεύστε ότι η ποιότητα της εξήγησης επικυρώνεται μέσω μελετών ανθρώπινης αξιολόγησης και μετρικών.                                                                        |   2   |  V   |
| 13.4.3 | Επαληθεύστε ότι οι βαθμολογίες σημασίας χαρακτηριστικών ή οι μέθοδοι απόδοσης (SHAP, LIME, κ.λπ.) είναι διαθέσιμες για κρίσιμες αποφάσεις.                                    |   3   | D/V  |
| 13.4.4 | Επαληθεύστε ότι οι αντιφατικές εξηγήσεις δείχνουν πώς μπορούν να τροποποιηθούν οι είσοδοι για να αλλάξουν τα αποτελέσματα, εφόσον ισχύει για το σενάριο χρήσης και τον τομέα. |   3   |  V   |

---

## C13.5 Κάρτες Μοντέλων και Αποκαλύψεις Χρήσης

Διατηρήστε κάρτες μοντέλων για τον προοριζόμενο σκοπό χρήσης, τα μετρικά απόδοσης και τις ηθικές παραμέτρους.

|   #    | Description                                                                                                                                                                                                                                      | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 13.5.1 | Επαληθεύστε ότι οι κάρτες μοντέλων τεκμηριώνουν τις προτεινόμενες περιπτώσεις χρήσης, τους περιορισμούς και τις γνωστές λειτουργίες αποτυχίας.                                                                                                   |   1   |  D   |
| 13.5.2 | Επαληθεύστε ότι οι μετρικές απόδοσης για διαφορετικές εφαρμοστέες περιπτώσεις χρήσης αποκαλύπτονται.                                                                                                                                             |   1   | D/V  |
| 13.5.3 | Επαληθεύστε ότι οι ηθικές προϋποθέσεις, οι αξιολογήσεις προκατάληψης, οι αξιολογήσεις δικαιοσύνης, τα χαρακτηριστικά των δεδομένων εκπαίδευσης και οι γνωστοί περιορισμοί των δεδομένων εκπαίδευσης έχουν τεκμηριωθεί και ενημερώνονται τακτικά. |   2   |  D   |
| 13.5.4 | Επαληθεύστε ότι οι κάρτες μοντέλων ελέγχονται ως προς την έκδοση και διατηρούνται καθ' όλη τη διάρκεια του κύκλου ζωής του μοντέλου με παρακολούθηση αλλαγών.                                                                                    |   2   | D/V  |

---

## C13.6 Ποσοτικοποίηση Αβεβαιότητας

Διαδώστε τους δείκτες εμπιστοσύνης ή τα μέτρα εντροπίας στις αποκρίσεις.

|   #    | Description                                                                                                                                           | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.6.1 | Επαληθεύστε ότι τα συστήματα ΤΝ παρέχουν βαθμούς εμπιστοσύνης ή μετρήσεις αβεβαιότητας με τις εξόδους τους.                                           |   1   |  D   |
| 13.6.2 | Επαληθεύστε ότι τα όρια αβεβαιότητας ενεργοποιούν επιπλέον ανθρώπινη επανεξέταση ή εναλλακτικές διαδρομές λήψης αποφάσεων.                            |   2   | D/V  |
| 13.6.3 | Επαληθεύστε ότι οι μέθοδοι ποσοτικοποίησης της αβεβαιότητας είναι βαθμονομημένες και επικυρωμένες σε σχέση με τα δεδομένα της πραγματικής κατάστασης. |   2   |  V   |
| 13.6.4 | Επαληθεύστε ότι η διάδοση της αβεβαιότητας διατηρείται μέσω πολυδιάστατων ροών εργασίας ΤΝ.                                                           |   3   | D/V  |

---

## C13.7 Αναφορές Διαφάνειας Προσανατολισμένες στον Χρήστη

Παρέχετε περιοδικές αποκαλύψεις σχετικά με τα περιστατικά, τη μετατόπιση και τη χρήση δεδομένων.

|   #    | Description                                                                                                                                                    | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 13.7.1 | Επαληθεύστε ότι οι πολιτικές χρήσης δεδομένων και οι πρακτικές διαχείρισης συναίνεσης χρηστών επικοινωνούνται σαφώς στους ενδιαφερόμενους φορείς.              |   1   | D/V  |
| 13.7.2 | Επιβεβαιώστε ότι οι αξιολογήσεις επιπτώσεων της ΤΝ διεξάγονται και τα αποτελέσματα περιλαμβάνονται στην αναφορά.                                               |   2   | D/V  |
| 13.7.3 | Επαληθεύστε ότι οι εκθέσεις διαφάνειας που δημοσιεύονται τακτικά αποκαλύπτουν περιστατικά τεχνητής νοημοσύνης και λειτουργικούς δείκτες με λογική λεπτομέρεια. |   2   | D/V  |

### Αναφορές

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX%3A32016R0679)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

