# پیش‌گفتار

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

## مقدمه

AISVS که در سال 2025 از طریق یک تلاش جامعه‌محور همکاری تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های هوش مصنوعی مدرن، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی مد نظر قرار گیرند، تعریف می‌کند.

AISVS نسخه 1.0 نمایانگر کار مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک نقطه شروع عملی و قابل آزمایش برای تأمین امنیت سیستم‌های هوش مصنوعی ایجاد کنند.

هدف ما در این نسخه این است که AISVS را به‌سادگی قابل استفاده کنیم در حالی که به دقت بر حوزه تعریف‌شده آن متمرکز مانده و به چشم‌انداز ریسک به سرعت در حال تغییر که مختص هوش مصنوعی است، پاسخ دهیم.

## اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چند اصل راهنما ایجاد خواهد شد.

### دامنه مشخص و تعریف‌شده

هر نیاز باید با نام و مأموریت AISVS هم‌راستا باشد:

* هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا نتیجه‌گیری) عمل می‌کنند و مسئولیت آن‌ها بر عهده کارشناسان هوش مصنوعی است.
* امنیت - الزامات به طور مستقیم خطرات امنیتی، حریم خصوصی یا ایمنی شناسایی‌شده را کاهش می‌دهند.
* اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتوان به‌طور عینی مورد ارزیابی قرار داد.
* استاندارد – بخش‌ها ساختار و اصطلاحات منسجمی را دنبال می‌کنند تا مرجع منسجمی ایجاد کنند.
  ​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی ایمن هوش مصنوعی را ترویج دهند.

