# اعتبارسنجی ورودی کاربر C2

## هدف کنترل

اعتبارسنجی قوی ورودی کاربر خط اول دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورات سیستم را لغو کنند، داده‌های حساس را نشت دهند یا مدل را به سمت رفتارهای غیرمجاز هدایت کنند. تحقیقات نشان می‌دهد که مگر فیلترهای اختصاصی و سلسله مراتب دستوری برقرار باشند، حملات "چندشات" فرار از محدودیت که از پنجره‌های متنی طولانی بهره می‌برند، مؤثر خواهند بود. همچنین، حملات تغییرات جزئی خصمانه—مانند تعویض هم‌نویس‌ها (homoglyph) یا استفاده از زبان لیتی (leetspeak)—می‌توانند به‌طور پنهانی تصمیمات مدل را تغییر دهند.

---

## C2.1 دفاع در برابر تزریق پرامپت

تزریق دستورات یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. تدابیر دفاعی در برابر این روش از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتبی دستورالعمل‌ها استفاده می‌کنند.

|   #   | Description                                                                                                                                                                                                                             | Level | Role |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.1.1 | اطمینان حاصل کنید که ورودی‌های کاربر در برابر کتابخانه‌ای به‌روز شده به صورت مداوم از الگوهای شناخته شده تزریق فرمان (کلمات کلیدی فرار از محدودیت، «نادیده گرفتن قبلی»، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند. |   1   | D/V  |
| 2.1.2 | تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجره‌ی زمینه.                                                                   |   1   | D/V  |
| 2.1.3 | اطمینان حاصل کنید که تست‌های ارزیابی خصمانه (مثلاً پرامپت‌های "چند-شات" تیم قرمز) قبل از هر انتشار مدل یا الگوی پرامپت اجرا می‌شوند، با تعیین حد آستانه نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.                               |   2   | D/V  |
| 2.1.4 | تأیید کنید که پرامپت‌های منبع از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه تجزیه جداگانه پاک‌سازی شده‌اند قبل از اینکه در پرامپت اصلی الحاق شوند.                                                                  |   2   |  D   |
| 2.1.5 | اطمینان حاصل کنید که تمام به‌روزرسانی‌های قوانین فیلتر متن، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات لیست مسدودکننده تحت کنترل نسخه و قابل بررسی باشند.                                                                                   |   3   | D/V  |

---

## C2.2 مقاومت در برابر نمونه‌های مخرب

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب متوجه آن‌ها نمی‌شوند ولی مدل‌ها معمولاً آن‌ها را اشتباه طبقه‌بندی می‌کنند.

|   #   | Description                                                                                                                                                                                            | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 2.2.1 | اطمینان حاصل کنید که مراحل اولیه نرمال‌سازی ورودی (NFC یونیکد، نگاشت هم‌ریخت‌ها، حذف فاصله‌های اضافی) قبل از توکنیزه کردن اجرا می‌شوند.                                                                |   1   |  D   |
| 2.2.2 | اطمینان حاصل کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمولاً بالا نسبت به هنجارهای زبانی، توکن‌های تکراری بیش از حد، یا فاصله‌های نهان‌سازی غیرطبیعی دارند، علامت‌گذاری می‌کند. |   2   | D/V  |
| 2.2.3 | اطمینان حاصل کنید که خط لوله استنتاج از انواع مدل‌های تقویت‌شده با آموزش خصمانه اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.              |   2   |  D   |
| 2.2.4 | اطمینان حاصل کنید که ورودی‌های مشکوک به حملات خصمانه قرنطینه شده و با کل داده‌های بار (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.                                                                    |   2   |  V   |
| 2.2.5 | اطمینان حاصل کنید که معیارهای پایداری (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان پیگیری می‌شوند و کاهش عملکرد موجب مسدود شدن انتشار می‌شود.                                                      |   3   | D/V  |

---

## اعتبارسنجی طرحواره، نوع و طول C2.3

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بزرگ‌تر از حد مجاز هستند، می‌توانند باعث بروز خطاهای پارسینگ، نشت دستور به فیلدهای دیگر و خستگی منابع شوند. اعمال سخت‌گیرانه‌تر قواعد ساختاری (اسکیما) نیز پیش‌نیاز انجام فراخوانی‌های قطعی ابزارها است.

|   #   | Description                                                                                                                                                                           | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.3.1 | اطمینان حاصل کنید که هر نقطه پایان فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندوجهی آن) تعریف می‌کند و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند. |   1   |  D   |
| 2.3.2 | تأیید کنید که ورودی‌هایی که از بیشینه تعداد توکن یا محدودیت بایت فراتر می‌روند، با یک خطای ایمن رد می‌شوند و هرگز به‌طور بی‌صدا کوتاه نمی‌شوند.                                       |   1   | D/V  |
| 2.3.3 | تأیید کنید که بررسی‌های نوع (مثلاً بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند، نه فقط در کد سمت کلاینت.                                      |   2   | D/V  |
| 2.3.4 | اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابتی اجرا می‌شوند تا از حملات انکار سرویس الگوریتمی جلوگیری شود.                                               |   2   |  D   |
| 2.3.5 | تأیید کنید که شکست‌های اعتبارسنجی با قطعات بارگذاری محرمانه‌شده و کدهای خطای بدون ابهام ثبت می‌شوند تا به جداسازی امنیتی کمک کنند.                                                    |   3   |  V   |

---

## C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند درخواست‌های دستوری معتبر که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق نشر) را درخواست می‌کنند، تشخیص دهند و سپس از انتشار آنها جلوگیری کنند.

|   #   | Description                                                                                                                                                                                            | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 2.4.1 | اطمینان حاصل کنید که یک دسته‌بند محتوا (صفر شات یا تنظیم‌شده دقیق) برای هر ورودی، امتیازهایی برای خشونت، آسیب به خود، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارائه می‌دهد. |   1   |  D   |
| 2.4.2 | تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت می‌کنند تا به تماس‌های بعدی مدل‌های زبانی بزرگ منتقل نشوند.                                         |   1   | D/V  |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده‌شده در خصوص دور زدن محدودیت‌ها یا قوانین را در بر می‌گیرد.                  |   2   |  D   |
| 2.4.4 | اطمینان حاصل کنید که غربالگری قوانین خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.                                         |   2   |  D   |
| 2.4.5 | اطمینان حاصل کنید که گزارش‌های غربالگری شامل امتیازهای اعتماد طبقه‌بند و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.                                                      |   3   |  V   |

---

## C2.5 محدودسازی نرخ ورودی و پیشگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، تخلیه منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

|   #   | Description                                                                                                                                                               | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.5.1 | تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر آدرس IP و هر کلید API برای تمامی نقاط ورودی اعمال می‌شوند.                                                                |   1   | D/V  |
| 2.5.2 | بررسی کنید که محدودیت‌های نرخ انفجاری و مداوم به گونه‌ای تنظیم شده باشند که از حملات محروم‌سازی سرویس (DoS) و حملات حدس زدن بی‌رحمانه جلوگیری کنند.                       |   2   | D/V  |
| 2.5.3 | تأیید کنید که الگوهای استفاده غیرعادی (به عنوان مثال، درخواست‌های پشت سر هم سریع، پر کردن ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح اقدامات امنیتی می‌شوند. |   2   | D/V  |
| 2.5.4 | تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده حفظ شده و برای الگوهای حمله جدید بررسی می‌شوند.                                                                               |   3   |  V   |

---

## C2.6 اعتبارسنجی ورودی چندوجهی

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صداها، فایل‌ها) داشته باشند تا از تزریق، دورزدن یا سوء استفاده از منابع جلوگیری کنند.

|   #   | Description                                                                                                                       | Level | Role |
| :---: | --------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.6.1 | اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت اعتبارسنجی شده باشند. |   1   |  D   |
| 2.6.2 | اطمینان حاصل کنید که فایل‌ها پیش از واردسازی برای بدافزارها و بارهای استگانوگرافیکی اسکن می‌شوند.                                 |   2   | D/V  |
| 2.6.3 | تأیید کنید که ورودی‌های تصویر/صدا برای تغییرات مخرب یا الگوهای حمله شناخته شده بررسی شده‌اند.                                     |   2   | D/V  |
| 2.6.4 | تأیید کنید که شکست‌های اعتبارسنجی ورودی چندوجهی ثبت شده و هشدارهایی برای بررسی فعال شوند.                                         |   3   |  V   |

---

## C2.7 منبع ورودی و نسبت‌دهی

سیستم‌های هوش مصنوعی باید با ردیابی سوءاستفاده، حسابرسی و رعایت قوانین از طریق نظارت و برچسب‌گذاری منابع تمامی ورودی‌های کاربران را پشتیبانی کنند.

|   #   | Description                                                                                                                                 | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.7.1 | اطمینان حاصل کنید که تمام ورودی‌های کاربر در هنگام دریافت با فراداده‌ها (شناسه کاربر، جلسه، منبع، زمان‌مهر، آدرس IP) برچسب‌گذاری شده باشند. |   1   | D/V  |
| 2.7.2 | اطمینان حاصل کنید که متاداده منبع حفظ شده و برای تمام ورودی‌های پردازش شده قابل حسابرسی باشد.                                               |   2   | D/V  |
| 2.7.3 | اطمینان حاصل شود که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.                   |   2   | D/V  |

---

## C2.8 شناسایی تهدید تطبیقی بلادرنگ

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و با استفاده از تطبیق الگوهای کامپایل‌شده، حفاظت بلادرنگ ارائه دهند.

|   #   | Description                                                                                                                                                               | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.8.1 | تأیید کنید که الگوهای شناسایی تهدید به موتورهای بیان منظم بهینه شده (regex) کامپایل شده‌اند تا برای فیلترکردن لحظه‌ای با کارایی بالا و حداقل تأخیر به کار روند.           |   1   | D/V  |
| 2.8.2 | تأیید کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌بندی‌های مختلف تهدید (تزریق درخواست، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند. |   1   | D/V  |
| 2.8.3 | تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.                                |   2   | D/V  |
| 2.8.4 | تأیید کنید که فیدهای اطلاعات تهدید بلادرنگ به صورت خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCها) به‌روزرسانی می‌کنند.                          |   2   | D/V  |
| 2.8.5 | تأیید کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌طور خودکار تنظیم می‌شوند تا حداقل مداخله در موارد استفاده مشروع ایجاد شود.  |   3   | D/V  |
| 2.8.6 | تأیید کنید که تحلیل تهدید متنی شامل منبع ورودی، الگوهای رفتار کاربر و تاریخچه نشست برای بهبود دقت شناسایی است.                                                            |   3   | D/V  |
| 2.8.7 | تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به صورت زمان واقعی رصد و بهینه‌سازی می‌شوند.                                        |   3   | D/V  |

---

## C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صدا و سایر حالت‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

|   #   | Description                                                                                                                                                                                                                                        | Level | Role |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.9.1 | اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده است (متن: تزریق درخواست، تصاویر: پنهان‌نگاری، صدا: حملات طیف‌نگاری) و آستانه‌های تشخیص مشخص می‌باشد.                                              |   1   | D/V  |
| 2.9.2 | تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های ایزوله شده (sandbox) با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که برای هر نوع حالت چندرسانه‌ای تعریف شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.         |   2   | D/V  |
| 2.9.3 | تأیید کنید که شناسایی حملات چندمودالی حملات هماهنگ شده در چندین نوع ورودی (مانند بارهای پنهان در تصاویر همراه با تزریق پرامپت در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.                                                |   2   | D/V  |
| 2.9.4 | اطمینان حاصل کنید که خطاهای اعتبارسنجی چند حالته باعث ثبت دقیق و گزارش‌های تفصیلی شامل همه حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختارمند گزارش برای یکپارچه‌سازی با SIEM می‌شوند.                        |   3   | D/V  |
| 2.9.5 | اطمینان حاصل شود که طبقه‌بندی‌کننده‌های محتوای خاص هر نوع مدالیته طبق برنامه‌های مستند شده (حداقل هر سه ماه یک‌بار) با الگوهای تهدید جدید، نمونه‌های متخاصم و شاخص‌های عملکرد که بالاتر از آستانه‌های پایه نگه داشته می‌شوند، به‌روزرسانی می‌شوند. |   3   | D/V  |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

