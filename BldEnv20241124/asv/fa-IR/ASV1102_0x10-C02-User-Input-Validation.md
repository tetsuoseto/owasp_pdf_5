# اعتبارسنجی ورودی کاربر C2

## هدف کنترل

اعتبارسنجی قوی ورودی کاربر اولین خط دفاع در برابر برخی از مخرب‌ترین حملات بر سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را نادیده بگیرند، داده‌های حساس را نشت دهند یا مدل را به سمت رفتارهای غیرمجاز هدایت کنند. مگر اینکه فیلترهای ویژه و سلسله مراتب دستورات اعمال شده باشد، تحقیقات نشان می‌دهد که "jailbreak" های چند مرحله‌ای که از پنجره‌های متنی بسیار بلند بهره می‌برند، مؤثر خواهند بود. همچنین، حملات ظریف تغییر مخرب—مانند جابجایی‌های هوموگلیف یا استفاده از زبان لِیت—می‌توانند به صورت بی‌صدا تصمیمات مدل را تغییر دهند.

---

## دفاع در برابر تزریق درخواست (Prompt Injection Defense)

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

|   #   | Description                                                                                                                                                                                                                      | Level | Role |
| :---: | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.1.1 | اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مستمر از الگوهای شناخته شده تزریق درخواست (کلیدواژه‌های فرار از زندان، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند. |   1   | D/V  |
| 2.1.2 | تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجرهٔ زمینه.                                                             |   1   | D/V  |
| 2.1.3 | اطمینان حاصل کنید که آزمایش‌های ارزیابی خصمانه (برای مثال، درخواست‌های "چندتایی" تیم قرمز) قبل از انتشار هر مدل یا قالب درخواست اجرا می‌شوند، همراه با تعیین آستانه‌های نرخ موفقیت و بلوکرهای خودکار برای عقب‌گردها.             |   2   | D/V  |
| 2.1.4 | اطمینان حاصل کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) می‌آیند، در یک زمینه تفسیر ایزوله شده پاک‌سازی می‌شوند قبل از اینکه به درخواست اصلی اضافه شوند.                                       |   2   |  D   |
| 2.1.5 | اطمینان حاصل کنید که همه به‌روزرسانی‌های قانون فیلتر درخواست، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده تحت کنترل نسخه بوده و قابل حسابرسی باشند.                                                                   |   3   | D/V  |

---

## C2.2 مقاومت در برابر مثال‌های ضد حال

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات جزئی در سطح کاراکتر یا کلمه آسیب‌پذیر هستند، تغییراتی که انسان‌ها معمولاً متوجه آن‌ها نمی‌شوند اما مدل‌ها به اشتباه طبقه‌بندی می‌کنند.

|   #   | Description                                                                                                                                                                              | Level | Role |
| :---: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.2.1 | اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هوموگلیف، حذف فاصله‌های اضافی) قبل از توکنیزاسیون اجرا می‌شوند.                                                     |   1   |  D   |
| 2.2.2 | تأیید کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایش غیرمعمولاً بالایی نسبت به معیارهای زبانی دارند، توکن‌های تکراری زیاد یا فواصل تعبیه غیرطبیعی دارند، علامت‌گذاری می‌کند. |   2   | D/V  |
| 2.2.3 | تأیید کنید که خط لوله استنتاج، نسخه‌های مدل مقاوم شده با آموزش متخاصم اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) را برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.       |   2   |  D   |
| 2.2.4 | تأیید کنید که ورودی‌های مشکوک به حملات خصمانه قرنطینه شده و با کل داده‌های بار (پس از حذف اطلاعات شخصی شناسایی‌پذیر) ثبت می‌شوند.                                                        |   2   |  V   |
| 2.2.5 | اطمینان حاصل کنید که معیارهای مقاومت (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان ثبت می‌شوند و پسرفت‌ها باعث ایجاد مانع در انتشار می‌شوند.                                          |   3   | D/V  |

---

## C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بیش از حد بزرگ هستند می‌توانند باعث خطاهای تجزیه، انتشار فرمان در بین فیلدها و خستگی منابع شوند. همچنین، اعمال دقیق اسکیمای سختگیرانه هنگام انجام فراخوانی‌های ابزاری قطعی یک پیش‌شرط است.

|   #   | Description                                                                                                                                                                         | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.3.1 | تأیید کنید که هر نقطه انتهایی فراخوانی API یا تابع، یک ساختار ورودی صریح (JSON Schema، Protobuf یا معادل چند‌وجهی) تعریف کرده است و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند. |   1   |  D   |
| 2.3.2 | اطمینان حاصل کنید که ورودی‌های بیشتر از حد مجاز توکن یا بایت با خطایی ایمن رد شده و هرگز به‌صورت خاموش کوتاه نشده‌اند.                                                              |   1   | D/V  |
| 2.3.3 | اطمینان حاصل کنید که بررسی نوع‌ها (مانند بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور نیز اعمال می‌شود و نه فقط در کد سمت کاربر.                           |   2   | D/V  |
| 2.3.4 | اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات محروم‌سازی سرویس الگوریتمی جلوگیری شود.                                         |   2   |  D   |
| 2.3.5 | اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات بار مخفی شده و کدهای خطای واضح برای کمک به واکاوی امنیتی ثبت می‌شوند.                                                               |   3   |  V   |

---

## C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند تا درخواست‌های دستوری صحیح نحوی که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق نسخه‌برداری) را درخواست می‌کنند، شناسایی کرده و سپس از گسترش آنها جلوگیری کنند.

|   #   | Description                                                                                                                                                                                                         | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.4.1 | اطمینان حاصل کنید که یک طبقه‌بند محتوا (بدون آموزش قبلی یا آموزش داده شده) هر ورودی را از نظر خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارزیابی می‌کند.                   |   1   |  D   |
| 2.4.2 | اطمینان حاصل کنید که ورودی‌هایی که نقض‌کننده سیاست‌ها هستند، پاسخ‌های استاندارد شده‌ای از نوع رد درخواست یا تکمیل‌های ایمن دریافت می‌کنند تا این ورودی‌ها به فراخوان‌های پایین‌دستی مدل‌های زبانی بزرگ منتقل نشوند. |   1   | D/V  |
| 2.4.3 | اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل به صورت فصلی بازآموزی/به‌روزرسانی می‌شود و الگوهای تازه مشاهده شده فرار از محدودیت یا دور زدن سیاست را در بر می‌گیرد.                                      |   2   |  D   |
| 2.4.4 | تأیید کنید که غربالگری از سیاست‌های خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، پیروی می‌کند.                                                           |   2   |  D   |
| 2.4.5 | تأیید کنید که گزارش‌های غربالگری شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و اجرای مجدد تیم قرمز در آینده باشند.                                                          |   3   |  V   |

---

## C2.5 محدودیت نرخ ورودی و پیشگیری از سوء استفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی، از سوءاستفاده، تمام شدن منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

|   #   | Description                                                                                                                                                                 | Level | Role |
| :---: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.5.1 | تأیید کنید که محدودیت‌های نرخ بر اساس هر کاربر، هر IP و هر کلید API برای تمامی نقطه‌های ورودی اعمال می‌شود.                                                                 |   1   | D/V  |
| 2.5.2 | بررسی کنید که محدودیت‌های نرخ انفجاری (burst) و پایدار (sustained) به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات جستجوی فراگیر (brute force) جلوگیری کنند. |   2   | D/V  |
| 2.5.3 | تأیید کنید که الگوهای استفاده غیرعادی (مثلاً درخواست‌های سریع پشت سر هم، ارسال انبوه ورودی) باعث فعال شدن بلوک‌های خودکار یا افزایش سطح نظارت شوند.                         |   2   | D/V  |
| 2.5.4 | اطمینان حاصل کنید که لاگ‌های پیشگیری از سوء استفاده نگهداری شده و برای الگوهای حمله نوظهور بررسی می‌شوند.                                                                   |   3   |  V   |

---

## C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، فرار یا سوء استفاده از منابع جلوگیری شود.

|   #   | Description                                                                                                                   | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.6.1 | اطمینان حاصل کنید که تمام ورودی‌های غیرمتنی (تصاویر، صدا، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت معتبرسازی شده‌اند. |   1   |  D   |
| 2.6.2 | بررسی کنید که فایل‌ها قبل از ورود برای بدافزار و بارهای استگانوگرافیک اسکن شوند.                                              |   2   | D/V  |
| 2.6.3 | تأیید کنید که ورودی‌های تصویر/صدا برای اختلالات مخرب یا الگوهای حمله شناخته‌شده بررسی شده‌اند.                                |   2   | D/V  |
| 2.6.4 | تأیید کنید که خطاهای اعتبارسنجی ورودی چند‌وجهی ثبت می‌شوند و هشدارهایی برای بررسی ایجاد می‌کنند.                              |   3   |  V   |

---

## C2.7 منبع ورودی و انتساب

سیستم‌های هوش مصنوعی باید با پایش و برچسب‌گذاری منبع تمام ورودی‌های کاربران، از حسابرسی، پیگیری سوءاستفاده و تطابق پشتیبانی کنند.

|   #   | Description                                                                                                                               | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.7.1 | تأیید کنید که تمام ورودی‌های کاربر هنگام دریافت با فراداده‌هایی مانند شناسه کاربر، جلسه، منبع، زمان‌بندی و آدرس IP علامت‌گذاری شده باشند. |   1   | D/V  |
| 2.7.2 | اطمینان حاصل کنید که متاداده‌های منشأ برای تمام ورودی‌های پردازش‌شده حفظ شده و قابل حسابرسی باشند.                                        |   2   | D/V  |
| 2.7.3 | تأیید کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.                          |   2   | D/V  |

---

## C2.8 شناسایی تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و با مطابقت الگوهای کامپایل شده حفاظت به‌موقع ارائه می‌دهند.

|   #   | Description                                                                                                                                                                          | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 2.8.1 | اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه شده برای فیلتر کردن با عملکرد بالا و تأخیر حداقلی در زمان واقعی تبدیل شده‌اند.                                      |   1   | D/V  |
| 2.8.2 | اطمینان حاصل کنید که سیستم‌های شناسایی تهدید برای دسته‌بندی‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، فرمان‌های سیستمی) کتابخانه‌های الگو جداگانه‌ای نگهداری می‌کنند. |   1   | D/V  |
| 2.8.3 | اطمینان حاصل کنید که تشخیص تهدید تطبیقی از مدل‌های یادگیری ماشین استفاده می‌کند که حساسیت به تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.                        |   2   | D/V  |
| 2.8.4 | اطمینان حاصل کنید که فیدهای اطلاعات تهدید در زمان واقعی به صورت خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.                         |   2   | D/V  |
| 2.8.5 | تأیید کنید که نرخ‌های مثبت کاذب تشخیص تهدید به‌طور مداوم پایش می‌شوند و ویژگی‌های الگو به‌صورت خودکار تنظیم می‌شوند تا از تداخل با موارد استفاده قانونی به حداقل برسد.               |   3   | D/V  |
| 2.8.6 | تأیید کنید که تحلیل تهدید زمینه‌ای منابع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت شناسایی در نظر می‌گیرد.                                                         |   3   | D/V  |
| 2.8.7 | اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به‌صورت لحظه‌ای نظارت و بهینه‌سازی می‌شوند.                                             |   3   | D/V  |

---

## خط لوله اعتبارسنجی امنیت چندرسانه‌ای C2.9

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و ایزوله‌سازی منابع فراهم کنند.

|   #   | Description                                                                                                                                                                                                                         | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 2.9.1 | تأیید کنید که هر مدالیته ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند (متن: تزریق درخواست، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.                                                |   1   | D/V  |
| 2.9.2 | تأیید کنید که ورودی‌های چندوجهی در محیط‌های ایزوله شده با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که به‌طور خاص برای هر نوع مدالیتی تعریف شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده باشد.     |   2   | D/V  |
| 2.9.3 | بررسی کنید که تشخیص حملات چندمدلی حملات هماهنگ شده‌ای که در چندین نوع ورودی گسترده می‌شوند (مثلاً بارهای پنهان استگانوگرافیک در تصاویر به همراه تزریق پرسش در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.    |   2   | D/V  |
| 2.9.4 | تأیید کنید که خطاهای اعتبارسنجی چندمودالی باعث ثبت دقیق و کامل لاگ‌ها می‌شوند که شامل تمامی حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختاریافته لاگ برای یکپارچه‌سازی با سیستم‌های SIEM باشد. |   3   | D/V  |
| 2.9.5 | اطمینان حاصل کنید که طبقه‌بندهای محتوای خاص هر حالت بر اساس برنامه‌های مستند (حداقل فصلی) با الگوهای تهدید جدید، مثال‌های مخرب و معیارهای عملکرد که بالاتر از آستانه‌های پایه حفظ می‌شوند، به‌روزرسانی شده‌اند.                     |   3   | D/V  |

---

## مراجع

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

