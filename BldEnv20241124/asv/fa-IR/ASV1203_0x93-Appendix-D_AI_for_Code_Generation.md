# پیوست د: حاکمیت و تأیید کدگذاری امن با کمک هوش مصنوعی

## هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی مبتنی بر هوش مصنوعی در طول توسعه نرم‌افزار تعریف می‌کند تا امنیت و قابل ردیابی بودن در سراسر چرخه عمر توسعه نرم‌افزار را تضمین کند.

---

## AD.1 جریان کاری رمزگذاری ایمن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) ادغام کنید بدون اینکه نقاط کنترل امنیتی موجود را تضعیف کنید.

|   #    | Description                                                                                                                                                                  | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AD.1.1 | اطمینان حاصل کنید که یک روند کاری مستند شده شرح می‌دهد چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد را تولید، بازسازی یا مرور کنند.                                      |   1   | D/V  |
| AD.1.2 | تأیید کنید که جریان کاری به هر مرحله از چرخه توسعه نرم‌افزار امن شده (SSDLC) مرتبط باشد (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار).                                       |   2   |  D   |
| AD.1.3 | اطمینان حاصل کنید که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان تشخیص) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با معیارهای پایه‌ی صرفاً انسانی مقایسه می‌شوند. |   3   | D/V  |

---

## AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای برنامه‌نویسی هوش مصنوعی قبل از استفاده، از نظر قابلیت‌های امنیتی، ریسک و تأثیر بر زنجیره تامین ارزیابی شوند.

|   #    | Description                                                                                                                                 | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AD.2.1 | تأیید کنید که مدل تهدید برای هر ابزار هوش مصنوعی، سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی را شناسایی می‌کند.               |   1   | D/V  |
| AD.2.2 | تأیید کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) باشد. |   2   |  D   |
| AD.2.3 | اطمینان حاصل کنید که ارزیابی‌ها بر اساس یک چارچوب شناخته‌شده انجام می‌شوند و پس از تغییرات عمده نسخه مجدداً انجام می‌گیرند.                 |   3   | D/V  |

---

## AD.3 مدیریت امن نمایش و زمینه

از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی جلوگیری کنید.

|   #    | Description                                                                                                                                            | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| AD.3.1 | تأیید کنید که دستورالعمل‌های مکتوب ارسال اسرار، مدارک شناسایی یا داده‌های محرمانه در درخواست‌ها را ممنوع می‌کند.                                       |   1   | D/V  |
| AD.3.2 | تأیید کنید که کنترل‌های فنی (حذف اطلاعات در سمت کاربر، فیلترهای زمینه تأیید شده) به‌صورت خودکار آثار حساس را حذف می‌کنند.                              |   2   |  D   |
| AD.3.3 | تأیید کنید که پرسش‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت ذخیره رمزگذاری شده‌اند و دوره‌های نگهداری مطابق با سیاست دسته‌بندی داده‌ها هستند. |   3   | D/V  |

---

## AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی هوش مصنوعی پیش از ادغام یا استقرار کد.

|   #    | Description                                                                                                                                                                                   | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AD.4.1 | اطمینان حاصل کنید که کد تولیدشده توسط هوش مصنوعی همواره تحت بازبینی کد توسط انسان قرار می‌گیرد.                                                                                               |   1   | D/V  |
| AD.4.2 | اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) بر روی هر درخواست کششی که شامل کد تولید شده توسط هوش مصنوعی است اجرا می‌شوند و ادغام‌ها را در صورت وجود یافته‌های بحرانی مسدود می‌کنند. |   2   |  D   |
| AD.4.3 | اطمینان حاصل کنید که تست‌های فازینگ تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی مانند اعتبارسنجی ورودی و منطق تأیید هویت را اثبات می‌کنند.                                        |   3   | D/V  |

---

## AD.5 قابل تبیین بودن و قابلیت ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان دیدگاهی ارائه دهید درباره اینکه چرا یک پیشنهاد مطرح شده است و چگونه توسعه یافته است.

|   #    | Description                                                                                                                                                                               | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AD.5.1 | تأیید کنید که جفت‌های درخواست/پاسخ با شناسه‌های تعهد (commit IDs) ثبت شده‌اند.                                                                                                            |   1   | D/V  |
| AD.5.2 | تأیید کنید که توسعه‌دهندگان می‌توانند ارجاعات مدل (بخش‌های آموزشی، مستندات) که پیشنهاد را پشتیبانی می‌کنند، نمایش دهند.                                                                   |   2   |  D   |
| AD.5.3 | اطمینان حاصل کنید که گزارش‌های تبیینی همراه با مستندات طراحی ذخیره شده و در بازبینی‌های امنیتی ارجاع داده می‌شوند، به طوری که اصول قابلیت ردیابی استاندارد ISO/IEC 42001 را برآورده کنند. |   3   | D/V  |

---

## AD.6 بازخورد مستمر و تنظیم دقیق مدل

بهبود عملکرد امنیت مدل در طول زمان در حالی که از انحراف منفی جلوگیری می‌شود.

|   #    | Description                                                                                                                                                                             | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AD.6.1 | بررسی کنید که توسعه‌دهندگان بتوانند پیشنهادات ناامن یا غیرسازگار را علامت‌گذاری کنند و اینکه این علامت‌گذاری‌ها پیگیری می‌شوند.                                                         |   1   | D/V  |
| AD.6.2 | اطمینان حاصل کنید که بازخورد تجمیع شده به آموزش دقیق دوره‌ای یا تولید با بازیابی تقویت‌شده با مجموعه داده‌های کدنویسی امن بررسی شده (مانند OWASP Cheat Sheets) اطلاع می‌دهد.            |   2   |  D   |
| AD.6.3 | اطمینان حاصل کنید که بسترسنجی ارزیابی حلقه بسته پس از هر بار تنظیم دقیق، آزمایش‌های رگرسیون را اجرا می‌کند؛ شاخص‌های امنیتی باید قبل از استقرار با یا بهتر از معیارهای پایه قبلی باشند. |   3   | D/V  |

---

### مراجع

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [OWASP Secure Coding Practices — Quick Reference Guide](https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/)

