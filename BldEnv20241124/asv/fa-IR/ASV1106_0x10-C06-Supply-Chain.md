# امنیت زنجیره تأمین C6 برای مدل‌ها، فریم‌ورک‌ها و داده‌ها

## هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه داده‌های شخص ثالث سوءاستفاده می‌کنند تا درب‌های پشتی، تعصب یا کد قابل سوءاستفاده را تزریق کنند. این کنترل‌ها ارائه‌دهنده شناسایی کامل منشأ، مدیریت آسیب‌پذیری و نظارت هستند تا از کل چرخه عمر مدل حفاظت کنند.

---

## C6.1 بررسی و تایید مدل‌های از پیش آموزش دیده و منشأ آن‌ها

پیش از هرگونه میکروفاین‌تیونینگ یا استقرار، اصالت، مجوزها و رفتارهای پنهان مدل‌های شخص ثالث را ارزیابی و تأیید کنید.

|   #   | Description                                                                                                                                                       | Level | Role |
| :---: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.1.1 | اطمینان حاصل کنید که هر مدل مصنوعی ثالث شامل یک سابقه منشأ امضا شده است که مخزن منبع و هش تعهد را شناسایی می‌کند.                                                 |   1   | D/V  |
| 6.1.2 | اطمینان حاصل کنید که مدل‌ها با استفاده از ابزارهای خودکار برای لایه‌های مخرب یا محرک‌های تروجان اسکن می‌شوند قبل از وارد کردن آن‌ها.                              |   1   | D/V  |
| 6.1.3 | اطمینان حاصل کنید که تنظیم دقیق آموزش انتقالی، ارزیابی ضد حمله را پشت سر می‌گذارد تا رفتارهای پنهان را شناسایی کند.                                               |   2   |  D   |
| 6.1.4 | اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات و اظهارات منبع داده در یک ورودی ML-BOM ثبت شده باشند.                                                    |   2   |  V   |
| 6.1.5 | اطمینان حاصل کنید که مدل‌های با ریسک بالا (وزن‌های بارگذاری شده به‌صورت عمومی، ایجادکنندگان تأییدنشده) تا زمان بررسی و تأیید توسط انسان در قرنطینه باقی می‌مانند. |   3   | D/V  |

---

## C6.2 چهارچوب و اسکن کتابخانه

به طور مداوم فریم‌ورک‌ها و کتابخانه‌های یادگیری ماشین را برای آسیب‌پذیری‌های امنیتی (CVE) و کدهای مخرب اسکن کنید تا پشته زمان اجرا امن بماند.

|   #   | Description                                                                                                                           | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.2.1 | تأیید کنید که خط لوله‌های CI اسکنرهای وابستگی را روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.                         |   1   | D/V  |
| 6.2.2 | تأیید کنید که آسیب‌پذیری‌های حیاتی (CVSS ≥ 7.0) باعث جلوگیری از ارتقاء به تصاویر تولیدی می‌شوند.                                      |   1   | D/V  |
| 6.2.3 | تأیید کنید که تحلیل کد ایستا روی کتابخانه‌های ML منشعب شده یا فروخته شده اجرا می‌شود.                                                 |   2   |  D   |
| 6.2.4 | اطمینان حاصل کنید که پیشنهادات ارتقاء فریمورک شامل ارزیابی تأثیر امنیتی با ارجاع به منابع عمومی CVE باشد.                             |   2   |  V   |
| 6.2.5 | اطمینان حاصل کنید که حسگرهای زمان اجرا در مورد بارگذاری کتابخانه‌های پویا غیرمنتظره که از SBOM امضا شده منحرف شده‌اند، هشدار می‌دهند. |   3   |  V   |

---

## C6.3 تثبیت وابستگی و تایید صحت

تمام وابستگی‌ها را به شناسه‌های تغییرناپذیر (immutable digests) قفل کنید و ساخت‌ها را بازتولید کنید تا از تولید آثار یکسان و بدون دستکاری اطمینان حاصل شود.

|   #   | Description                                                                                                                     | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.3.1 | اطمینان حاصل کنید که تمام مدیران بسته نسخه‌ها را از طریق فایل‌های قفل شده کنترل می‌کنند.                                        |   1   | D/V  |
| 6.3.2 | اطمینان حاصل کنید که به جای تگ‌های قابل تغییر، از خلاصه‌های غیرقابل تغییر در ارجاعات کانتینر استفاده می‌شود.                    |   1   | D/V  |
| 6.3.3 | اطمینان حاصل کنید که بررسی‌های ساخت قابل بازتولید، هش‌ها را در طول اجرای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شوند.       |   2   |  D   |
| 6.3.4 | اطمینان حاصل کنید که گواهی‌های ساخت به مدت 18 ماه برای قابلیت پیگیری حسابرسی ذخیره می‌شوند.                                     |   2   |  V   |
| 6.3.5 | تأیید کنید که وابستگی‌های منقضی‌شده باعث ایجاد درخواست‌های خودکار (PR) برای به‌روزرسانی یا ایجاد فورک نسخه‌های پین‌شده می‌شوند. |   3   |  D   |

---

## C6.4 اجرای منبع مورد اعتماد

تنها اجازه دانلود آر تیفکت‌ها از منابع تایید شده رمزنگاری شده و مورد تایید سازمان را بدهید و تمام موارد دیگر را مسدود کنید.

|   #   | Description                                                                                                                  | Level | Role |
| :---: | ---------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 6.4.1 | اطمینان حاصل کنید که وزن‌های مدل، مجموعه داده‌ها و کانتینرها فقط از دامنه‌های تایید شده یا رجیستری‌های داخلی دانلود می‌شوند. |   1   | D/V  |
| 6.4.2 | تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از اینکه آرтификت‌ها به صورت محلی کش شوند، اعتبارسنجی می‌کنند.        |   1   | D/V  |
| 6.4.3 | تأیید کنید که پراکسی‌های خروجی دانلودهای بدون احراز هویت اشیاء را مسدود می‌کنند تا سیاست منبع مورد اعتماد را اعمال کنند.     |   2   |  D   |
| 6.4.4 | اطمینان حاصل کنید که فهرست‌های مجاز مخزن به صورت سه‌ماهه بازبینی می‌شوند و برای هر ورودی، شواهدی از توجیه تجاری وجود دارد.   |   2   |  V   |
| 6.4.5 | اطمینان حاصل کنید که نقض سیاست‌ها باعث قرنطینه شدن آثار و بازگردانی اجرای‌های وابسته به لوله‌کشی می‌شود.                     |   3   |  V   |

---

## C6.5 ارزیابی ریسک داده‌های شخص ثالث

داده‌های خارجی را برای تشخیص حملات مسموم‌سازی، سوگیری و مطابقت قانونی ارزیابی کرده و در طول چرخه عمر آن‌ها را زیر نظر داشته باشید.

|   #   | Description                                                                                                              | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 6.5.1 | تأیید کنید که مجموعه داده‌های خارجی تحت ارزیابی ریسک مسمومیت قرار می‌گیرند (مثلاً اثر انگشت داده، تشخیص نقاط دورافتاده). |   1   | D/V  |
| 6.5.2 | اطمینان حاصل کنید که معیارهای سوگیری (توازن جمعیتی، فرصت برابر) قبل از تایید مجموعه داده محاسبه شده‌اند.                 |   1   |  D   |
| 6.5.3 | اطمینان حاصل کنید که منبع و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML‑BOM ثبت شده‌اند.                              |   2   |  V   |
| 6.5.4 | تأیید کنید که مانیتورینگ دوره‌ای تغییرات یا فساد در داده‌های میزبانی شده را شناسایی می‌کند.                              |   2   |  V   |
| 6.5.5 | اطمینان حاصل کنید که محتوای غیرمجاز (حق نشر، اطلاعات شناسایی شخصی) پیش از آموزش از طریق پاک‌سازی خودکار حذف شده باشد.    |   3   |  D   |

---

## C6.6 نظارت بر حملات زنجیره تامین

تهدیدهای زنجیره تأمین را از طریق فیدهای CVE، تحلیل‌های لاگ حسابرسی، و شبیه‌سازی‌های تیم قرمز زودتر شناسایی کنید.

|   #   | Description                                                                                                                                            | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 6.6.1 | اطمینان حاصل کنید که لاگ‌های حسابرسی CI/CD به صورت جریان به تشخیص‌های SIEM برای کشش بسته‌های غیرعادی یا مراحل ساخت دستکاری شده منتقل می‌شوند.          |   1   |  V   |
| 6.6.2 | تأیید کنید که دفترچه‌های پاسخ به حادثه شامل رویه‌های بازگردانی برای مدل‌ها یا کتابخانه‌های به خطر افتاده باشند.                                        |   2   |  D   |
| 6.6.3 | اطمینان حاصل کنید که برچسب‌های غنی‌سازی تهدید-اطلاعات شاخص‌های خاص یادگیری ماشین (مانند IoCهای آلودگی مدل) را در طبقه‌بندی هشدارها علامت‌گذاری می‌کند. |   3   |  V   |

---

## C6.7 ML‑BOM برای آثار مدل

تولید و امضای SBOMهای دقیق مخصوص یادگیری ماشین (ML-BOMها) به طوری که مصرف‌کنندگان پایین‌دستی بتوانند صحت اجزا را در زمان استقرار تأیید کنند.

|   #   | Description                                                                                                                          | Level | Role |
| :---: | ------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 6.7.1 | اطمینان حاصل کنید که هر مدل مصنوعی یک ML‑BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، ابرپارامترها و مجوزها باشد.                |   1   | D/V  |
| 6.7.2 | اطمینان حاصل کنید که تولید ML-BOM و امضای Cosign به صورت خودکار در CI انجام می‌شود و برای ادغام الزامی است.                          |   1   | D/V  |
| 6.7.3 | بررسی کنید که چک‌های کامل بودن ML-BOM در صورت مفقود بودن هر گونه فراداده مؤلفه (هش، مجوز) باعث شکست ساخت می‌شوند.                    |   2   |  D   |
| 6.7.4 | تأیید کنید که مصرف‌کنندگان پایین‌دستی بتوانند از طریق API به ML-BOMها برای اعتبارسنجی مدل‌های وارد شده در زمان استقرار پرس‌وجو کنند. |   2   |  V   |
| 6.7.5 | تأیید کنید که فهرست مواد یادگیری ماشینی (ML-BOMs) تحت کنترل نسخه هستند و تغییرات آن‌ها برای شناسایی اصلاحات غیرمجاز مقایسه می‌شوند.  |   3   |  V   |

---

## مراجع

* [ML Supply Chain Compromise – MITRE ATLAS](https://misp-galaxy.org/mitre-atlas-attack-pattern/)
* [Supply‑chain Levels for Software Artifacts (SLSA)](https://slsa.dev/)
* [CycloneDX – Machine Learning Bill of Materials](https://cyclonedx.org/capabilities/mlbom/)
* [What is Data Poisoning? – SentinelOne](https://www.sentinelone.com/cybersecurity-101/cybersecurity/data-poisoning/)
* [Transfer Learning Attack – OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML07_2023-Transfer_Learning_Attack)
* [AI Data Security Best Practices – CISA](https://www.cisa.gov/news-events/cybersecurity-advisories/aa25-142a)
* [Secure CI/CD Supply Chain – Sumo Logic](https://www.sumologic.com/blog/secure-azure-devops-github-supply-chain-attacks)
* [AI & Transparency: Protect ML Models – ReversingLabs](https://www.reversinglabs.com/blog/ai-and-transparency-how-ml-model-creators-can-protect-against-supply-chain-attacks)
* [SBOM Overview – CISA](https://www.cisa.gov/sbom)
* [Training Data Poisoning Guide – Lakera.ai](https://www.lakera.ai/blog/training-data-poisoning)
* [Dependency Pinning for Reproducible Python – Medium](https://medium.com/data-science-collective/guarantee-a-locked-reproducible-environment-with-every-python-run-c0e2bf19fb53)

