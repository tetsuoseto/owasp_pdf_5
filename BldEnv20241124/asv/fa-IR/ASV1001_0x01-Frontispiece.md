# صفحه اول

## درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسین MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابلیت‌دار هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مداوم—فراهم می‌کند تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در دست اقدام)، 2025  

![license](../images/license.png)

کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هرگونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|             |                       |
| ----------- | --------------------- |
| جیم مانویکو | آراس "راس" میمیزیازچی |

## مشارکت‌کنندگان و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS استانداردی کاملاً جدید است که به‌طور خاص برای مقابله با چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر الزامی در AISVS از پایه توسعه یافته تا بازتاب‌دهنده چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تر کمک کند.

