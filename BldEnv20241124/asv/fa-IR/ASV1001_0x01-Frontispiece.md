# جلد اول

## درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست جامعه محور از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابل اعتماد مجهز به هوش مصنوعی از آن استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در طول چرخه عمر هوش مصنوعی — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم — فراهم می‌کند تا سازمان‌ها بتوانند مقاومت، حفظ حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

## حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال انجام)، ۲۰۲۵  

![license](../images/license.png)

کپی‌رایت © ۲۰۲۵ پروژه AISVS.  

منتشر شده تحت[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

## رهبران پروژه

|             |                       |
| ----------- | --------------------- |
| جیم مانویکو | آراس "راس" میمیزیازچی |

## مشارکت‌کنندگان و بازبین‌ها

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS یک استاندارد کاملاً جدید است که به‌طور خاص برای مقابله با چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. هرچند این استاندارد از بهترین شیوه‌های کلی امنیت الهام گرفته است، اما هر نیازمندی در AISVS از پایه توسعه یافته است تا به‌درستی چشم‌انداز تهدیدات هوش مصنوعی را بازتاب دهد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی امن‌تر و مقاوم‌تر کمک کند.

