## صفحه اول

### درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست مبتنی بر جامعه از الزامات امنیتی است که دانشمندان داده، مهندسین MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند از آن برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابلیت‌دار هوش مصنوعی قابل اعتماد استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در سراسر چرخه عمر هوش مصنوعی—از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و پایش مداوم—فراهم می‌کند تا سازمان‌ها بتوانند مقاومت، حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در دست اقدام)، 2025  

![license](images/license.png)
کپی‌رایت © 2025 پروژه AISVS.  

منتشر شده تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
برای هرگونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مانویکو
آراس "راس" میمیزیازچی

### مشارکت‌کنندگان و بازبین‌ها

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS استانداردی کاملاً جدید است که به‌طور خاص برای مقابله با چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. در حالی که از بهترین شیوه‌های امنیتی گسترده‌تر الهام گرفته است، هر الزامی در AISVS از پایه توسعه یافته تا بازتاب‌دهنده چشم‌انداز تهدیدات هوش مصنوعی باشد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی ایمن‌تر و مقاوم‌تر کمک کند.

## پیش‌گفتار

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال 2025 از طریق یک تلاش جامعه‌محور همکاری تأسیس شد، الزامات امنیتی را که باید هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های هوش مصنوعی مدرن، خطوط لوله و خدمات فعال‌شده با هوش مصنوعی مد نظر قرار گیرند، تعریف می‌کند.

AISVS نسخه 1.0 نمایانگر کار مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه است تا یک نقطه شروع عملی و قابل آزمایش برای تأمین امنیت سیستم‌های هوش مصنوعی ایجاد کنند.

هدف ما در این نسخه این است که AISVS را به‌سادگی قابل استفاده کنیم در حالی که به دقت بر حوزه تعریف‌شده آن متمرکز مانده و به چشم‌انداز ریسک به سرعت در حال تغییر که مختص هوش مصنوعی است، پاسخ دهیم.

### اهداف کلیدی برای نسخه 1.0 AISVS

نسخه 1.0 با چند اصل راهنما ایجاد خواهد شد.

#### دامنه مشخص و تعریف‌شده

هر نیاز باید با نام و مأموریت AISVS هم‌راستا باشد:

هوش مصنوعی – کنترل‌ها در لایه AI/ML (داده، مدل، خط لوله، یا نتیجه‌گیری) عمل می‌کنند و مسئولیت آن‌ها بر عهده کارشناسان هوش مصنوعی است.
امنیت - الزامات به طور مستقیم خطرات امنیتی، حریم خصوصی یا ایمنی شناسایی‌شده را کاهش می‌دهند.
اعتبارسنجی – زبان به گونه‌ای نوشته شده است که انطباق آن بتوان به‌طور عینی مورد ارزیابی قرار داد.
استاندارد – بخش‌ها ساختار و اصطلاحات منسجمی را دنبال می‌کنند تا مرجع منسجمی ایجاد کنند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به طور سیستماتیک وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کنند و فرهنگ مهندسی ایمن هوش مصنوعی را ترویج دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) الزامات امنیتی برای برنامه‌ها و خدمات هوش مصنوعی مدرن را تعریف می‌کند و بر جنبه‌هایی که تحت کنترل توسعه‌دهندگان برنامه هستند تمرکز دارد.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسان امنیت و حسابرسان، طراحی شده است. این فصل ساختار و استفاده از AISVS را معرفی می‌کند که شامل سطوح تأیید آن و کاربردهای مورد نظر است.

### سطوح تأیید امنیتی هوش مصنوعی

AISVS سه سطح تصاعدی از تأیید امنیتی را تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری اضافه می‌کند و به سازمان‌ها این امکان را می‌دهد که وضعیت امنیتی خود را متناسب با سطح ریسک سیستم‌های هوش مصنوعی خود تنظیم کنند.

سازمان‌ها ممکن است از سطح 1 شروع کنند و به تدریج با افزایش بلوغ امنیتی و میزان مواجهه با تهدیدات، سطوح بالاتری را اتخاذ کنند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر اختصاص داده شده است:

 الزامات سطح 1

سطح 1 شامل الزامات امنیتی بنیادین و حیاتی‌ترین است. این سطح بر جلوگیری از حملات رایجی که به شرایط یا آسیب‌پذیری‌های دیگر متکی نیستند، تمرکز دارد. بیشتر کنترل‌های سطح 1 یا اجرای ساده‌ای دارند یا آنقدر ضروری هستند که توجیه‌کننده تلاش لازم برای پیاده‌سازی آنها باشند.

 الزامات سطح 2

سطح 2 به حملات پیشرفته‌تر یا کمتر رایج‌تر می‌پردازد، همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده را شامل می‌شود. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف قرار دادن پیش‌نیازهای خاص حمله باشند.

##### الزامات سطح ۳

سطح ۳ شامل کنترل‌هایی است که معمولاً سخت‌تر اجرا می‌شوند یا کاربرد آنها موقعیتی است. این‌ها اغلب نمایانگر مکانیزم‌های دفاع در عمق یا راهکارهایی در برابر حملات خاص، هدفمند یا با پیچیدگی بالا هستند.

#### نقش (D/V)

هر الزام AISVS بر اساس مخاطب اصلی آن علامت‌گذاری شده است:

D – نیازمندی‌های متمرکز بر توسعه‌دهنده
V – نیازمندی‌های متمرکز بر تاییدکننده/ممیزی‌کننده
D/V – مرتبط با هر دو توسعه‌دهندگان و تاییدکنندگان

## آموزش C1: حاکمیت داده‌ها و مدیریت تعصبات

### هدف کنترل

داده‌های آموزش باید به گونه‌ای تأمین، مدیریت و نگهداری شوند که اصالت، امنیت، کیفیت و عدالت آن حفظ شود. انجام این کارها وظایف قانونی را برآورده کرده و ریسک‌های جانبداری، مسمومیت یا نقض حریم خصوصی را در طول چرخه حیات هوش مصنوعی کاهش می‌دهد.

---

### C1.1 منشا داده‌های آموزش

یک فهرست قابل تأیید از تمام مجموعه داده‌ها نگه دارید، فقط منابع مورد اعتماد را قبول کنید و هر تغییر را برای حسابرسی ثبت کنید.

 #1.1.1    Level: 1    Role: D/V
 تأیید کنید که یک فهرست به‌روز از هر منبع داده آموزشی (مبدا، نگهدارنده/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مورد نظر و تاریخچه پردازش) نگهداری می‌شود.
 #1.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که فقط مجموعه‌داده‌هایی که از نظر کیفیت، نمایندگی، منبع‌یابی اخلاقی و انطباق با مجوز بررسی شده‌اند، مجاز باشند تا خطرات مسمومیت، تعصب نهفته و نقض مالکیت فکری کاهش یابد.
 #1.1.3    Level: 1    Role: D/V
 تأیید کنید که کاهش داده‌ها اجرا شده است تا ویژگی‌های غیرضروری یا حساس حذف شوند.
 #1.1.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام تغییرات مجموعه داده تحت یک جریان کاری تصویب ثبت شده قرار دارند.
 #1.1.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بازبینی‌های متقابل توسط بازبین‌ها یا توافق جمعی تضمین شده است.
 #1.1.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که "کارت‌های داده" یا "برگه‌های داده برای مجموعه‌های داده" برای مجموعه‌های آموزش قابل توجه نگهداری می‌شود، که ویژگی‌ها، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش و استفاده‌های توصیه‌شده/غیر توصیه‌شده را به تفصیل شرح می‌دهند.

---

### C1.2 امنیت و صحت داده‌های آموزش

دسترسی را محدود کنید، داده‌ها را در حالت استراحت و در حین انتقال رمزنگاری کنید و صحت داده‌ها را برای جلوگیری از دستکاری یا سرقت اعتبارسنجی کنید.

 #1.2.1    Level: 1    Role: D/V
 تأیید کنید که کنترل‌های دسترسی از ذخیره‌سازی و خطوط لوله محافظت می‌کنند.
 #1.2.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌ها هنگام انتقال رمزنگاری شده‌اند و برای تمامی اطلاعات حساس یا اطلاعات شخصی قابل شناسایی (PII)، در حالت ذخیره‌سازی نیز با استفاده از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید رمزنگاری محافظت شده‌اند.
 #1.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری یا امضاهای دیجیتال برای تضمین صحت داده‌ها در هنگام ذخیره‌سازی و انتقال استفاده می‌شوند و تکنیک‌های خودکار تشخیص ناهنجاری برای محافظت در برابر تغییرات یا فساد غیرمجاز، از جمله تلاش‌های هدفمند آلوده‌سازی داده‌ها، به کار گرفته شده‌اند.
 #1.2.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که نسخه‌های مجموعه داده ردیابی می‌شوند تا امکان بازگشت فراهم شود.
 #1.2.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌های منسوخ به‌طور ایمن پاک شده یا ناشناس‌سازی شده‌اند تا با سیاست‌های حفظ داده، الزامات قانونی و کاهش سطح حمله مطابقت داشته باشند.

---

### C1.3 کامل بودن و عدالت در نمایش

کجی‌های دموگرافیک را شناسایی کرده و اقدامات کاهش را به‌کار ببرید تا نرخ خطاهای مدل به طور عادلانه در میان گروه‌ها تقسیم شود.

 #1.3.1    Level: 1    Role: D/V
 تأیید کنید که داده‌ها بررسی شده‌اند تا عدم تعادل نمایشی و تعصب‌های بالقوه در خصوص ویژگی‌های قانونی محافظت‌شده (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اقتصادی-اجتماعی، مکان) را شناسایی کنند.
 #1.3.2    Level: 2    Role: D/V
 تأیید کنید که سوگیری‌های شناسایی‌شده از طریق استراتژی‌های مستند شده مانند تعادل‌بخشی مجدد، تقویت داده‌های هدفمند، تنظیمات الگوریتمی (مثلاً تکنیک‌های پیش‌پردازش، پردازش حین اجرا، پس‌پردازش) یا بازوزن‌دهی کاهش یافته‌اند و تأثیر کاهش سوگیری بر عدالت و عملکرد کلی مدل ارزیابی شده است.
 #1.3.3    Level: 2    Role: D/V
 تأیید کنید که معیارهای عدالت پس از آموزش ارزیابی و مستند شده‌اند.
 #1.3.4    Level: 3    Role: D/V
 تأیید کنید که سیاست مدیریت تعصب چرخه عمر، مالکین و دوره بازبینی را تعیین می‌کند.

---

### C1.4 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را با رمزگذاری محافظت کرده و برای دسته‌های حیاتی، بررسی دو مرحله‌ای را الزامی کنید.

 #1.4.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق دستورالعمل‌های واضح، بررسی‌های متقابل توسط بازبین‌ها، مکانیزم‌های توافق (مثلاً نظارت بر توافق بین حاشیه‌نویسان) و فرآیندهای تعریف‌شده برای رفع اختلافات تضمین شده است.
 #1.4.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال بر روی آثار برچسب‌گذاری شده اعمال شده‌اند تا صحت و اصالت آنها تضمین شود.
 #1.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اعمال می‌کنند، لاگ‌های حسابرسی مقاوم در برابر دستکاری از تمام فعالیت‌های برچسب‌گذاری نگهداری می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌کنند.
 #1.4.4    Level: 3    Role: D/V
 تأیید کنید که برچسب‌های حیاتی برای ایمنی، امنیت یا عدالت (مانند شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) بررسی دوگانه مستقل اجباری یا تأیید قوی معادل دریافت می‌کنند.
 #1.4.5    Level: 2    Role: D/V
 تأیید کنید که اطلاعات حساس (از جمله اطلاعات شناسایی شخصی) که به طور تصادفی ضبط شده یا به ناچار در برچسب‌ها حضور دارند، مطابق با اصول کاهش داده‌ها، در حالت ذخیره و انتقال، حذف، شبه‌نام‌گذاری، ناشناس‌سازی یا رمزگذاری شده باشند.
 #1.4.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که راهنماها و دستورالعمل‌های برچسب‌گذاری جامع، نسخه‌گذاری شده و مورد بررسی همتایان قرار گرفته‌اند.
 #1.4.7    Level: 2    Role: D/V
 اطمینان حاصل کنید که طرح‌های داده‌ها (از جمله برچسب‌ها) به‌وضوح تعریف شده و تحت کنترل نسخه باشند.
 #1.8.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که جریان‌های کاری برچسب‌گذاری برون‌سپاری شده یا جمع‌سپاری شده شامل ایمنی‌های فنی/رویّه‌ای برای تضمین محرمانگی داده‌ها، صحت داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها باشند.

---

### تضمین کیفیت داده‌های آموزش C1.5

ترکیب اعتبارسنجی خودکار، بررسی‌های نمونه‌برداری دستی و رفع اشکال ثبت‌شده برای تضمین قابلیت اعتماد مجموعه داده‌ها.

 #1.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای فرمت، مقدارهای تهی (null) و واگرایی برچسب‌ها را در هر بار دریافت داده یا تغییرات مهم شناسایی می‌کنند.
 #1.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های ناموفق با ردپاهای حسابرسی قرنطینه شده‌اند.
 #1.5.3    Level: 2    Role: V
 اطمینان حاصل کنید که بازبینی‌های دستی توسط کارشناسان حوزه، یک نمونه آماری معنادار را پوشش می‌دهد (مثلاً ≥1% یا ۱۰۰۰ نمونه، هر کدام که بزرگتر است، یا طبق ارزیابی ریسک تعیین شده است) تا مسائل ظریف کیفیت که توسط خودکارسازی شناسایی نشده‌اند را شناسایی کند.
 #1.5.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که مراحل اصلاح به سوابق منشاء اضافه شده‌اند.
 #1.5.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که دروازه‌های کیفیت، مجموعه‌داده‌های پایین‌تر از استاندارد را مسدود می‌کنند مگر اینکه استثناها تأیید شده باشند.

---

### C1.6 شناسایی مسموم‌سازی داده‌ها

اجرای تشخیص ناهنجاری‌های آماری و روندهای قرنطینه برای متوقف کردن واردات خصمانه.

 #1.6.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تکنیک‌های تشخیص ناهنجاری (مانند روش‌های آماری، تشخیص نقاط پرت، تحلیل تعبیه) بر روی داده‌های آموزش در هنگام دریافت و قبل از اجرای‌های اصلی آموزش اعمال می‌شوند تا حملات احتمالی مسموم‌سازی یا فساد داده‌های غیرعمدی شناسایی شوند.
 #1.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری شده قبل از آموزش، بازبینی دستی را فعال می‌کنند.
 #1.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج پرونده امنیتی مدل را تغذیه کرده و اطلاعات تهدیدات جاری را اطلاع می‌دهند.
 #1.6.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که منطق تشخیص با اطلاعات تهدید جدید به‌روزرسانی شده است.
 #1.6.5    Level: 3    Role: D/V
 تأیید کنید که خطوط لوله یادگیری آنلاین تغییر توزیع را پایش می‌کنند.
 #1.6.6    Level: 3    Role: D/V
 تأیید کنید که دفاع‌های خاص در برابر انواع شناخته شده حملات مسموم‌سازی داده (مانند تغییر برچسب، درج تریگر درب‌پشتی، حملات نمونه تأثیرگذار) بر اساس پروفایل ریسک سیستم و منابع داده در نظر گرفته شده و پیاده‌سازی گردد.

---

### C1.7 حذف داده‌های کاربر و اجرای رضایت

درخواست‌های حذف داده‌ها و انصراف از رضایت را در سراسر مجموعه‌های داده، نسخه‌های پشتیبان، و مصنوعات استخراج شده رعایت کنید.

 #1.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که روندهای حذف داده‌های اصلی و مشتق شده را پاک‌سازی می‌کنند و تأثیر بر مدل را ارزیابی کرده و در صورت لزوم، تأثیر بر مدل‌های متأثر بررسی و برطرف شود (مثلاً از طریق آموزش مجدد یا بازتنظیم).
 #1.7.2    Level: 2    Role: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای پیگیری و احترام به دامنه و وضعیت رضایت کاربر (و همچنین لغو آن) برای داده‌های استفاده شده در آموزش وجود دارد و رضایت قبل از وارد کردن داده‌ها در فرآیندهای آموزشی جدید یا به‌روزرسانی‌های مهم مدل، تایید می‌شود.
 #1.7.3    Level: 2    Role: V
 اطمینان حاصل کنید که گردش کارها سالانه آزمایش شده و ثبت می‌شوند.

---

### C1.8 امنیت زنجیره تأمین

ارائه‌دهندگان داده‌های خارجی را بررسی کنید و صحت آنها را از طریق کانال‌های تأیید شده و رمزگذاری شده تأیید نمایید.

 #1.8.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تأمین‌کنندگان داده‌های شخص ثالث، از جمله ارائه‌دهندگان مدل‌های از پیش آموزش‌دیده و مجموعه‌های داده خارجی، قبل از ادغام داده‌ها یا مدل‌هایشان، بررسی‌های لازم در زمینه امنیت، حریم خصوصی، تأمین اخلاقی و کیفیت داده‌ها را انجام می‌دهند.
 #1.8.2    Level: 1    Role: D
 اطمینان حاصل کنید که انتقالات خارجی از TLS/احراز هویت و بررسی‌های یکپارچگی استفاده می‌کنند.
 #1.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که منابع داده با ریسک بالا (مانند مجموعه داده‌های متن‌باز با منشاء ناشناخته، تأمین‌کنندگان تاییدنشده) قبل از استفاده در برنامه‌های حساس، تحت نظارت دقیق‌تری قرار گیرند، مانند تحلیل در محیط ایزوله، بررسی‌های گسترده کیفیت/سوگیری، و تشخیص هدفمند آلودگی داده.
 #1.8.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که مدل‌های پیش‌آموزش‌دیده شده از سوی اشخاص ثالث از نظر تعصبات نهفته، درهای پشتی احتمالی، صحت ساختار معماری و اصالت داده‌های آموزشی اصلی قبل از تنظیم دقیق یا به‌کارگیری ارزیابی شده باشند.

---

### C1.9 تشخیص نمونه‌های متخاصم

اقداماتی را در طول مرحله آموزش اجرا کنید، مانند آموزش خصمانه، برای افزایش مقاومت مدل در برابر نمونه‌های خصمانه.

 #1.9.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که دفاع‌های مناسب، مانند آموزش دشمن‌محور (با استفاده از نمونه‌های دشمن‌محور تولیدشده)، افزایش داده با ورودی‌های مختل‌شده، یا تکنیک‌های بهینه‌سازی مقاوم، برای مدل‌های مرتبط بر اساس ارزیابی ریسک پیاده‌سازی و تنظیم شده‌اند.
 #1.9.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که در صورت استفاده از آموزش مواجهه‌ای، تولید، مدیریت و نسخه‌بندی مجموعه داده‌های مواجهه‌ای مستندسازی و کنترل شده باشد.
 #1.9.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تأثیر آموزش مقاوم‌سازی در برابر حملات خصمانه بر عملکرد مدل (در برابر ورودی‌های پاک و خصمانه) و معیارهای عدالت ارزیابی، مستند و نظارت می‌شود.
 #1.9.4    Level: 3    Role: D/V
 تأیید کنید که استراتژی‌های آموزش دشمن‌محور (adversarial training) و مقاومت به صورت دوره‌ای بررسی و به‌روزرسانی می‌شوند تا در برابر تکنیک‌های در حال تحول حملات دشمن‌محور مقابله کنند.

---

### C1.10 ردیابی داده‌ها و پیگیری منشاء داده‌ها

برای امکان بررسی و پاسخ به حوادث، مسیر کامل هر نقطه داده از منبع تا ورودی مدل را دنبال کنید.

 #1.10.1    Level: 2    Role: D/V
 تأیید کنید که شجره هر نقطه داده، شامل تمام تبدیل‌ها، افزایش‌ها و ادغام‌ها ثبت شده و قابل بازسازی است.
 #1.10.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوابق تبارشناسی غیرقابل تغییر، به‌صورت ایمن ذخیره شده و برای ممیزی‌ها یا تحقیقات قابل دسترسی باشند.
 #1.10.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که پیگیری تبار هر دو داده خام و داده مصنوعی را پوشش می‌دهد.

---

### C1.11 مدیریت داده‌های مصنوعی

اطمینان حاصل کنید که داده‌های مصنوعی به‌درستی مدیریت، برچسب‌گذاری و ارزیابی ریسک می‌شوند.

 #1.11.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام داده‌های مصنوعی به وضوح برچسب‌گذاری شده و در سراسر مسیر پردازش از داده‌های واقعی قابل تشخیص باشند.
 #1.11.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیند تولید، پارامترها و استفاده مورد نظر از داده‌های مصنوعی مستندسازی شده باشند.
 #1.11.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی قبل از استفاده در آموزش، از نظر سوگیری، نشت حریم خصوصی و مسائل نمایشی مورد ارزیابی ریسک قرار گرفته‌اند.

---

### C1.12 پایش دسترسی به داده‌ها و شناسایی ناهنجاری‌ها

نظارت و هشدار درباره دسترسی‌های غیرمعمول به داده‌های آموزشی برای شناسایی تهدیدات داخلی یا استخراج غیرمجاز اطلاعات.

 #1.12.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمامی دسترسی‌ها به داده‌های آموزشی ثبت می‌شود، از جمله کاربر، زمان و اقدام انجام شده.
 #1.12.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که گزارش‌های دسترسی به‌طور منظم برای الگوهای غیرمعمول، مانند صادرات‌های بزرگ یا دسترسی از مکان‌های جدید، بررسی می‌شوند.
 #1.12.3    Level: 2    Role: D/V
 تأیید کنید که هشدارها برای رویدادهای دسترسی مشکوک تولید شده و به‌سرعت بررسی می‌شوند.

---

### C1.13 سیاست‌های نگهداری و انقضای داده‌ها

تعریف و اعمال دوره‌های نگهداری داده‌ها به منظور به حداقل رساندن ذخیره‌سازی غیرضروری داده‌ها.

 #1.13.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که دوره‌های نگهداری صریح برای تمام داده‌های آموزشی تعریف شده است.
 #1.13.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌ها به‌طور خودکار در پایان دوره عمرشان منقضی، حذف یا برای حذف مورد بازبینی قرار می‌گیرند.
 #1.13.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که اقدامات نگهداری و حذف ثبت و قابل حسابرسی هستند.

---

### C1.14 انطباق با مقررات و حوزه قضایی

اطمینان حاصل کنید که همه داده‌های آموزشی مطابق با قوانین و مقررات قابل اجرا باشد.

 #1.14.1    Level: 2    Role: D/V
 تأیید کنید که الزامات محل نگهداری داده‌ها و انتقال اطلاعات فرامرزی برای تمام مجموعه داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    Level: 2    Role: D/V
 تأیید کنید که مقررات خاص هر بخش (مانند بهداشت و درمان، امور مالی) شناسایی شده و در مدیریت داده‌ها رعایت می‌شوند.
 #1.14.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که پیروی از قوانین حریم خصوصی مرتبط (مانند GDPR، CCPA) مستند شده و به طور منظم بررسی می‌شود.

---

### C1.15 نشانه‌گذاری داده‌ها و اثر انگشتگذاری

شناسایی استفاده یا نشت غیرمجاز از داده‌های مالکیتی یا حساس.

 #1.15.1    Level: 3    Role: D/V
 تأیید کنید که داده‌ها یا زیرمجموعه‌ها در صورت امکان دارای واترمارک یا اثر انگشت دیجیتال باشند.
 #1.15.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که روش‌های واترمارکینگ/اثر انگشتی باعث ایجاد سوگیری یا خطرات حریم خصوصی نمی‌شوند.
 #1.15.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که بررسی‌های دوره‌ای برای تشخیص استفاده‌ی غیرمجاز یا نشت داده‌های نشانه‌گذاری شده انجام می‌شود.

---

### C1.16 مدیریت حقوق موضوع داده

حمایت از حقوق ذینفعان داده مانند دسترسی، اصلاح، محدودیت و اعتراض.

 #1.16.1    Level: 2    Role: D/V
 تأیید کنید که مکانیزم‌هایی برای پاسخ به درخواست‌های صاحب داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    Level: 2    Role: D/V
 تأیید کنید که درخواست‌ها در چارچوب زمان‌های مقرر قانونی ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیندهای حقوق موضوع داده به طور منظم برای اثربخشی آزمایش و بازبینی می‌شوند.

---

### تجزیه و تحلیل تاثیر نسخه مجموعه داده C1.17

قبل از به‌روزرسانی یا جایگزینی نسخه‌ها، تأثیر تغییرات مجموعه داده‌ها را ارزیابی کنید.

 #1.17.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که قبل از به‌روزرسانی یا جایگزینی نسخه مجموعه داده، تحلیل تأثیر انجام شده باشد که شامل عملکرد مدل، عدالت و انطباق می‌شود.
 #1.17.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که نتایج تحلیل تأثیر مستند شده و توسط ذینفعان مربوطه بازبینی شده است.
 #1.17.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که برنامه‌های بازگشت وجود دارند تا در صورت ایجاد ریسک‌ها یا پسرفت‌های غیرقابل قبول توسط نسخه‌های جدید، بتوان به نسخه‌های قبلی بازگشت.

---

### C1.18 امنیت نیروی کار حاشیه‌نویسی داده‌ها

تضمین امنیت و یکپارچگی پرسنل درگیر در برچسب‌گذاری داده‌ها.

 #1.18.1    Level: 2    Role: D/V
 تایید کنید که تمام کارکنان درگیر در برچسب‌گذاری داده‌ها، پیش‌زمینه‌ای بررسی شده و در زمینه امنیت داده‌ها و حریم خصوصی آموزش دیده‌اند.
 #1.18.2    Level: 2    Role: D/V
 تأیید کنید که تمام پرسنل حاشیه‌نویسی قراردادهای حفظ محرمانگی و عدم افشا را امضا کرده‌اند.
 #1.18.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اعمال کرده و تهدیدات داخلی را نظارت می‌کنند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر C2

### هدف کنترل

اعتبارسنجی قوی ورودی کاربر اولین خط دفاع در برابر برخی از مخرب‌ترین حملات بر سیستم‌های هوش مصنوعی است. حملات تزریق فرمان می‌توانند دستورالعمل‌های سیستم را نادیده بگیرند، داده‌های حساس را نشت دهند یا مدل را به سمت رفتارهای غیرمجاز هدایت کنند. مگر اینکه فیلترهای ویژه و سلسله مراتب دستورات اعمال شده باشد، تحقیقات نشان می‌دهد که "jailbreak" های چند مرحله‌ای که از پنجره‌های متنی بسیار بلند بهره می‌برند، مؤثر خواهند بود. همچنین، حملات ظریف تغییر مخرب—مانند جابجایی‌های هوموگلیف یا استفاده از زبان لِیت—می‌توانند به صورت بی‌صدا تصمیمات مدل را تغییر دهند.

---

### دفاع در برابر تزریق درخواست (Prompt Injection Defense)

تزریق پرامپت یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. دفاع در برابر این تاکتیک از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتبی دستورات استفاده می‌کند.

 #2.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که ورودی‌های کاربر در برابر یک کتابخانه به‌روز شده مستمر از الگوهای شناخته شده تزریق درخواست (کلیدواژه‌های فرار از زندان، "نادیده گرفتن قبلی"، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    Level: 1    Role: D/V
 تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجرهٔ زمینه.
 #2.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که آزمایش‌های ارزیابی خصمانه (برای مثال، درخواست‌های "چندتایی" تیم قرمز) قبل از انتشار هر مدل یا قالب درخواست اجرا می‌شوند، همراه با تعیین آستانه‌های نرخ موفقیت و بلوکرهای خودکار برای عقب‌گردها.
 #2.1.4    Level: 2    Role: D
 اطمینان حاصل کنید که درخواست‌هایی که از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) می‌آیند، در یک زمینه تفسیر ایزوله شده پاک‌سازی می‌شوند قبل از اینکه به درخواست اصلی اضافه شوند.
 #2.1.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که همه به‌روزرسانی‌های قانون فیلتر درخواست، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات فهرست مسدود شده تحت کنترل نسخه بوده و قابل حسابرسی باشند.

---

### C2.2 مقاومت در برابر مثال‌های ضد حال

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات جزئی در سطح کاراکتر یا کلمه آسیب‌پذیر هستند، تغییراتی که انسان‌ها معمولاً متوجه آن‌ها نمی‌شوند اما مدل‌ها به اشتباه طبقه‌بندی می‌کنند.

 #2.2.1    Level: 1    Role: D
 اطمینان حاصل کنید که مراحل پایه نرمال‌سازی ورودی (Unicode NFC، نگاشت هوموگلیف، حذف فاصله‌های اضافی) قبل از توکنیزاسیون اجرا می‌شوند.
 #2.2.2    Level: 2    Role: D/V
 تأیید کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایش غیرمعمولاً بالایی نسبت به معیارهای زبانی دارند، توکن‌های تکراری زیاد یا فواصل تعبیه غیرطبیعی دارند، علامت‌گذاری می‌کند.
 #2.2.3    Level: 2    Role: D
 تأیید کنید که خط لوله استنتاج، نسخه‌های مدل مقاوم شده با آموزش متخاصم اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) را برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    Level: 2    Role: V
 تأیید کنید که ورودی‌های مشکوک به حملات خصمانه قرنطینه شده و با کل داده‌های بار (پس از حذف اطلاعات شخصی شناسایی‌پذیر) ثبت می‌شوند.
 #2.2.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای مقاومت (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان ثبت می‌شوند و پسرفت‌ها باعث ایجاد مانع در انتشار می‌شوند.

---

### C2.3 اعتبارسنجی طرح‌واره، نوع و طول

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بیش از حد بزرگ هستند می‌توانند باعث خطاهای تجزیه، انتشار فرمان در بین فیلدها و خستگی منابع شوند. همچنین، اعمال دقیق اسکیمای سختگیرانه هنگام انجام فراخوانی‌های ابزاری قطعی یک پیش‌شرط است.

 #2.3.1    Level: 1    Role: D
 تأیید کنید که هر نقطه انتهایی فراخوانی API یا تابع، یک ساختار ورودی صریح (JSON Schema، Protobuf یا معادل چند‌وجهی) تعریف کرده است و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند.
 #2.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که ورودی‌های بیشتر از حد مجاز توکن یا بایت با خطایی ایمن رد شده و هرگز به‌صورت خاموش کوتاه نشده‌اند.
 #2.3.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بررسی نوع‌ها (مانند بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور نیز اعمال می‌شود و نه فقط در کد سمت کاربر.
 #2.3.4    Level: 2    Role: D
 اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابت اجرا می‌شوند تا از حملات محروم‌سازی سرویس الگوریتمی جلوگیری شود.
 #2.3.5    Level: 3    Role: V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی با قطعات بار مخفی شده و کدهای خطای واضح برای کمک به واکاوی امنیتی ثبت می‌شوند.

---

### C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند تا درخواست‌های دستوری صحیح نحوی که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق نسخه‌برداری) را درخواست می‌کنند، شناسایی کرده و سپس از گسترش آنها جلوگیری کنند.

 #2.4.1    Level: 1    Role: D
 اطمینان حاصل کنید که یک طبقه‌بند محتوا (بدون آموزش قبلی یا آموزش داده شده) هر ورودی را از نظر خشونت، خودآسیبی، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارزیابی می‌کند.
 #2.4.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که ورودی‌هایی که نقض‌کننده سیاست‌ها هستند، پاسخ‌های استاندارد شده‌ای از نوع رد درخواست یا تکمیل‌های ایمن دریافت می‌کنند تا این ورودی‌ها به فراخوان‌های پایین‌دستی مدل‌های زبانی بزرگ منتقل نشوند.
 #2.4.3    Level: 2    Role: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل به صورت فصلی بازآموزی/به‌روزرسانی می‌شود و الگوهای تازه مشاهده شده فرار از محدودیت یا دور زدن سیاست را در بر می‌گیرد.
 #2.4.4    Level: 2    Role: D
 تأیید کنید که غربالگری از سیاست‌های خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) از طریق قواعد مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، پیروی می‌کند.
 #2.4.5    Level: 3    Role: V
 تأیید کنید که گزارش‌های غربالگری شامل امتیازهای اطمینان طبقه‌بندی‌کننده و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و اجرای مجدد تیم قرمز در آینده باشند.

---

### C2.5 محدودیت نرخ ورودی و پیشگیری از سوء استفاده

توسعه‌دهندگان باید با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی، از سوءاستفاده، تمام شدن منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی جلوگیری کنند.

 #2.5.1    Level: 1    Role: D/V
 تأیید کنید که محدودیت‌های نرخ بر اساس هر کاربر، هر IP و هر کلید API برای تمامی نقطه‌های ورودی اعمال می‌شود.
 #2.5.2    Level: 2    Role: D/V
 بررسی کنید که محدودیت‌های نرخ انفجاری (burst) و پایدار (sustained) به گونه‌ای تنظیم شده‌اند که از حملات انکار سرویس (DoS) و حملات جستجوی فراگیر (brute force) جلوگیری کنند.
 #2.5.3    Level: 2    Role: D/V
 تأیید کنید که الگوهای استفاده غیرعادی (مثلاً درخواست‌های سریع پشت سر هم، ارسال انبوه ورودی) باعث فعال شدن بلوک‌های خودکار یا افزایش سطح نظارت شوند.
 #2.5.4    Level: 3    Role: V
 اطمینان حاصل کنید که لاگ‌های پیشگیری از سوء استفاده نگهداری شده و برای الگوهای حمله نوظهور بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندرسانه‌ای

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیر متنی (تصاویر، صدا، فایل‌ها) شامل شوند تا از تزریق، فرار یا سوء استفاده از منابع جلوگیری شود.

 #2.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که تمام ورودی‌های غیرمتنی (تصاویر، صدا، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت معتبرسازی شده‌اند.
 #2.6.2    Level: 2    Role: D/V
 بررسی کنید که فایل‌ها قبل از ورود برای بدافزار و بارهای استگانوگرافیک اسکن شوند.
 #2.6.3    Level: 2    Role: D/V
 تأیید کنید که ورودی‌های تصویر/صدا برای اختلالات مخرب یا الگوهای حمله شناخته‌شده بررسی شده‌اند.
 #2.6.4    Level: 3    Role: V
 تأیید کنید که خطاهای اعتبارسنجی ورودی چند‌وجهی ثبت می‌شوند و هشدارهایی برای بررسی ایجاد می‌کنند.

---

### C2.7 منبع ورودی و انتساب

سیستم‌های هوش مصنوعی باید با پایش و برچسب‌گذاری منبع تمام ورودی‌های کاربران، از حسابرسی، پیگیری سوءاستفاده و تطابق پشتیبانی کنند.

 #2.7.1    Level: 1    Role: D/V
 تأیید کنید که تمام ورودی‌های کاربر هنگام دریافت با فراداده‌هایی مانند شناسه کاربر، جلسه، منبع، زمان‌بندی و آدرس IP علامت‌گذاری شده باشند.
 #2.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که متاداده‌های منشأ برای تمام ورودی‌های پردازش‌شده حفظ شده و قابل حسابرسی باشند.
 #2.7.3    Level: 2    Role: D/V
 تأیید کنید که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار گیرند.

---

### C2.8 شناسایی تهدید تطبیقی در زمان واقعی

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای حمله جدید سازگار شده و با مطابقت الگوهای کامپایل شده حفاظت به‌موقع ارائه می‌دهند.

 #2.8.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که الگوهای تشخیص تهدید به موتورهای regex بهینه شده برای فیلتر کردن با عملکرد بالا و تأخیر حداقلی در زمان واقعی تبدیل شده‌اند.
 #2.8.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیستم‌های شناسایی تهدید برای دسته‌بندی‌های مختلف تهدید (تزریق فرمان، محتوای مضر، داده‌های حساس، فرمان‌های سیستمی) کتابخانه‌های الگو جداگانه‌ای نگهداری می‌کنند.
 #2.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تشخیص تهدید تطبیقی از مدل‌های یادگیری ماشین استفاده می‌کند که حساسیت به تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.
 #2.8.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که فیدهای اطلاعات تهدید در زمان واقعی به صورت خودکار کتابخانه‌های الگو را با امضاهای حمله جدید و شاخص‌های نفوذ (IOCs) به‌روزرسانی می‌کنند.
 #2.8.5    Level: 3    Role: D/V
 تأیید کنید که نرخ‌های مثبت کاذب تشخیص تهدید به‌طور مداوم پایش می‌شوند و ویژگی‌های الگو به‌صورت خودکار تنظیم می‌شوند تا از تداخل با موارد استفاده قانونی به حداقل برسد.
 #2.8.6    Level: 3    Role: D/V
 تأیید کنید که تحلیل تهدید زمینه‌ای منابع ورودی، الگوهای رفتار کاربر و تاریخچه جلسه را برای بهبود دقت شناسایی در نظر می‌گیرد.
 #2.8.7    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به‌صورت لحظه‌ای نظارت و بهینه‌سازی می‌شوند.

---

### خط لوله اعتبارسنجی امنیت چندرسانه‌ای C2.9

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای ورودی‌های متنی، تصویری، صوتی و سایر حالت‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و ایزوله‌سازی منابع فراهم کنند.

 #2.9.1    Level: 1    Role: D/V
 تأیید کنید که هر مدالیته ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند (متن: تزریق درخواست، تصاویر: استگانوگرافی، صوت: حملات اسپکتروگرام) و آستانه‌های تشخیص باشد.
 #2.9.2    Level: 2    Role: D/V
 تأیید کنید که ورودی‌های چندوجهی در محیط‌های ایزوله شده با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که به‌طور خاص برای هر نوع مدالیتی تعریف شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده باشد.
 #2.9.3    Level: 2    Role: D/V
 بررسی کنید که تشخیص حملات چندمدلی حملات هماهنگ شده‌ای که در چندین نوع ورودی گسترده می‌شوند (مثلاً بارهای پنهان استگانوگرافیک در تصاویر به همراه تزریق پرسش در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    Level: 3    Role: D/V
 تأیید کنید که خطاهای اعتبارسنجی چندمودالی باعث ثبت دقیق و کامل لاگ‌ها می‌شوند که شامل تمامی حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختاریافته لاگ برای یکپارچه‌سازی با سیستم‌های SIEM باشد.
 #2.9.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که طبقه‌بندهای محتوای خاص هر حالت بر اساس برنامه‌های مستند (حداقل فصلی) با الگوهای تهدید جدید، مثال‌های مخرب و معیارهای عملکرد که بالاتر از آستانه‌های پایه حفظ می‌شوند، به‌روزرسانی شده‌اند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناایمن مدل به محیط تولید جلوگیری کند. این کنترل، تمامیت مدل را در طول چرخه عمر آن - از توسعه تا استقرار و بازنشستگی - تضمین می‌کند که امکان واکنش سریع به حوادث را فراهم کرده و مسئولیت‌پذیری برای تمامی تغییرات را حفظ می‌نماید.

هدف اصلی امنیتی: تنها مدل‌های مجاز و تأیید شده از طریق فرآیندهای کنترل شده که یکپارچگی، ردیابی‌پذیری و قابلیت بازیابی را حفظ می‌کنند، وارد مرحله تولید می‌شوند.

---

### C3.1 مجوزدهی و صحت مدل

تنها مدل‌های مجاز با صحت تایید شده به محیط‌های تولید می‌رسند.

 #3.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمامی آثار مدل (وزن‌ها، تنظیمات، توکن‌سازها) قبل از استقرار توسط نهادهای مجاز به صورت رمزنگاری شده امضا شده‌اند.
 #3.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که صحت مدل در زمان استقرار تایید می‌شود و عدم تطابق امضا مانع بارگذاری مدل می‌گردد.
 #3.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوابق منشأ مدل شامل هویت نهاد مجاز کننده، چکسام‌های داده‌های آموزش، نتایج آزمون اعتبارسنجی با وضعیت قبول/رد، و یک مهر زمان ایجاد است.
 #3.1.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستندی برای مشخص کردن زمان افزایش هر مؤلفه نسخه وجود دارد.
 #3.1.5    Level: 2    Role: V
 تأیید کنید که ردیابی وابستگی یک موجودی به‌روزرسانی شده در زمان واقعی را حفظ می‌کند که امکان شناسایی سریع همه سیستم‌های مصرف‌کننده را فراهم می‌آورد.

---

### C3.2 اعتبارسنجی و آزمایش مدل

مدل‌ها باید قبل از استقرار، آزمایش‌های تعریف‌شده امنیتی و ایمنی را پشت سر بگذارند.

 #3.2.1    Level: 1    Role: D/V
 اطمینان حاصل شود که مدل‌ها قبل از استقرار تحت آزمایش امنیتی خودکار قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی و ارزیابی‌های ایمنی با حد نصاب‌های قبلاً توافق‌شده سازمانی برای قبولی یا رد است.
 #3.2.2    Level: 1    Role: D/V
 تأیید کنید که شکست‌های اعتبارسنجی پس از تأیید صریح از سوی افراد مجاز از پیش تعیین شده با دلایل تجاری مستند، به طور خودکار مانع از استقرار مدل می‌شوند.
 #3.2.3    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج آزمایش به صورت رمزنگاری امضا شده و به طور تغییرناپذیری به هش نسخه خاص مدل که در حال اعتبارسنجی است، مرتبط شده‌اند.
 #3.2.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأیید از سوی مرجع امنیتی از پیش تعیین‌شده در بازه‌های زمانی توافق شده هستند.

---

### C3.3 استقرار کنترل شده و بازگردانی

استقرار مدل‌ها باید کنترل‌شده، نظارت‌شده و قابل برگشت باشد.

 #3.3.1    Level: 1    Role: D
 اطمینان حاصل کنید که استقرارهای تولیدی مکانیزم‌های عرضه تدریجی (استقرار کاناری، استقرار آبی-سبز) را اجرا می‌کنند که دارای ماشه‌های بازگردانی خودکار بر اساس نرخ خطاهای از پیش توافق شده، آستانه‌های تأخیر، یا معیارهای هشدار امنیتی باشند.
 #3.3.2    Level: 1    Role: D/V
 تأیید کنید که قابلیت‌های بازگشت به عقب به‌صورت اتمی در بازه‌های زمانی سازمانی از پیش تعریف شده، وضعیت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را بازیابی می‌کنند.
 #3.3.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیندهای استقرار امضاهای رمزنگاری شده را بررسی کرده و قبل از فعال‌سازی مدل، چک‌سام‌های صحت را محاسبه می‌کنند و در صورت هر گونه عدم تطابق، استقرار را متوقف می‌کنند.
 #3.3.4    Level: 2    Role: D/V
 تأیید کنید که قابلیت‌های خاموش‌سازی اضطراری مدل قادر به غیرفعال کردن نقاط انتهایی مدل در زمان‌های پاسخ تعریف‌شده از پیش از طریق مدارشکن‌های خودکار یا سوئیچ‌های قطع دستی هستند.
 #3.3.5    Level: 2    Role: V
 تایید کنید که آثار بازگشتی (نسخه‌های قبلی مدل، تنظیمات، وابستگی‌ها) مطابق با سیاست‌های سازمانی با ذخیره‌سازی غیرقابل تغییر برای پاسخ به حوادث نگهداری می‌شوند.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات چرخه عمر مدل باید قابل ردیابی و حسابرسی باشند.

 #3.4.1    Level: 1    Role: V
 بررسی کنید که تمامی تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر را شامل زمان‌سنجی، هویت بازیگر تأیید شده، نوع تغییر و وضعیت‌های قبل/بعد ایجاد کنند.
 #3.4.2    Level: 2    Role: D/V
 تأیید کنید که دسترسی به گزارش‌های حسابرسی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی با هویت کاربر و زمان‌سنجی ثبت می‌شوند.
 #3.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که قالب‌های پرامپت و پیام‌های سیستمی در مخازن گیت نسخه‌بندی شده‌اند و پیش از استقرار، بررسی و تأیید کد توسط بازبینان تعیین‌شده الزامی است.
 #3.4.4    Level: 2    Role: V
 تأیید کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، عکس‌برداری‌های پیکربندی، نسخه‌های وابستگی) باشد تا بازسازی کامل وضعیت مدل را برای هر بازه زمانی در دوره نگهداری ممکن سازد.

---

### عملکردهای توسعه امن C3.5

فرایندهای توسعه و آموزش مدل باید از رویه‌های ایمن پیروی کنند تا از به خطر افتادن جلوگیری شود.

 #3.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که محیط‌های توسعه مدل، آزمایش و تولید به صورت فیزیکی یا منطقی جدا شده‌اند. این محیط‌ها هیچ زیرساخت مشترکی ندارند، کنترل‌های دسترسی متمایز دارند و فروشگاه‌های داده جداگانه‌ای دارند.
 #3.5.2    Level: 1    Role: D
 اطمینان حاصل کنید که آموزش مدل و تنظیم دقیق آن در محیط‌های ایزوله با دسترسی شبکه کنترل‌شده انجام می‌شود.
 #3.5.3    Level: 1    Role: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی از طریق بررسی‌های صحت اعتبارسنجی شده و از طریق منابع معتبر با زنجیره نگهداری مستند تأیید هویت شده‌اند قبل از استفاده در توسعه مدل.
 #3.5.4    Level: 2    Role: D
 اطمینان حاصل کنید که مصنوعات توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده و قبل از استفاده در آموزش، نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی و از خدمت خارج کردن مدل

مدل‌ها باید به‌صورت امن بازنشسته شوند زمانی که دیگر مورد نیاز نیستند یا مشکلات امنیتی شناسایی شده است.

 #3.6.1    Level: 1    Role: D
 تأیید کنید که فرآیندهای بازنشستگی مدل به‌طور خودکار نمودارهای وابستگی را اسکن می‌کنند، تمامی سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی پیش‌توافق‌شده را قبل از از کار انداختن فراهم می‌آورند.
 #3.6.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های مدل بازنشسته شده با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندمرحله‌ای به طور ایمن حذف شده‌اند، مطابق با سیاست‌های حفظ داده مستند شده و با گواهی‌های تخریب تأیید شده.
 #3.6.3    Level: 2    Role: V
 تأیید کنید که رویدادهای بازنشستگی مدل با زمان‌بندی و هویت بازیگر ثبت شده‌اند و امضاهای مدل برای جلوگیری از استفاده مجدد لغو شده‌اند.
 #3.6.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در چارچوب‌های زمانی واکنش اضطراری از پیش تعیین‌شده از طریق کلیدهای قطع خودکار غیرفعال کند اگر آسیب‌پذیری‌های حیاتی امنیتی شناسایی شوند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## زیرساخت C4، پیکربندی و امنیت استقرار

### هدف کنترل

زیرساخت هوش مصنوعی باید در برابر بالا رفتن امتیازات، دستکاری زنجیره تامین و حرکت جانبی مقاوم شود از طریق پیکربندی امن، جداسازی زمان اجرا، خطوط تولید استقرار مورد اعتماد و نظارت جامع. فقط اجزای زیرساخت و پیکربندی‌های مجاز و تایید شده از طریق فرآیندهای کنترل شده که امنیت، صحت و قابلیت حسابرسی را حفظ می‌کنند به تولید می‌رسند.

هدف اصلی امنیت: تنها اجزای زیرساختی که به صورت رمزنگاری شده امضا شده‌اند و از نظر آسیب‌پذیری مورد اسکن قرار گرفته‌اند، از طریق خطوط لوله اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی تغییرناپذیر را حفظ می‌کنند، به تولید می‌رسند.

---

### جداسازی محیط زمان اجرای C4.1

جلوگیری از فرار از کانتینر و افزایش امتیاز با استفاده از اصول ایزولاسیون در سطح هسته و کنترل‌های دسترسی اجباری.

 #4.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمام کانتینرهای هوش مصنوعی تمام مجوزهای لینوکس را به جز CAP_SETUID، CAP_SETGID و مجوزهای صریحاً مورد نیاز که در استانداردهای امنیتی مستند شده‌اند، حذف کنند.
 #4.1.2    Level: 1    Role: D/V
 تأیید کنید که پروفایل‌های seccomp تمام فراخوانی‌های سیستم را به جز آن‌هایی که در فهرست‌های سفید از پیش تأیید شده هستند، مسدود می‌کنند و در صورت نقض، کانتینر را خاتمه داده و هشدارهای امنیتی تولید می‌کنند.
 #4.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی با سیستم‌های فایل ریشه فقط خواندنی، tmpfs برای داده‌های موقت و حجم‌های نام‌گذاری شده برای داده‌های پایدار اجرا شوند، به طوری که گزینه‌های mount با noexec اعمال شده باشند.
 #4.1.4    Level: 2    Role: D/V
 تأیید کنید که نظارت زمان‌اجرای مبتنی بر eBPF (مانند Falco، Tetragon یا معادل آن) تلاش‌های افزایش امتیاز دسترسی را شناسایی کرده و به‌طور خودکار فرآیندهای متخلف را در چارچوب زمان پاسخ سازمانی متوقف می‌کند.
 #4.1.5    Level: 3    Role: D/V
 تأیید کنید که بارهای کاری AI با ریسک بالا در محیط‌های ایزوله‌شده سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی بدون سیستم‌عامل) با تأیید صحت اعتبار اجرا می‌شوند.

---

### C4.2 خطوط لوله امن ساخت و استقرار

از طریق ساخت‌های بازتولیدپذیر و آثار امضاشده، صحت رمزنگاری و امنیت زنجیره تأمین را تضمین کنید.

 #4.2.1    Level: 1    Role: D/V
 تأیید کنید که زیرساخت به‌عنوان کد در هر کامیت با ابزارهای (tfsec، Checkov یا Terrascan) اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت CRITICAL یا HIGH مسدود می‌گردند.
 #4.2.2    Level: 1    Role: D/V
 تأیید کنید که ساخت کانتینرها با هش‌های SHA256 یکسان در همه ساخت‌ها قابل بازتولید هستند و تأییدیه‌های منشأ SLSA سطح 3 را با امضای Sigstore تولید نمایید.
 #4.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تصاویر کانتینر شامل CycloneDX یا SPDX SBOM هستند و قبل از ارسال به رجیستری با Cosign امضا شده‌اند و تصاویر بدون امضا در هنگام استقرار رد می‌شوند.
 #4.2.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که خط لوله‌های CI/CD از توکن‌های OIDC از HashiCorp Vault، نقش‌های AWS IAM یا هویت مدیریت شده Azure استفاده می‌کنند که عمر آنها از محدودیت‌های سیاست امنیتی سازمان فراتر نرود.
 #4.2.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که امضاهای Cosign و منابع SLSA در طول فرآیند استقرار قبل از اجرای کانتینر اعتبارسنجی می‌شوند و خطاهای اعتبارسنجی باعث شکست در استقرار می‌شوند.
 #4.2.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرها یا ماشین‌های مجازی موقتی اجرا می‌شوند که فاقد حافظه پایدار بوده و از شبکه‌های تولیدی VPCها جدا شده‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

اجرای شبکه‌های بدون اعتماد با سیاست‌های پیش‌فرض انکار و ارتباطات رمزگذاری شده.

 #4.3.1    Level: 1    Role: D/V
 تأیید کنید که NetworkPolicies کابرنتیز یا هر معادل دیگری پیاده‌سازی پیش‌فرض عدم اجازه ورودی/خروجی را با قوانین صریح اجازه برای پورت‌های مورد نیاز (443، 8080 و غیره) اعمال می‌کند.
 #4.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که SSH (پورت 22)، RDP (پورت 3389)، و نقاط پایانی متادیتای ابری (169.254.169.254) مسدود شده‌اند یا نیاز به احراز هویت مبتنی بر گواهی‌نامه دارند.
 #4.3.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که ترافیک خروجی از طریق پراکسی‌های HTTP/HTTPS (مانند Squid، Istio، یا دروازه‌های NAT ابری) با فهرست‌های مجاز دامنه فیلتر شده و درخواست‌های مسدود شده ثبت می‌شوند.
 #4.3.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که ارتباط بین خدمات از TLS متقابل با گواهی‌نامه‌هایی که بر اساس سیاست سازمانی چرخش می‌کنند استفاده می‌کند و اعتبارسنجی گواهی‌نامه اعمال شده است (هیچ پرچم skip-verify وجود نداشته باشد).
 #4.3.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی در VPCها/VNetهای اختصاصی اجرا می‌شود که دسترسی مستقیم به اینترنت ندارند و تنها از طریق دروازه‌های NAT یا میزبان‌های استوار ارتباط برقرار می‌کند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

محافظت از مدارک با استفاده از ذخیره‌سازی مبتنی بر سخت‌افزار و گردش خودکار با دسترسی مبتنی بر اعتماد صفر.

 #4.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که اسرار در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزنگاری در حالت استراحت با استفاده از AES-256 ذخیره می‌شوند.
 #4.4.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری در HSM های سطح 2 استاندارد FIPS 140-2 (AWS CloudHSM، Azure Dedicated HSM) با چرخش کلید مطابق با سیاست رمزنگاری سازمانی تولید می‌شوند.
 #4.4.3    Level: 2    Role: D/V
 تأیید کنید که گردش حساسیت‌ها به‌صورت خودکار با استقرار بدون قطعی و چرخش فوری که توسط تغییرات پرسنلی یا حوادث امنیتی تحریک می‌شود، انجام می‌گیرد.
 #4.4.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تصاویر کانتینر با استفاده از ابزارهایی مانند GitLeaks، TruffleHog یا detect-secrets اسکن می‌شوند و ساخت‌هایی که شامل کلیدهای API، رمزهای عبور یا گواهی‌ها هستند را مسدود می‌کنند.
 #4.4.5    Level: 2    Role: D/V
 تأیید کنید که دسترسی به کلیدهای مخفی تولیدی با MFA از طریق توکن‌های سخت‌افزاری (YubiKey، FIDO2) انجام می‌شود و توسط گزارش‌های حسابرسی غیرقابل تغییر با شناسه‌های کاربران و زمان‌بندی‌ها ثبت می‌گردد.
 #4.4.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که اسرار از طریق اسرار Kubernetes، حجم‌های متصل شده یا کانتینرهای اولیه تزریق می‌شوند و مطمئن شوید که اسرار هرگز در متغیرهای محیطی یا تصاویر نهفته نمی‌شوند.

---

### ایزوله‌سازی و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی غیرقابل اعتماد را در محیط‌های ایمن ایزوله کنید و با تحلیل رفتاری جامع آنها را بررسی نمایید.

 #4.5.1    Level: 1    Role: D/V
 تأیید کنید که مدل‌های هوش مصنوعی خارجی در gVisor، میکروVMها (مانند Firecracker، CrossVM) یا کانتینرهای Docker با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    Level: 1    Role: D/V
 تأیید کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای ندارند (--network=none) یا فقط دسترسی به localhost دارند و همه درخواست‌های خارجی توسط قوانین iptables مسدود شده‌اند.
 #4.5.3    Level: 2    Role: D/V
 تأیید کنید که اعتبارسنجی مدل هوش مصنوعی شامل تست خودکار تیم قرمز با پوشش تست تعریف شده سازمانی و تحلیل رفتاری برای تشخیص درهای پشتی باشد.
 #4.5.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که قبل از ارتقاء یک مدل هوش مصنوعی به محیط تولید، نتایج تست‌های آن در محیط شبیه‌سازی به طور رمزنگاری شده توسط پرسنل امنیتی مجاز امضا شده و در گزارش‌های حسابرسی غیرقابل تغییر ذخیره می‌شوند.
 #4.5.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها از تصاویر طلایی حذف و مجدداً ایجاد می‌شوند و پاک‌سازی کامل سیستم‌فایل و حافظه انجام می‌گیرد.

---

### C4.6 نظارت بر امنیت زیرساخت

زیرساخت را به صورت مستمر با اصلاح خودکار و هشداردهی در زمان واقعی اسکن و نظارت کنید.

 #4.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تصاویر کانتینر مطابق با برنامه‌های سازمانی اسکن شده‌اند و آسیب‌پذیری‌های بحرانی بر اساس آستانه‌های ریسک سازمانی، مانع از استقرار می‌شوند.
 #4.6.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که زیرساخت مطابق با معیارهای CIS یا کنترل‌های NIST 800-53 با آستانه‌های انطباق تعریف‌شده سازمانی بوده و اصلاح خودکار برای بررسی‌های ناموفق انجام می‌دهد.
 #4.6.3    Level: 2    Role: D/V
 تأیید کنید که آسیب‌پذیری‌های با شدت بالا طبق جدول زمانی مدیریت ریسک سازمانی وصله شده‌اند و برای CVEهایی که به طور فعال مورد بهره‌برداری قرار گرفته‌اند، رویه‌های اضطراری وجود دارد.
 #4.6.4    Level: 2    Role: V
 تأیید کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (مانند Splunk، Elastic، یا Sentinel) با استفاده از فرمت‌های CEF یا STIX/TAXII همراه با غنای خودکار یکپارچه شده‌اند.
 #4.6.5    Level: 3    Role: V
 بررسی کنید که معیارهای زیرساخت به سیستم‌های نظارتی (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر شده باشند.
 #4.6.6    Level: 2    Role: D/V
 تأیید کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) بر اساس الزامات نظارت سازمانی شناسایی شده و بازگردانی خودکار برای تغییرات غیرمجاز انجام می‌شود.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات خستگی منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌بندی و نظارت.

 #4.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که استفاده از GPU/TPU با ایجاد هشدار در آستانه‌های تعیین شده سازمانی رصد می‌شود و مقیاس‌گذاری خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال می‌شود.
 #4.7.2    Level: 1    Role: D/V
 تأیید کنید که شاخص‌های کاری بار هوش مصنوعی (تاخیر استنتاج، توان عملیاتی، نرخ خطا) مطابق با نیازهای نظارت سازمانی جمع‌آوری شده و با استفاده از زیرساخت مرتبط شده باشند.
 #4.7.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که ResourceQuotaهای کوبرنتیز یا محدودیت‌های معادل، بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی محدود می‌کنند و محدودیت‌های سخت‌گیرانه اعمال شده‌اند.
 #4.7.4    Level: 2    Role: V
 تأیید کنید که پایش هزینه، هزینه‌ها را برای هر بار کاری/مستأجر ردیابی می‌کند و هشدارهایی بر اساس آستانه‌های بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه ارائه می‌دهد.
 #4.7.5    Level: 3    Role: V
 اطمینان حاصل کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعریف‌شده سازمانی و فراهم‌سازی خودکار منابع بر اساس الگوهای تقاضا استفاده می‌کند.
 #4.7.6    Level: 2    Role: D/V
 تأیید کنید که تخلیه منابع مطابق با الزامات پاسخ سازمانی، از جمله محدود کردن نرخ بر اساس سیاست‌های ظرفیت و ایزوله‌سازی بار کاری، باعث فعال شدن مدارهای قطع‌کننده می‌شود.

---

### C4.8 کنترل‌های جداسازی محیط و ترفیع

اجرای مرزهای سختگیرانه محیطی با دروازه‌های ارتقاء خودکار و اعتبارسنجی امنیتی.

 #4.8.1    Level: 1    Role: D/V
 تأیید کنید که محیط‌های توسعه/آزمایش/تولید در VPCها/VNetهای جداگانه اجرا می‌شوند و هیچ نقش IAM مشترک، گروه‌های امنیتی یا اتصال شبکه‌ای به اشتراک گذاشته شده وجود ندارد.
 #4.8.2    Level: 1    Role: D/V
 بررسی کنید که ارتقاء محیط نیازمند تایید از سوی پرسنل مجاز تعریف شده سازمانی با امضاهای رمزنگاری شده و مسیرهای حسابرسی غیرقابل تغییر باشد.
 #4.8.3    Level: 2    Role: D/V
 تأیید کنید که محیط‌های تولید دسترسی SSH را مسدود می‌کنند، نقاط انتهایی اشکال‌زدایی را غیرفعال می‌کنند و درخواست‌های تغییر را با نیازمندی‌های اطلاع‌رسانی پیشاپیش سازمانی، به جز در موارد اضطراری، الزامی می‌دانند.
 #4.8.4    Level: 2    Role: D/V
 تأیید کنید که تغییرات زیرساخت به عنوان کد نیاز به بازبینی توسط همکار با آزمایش خودکار و اسکن امنیتی قبل از ادغام با شاخه اصلی دارند.
 #4.8.5    Level: 2    Role: D/V
 تأیید کنید که داده‌های غیرتولیدی مطابق با الزامات حفظ حریم خصوصی سازمانی ناشناس‌سازی شده‌اند، تولید داده‌های سنتتیک انجام شده است یا ماسک‌گذاری کامل داده‌ها با حذف اطلاعات شناسایی شخصی (PII) تایید شده است.
 #4.8.6    Level: 2    Role: D/V
 تأیید کنید که دروازه‌های ارتقاء شامل آزمایش‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) باشند و برای تأیید، یافتن هیچ مورد بحرانی (CRITICAL) لازم باشد.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

اطمینان از پایداری زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی در برابر بحران.

 #4.9.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که پیکربندی‌های زیرساخت طبق برنامه‌های پشتیبان‌گیری سازمانی با پیاده‌سازی استراتژی پشتیبان‌گیری 3-2-1 به مناطق جغرافیایی جداگانه پشتیبان‌گیری می‌شوند.
 #4.9.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های جداگانه با اطلاعات ورود مجزا و ذخیره‌سازی ایزوله (air-gapped) برای محافظت در برابر باج‌افزار اجرا می‌شوند.
 #4.9.3    Level: 2    Role: V
 تأیید کنید که فرایندهای بازیابی از طریق آزمایش خودکار طبق برنامه‌های سازمانی و با اهداف RTO و RPO که مطابق با نیازهای سازمانی هستند، آزمایش و اعتبارسنجی شده‌اند.
 #4.9.4    Level: 3    Role: V
 اطمینان حاصل کنید که بازیابی بلایای طبیعی شامل راهنمای اجرایی خاص هوش مصنوعی با بازگردانی وزن مدل، بازسازی خوشه GPU، و نگاشت وابستگی‌های سرویس باشد.

---

### C4.10 انطباق زیرساخت و حاکمیت

تطابق با مقررات را از طریق ارزیابی مداوم، مستندسازی و کنترل‌های خودکار حفظ کنید.

 #4.10.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تطبیق زیرساخت‌ها مطابق با زمانبندی‌های سازمانی و بر اساس کنترل‌های SOC 2، ISO 27001، یا FedRAMP با جمع‌آوری خودکار شواهد ارزیابی می‌شود.
 #4.10.2    Level: 2    Role: V
 اطمینان حاصل کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید باشد که مطابق با الزامات مدیریت تغییر سازمانی به‌روز شده‌اند.
 #4.10.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تغییرات زیرساخت تحت ارزیابی تأثیر انطباق خودکار با گردش‌کارهای تصویب مقررات برای اصلاحات پرخطر قرار می‌گیرند.

---

### امنیت سخت‌افزار هوش مصنوعی C4.11

قطعات سخت‌افزاری ویژه هوش مصنوعی از جمله GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی را امن کنید.

 #4.11.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرم‌ور شتاب‌دهنده‌های هوش مصنوعی (BIOS کارت گرافیک، فرم‌ور TPU) با امضاهای رمزنگاری شده تأیید شده و مطابق با جدول زمانی مدیریت به‌روزرسانی‌های سازمانی به‌روزرسانی می‌شوند.
 #4.11.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که قبل از اجرای بار کاری، صحت شتاب‌دهنده هوش مصنوعی با استفاده از اثبات اعتبار سخت‌افزاری از طریق TPM 2.0، Intel TXT، یا AMD SVM تأیید می‌شود.
 #4.11.3    Level: 2    Role: D/V
 تأیید کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (گرافیک چندنمونه‌ای چندگانه) یا تقسیم‌بندی سخت‌افزاری معادل با پاکسازی حافظه بین وظایف ایزوله شده است.
 #4.11.4    Level: 3    Role: V
 اطمینان حاصل کنید که زنجیره تأمین سخت‌افزار هوش مصنوعی شامل تأیید اصالت از طریق گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی ضد دستکاری باشد.
 #4.11.5    Level: 3    Role: D/V
 تأیید کنید که ماژول‌های امنیت سخت‌افزاری (HSM) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهینامه FIPS 140-2 سطح 3 یا معیار مشترک EAL4+ محافظت می‌کنند.

---

### زیرساخت هوش مصنوعی لبه‌ای و توزیع شده C4.12

پیاده‌سازی‌های امن هوش مصنوعی توزیع‌شده شامل محاسبات مرزی، یادگیری همگرا و معماری‌های چندسایتی.

 #4.12.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که دستگاه‌های هوش مصنوعی لبه‌ای با استفاده از TLS دوطرفه و گواهی‌های دستگاهی که مطابق با سیاست مدیریت گواهی سازمانی تعویض می‌شوند، به زیرساخت مرکزی احراز هویت می‌کنند.
 #4.12.2    Level: 2    Role: D/V
 تأیید کنید که دستگاه‌های لبه‌ای بوت امن با امضاهای تأییدشده و محافظت در برابر بازگشت نسخه که از حملات کاهش نسخه فریمور جلوگیری می‌کند، پیاده‌سازی کرده‌اند.
 #4.12.3    Level: 3    Role: D/V
 تأیید کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های اجماع مقاوم در برابر خطای بیزانتی استفاده می‌کند که شامل اعتبارسنجی مشارکت‌کنندگان و شناسایی گره‌های مخرب باشد.
 #4.12.4    Level: 3    Role: D/V
 تأیید کنید که ارتباط بین لبه و ابر شامل کنترل پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملکرد آفلاین با ذخیره‌سازی محلی امن باشد.

---

### امنیت زیرساخت چندابری و ترکیبی C4.13

ایمن‌سازی بارهای کاری هوش مصنوعی در چندین ارائه‌دهنده ابر و استقرارهای ترکیبی ابر-محل.

 #4.13.1    Level: 2    Role: D/V
 تأیید کنید که استقرارهای هوش مصنوعی چندابری از فدراسیون هویت مستقل از ابر (OIDC, SAML) با مدیریت سیاست متمرکز در بین ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    Level: 2    Role: D/V
 تأیید کنید که انتقال داده بین ابرها با استفاده از رمزنگاری سرتاسر ارتباط و کلیدهای مدیریت شده توسط مشتری و کنترل‌های محل اقامت داده بر اساس حوزه قضایی اعمال می‌شود.
 #4.13.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی ابری ترکیبی، سیاست‌های امنیتی یکسانی را در محیط‌های محلی و ابری پیاده‌سازی می‌کنند و از پایش و هشداردهی یکپارچه برخوردار هستند.
 #4.13.4    Level: 3    Role: V
 تأیید کنید که جلوگیری از قفل شدن به فروشنده ابر شامل زیرساخت قابل حمل به‌صورت کد، APIهای استاندارد و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت باشد.
 #4.13.5    Level: 3    Role: V
 اطمینان حاصل کنید که بهینه‌سازی هزینه چند ابر شامل کنترل‌های امنیتی برای جلوگیری از پراکندگی منابع و همچنین هزینه‌های انتقال داده غیرمجاز بین ابرها باشد.

---

### امنیت اتوماسیون زیرساخت و GitOps C4.14

خط لوله‌های اتوماسیون زیرساخت ایمن و جریان‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    Level: 2    Role: D/V
 تأیید کنید که مخازن GitOps نیاز به کامیت‌های امضا شده با کلیدهای GPG دارند و قوانین محافظت از شاخه‌ها که از ارسال مستقیم به شاخه‌های اصلی جلوگیری می‌کنند، اعمال شده‌اند.
 #4.14.2    Level: 2    Role: D/V
 تأیید کنید که اتوماسیون زیرساخت شامل تشخیص تغییرات ناخواسته (drift detection) همراه با قابلیت‌های اصلاح خودکار و بازگشت به وضعیت قبلی است که بر اساس نیازهای پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    Level: 2    Role: D/V
 تأیید کنید که تأمین خودکار زیرساخت شامل اعتبارسنجی سیاست‌های امنیتی با مسدودسازی استقرار برای پیکربندی‌های ناسازگار باشد.
 #4.14.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که اسرار اتوماسیون زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator, Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    Level: 3    Role: V
 تأیید کنید که زیرساخت خودترمیم شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حادثه و گردش کار اطلاع‌رسانی به ذینفعان باشد.

---

### امنیت زیرساخت مقاوم در برابر کوانتومی C4.15

آماده‌سازی زیرساخت‌های هوش مصنوعی برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتومی و پروتکل‌های امن در برابر کوانتوم.

 #4.15.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی الگوریتم‌های رمزنگاری پساکوانتومی تایید شده توسط NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) را برای تبادل کلید و امضاهای دیجیتال پیاده‌سازی می‌کند.
 #4.15.2    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با پروتکل‌های مدیریت کلید کوانتومی امن پیاده‌سازی شده‌اند.
 #4.15.3    Level: 3    Role: D/V
 تأیید کنید که چارچوب‌های چابکی رمزنگاری امکان مهاجرت سریع به الگوریتم‌های پساکوانتومی جدید را با چرخش خودکار گواهی‌نامه‌ها و کلیدها فراهم می‌کنند.
 #4.15.4    Level: 3    Role: V
 تأیید کنید که مدل‌سازی تهدیدهای کوانتومی آسیب‌پذیری زیرساخت‌های هوش مصنوعی در برابر حملات کوانتومی را با زمان‌بندی‌های مستند مهاجرت و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در دوره گذار کوانتومی با نظارت بر عملکرد، دفاع در عمق را فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محفظه‌های امن

محافظت از بار کاری هوش مصنوعی و وزن‌های مدل با استفاده از محیط‌های اجرای مطمئن مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه.

 #4.16.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که مدل‌های حساس هوش مصنوعی در محیط‌های Intel SGX، AMD SEV-SNP یا ARM TrustZone با حافظه رمزنگاری شده و تایید صحت اجرا می‌شوند.
 #4.16.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزگذاری حافظه سخت‌افزاری جدا می‌کنند.
 #4.16.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تأیید از راه دور صحت انکلیو را قبل از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری اعتبار محیط اجرایی تأیید می‌کند.
 #4.16.4    Level: 3    Role: D/V
 تأیید کنید که خدمات استنتاج محرمانه هوش مصنوعی از طریق محاسبات رمزنگاری‌شده با وزن‌های مدل مهر و موم‌شده و اجرای محافظت‌شده، از استخراج مدل جلوگیری می‌کنند.
 #4.16.5    Level: 3    Role: D/V
 بررسی کنید که ارکستراسیون محیط اجرای مورد اعتماد، چرخه عمر ناحیه امن را با اعتبارسنجی از راه دور و کانال‌های ارتباطی رمزگذاری شده مدیریت می‌کند.
 #4.16.6    Level: 3    Role: D/V
 تأیید کنید که محاسبات چند جانبه امن (SMPC) امکان آموزش مشترک هوش مصنوعی را بدون افشای داده‌ها یا پارامترهای مدل فردی فراهم می‌کند.

---

### زیرساخت دانش-صفر C4.17

پیاده‌سازی سیستم‌های اثبات بدون دانش برای تأیید صحت و احراز هویت هوش مصنوعی با حفظ حریم خصوصی بدون افشای اطلاعات حساس.

 #4.17.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که اثبات‌های دانش صفر (ZK-SNARKs، ZK-STARKs) صحت مدل هوش مصنوعی و منشأ آموزش را بدون افشای وزن‌های مدل یا داده‌های آموزشی تأیید می‌کنند.
 #4.17.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربران با حفظ حریم خصوصی برای خدمات هوش مصنوعی را بدون افشای اطلاعات مرتبط با هویت فراهم می‌کنند.
 #4.17.3    Level: 3    Role: D/V
 تأیید کنید که پروتکل‌های هم‌پوشانی مجموعه خصوصی (PSI) امکان مطابقت امن داده‌ها را برای هوش مصنوعی فدرال فراهم می‌کنند بدون اینکه داده‌های فردی را افشا کنند.
 #4.17.4    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های یادگیری ماشین دانش صفر (ZKML) امکان استنتاج‌های قابل تایید هوش مصنوعی را با اثبات رمزنگاری شده درستی محاسبات فراهم می‌کنند.
 #4.17.5    Level: 3    Role: D/V
 تأیید کنید که ZK-rollups پردازش تراکنش‌های هوش مصنوعی قابل توسعه و حفظ حریم خصوصی را با تصدیق دسته‌ای و کاهش بار محاسباتی فراهم می‌کنند.

---

### C4.18 جلوگیری از حملات کانال جانبی

محافظت از زیرساخت هوش مصنوعی در برابر حملات جانبی مبتنی بر زمان‌بندی، انرژی، الکترومغناطیسی و کش که ممکن است اطلاعات حساس را فاش کنند.

 #4.18.1    Level: 3    Role: D/V
 تأیید کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان ثابت و پدینگ نرمال‌سازی شده است تا از حملات استخراج مدل مبتنی بر زمان جلوگیری شود.
 #4.18.2    Level: 3    Role: D/V
 تأیید کنید که حفاظت در برابر تحلیل توان شامل تزریق نویز، فیلتر کردن خط برق، و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی می‌باشد.
 #4.18.3    Level: 3    Role: D/V
 تأیید کنید که کاهش تهدید کانال فرعی مبتنی بر حافظه پنهان از تقسیم‌بندی حافظه پنهان، تصادفی‌سازی و دستورالعمل‌های پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    Level: 3    Role: D/V
 تأیید کنید که حفاظت در برابر تابش الکترومغناطیسی شامل پوشش‌دهی، فیلترینگ سیگنال و پردازش تصادفی به منظور جلوگیری از حملات نوع TEMPEST باشد.
 #4.18.5    Level: 3    Role: D/V
 تأیید کنید که دفاع‌های کانال جانبی میکرومعماری شامل کنترل‌های اجرای حدس‌زده و مبهم‌سازی الگوهای دسترسی به حافظه است.

---

### C4.19 امنیت سخت‌افزار نورومورفیک و تخصصی هوش مصنوعی

تامین امنیت معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل چیپ‌های نورو مورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    Level: 3    Role: D/V
 تأیید کنید که امنیت تراشه نورومورفیک شامل رمزنگاری الگوی اسپایک، حفاظت از وزن سیناپسی و اعتبارسنجی قانون یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    Level: 3    Role: D/V
 تأیید کنید که شتاب‌دهنده‌های مبتنی بر FPGA برای هوش مصنوعی از رمزگذاری بیت‌استریم، مکانیزم‌های ضد دستکاری، و بارگذاری تنظیمات امن با به‌روزرسانی‌های تأیید شده استفاده می‌کنند.
 #4.19.3    Level: 3    Role: D/V
 تأیید کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی تراشه، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی ایمن کلید با قابلیت تشخیص دستکاری است.
 #4.19.4    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های محاسبات نوری رمزنگاری نوری امن در برابر کوانتوم، سوئیچینگ فوتونیکی امن و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تراشه‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات آنالوگ امن، ذخیره‌سازی وزن محافظت‌شده و تبدیل آنالوگ به دیجیتال احراز هویت شده باشند.

---

### زیرساخت محاسباتی حفظ حریم خصوصی C4.20

پیاده‌سازی کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور محافظت از داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی.

 #4.20.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که زیرساخت رمزنگاری همومورفیک امکان محاسبات رمزگذاری شده روی بارهای کاری حساس هوش مصنوعی را با تأیید صحت رمزنگاری و نظارت بر عملکرد فراهم می‌کند.
 #4.20.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان انجام پرس‌وجوهای پایگاه داده را بدون افشای الگوهای پرس‌وجو با حفاظت رمزنگاری از الگوهای دسترسی فراهم می‌کنند.
 #4.20.3    Level: 3    Role: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان استنتاج هوش مصنوعی حفظ حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    Level: 3    Role: D/V
 تأیید کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع‌شده، رمزنگاری آستانه‌ای، و چرخش امن کلید با محافظت پشتیبانی‌شده توسط سخت‌افزار است.
 #4.20.5    Level: 3    Role: D/V
 تأیید کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، کشینگ، و شتاب‌دهی سخت‌افزاری بهینه شده است، در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شود.

---

### چارچوب عامل C4.15 امنیت یکپارچه‌سازی ابری و استقرار ترکیبی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های ترکیبی محلی/ابری.

 #4.15.1    Level: 1    Role: D/V
 تأیید کنید که یکپارچه‌سازی ذخیره‌سازی ابری از رمزگذاری انتها به انتها با مدیریت کلید کنترل شده توسط عامل استفاده می‌کند.
 #4.15.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که مرزهای امنیتی استقرار هیبریدی با کانال‌های ارتباطی رمزگذاری شده به وضوح تعریف شده‌اند.
 #4.15.3    Level: 2    Role: D/V
 تأیید کنید که دسترسی به منابع ابری شامل تأیید هویت صفر-اعتماد با احراز هویت مداوم باشد.
 #4.15.4    Level: 3    Role: D/V
 تأیید کنید که الزامات محل اقامت داده‌ها از طریق گواهی‌نامه رمزنگاری شده مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده خدمات ابری شامل مدل‌سازی تهدیدات خاص عامل و ارزیابی ریسک می‌باشد.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای اجزا و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی مؤثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، احراز هویت مبتنی بر زمینه و اجرای زمان واقعی مطابق با اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، سرویس‌ها و عامل‌های خودمختار تنها در محدوده‌های صریحاً اعطا شده با مدل‌ها، داده‌ها و منابع محاسباتی تعامل داشته باشند، همراه با توانایی‌های تأیید و حسابرسی مستمر.

---

### C5.1 مدیریت هویت و احراز هویت

ایجاد هویت‌های رمزنگاری‌شده برای تمام موجودیت‌ها با احراز هویت چندعاملی برای عملیات‌های دارای امتیاز ویژه.

 #5.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه کاربران انسانی و اصول خدمات از طریق یک ارائه‌دهنده هویت سازمانی متمرکز (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند و نگاشت‌های منحصر به فرد هویت به توکن دارند (حساب‌ها یا مدارک اشتراکی وجود ندارد).
 #5.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که عملیات‌های پرخطر (استقرار مدل، صادرات وزن، دسترسی به داده‌های آموزشی، تغییرات تنظیمات تولید) نیازمند احراز هویت چندعاملی یا احراز هویت مرحله‌ای با اعتبارسنجی مجدد جلسه باشند.
 #5.1.3    Level: 2    Role: D
 تأیید کنید که مدیران جدید قبل از دریافت دسترسی به سیستم تولید، فرآیند احراز هویت هویتی را مطابق با استاندارد NIST 800-63-3 IAL-2 یا استانداردهای معادل آن گذرانده باشند.
 #5.1.4    Level: 2    Role: V
 اطمینان حاصل کنید که بررسی‌های دسترسی به صورت فصلی انجام می‌شوند و شامل شناسایی خودکار حساب‌های غیرفعال، اعمال چرخش مدارک احراز هویت، و گردش‌های کاری حذف دسترسی هستند.
 #5.1.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که عوامل فدرال AI از طریق ادعاهای JWT امضا شده که حداکثر عمر آنها 24 ساعت است و شامل اثبات رمزنگاری مبدا می‌باشند، احراز هویت می‌کنند.

---

### C5.2 مجوز دسترسی به منابع و حداقل امتیاز

پیاده‌سازی کنترل‌های دسترسی دقیق برای تمام منابع هوش مصنوعی با مدل‌های اجازه صریح و رد پای حسابرسی.

 #5.2.1    Level: 1    Role: D/V
 تأیید کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقاط پایان، مجموعه‌های برداری، شاخص‌های جاسازی، نمونه‌های محاسباتی) کنترل‌های دسترسی مبتنی بر نقش را با فهرست‌های اجازه صریح و سیاست‌های پیش‌فرض رد اعمال می‌کند.
 #5.2.2    Level: 1    Role: D/V
 تأیید کنید که اصول حداقل امتیاز به طور پیش‌فرض در حساب‌های خدماتی اعمال می‌شود، به طوری که مجوزها از دسترسی فقط خواندنی شروع شده و برای دسترسی نوشتنی دلیل کسب‌وکار مستند شده لازم است.
 #5.2.3    Level: 1    Role: V
 تأیید کنید که تمام تغییرات کنترل دسترسی به درخواست‌های تغییر تأییدشده مرتبط شده و به‌طور غیرقابل تغییر با زمان‌سنجی‌ها، هویت بازیگران، شناسه‌های منابع، و تغییرات مجوز ثبت شده‌اند.
 #5.2.4    Level: 2    Role: D
 تأیید کنید که برچسب‌های طبقه‌بندی داده‌ها (PII، PHI، کنترل‌شده برای صادرات، مالکیتی) به‌طور خودکار به منابع مشتق شده (نمایه‌ها، کش‌های پرسش، خروجی‌های مدل) با اعمال سیاست منسجم منتقل می‌شوند.
 #5.2.5    Level: 2    Role: D/V
 تأیید کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش امتیازات، هشدارهای بلادرنگ با متاداده‌های زمینه‌ای را ظرف ۵ دقیقه به سیستم‌های SIEM ارسال می‌کنند.

---

### C5.3 ارزیابی دینامیک سیاست

استفاده از موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجوزدهی مبتنی بر زمینه با قابلیت‌های حسابرسی را پیاده‌سازی کنید.

 #5.3.1    Level: 1    Role: D/V
 تأیید کنید که تصمیمات مجوزدهی به یک موتور سیاست اختصاصی (مانند OPA، Cedar یا معادل آن) که از طریق APIهای احراز هویت شده و با حفاظت از یکپارچگی رمزنگاری‌شده قابل دسترسی است، برون‌سپاری شده‌اند.
 #5.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیاست‌ها صفات پویا را در زمان اجرا ارزیابی می‌کنند، از جمله سطح مجوز کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستاجر و محدودیت‌های زمانی.
 #5.3.3    Level: 2    Role: D
 تأیید کنید که تعاریف سیاست‌ها کنترل نسخه شده، بازبینی همتا شده و از طریق آزمایش خودکار در خطوط لوله CI/CD قبل از استقرار در محیط تولید اعتبارسنجی شده‌اند.
 #5.3.4    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل دلایل ساختاریافته تصمیم‌گیری هستند و به سیستم‌های SIEM برای تحلیل همبستگی و گزارش‌دهی انطباق منتقل می‌شوند.
 #5.3.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که مقادیر زمان حیات (TTL) کش سیاست‌ها برای منابع با حساسیت بالا بیش از ۵ دقیقه و برای منابع استاندارد با قابلیت ابطال کش بیش از ۱ ساعت نباشد.

---

### اجرای امنیت در زمان پرس‌وجو C5.4

اجرای کنترل‌های امنیتی در لایه پایگاه داده با فیلتر اجباری و سیاست‌های امنیت سطح سطر.

 #5.4.1    Level: 1    Role: D/V
 بررسی کنید که تمام پرس‌وجوهای پایگاه داده برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستأجر، برچسب‌های حساسیت، حوزه کاربر) باشند که در سطح موتور پایگاه داده اعمال شده‌اند، نه در کد برنامه.
 #5.4.2    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های امنیت در سطح ردیف (RLS) و ماسک‌گذاری در سطح فیلد با وراثت سیاست برای تمامی پایگاه‌های داده برداری، شاخص‌های جستجو و مجموعه داده‌های آموزشی فعال شده‌اند.
 #5.4.3    Level: 2    Role: D
 تأیید کنید که ارزیابی‌های ناموفق مجوز با متوقف کردن فوری درخواست‌ها و بازگرداندن کدهای خطای مجوز صریح، به جای بازگرداندن مجموعه نتایج خالی، از حملات "نماینده گیج‌شده" جلوگیری می‌کنند.
 #5.4.4    Level: 2    Role: V
 تأیید کنید که تأخیر در ارزیابی سیاست به طور مداوم با هشدارهای خودکار برای شرایط تایم‌اوت که می‌تواند امکان دورزدن مجوز را فراهم کند، نظارت می‌شود.
 #5.4.5    Level: 3    Role: D/V
 تأیید کنید که مکانیزم‌های تکرار پرس‌وجو سیاست‌های مجوزدهی را مجدداً ارزیابی می‌کنند تا تغییرات پویا در مجوزها را در طول جلسات فعال کاربر در نظر بگیرند.

---

### فیلتر کردن خروجی C5.5 و جلوگیری از از دست رفتن داده‌ها

استقرار کنترل‌های پس‌پردازش برای جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولید شده توسط هوش مصنوعی.

 #5.5.1    Level: 1    Role: D/V
 تأیید کنید که مکانیسم‌های فیلترینگ پس از استنتاج، اطلاعات شناسایی شخصی غیرمجاز (PII)، اطلاعات طبقه‌بندی شده و داده‌های اختصاصی را قبل از ارائه محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که استنادها، منابع و نسبت‌دهی‌های منبع در خروجی‌های مدل بر اساس مجوزهای فراخواننده معتبرسازی شده و در صورت شناسایی دسترسی غیرمجاز، حذف شوند.
 #5.5.3    Level: 2    Role: D
 تأیید کنید که محدودیت‌های فرمت خروجی (فایل‌های PDF پاک‌سازی شده، تصاویر بدون متادیتا، انواع فایل‌های تأیید شده) بر اساس سطوح دسترسی کاربران و طبقه‌بندی داده‌ها اعمال می‌شود.
 #5.5.4    Level: 2    Role: V
 تأیید کنید که الگوریتم‌های سانسور (رداکشن) معین، نسخه‌بندی شده و دارای ثبت گزارش‌های ممیزی هستند تا از تحقیقات انطباقی و تحلیل‌های جنایی پشتیبانی کنند.
 #5.5.5    Level: 3    Role: V
 تأیید کنید که رویدادهای سانسور پرخطر، لاگ‌های تطبیقی ایجاد می‌کنند که شامل هش‌های رمزنگاری شده از محتوای اصلی برای بازیابی قانونی بدون افشای داده‌ها باشد.

---

### C5.6 جداسازی چند مستاجری

اطمینان از جداسازی رمزنگاری و منطقی بین مستأجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که فضای حافظه، مخازن جاسازی، ورودی‌های کش و فایل‌های موقتی به‌صورت جدا شده بر اساس فضای نام هر مستأجر نگهداری می‌شوند و پاک‌سازی امن هنگام حذف مستأجر یا خاتمه جلسه انجام می‌گیرد.
 #5.6.2    Level: 1    Role: D/V
 تأیید کنید که هر درخواست API شامل شناسه مستأجر احراز هویت‌شده‌ای باشد که به‌صورت رمزنگاری شده در مقابل زمینه جلسه و مجوزهای کاربر اعتبارسنجی شده است.
 #5.6.3    Level: 2    Role: D
 تأیید کنید که سیاست‌های شبکه قوانین پیش‌فرض انکار را برای ارتباطات بین مستأجران درون سرویس مش‌ها و پلتفرم‌های ارکستراسیون کانتینر اعمال کرده‌اند.
 #5.6.4    Level: 3    Role: D
 اطمینان حاصل کنید که کلیدهای رمزنگاری برای هر مستأجر منحصر به فرد باشند و از کلیدهای مدیریت شده توسط مشتری (CMK) پشتیبانی شود و جداسازی رمزنگاری بین ذخیره‌سازی داده‌های مستأجران برقرار باشد.

---

### C5.7 مجوز عامل خودران

کنترل مجوزها برای عامل‌های هوش مصنوعی و سیستم‌های خودکار از طریق توکن‌های قابلیت محدوده‌دار و تأیید مداوم.

 #5.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که عوامل خودکار توکن‌های قابلیت محدوده‌دار دریافت می‌کنند که به‌طور صریح اقدامات مجاز، منابع قابل دسترس، محدودیت‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کند.
 #5.7.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که قابلیت‌های پرخطر (دسترسی به سیستم فایل، اجرای کد، تماس با API خارجی، معاملات مالی) به طور پیش‌فرض غیرفعال بوده و برای فعال‌سازی نیاز به مجوزهای صریح با توجیهات تجاری دارند.
 #5.7.3    Level: 2    Role: D
 تأیید کنید که توکن‌های قابلیت به نشست‌های کاربری متصل شده‌اند، شامل حفاظت از صحت رمزنگاری شده باشند، و اطمینان حاصل کنید که نتوان آن‌ها را در سناریوهای آفلاین ذخیره یا مجدداً استفاده کرد.
 #5.7.4    Level: 2    Role: V
 تأیید کنید که اقدامات شروع‌شده توسط عامل، از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ثبت گزارش‌های حسابرسی، مورد تأیید ثانویه قرار می‌گیرند.
 #5.7.5    Level: 3    Role: V
 اطمینان حاصل کنید که شرایط خطاهای عامل و مدیریت استثنا شامل اطلاعات دامنه قابلیت‌ها برای پشتیبانی از تحلیل حادثه و تحقیقات جنایی باشد.

---

### مراجع

#### استانداردها و چهارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت ویژه هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تأمین C6 برای مدل‌ها، فریم‌ورک‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تأمین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه داده‌های شخص ثالث سوءاستفاده می‌کنند تا درب‌های پشتی، تعصب یا کد قابل سوءاستفاده را تزریق کنند. این کنترل‌ها ارائه‌دهنده شناسایی کامل منشأ، مدیریت آسیب‌پذیری و نظارت هستند تا از کل چرخه عمر مدل حفاظت کنند.

---

### C6.1 بررسی و تایید مدل‌های از پیش آموزش دیده و منشأ آن‌ها

پیش از هرگونه میکروفاین‌تیونینگ یا استقرار، اصالت، مجوزها و رفتارهای پنهان مدل‌های شخص ثالث را ارزیابی و تأیید کنید.

 #6.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر مدل مصنوعی ثالث شامل یک سابقه منشأ امضا شده است که مخزن منبع و هش تعهد را شناسایی می‌کند.
 #6.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که مدل‌ها با استفاده از ابزارهای خودکار برای لایه‌های مخرب یا محرک‌های تروجان اسکن می‌شوند قبل از وارد کردن آن‌ها.
 #6.1.3    Level: 2    Role: D
 اطمینان حاصل کنید که تنظیم دقیق آموزش انتقالی، ارزیابی ضد حمله را پشت سر می‌گذارد تا رفتارهای پنهان را شناسایی کند.
 #6.1.4    Level: 2    Role: V
 اطمینان حاصل کنید که مجوزهای مدل، برچسب‌های کنترل صادرات و اظهارات منبع داده در یک ورودی ML-BOM ثبت شده باشند.
 #6.1.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که مدل‌های با ریسک بالا (وزن‌های بارگذاری شده به‌صورت عمومی، ایجادکنندگان تأییدنشده) تا زمان بررسی و تأیید توسط انسان در قرنطینه باقی می‌مانند.

---

### C6.2 چهارچوب و اسکن کتابخانه

به طور مداوم فریم‌ورک‌ها و کتابخانه‌های یادگیری ماشین را برای آسیب‌پذیری‌های امنیتی (CVE) و کدهای مخرب اسکن کنید تا پشته زمان اجرا امن بماند.

 #6.2.1    Level: 1    Role: D/V
 تأیید کنید که خط لوله‌های CI اسکنرهای وابستگی را روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    Level: 1    Role: D/V
 تأیید کنید که آسیب‌پذیری‌های حیاتی (CVSS ≥ 7.0) باعث جلوگیری از ارتقاء به تصاویر تولیدی می‌شوند.
 #6.2.3    Level: 2    Role: D
 تأیید کنید که تحلیل کد ایستا روی کتابخانه‌های ML منشعب شده یا فروخته شده اجرا می‌شود.
 #6.2.4    Level: 2    Role: V
 اطمینان حاصل کنید که پیشنهادات ارتقاء فریمورک شامل ارزیابی تأثیر امنیتی با ارجاع به منابع عمومی CVE باشد.
 #6.2.5    Level: 3    Role: V
 اطمینان حاصل کنید که حسگرهای زمان اجرا در مورد بارگذاری کتابخانه‌های پویا غیرمنتظره که از SBOM امضا شده منحرف شده‌اند، هشدار می‌دهند.

---

### C6.3 تثبیت وابستگی و تایید صحت

تمام وابستگی‌ها را به شناسه‌های تغییرناپذیر (immutable digests) قفل کنید و ساخت‌ها را بازتولید کنید تا از تولید آثار یکسان و بدون دستکاری اطمینان حاصل شود.

 #6.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمام مدیران بسته نسخه‌ها را از طریق فایل‌های قفل شده کنترل می‌کنند.
 #6.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که به جای تگ‌های قابل تغییر، از خلاصه‌های غیرقابل تغییر در ارجاعات کانتینر استفاده می‌شود.
 #6.3.3    Level: 2    Role: D
 اطمینان حاصل کنید که بررسی‌های ساخت قابل بازتولید، هش‌ها را در طول اجرای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شوند.
 #6.3.4    Level: 2    Role: V
 اطمینان حاصل کنید که گواهی‌های ساخت به مدت 18 ماه برای قابلیت پیگیری حسابرسی ذخیره می‌شوند.
 #6.3.5    Level: 3    Role: D
 تأیید کنید که وابستگی‌های منقضی‌شده باعث ایجاد درخواست‌های خودکار (PR) برای به‌روزرسانی یا ایجاد فورک نسخه‌های پین‌شده می‌شوند.

---

### C6.4 اجرای منبع مورد اعتماد

تنها اجازه دانلود آر تیفکت‌ها از منابع تایید شده رمزنگاری شده و مورد تایید سازمان را بدهید و تمام موارد دیگر را مسدود کنید.

 #6.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که وزن‌های مدل، مجموعه داده‌ها و کانتینرها فقط از دامنه‌های تایید شده یا رجیستری‌های داخلی دانلود می‌شوند.
 #6.4.2    Level: 1    Role: D/V
 تأیید کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از اینکه آرтификت‌ها به صورت محلی کش شوند، اعتبارسنجی می‌کنند.
 #6.4.3    Level: 2    Role: D
 تأیید کنید که پراکسی‌های خروجی دانلودهای بدون احراز هویت اشیاء را مسدود می‌کنند تا سیاست منبع مورد اعتماد را اعمال کنند.
 #6.4.4    Level: 2    Role: V
 اطمینان حاصل کنید که فهرست‌های مجاز مخزن به صورت سه‌ماهه بازبینی می‌شوند و برای هر ورودی، شواهدی از توجیه تجاری وجود دارد.
 #6.4.5    Level: 3    Role: V
 اطمینان حاصل کنید که نقض سیاست‌ها باعث قرنطینه شدن آثار و بازگردانی اجرای‌های وابسته به لوله‌کشی می‌شود.

---

### C6.5 ارزیابی ریسک داده‌های شخص ثالث

داده‌های خارجی را برای تشخیص حملات مسموم‌سازی، سوگیری و مطابقت قانونی ارزیابی کرده و در طول چرخه عمر آن‌ها را زیر نظر داشته باشید.

 #6.5.1    Level: 1    Role: D/V
 تأیید کنید که مجموعه داده‌های خارجی تحت ارزیابی ریسک مسمومیت قرار می‌گیرند (مثلاً اثر انگشت داده، تشخیص نقاط دورافتاده).
 #6.5.2    Level: 1    Role: D
 اطمینان حاصل کنید که معیارهای سوگیری (توازن جمعیتی، فرصت برابر) قبل از تایید مجموعه داده محاسبه شده‌اند.
 #6.5.3    Level: 2    Role: V
 اطمینان حاصل کنید که منبع و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML‑BOM ثبت شده‌اند.
 #6.5.4    Level: 2    Role: V
 تأیید کنید که مانیتورینگ دوره‌ای تغییرات یا فساد در داده‌های میزبانی شده را شناسایی می‌کند.
 #6.5.5    Level: 3    Role: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حق نشر، اطلاعات شناسایی شخصی) پیش از آموزش از طریق پاک‌سازی خودکار حذف شده باشد.

---

### C6.6 نظارت بر حملات زنجیره تامین

تهدیدهای زنجیره تأمین را از طریق فیدهای CVE، تحلیل‌های لاگ حسابرسی، و شبیه‌سازی‌های تیم قرمز زودتر شناسایی کنید.

 #6.6.1    Level: 1    Role: V
 اطمینان حاصل کنید که لاگ‌های حسابرسی CI/CD به صورت جریان به تشخیص‌های SIEM برای کشش بسته‌های غیرعادی یا مراحل ساخت دستکاری شده منتقل می‌شوند.
 #6.6.2    Level: 2    Role: D
 تأیید کنید که دفترچه‌های پاسخ به حادثه شامل رویه‌های بازگردانی برای مدل‌ها یا کتابخانه‌های به خطر افتاده باشند.
 #6.6.3    Level: 3    Role: V
 اطمینان حاصل کنید که برچسب‌های غنی‌سازی تهدید-اطلاعات شاخص‌های خاص یادگیری ماشین (مانند IoCهای آلودگی مدل) را در طبقه‌بندی هشدارها علامت‌گذاری می‌کند.

---

### C6.7 ML‑BOM برای آثار مدل

تولید و امضای SBOMهای دقیق مخصوص یادگیری ماشین (ML-BOMها) به طوری که مصرف‌کنندگان پایین‌دستی بتوانند صحت اجزا را در زمان استقرار تأیید کنند.

 #6.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر مدل مصنوعی یک ML‑BOM منتشر می‌کند که شامل مجموعه داده‌ها، وزن‌ها، ابرپارامترها و مجوزها باشد.
 #6.7.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که تولید ML-BOM و امضای Cosign به صورت خودکار در CI انجام می‌شود و برای ادغام الزامی است.
 #6.7.3    Level: 2    Role: D
 بررسی کنید که چک‌های کامل بودن ML-BOM در صورت مفقود بودن هر گونه فراداده مؤلفه (هش، مجوز) باعث شکست ساخت می‌شوند.
 #6.7.4    Level: 2    Role: V
 تأیید کنید که مصرف‌کنندگان پایین‌دستی بتوانند از طریق API به ML-BOMها برای اعتبارسنجی مدل‌های وارد شده در زمان استقرار پرس‌وجو کنند.
 #6.7.5    Level: 3    Role: V
 تأیید کنید که فهرست مواد یادگیری ماشینی (ML-BOMs) تحت کنترل نسخه هستند و تغییرات آن‌ها برای شناسایی اصلاحات غیرمجاز مقایسه می‌شوند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختاریافته، قابل‌اعتماد، ایمن، قابل توضیح و به‌طور مداوم در تولید تحت‌نظارت باشند. انجام این کار باعث کاهش هذیان‌ها، نشت‌های حریم خصوصی، محتوای مضر و اقدامات خارج از کنترل می‌شود و در عین حال اعتماد کاربران و تطابق با مقررات را افزایش می‌دهد.

---

### C7.1 اعمال قالب خروجی

اسکیم‌های سختگیرانه، رمزگشایی محدود شده، و اعتبارسنجی پایین‌دستی محتوای ناقص یا مخرب را قبل از انتشار متوقف می‌کنند.

 #7.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که طرح‌واره‌های پاسخ (مثلاً JSON Schema) در فرمان سیستم ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های ناسازگار باعث تعمیر یا رد می‌شوند.
 #7.1.2    Level: 1    Role: D/V
 تأیید کنید که رمزگشایی محدودشده (توکن‌های توقف، عبارات منظم، حداکثر توکن‌ها) فعال باشد تا از سرریز یا کانال‌های جانبی تزریق پرامپت جلوگیری شود.
 #7.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که اجزای پایین‌دستی خروجی‌ها را به عنوان داده‌های غیرقابل اعتماد در نظر می‌گیرند و آن‌ها را بر اساس اسکیماها یا سریال‌زدایی‌های ایمن در برابر تزریق اعتبارسنجی می‌کنند.
 #7.1.4    Level: 3    Role: V
 اطمینان حاصل کنید که رویدادهای خروجی نادرست ثبت، محدود نرخ و به سیستم نظارت نمایش داده می‌شوند.

---

### C7.2 شناسایی و کاهش هذیان

تخمین عدم قطعیت و استراتژی‌های پشتیبان، پاسخ‌های ساخته شده را کنترل می‌کنند.

 #7.2.1    Level: 1    Role: D/V
 تأیید کنید که احتمال‌های لوگ در سطح توکن، انسجام خود الگوهای گروهی، یا آشکارسازهای هالوسیناسیون تنظیم‌شده، به هر پاسخ یک امتیاز اطمینان اختصاص می‌دهند.
 #7.2.2    Level: 1    Role: D/V
 تأیید کنید که پاسخ‌هایی با اطمینان کمتر از حد آستانه قابل تنظیم، فرآیندهای جایگزین (مانند تولید با افزایش بازیابی، مدل ثانویه، یا بازبینی انسانی) را فعال کنند.
 #7.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که موارد توهم با فراداده علت اصلی برچسب‌گذاری شده و به جریان‌های پسامدن و آموزش دقیق داده می‌شوند.
 #7.2.4    Level: 3    Role: D/V
 تأیید کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های عمده مدل یا پایگاه دانش مجدداً کالیبره شده‌اند.
 #7.2.5    Level: 3    Role: V
 اطمینان حاصل کنید که تجسم‌های داشبورد نرخ‌های هذیان را رصد می‌کنند.

---

### C7.3 فیلترگذاری ایمنی و حفظ حریم خصوصی خروجی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    Level: 1    Role: D/V
 تأیید کنید که طبقه‌بندی‌کننده‌های پیش و پس از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآسیب‌رسان، افراطی و مطالب جنسی صریح که با سیاست مطابقت دارد را مسدود می‌کنند.
 #7.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که شناسایی PII/PCI و اصلاح خودکار در هر پاسخ اجرا می‌شود؛ تخلفات منجر به بروز یک حادثه حریم خصوصی می‌شود.
 #7.3.3    Level: 2    Role: D
 تأیید کنید که برچسب‌های محرمانگی (مثلاً اسرار تجاری) در تمام حالت‌ها منتقل می‌شوند تا از نشت در متن، تصاویر یا کد جلوگیری شود.
 #7.3.4    Level: 3    Role: D/V
 تأیید کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های با ریسک بالا نیازمند تأیید ثانویه یا احراز هویت مجدد کاربر باشند.
 #7.3.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که آستانه‌های فیلترینگ منعکس‌کننده حوزه‌های قانونی و زمینه سنی/نقشی کاربران باشد.

---

### C7.4 محدودسازی خروجی و اقدام

محدودیت‌های نرخ و دروازه‌های تأیید از سوءاستفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    Level: 1    Role: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را محدود می‌کنند و در صورت خطای 429، با عقب‌نشینی نمایی برخورد می‌کنند.
 #7.4.2    Level: 1    Role: D/V
 تأیید کنید که اقدامات دارای امتیاز ویژه (نوشتن فایل، اجرای کد، فراخوانی شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسان در فرآیند هستند.
 #7.4.3    Level: 2    Role: D/V
 تأیید کنید که بررسی‌های سازگاری میان‌مدلی اطمینان می‌دهد تصاویر، کد و متن تولید شده برای یک درخواست یکسان نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    Level: 2    Role: D
 تأیید کنید که عمق واگذاری نماینده، محدودیت‌های بازگشتی و فهرست ابزارهای مجاز به‌طور صریح پیکربندی شده‌اند.
 #7.4.5    Level: 3    Role: V
 تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساختاریافته برای دریافت در سیستم SIEM ارسال می‌کند.

---

### قابلیت توضیح خروجی C7.5

سیگنال‌های شفاف باعث افزایش اعتماد کاربران و تسهیل اشکال‌زدایی داخلی می‌شوند.

 #7.5.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که امتیازهای اطمینان نمایش داده شده برای کاربر یا خلاصه‌های کوتاه استدلال زمانی که ارزیابی ریسک مناسب تشخیص داده می‌شود، ارائه شوند.
 #7.5.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از افشای دعوت‌نامه‌های سیستم حساس یا داده‌های مالکیتی خودداری می‌کنند.
 #7.5.3    Level: 3    Role: D
 تأیید کنید که سیستم احتمال‌های لگاریتمی در سطح توکن یا نقشه‌های توجه را ضبط کرده و آنها را برای بررسی‌های مجاز ذخیره می‌کند.
 #7.5.4    Level: 3    Role: V
 اطمینان حاصل کنید که مصنوعات قابل توضیح در کنار نسخه‌های مدل برای قابلیت حسابرسی، تحت کنترل نسخه قرار دارند.

---

### C7.6 یکپارچه‌سازی نظارت

قابلیت مشاهده به‌موقع حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    Level: 1    Role: D
 تأیید کنید که معیارها (نقض الگو، نرخ توهم، سمی بودن، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم نظارتی مرکزی ارسال می‌شوند.
 #7.6.2    Level: 1    Role: V
 تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده‌اند، همراه با مسیرهای ارتقاء تماس در مواقع اضطراری.
 #7.6.3    Level: 2    Role: V
 بررسی کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، پرچم ویژگی و تغییرات داده‌های بالادستی همبسته کنند.
 #7.6.4    Level: 2    Role: D/V
 تأیید کنید که داده‌های پایش‌شده در یک گردش کار مستند MLOps به بازآموزی، تنظیم دقیق یا به‌روزرسانی قوانین وارد می‌شوند.
 #7.6.5    Level: 3    Role: V
 اطمینان حاصل کنید که خط لوله‌های نظارتی از نظر نفوذپذیری آزمایش شده و کنترل دسترسی شده‌اند تا از نشت لاگ‌های حساس جلوگیری شود.

---

### ۷.۷ تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند از طریق اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت ردیابی.

 #7.7.1    Level: 1    Role: D/V
 تأیید کنید که دستورات سیستم و راهنمایی‌های کاربر به‌طور صریح تولید رسانه‌های دیپ‌فیک غیرقانونی، آسیب‌زا یا بدون رضایت (مانند تصویر، ویدئو، صدا) را ممنوع می‌کنند.
 #7.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که درخواست‌ها برای تلاش در تولید تقلیدهای هویتی، تصاویر جعلی جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند، فیلتر شده‌اند.
 #7.7.3    Level: 2    Role: V
 تأیید کنید که سیستم از هش ادراکی، تشخیص واترمارک، یا اثرانگشت دیجیتال برای جلوگیری از تکثیر غیرمجاز رسانه‌های دارای حق نشر استفاده می‌کند.
 #7.7.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولید شده به صورت رمزنگاری شده امضا، دارای واترمارک، یا با متادیتای منشأ مقاوم در برابر دستکاری برای ردیابی‌های بعدی جاسازی شده‌اند.
 #7.7.5    Level: 3    Role: V
 اطمینان حاصل کنید که تلاش‌های دور زدن (مانند مبهم‌سازی پرامپت، زبان عامیانه، جملات مخرب) شناسایی شده، ثبت شده و با محدودیت سرعت مدیریت می‌شوند؛ سوءاستفاده‌های مکرر به سیستم‌های نظارتی گزارش می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، تعبیه‌ها و پایگاه داده برداری

### هدف کنترل

تعبیه‌ها و پایگاه‌های داده برداری به‌عنوان "حافظه زنده" سیستم‌های هوش مصنوعی معاصر عمل می‌کنند، به‌طور مداوم داده‌های ارائه‌شده توسط کاربر را دریافت کرده و از طریق تولید تقویت‌شده با بازیابی (RAG) آن‌ها را به زمینه‌های مدل بازمی‌گردانند. اگر این حافظه به‌درستی مدیریت نشود، ممکن است اطلاعات شناسایی شخصی (PII) را فاش کند، حقوق موافقت را نقض نماید یا به‌طور معکوس متن اصلی را بازسازی کند. هدف این مجموعه کنترل‌ها سخت‌کردن خطوط لوله حافظه و پایگاه‌های داده برداری است تا دسترسی با حداقل امتیاز باشد، تعبیه‌ها حفظ حریم خصوصی را تضمین کنند، بردارهای ذخیره‌شده منقضی شده یا طبق درخواست لغو شوند، و حافظه هر کاربر هرگز ورودی‌ها یا خروجی‌های سایر کاربران را آلوده نکند.

---

### C8.1 کنترل‌های دسترسی بر حافظه و شاخص‌های RAG

اجرای کنترل‌های دسترسی دقیق روی هر مجموعه برداری.

 #8.1.1    Level: 1    Role: D/V
 تأیید کنید که قوانین کنترل دسترسی در سطح ردیف/فضا نام به عملیات درج، حذف و پرس‌وجو بر اساس مستأجر، مجموعه، یا برچسب سند محدودیت اعمال کند.
 #8.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که کلیدهای API یا JWT شامل اعلامیه‌های محدوده‌دار (مثلاً شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر سه ماه یکبار تغییر می‌کنند.
 #8.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تلاش‌های افزایش امتیاز (مانند کوئری‌های شباهت بین فضاهای نام مختلف) شناسایی شده و در عرض ۵ دقیقه به سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) گزارش شوند.
 #8.1.4    Level: 2    Role: D/V
 تأیید کنید که پایگاه داده برداری سوابق ممیزی شامل شناسه موضوع، عملیات، شناسه بردار/فضای نام، آستانه شباهت و تعداد نتایج را ثبت می‌کند.
 #8.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که تصمیمات دسترسی هرگاه موتور‌ها به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی ایندکس تغییر می‌کنند، برای نقص‌های دورزدن آزمایش شوند.

---

### C8.2 پاک‌سازی و اعتبارسنجی جاسازی‌ها

متن را برای اطلاعات شناسایی شخصی (PII) پیش‌بررسی کنید، قبل از بردارسازی سیاه یا تغییر نام آن، و به طور اختیاری پس از پردازش تعبیه‌ها برای حذف سیگنال‌های باقی‌مانده اقدام کنید.

 #8.2.1    Level: 1    Role: D/V
 تأیید کنید که داده‌های PII و داده‌های تنظیم‌شده از طریق طبقه‌بندی‌کننده‌های خودکار شناسایی شده و قبل از تعبیه، ماسک‌گذاری، توکنیزه یا حذف شده‌اند.
 #8.2.2    Level: 1    Role: D
 تأیید کنید که خطوط لوله تعبیه، ورودی‌هایی که حاوی کد اجرایی یا آثار غیر UTF-8 هستند و ممکن است ایندکس را آلوده کنند، رد یا قرنطینه می‌کنند.
 #8.2.3    Level: 2    Role: D/V
 تأیید کنید که پاک‌سازی حریم خصوصی تفاضلی محلی یا متریکی روی جاسازی‌های جمله اعمال شده است که فاصله آن‌ها تا هر توکن شناسایی اطلاعات شخصی (PII) شناخته شده کمتر از آستانه قابل پیکربندی باشد.
 #8.2.4    Level: 2    Role: V
 اطمینان حاصل کنید که اثربخشی پاک‌سازی (مثلاً بازیابی اطلاعات شناسایی شخصی حذف‌شده، تغییر معنایی) حداقل هر شش ماه یک‌بار با استفاده از مجموعه‌های مرجع معتبر تایید شود.
 #8.2.5    Level: 3    Role: D/V
 تأیید کنید که پیکربندی‌های پاکسازی کنترل نسخه شده‌اند و تغییرات تحت بازبینی همتایان قرار می‌گیرند.

---

### C8.3 منقضی شدن حافظه، لغو و حذف

قانون GDPR "حق فراموش شدن" و قوانین مشابه نیازمند پاک‌سازی به موقع هستند؛ بنابراین فروشگاه‌های برداری باید از TTL‌ها، حذف‌های سخت و تدفین‌سازی پشتیبانی کنند تا بردارهای لغو شده قابل بازیابی یا نمایه‌سازی مجدد نباشند.

 #8.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر بردار و رکورد متادیتا دارای یک TTL یا برچسب نگهداری صریح است که توسط کارهای پاک‌سازی خودکار رعایت می‌شود.
 #8.3.2    Level: 1    Role: D/V
 تأیید کنید که درخواست‌های حذف آغاز شده توسط کاربر، وکتورها، فراداده‌ها، نسخه‌های کش شده و شاخص‌های مشتق شده را ظرف 30 روز پاک می‌کنند.
 #8.3.3    Level: 2    Role: D
 اطمینان حاصل کنید که حذف‌های منطقی با پاک‌سازی رمزنگاری شده بلاک‌های ذخیره‌سازی در صورت پشتیبانی سخت‌افزار دنبال می‌شوند، یا با نابودی کلیدهای موجود در مخزن کلید.
 #8.3.4    Level: 3    Role: D/V
 تأیید کنید که وکتورهای منقضی شده کمتر از 500 میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف می‌شوند.

---

### C8.4 جلوگیری از معکوس‌سازی و نشت جاسازی

دفاع‌های اخیر—هم‌افزایی نویز، شبکه‌های پروجکشن، تغییرات نورون‌های حریم خصوصی، و رمزنگاری لایه برنامه—می‌توانند نرخ معکوس‌سازی در سطح توکن را به زیر ۵٪ کاهش دهند.

 #8.4.1    Level: 1    Role: V
 تأیید کنید که یک مدل تهدید رسمی که شامل حملات وارونگی، عضویت و استنتاج ویژگی‌ها باشد، وجود دارد و سالانه بازبینی می‌شود.
 #8.4.2    Level: 2    Role: D/V
 تأیید کنید که رمزنگاری در لایه برنامه یا رمزنگاری قابل جستجو، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    Level: 3    Role: V
 تأیید کنید که پارامترهای دفاعی (ε برای DP، نویز σ، رتبه پروژه k) تعادل حفظ حریم خصوصی ≥ ۹۹٪ حفاظت از توکن و کارایی ≤ ۳٪ کاهش دقت را برقرار می‌کنند.
 #8.4.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای مقاومت در برابر معکوس شدن، بخشی از موانع انتشار برای به‌روزرسانی‌های مدل هستند و بودجه‌های رگرسیون مشخص شده‌اند.

---

### اجرای حوزه C8.5 برای حافظه خاص کاربر

نشت اطلاعات میان مستاجران مختلف همچنان یکی از بزرگترین ریسک‌های RAG است: جستجوهای شباهتی که به درستی فیلتر نشده‌اند می‌توانند مدارک خصوصی مشتری دیگر را نمایان کنند.

 #8.5.1    Level: 1    Role: D/V
 تأیید کنید که هر پرس و جوی بازیابی قبل از ارسال به پرامپت LLM، توسط شناسه مستاجر/کاربر پس‌فیلتر می‌شود.
 #8.5.2    Level: 1    Role: D
 تأیید کنید که نام‌های مجموعه یا شناسه‌های نام‌گذاری شده بر اساس کاربر یا مستأجر به صورت salted باشند تا بردارها در حوزه‌های مختلف با هم تداخل نداشته باشند.
 #8.5.3    Level: 2    Role: D/V
 تأیید کنید که نتایج شباهت بالاتر از آستانه فاصله قابل تنظیم اما خارج از حوزه فراخواننده، رد شده و هشدارهای امنیتی را فعال می‌کنند.
 #8.5.4    Level: 2    Role: V
 اطمینان حاصل کنید که تست‌های فشار چند مستاجمی، پرس‌وجوهای خصمانه‌ای که تلاش دارند اسناد خارج از محدوده را بازیابی کنند، شبیه‌سازی می‌کنند و نشان‌دهنده عدم نشت اطلاعات هستند.
 #8.5.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری برای هر مستأجر جدا شده‌اند، به گونه‌ای که جداسازی رمزنگاری حتی در صورت اشتراک‌گذاری فضای ذخیره‌سازی فیزیکی حفظ شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های پیچیده حافظه شامل حافظه اپیزودیک، معنایی و حافظه کاری با نیازهای خاص جداسازی و اعتبارسنجی.

 #8.6.1    Level: 1    Role: D/V
 تأیید کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزنگاری جداگانه و الگوهای دسترسی مستندسازی شده برای هر نوع حافظه باشند.
 #8.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق حافظه‌های مخرب از طریق پاک‌سازی محتوا، تایید منبع و بررسی‌های یکپارچگی قبل از ذخیره‌سازی است.
 #8.6.3    Level: 2    Role: D/V
 تایید کنید که پرس‌وجوهای بازیابی حافظه بررسی و پاک‌سازی می‌شوند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی پرس‌وجو، اعمال کنترل دسترسی و فیلترینگ نتایج جلوگیری شود.
 #8.6.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های فراموشی حافظه، اطلاعات حساس را با تضمین‌های پاک‌سازی رمزنگاری شده به‌طور ایمن حذف می‌کنند، از جمله با حذف کلید، بازنویسی چندگانه، یا حذف ایمن مبتنی بر سخت‌افزار با گواهی‌های تأیید.
 #8.6.5    Level: 3    Role: D/V
 اطمینان حاصل شود که یکپارچگی سیستم حافظه به طور مداوم برای تغییرات یا خرابی‌های غیرمجاز از طریق مجموع‌های کنترلی (checksums)، گزارش‌های حسابرسی و هشدارهای خودکار هنگام تغییر محتوای حافظه خارج از عملیات عادی، نظارت می‌شود.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 هماهنگی خودکار و امنیت عمل عاملی

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودکار یا چندعاملی فقط اقداماتی را اجرا می‌کنند که به‌طور صریح مورد نظر، احراز هویت شده، قابل بررسی و در محدوده هزینه‌ها و خطرات مشخص شده هستند. این امر در برابر تهدیداتی مانند نفوذ به سیستم خودکار، سوءاستفاده از ابزار، شناسایی حلقه‌های عامل، ربودن ارتباطات، جعل هویت، دستکاری جمعی و دستکاری قصد محافظت می‌کند.

---

### 9.1 بودجه‌های برنامه‌ریزی وظایف عامل و بازگشتی

محدود کردن برنامه‌های بازگشتی و اجباری کردن نقاط بررسی انسانی برای اقدامات دارای امتیاز ویژه.

 #9.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که بیشینه عمق بازگشتی، پهنا، زمان واقعی ساعت دیواری، توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی و کنترل نسخه شده‌اند.
 #9.1.2    Level: 1    Role: D/V
 تأیید کنید که اقدامات خاص یا غیرقابل بازگشت (مانند تعهدات کد، انتقالات مالی) پیش از اجرا نیازمند تأیید صریح انسانی از طریق یک کانال قابل حسابرسی باشند.
 #9.1.3    Level: 2    Role: D
 تأیید کنید که نظارت‌کننده‌های منابع در زمان واقعی هنگامی که هر آستانه بودجه‌ای نقض می‌شود، وقفه مدار شکن را فعال کرده و از گسترش بیشتر وظایف جلوگیری می‌کنند.
 #9.1.4    Level: 2    Role: D/V
 تأیید کنید که رویدادهای مدارشکن با شناسه عامل، شرایط فعال‌سازی و وضعیت برنامه ضبط‌شده برای بررسی قضایی ثبت شوند.
 #9.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که تست‌های امنیتی شامل سناریوهای تخلیه بودجه و برنامه‌های runaway هستند و توقف ایمن بدون از دست دادن داده‌ها تأیید شود.
 #9.1.6    Level: 3    Role: D
 اطمینان حاصل کنید که سیاست‌های بودجه به صورت سیاست به عنوان کد بیان شده و در CI/CD اعمال می‌شوند تا از انحراف تنظیمات جلوگیری شود.

---

### 9.2 جداسازی ابزار افزونه

تعاملات ابزار را جدا کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر ابزار/افزونه داخل یک سیستم‌عامل، کانتینر، یا سندباکس سطح WASM با سیاست‌های حداقل امتیاز برای سیستم‌فایل، شبکه و فراخوانی‌های سیستمی اجرا می‌شود.
 #9.2.2    Level: 1    Role: D/V
 تأیید کنید که محدودیت‌های منابع سندباکس (پردازنده، حافظه، دیسک، خروجی شبکه) و محدودیت‌های زمانی اجرا اعمال و ثبت می‌شوند.
 #9.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که باینری‌های ابزار یا توصیف‌کننده‌ها به صورت دیجیتالی امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    Level: 2    Role: V
 تأیید کنید که تلومتری سندباکس به یک سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ارسال می‌شود؛ ناهنجاری‌ها (مانند تلاش‌های اتصال خروجی) هشدارها را ایجاد می‌کنند.
 #9.2.5    Level: 3    Role: V
 اطمینان حاصل کنید که پلاگین‌های پرخطر قبل از استقرار در محیط تولید، تحت بررسی امنیتی و تست نفوذ قرار می‌گیرند.
 #9.2.6    Level: 3    Role: D/V
 تأیید کنید که تلاش‌های فرار از سندباکس به صورت خودکار مسدود شده و افزونه متخلف تا زمان بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودکار و تعیین محدودیت هزینه

شناسایی و جلوگیری از بازگشت بی‌رویه عامل به عامل و انفجار هزینه‌ها.

 #9.3.1    Level: 1    Role: D/V
 تأیید کنید که تماس‌های بین عوامل شامل محدودیت پرش یا TTL باشد که زمان اجرا آن را کاهش داده و اعمال می‌کند.
 #9.3.2    Level: 2    Role: D
 تأیید کنید که عوامل یک شناسه منحصر به فرد نمودار فراخوانی (invocation-graph ID) را حفظ کنند تا خودفراخوانی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    Level: 2    Role: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسبه و هزینه به‌ازای هر زنجیره درخواست پیگیری می‌شوند؛ نقض این محدودیت باعث توقف زنجیره می‌شود.
 #9.3.4    Level: 3    Role: V
 بررسی کنید که تحلیل رسمی یا مدل‌چکینگ عدم وجود بازگشت نامحدود در پروتکل‌های نماینده را نشان می‌دهد.
 #9.3.5    Level: 3    Role: D
 اطمینان حاصل کنید که رویدادهای وقفه حلقه هشدارها را تولید کرده و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 حفاظت در برابر سوءاستفاده در سطح پروتکل

کانال‌های ارتباطی امن بین عامل‌ها و سیستم‌های خارجی برای جلوگیری از ربوده شدن یا دستکاری ایجاد کنید.

 #9.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه پیام‌های بین عامل و ابزار و بین عامل‌ها به صورت احراز هویت شده (مانند TLS دوطرفه یا JWT) و رمزنگاری انتها به انتها هستند.
 #9.4.2    Level: 1    Role: D
 اطمینان حاصل کنید که اسکیم‌ها به‌طور دقیق اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های نادرست رد می‌شوند.
 #9.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که چک‌های یکپارچگی (MACها یا امضاهای دیجیتال) کل بار پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    Level: 2    Role: D
 اطمینان حاصل کنید که حفاظت در برابر بازپخش (نونس‌ها یا بازه‌های زمانی تاریخچه) در لایه پروتکل اعمال می‌شود.
 #9.4.5    Level: 3    Role: V
 تأیید کنید که پیاده‌سازی‌های پروتکل تحت فرآیند فازینگ و تحلیل ایستا برای یافتن آسیب‌پذیری‌های تزریق یا سریال‌زدایی قرار گرفته‌اند.

---

### 9.5 هویت عامل و شواهد تغییرناپذیری

اطمینان حاصل کنید که اقدامات قابل انتساب باشند و تغییرات قابل تشخیص باشند.

 #9.5.1    Level: 1    Role: D/V
 تأیید کنید که هر نمونه عامل دارای یک هویت رمزنگاری منحصر به فرد (جفت کلید یا اعتبارنامه ریشه‌ای سخت‌افزاری) باشد.
 #9.5.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمامی اقدامات عامل امضا و دارای مهر زمانی هستند؛ لاگ‌ها شامل امضا برای جلوگیری از انکار باشند.
 #9.5.3    Level: 2    Role: V
 تایید کنید که لاگ‌های مقاوم در برابر دستکاری در یک رسانه فقط افزایشی یا نوشتن تنها ذخیره می‌شوند.
 #9.5.4    Level: 3    Role: D
 تأیید کنید که کلیدهای هویتی بر اساس برنامه‌ای تعیین شده و در صورت نشانگرهای خطر نفوذ، تغییر می‌کنند.
 #9.5.5    Level: 3    Role: D/V
 تأیید کنید که تلاش‌های جعل هویت یا تناقض کلید، قرنطینه فوری عامل آسیب‌دیده را فعال می‌کنند.

---

### 9.6 کاهش ریسک توسط گروه‌های چندعاملهٔ دسته‌جمعی

کاهش خطرات رفتار جمعی از طریق ایزوله‌سازی و مدل‌سازی رسمی ایمنی.

 #9.6.1    Level: 1    Role: D/V
 تأیید کنید که عوامل (agents) که در حوزه‌های امنیتی مختلف فعالیت می‌کنند، در محیط‌های اجرای ایزوله شده یا بخش‌های شبکه جداگانه اجرا شوند.
 #9.6.2    Level: 3    Role: V
 اطمینان حاصل کنید که رفتارهای گروهی مدل‌سازی شده و از نظر پویایی و ایمنی به‌صورت رسمی تأیید شده‌اند قبل از استقرار.
 #9.6.3    Level: 3    Role: D
 تأیید کنید که ناظرهای زمان اجرا الگوهای ناایمن ظهور یافته (مانند نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدام اصلاحی را آغاز می‌کنند.

---

### ۹.۷ احراز هویت / مجوز کاربران و ابزارها

برای هر اقدام فعال‌شده توسط عامل، کنترل‌های دسترسی مستحکم پیاده‌سازی کنید.

 #9.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که عوامل به عنوان اصول درجه یک به سیستم‌های پایین‌دست احراز هویت می‌شوند و هرگز از اعتبارنامه‌های کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    Level: 2    Role: D
 تأیید کنید که سیاست‌های مجوزدهی دقیق تعیین می‌کنند که کدام ابزارها توسط یک عامل قابل فراخوانی هستند و کدام پارامترها می‌توانند تأمین شوند.
 #9.7.3    Level: 2    Role: V
 اطمینان حاصل کنید که بررسی‌های دسترسی در هر بار فراخوانی مجدداً ارزیابی می‌شوند (مجوزدهی مستمر)، نه فقط در ابتدای جلسه.
 #9.7.4    Level: 3    Role: D
 تأیید کنید که مجوزهای واگذار شده به‌طور خودکار پس از اتمام زمان یا تغییر دامنه منقضی شده و نیازمند رضایت مجدد باشند.

---

### ۹.۸ امنیت ارتباط عامل به عامل

تمام پیام‌های بین عامل‌ها را رمزنگاری کنید و از صحت آن‌ها محافظت کنید تا از شنود و دستکاری جلوگیری شود.

 #9.8.1    Level: 1    Role: D/V
 تأیید کنید که احراز هویت دوجانبه و رمزگذاری با امنیت کامل انتقال به جلو (مانند TLS 1.3) برای کانال‌های عامل اجباری باشند.
 #9.8.2    Level: 1    Role: D
 اطمینان حاصل کنید که صحت و منبع پیام قبل از پردازش تأیید شده باشد؛ در صورت شکست، هشدارها صادر شده و پیام دور ریخته می‌شود.
 #9.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فراداده‌های ارتباطی (زمان‌بندی‌ها، شماره‌های توالی) برای پشتیبانی از بازسازی قضایی ثبت می‌شوند.
 #9.8.4    Level: 3    Role: V
 اطمینان حاصل کنید که تایید رسمی یا مدل چکینگ تایید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالات ناامن هدایت شوند.

---

### ۹.۹ تأیید نیت و اعمال محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با قصد اعلام شده توسط کاربر و محدودیت‌های سیستم هم‌راستا باشند.

 #9.9.1    Level: 1    Role: D
 اطمینان حاصل کنید که حل‌کننده‌های محدودیت پیش‌اجرایی، اقدامات پیشنهادی را در برابر قوانین ایمنی و سیاست‌های سخت‌کد شده بررسی می‌کنند.
 #9.9.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که اقدامات با تاثیر بالا (مالی، مخرب، حساس به حریم خصوصی) نیازمند تایید صریح قصد از سوی کاربر شروع‌کننده هستند.
 #9.9.3    Level: 2    Role: V
 تأیید کنید که بررسی‌های پس‌شرط صحت انجام اقدامات تکمیل‌شده و دستیابی به تأثیرات مورد نظر را بدون عوارض جانبی تأیید می‌کنند؛ ناهماهنگی‌ها باعث بازگشت به حالت قبلی می‌شوند.
 #9.9.4    Level: 3    Role: V
 تأیید کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضیه) یا آزمون‌های مبتنی بر ویژگی نشان می‌دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام‌شده را برآورده می‌کنند.
 #9.9.5    Level: 3    Role: D
 اطمینان حاصل کنید که حوادث ناسازگاری هدف یا نقض محدودیت‌ها باعث تغذیه چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدید می‌شوند.

---

### 9.10 استراتژی استدلال عامل امنیت

انتخاب و اجرای امن استراتژی‌های مختلف استدلال از جمله روش‌های ReAct، Chain-of-Thought و Tree-of-Thoughts.

 #9.10.1    Level: 1    Role: D/V
 تأیید کنید که انتخاب استراتژی استدلال از معیارهای قطعی (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان، انتخاب‌های استراتژی یکسانی را در همان زمینه امنیتی به همراه دارند.
 #9.10.2    Level: 1    Role: D/V
 تأیید کنید که هر استراتژی استدلال (ReAct، Chain-of-Thought، Tree-of-Thoughts) دارای اعتبارسنجی ورودی اختصاصی، پالایش خروجی و محدودیت‌های زمان اجرای خاص به رویکرد شناختی خود باشد.
 #9.10.3    Level: 2    Role: D/V
 تأیید کنید که انتقال‌های استراتژی استدلال با زمینه کامل شامل ویژگی‌های ورودی، مقادیر معیار انتخاب و فراداده‌های اجرا برای بازسازی مسیر حسابرسی ثبت می‌شوند.
 #9.10.4    Level: 2    Role: D/V
 تأیید کنید که استدلال درخت افکار شامل مکانیزم‌های هرس شاخه است که زمانی که تخلفات سیاستی، محدودیت‌های منابع یا مرزهای ایمنی شناسایی می‌شوند، کاوش را متوقف می‌کنند.
 #9.10.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که چرخه‌های ReAct (استدلال-اقدام-مشاهده) شامل نقاط بازرسی اعتبارسنجی در هر مرحله باشند: تأیید گام استدلال، مجوز اقدام و پاک‌سازی مشاهده قبل از ادامه.
 #9.10.6    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، استفاده از منابع، کیفیت خروجی) با هشدارهای خودکار مانیتور می‌شوند هنگامی که معیارها از آستانه‌های تنظیم شده فراتر روند.
 #9.10.7    Level: 3    Role: D/V
 اطمینان حاصل کنید که رویکردهای استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی تمامی استراتژی‌های تشکیل‌دهنده را حفظ می‌کنند بدون اینکه هیچ یک از کنترل‌های امنیتی را دور بزنند.
 #9.10.8    Level: 3    Role: D/V
 تایید کنید که تست امنیت استراتژی استدلال شامل انجام فازینگ با ورودی‌های مخدوش، درخواست‌های خصمانه طراحی‌شده برای مجبور کردن به تغییر استراتژی، و تست شرایط مرزی برای هر روش شناختی می‌شود.

---

### مدیریت و امنیت وضعیت چرخه عمر عامل 9.11

راه‌اندازی ایمن عامل، انتقال‌های حالت و خاتمه با مسیرهای حسابرسی رمزنگاری‌شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    Level: 1    Role: D/V
 تأیید کنید که راه‌اندازی عامل شامل ایجاد هویت رمزنگاری شده با مدارک پشتیبانی شده توسط سخت‌افزار و ثبت‌های بازرسی راه‌اندازی غیرقابل تغییر شامل شناسه عامل، زمان‌نمای زمانی، هش پیکربندی و پارامترهای راه‌اندازی باشد.
 #9.11.2    Level: 2    Role: D/V
 تأیید کنید که انتقال وضعیت عامل به صورت رمزنگاری شده امضا، دارای مهر زمان باشد و با زمینه کامل از جمله رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام شده ثبت شود.
 #9.11.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که رویه‌های خاموش‌کردن عامل شامل پاک‌سازی ایمن حافظه با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندمرحله‌ای، لغو مجوزها با اطلاع‌رسانی به مرجع صدور گواهی و تولید گواهی‌های خاتمه با قابلیت تشخیص دستکاری باشد.
 #9.11.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازیابی عامل صحت یکپارچگی وضعیت را با استفاده از چکسام‌های رمزنگاری (حداقل SHA-256) تأیید می‌کنند و در صورت شناسایی فساد، با ارسال هشدارهای خودکار و نیاز به تأیید دستی به وضعیت‌های شناخته‌شده سالم بازگردانی می‌شوند.
 #9.11.5    Level: 3    Role: D/V
 تأیید کنید که مکانیزم‌های پایداری عامل داده‌های حساس حالت را با کلیدهای AES-256 جداگانه برای هر عامل رمزگذاری می‌کنند و چرخش ایمن کلید را بر اساس برنامه‌های قابل تنظیم (حداکثر 90 روز) با استقرار بدون قطع سرویس انجام می‌دهند.

---

### چارچوب امنیتی یکپارچه‌سازی ابزار 9.12

کنترل‌های امنیتی برای بارگذاری ابزار پویا، اجرا و اعتبارسنجی نتایج با فرآیندهای تعریف‌شده ارزیابی ریسک و تصویب.

 #9.12.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که توصیف‌گرهای ابزار شامل متاداده‌های امنیتی هستند که مشخص‌کننده امتیازات مورد نیاز (خواندن/نوشتن/اجرا)، سطوح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (پردازنده، حافظه، شبکه) و الزامات اعتبارسنجی مستند شده در مشخصات ابزار می‌باشند.
 #9.12.2    Level: 1    Role: D/V
 تأیید کنید که نتایج اجرای ابزار بر اساس طرحواره‌های مورد انتظار (JSON Schema، XML Schema) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) اعتبارسنجی شده‌اند قبل از ادغام با محدودیت‌های زمانی و رویه‌های هندلینگ خطا.
 #9.12.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که گزارش‌های تعامل ابزار شامل زمینه امنیتی دقیق از جمله استفاده از امتیازات، الگوهای دسترسی به داده‌ها، زمان اجرا، مصرف منابع و کدهای بازگشتی با ثبت ساخت‌یافته برای یکپارچه‌سازی SIEM باشد.
 #9.12.4    Level: 2    Role: D/V
 تأیید کنید که مکانیزم‌های بارگذاری ابزار پویا، امضاهای دیجیتال را با استفاده از زیرساخت PKI اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری امن را با ایزولاسیون سندباکس و تأیید مجوز پیش از اجرای آن پیاده‌سازی می‌کنند.
 #9.12.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزارها به صورت خودکار برای نسخه‌های جدید با دروازه‌های تایید اجباری شامل تحلیل استاتیک، تست دینامیک و بازبینی تیم امنیتی با معیارهای تایید مستند شده و الزامات SLA فعال می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت در برابر حملات خصمانه و دفاع از حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات دور زدن، استنتاج، استخراج یا مسمومیت، قابل اعتماد، حافظ حریم خصوصی و مقاوم در برابر سوء استفاده باقی بمانند.

---

### ۱۰.۱ همسویی مدل و ایمنی

مراقب خروجی‌های مضر یا نقض‌کننده سیاست‌ها باشید.

 #10.1.1    Level: 1    Role: D/V
 تأیید کنید که یک مجموعه آزمایشی هم‌راستایی (دستورات تیم قرمز، آزمایش‌های فرار از محدودیت، محتوای ممنوع) تحت کنترل نسخه قرار دارد و در هر انتشار مدل اجرا می‌شود.
 #10.1.2    Level: 1    Role: D
 تأیید کنید که سازوکارهای منع و محافظت در اتمام ایمن به درستی اجرا شده‌اند.
 #10.1.3    Level: 2    Role: D/V
 تأیید کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و افت کیفیت‌هایی را که از یک آستانه مشخص فراتر می‌روند، علامت‌گذاری می‌کند.
 #10.1.4    Level: 2    Role: D
 تأیید کنید که آموزش مقابله با جیلبریک مستندسازی شده و قابل بازتولید باشد.
 #10.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که اثبات‌های رسمی تطابق با سیاست یا پایش معتبر، حوزه‌های حیاتی را پوشش می‌دهند.

---

### 10.2 سخت‌سازی در برابر نمونه‌های مخرب

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش متقابل مقاوم و امتیازدهی معیار فعلی بهترین روش است.

 #10.2.1    Level: 1    Role: D
 تأیید کنید که مخازن پروژه شامل پیکربندی‌های آموزش دشمن‌محور با دانه‌های بازتولیدپذیر هستند.
 #10.2.2    Level: 2    Role: D/V
 تأیید کنید که تشخیص نمونه‌های مخرب در خط‌های تولید هشدارهای مسدودکننده ایجاد می‌کند.
 #10.2.4    Level: 3    Role: V
 اطمینان حاصل کنید که اثبات‌های پایدار-تصدیق‌شده یا گواهی‌های محدوده‌فاصله حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    Level: 3    Role: V
 اطمینان حاصل کنید که تست‌های رگرسیون از حملات تطبیقی برای تأیید عدم وجود کاهش قابل اندازه‌گیری در استحکام استفاده می‌کنند.

---

### 10.3 کاهش استنتاج عضویت

محدود کردن توانایی تصمیم‌گیری در مورد اینکه آیا یک رکورد در داده‌های آموزشی بوده است. حریم خصوصی تفاضلی و ماسک‌گذاری نمره اطمینان همچنان مؤثرترین روش‌های دفاعی شناخته‌شده باقی می‌مانند.

 #10.3.1    Level: 1    Role: D
 تأیید کنید که تنظیم انحراف آنتروپی به ازای هر پرسش یا مقیاس‌بندی دما، پیش‌بینی‌های بیش از حد مطمئن را کاهش می‌دهد.
 #10.3.2    Level: 2    Role: D
 اطمینان حاصل کنید که آموزش از بهینه‌سازی دارای حریم خصوصی تفاضلی با کران ε برای داده‌های حساس استفاده می‌کند.
 #10.3.3    Level: 2    Role: V
 اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه‌سیاه) نشان‌دهنده AUC حمله ≤ 0.60 روی داده‌های نگه‌داشته شده هستند.

---

### 10.4 مقاومت در برابر وارونگی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر بر کوتاه‌سازی خروجی و تضمین‌های DP به عنوان دفاع‌های عملی تأکید دارند.

 #10.4.1    Level: 1    Role: D
 اطمینان حاصل کنید که ویژگی‌های حساس هرگز به‌طور مستقیم خروجی داده نمی‌شوند؛ در صورت نیاز، از دسته‌بندی‌ها (buckets) یا تبدیل‌های یک‌طرفه استفاده کنید.
 #10.4.2    Level: 1    Role: D/V
 تأیید کنید که محدودیت‌های نرخ پرس‌وجو، پرس‌وجوهای تطبیقی تکراری از همان شخصیت (principal) را محدود می‌کنند.
 #10.4.3    Level: 2    Role: D
 اطمینان حاصل کنید که مدل با نویز حفظ حریم خصوصی آموزش دیده است.

---

### 10.5 دفاع در برابر استخراج مدل

شناسایی و جلوگیری از کپی‌برداری غیرمجاز. استفاده از واترمارکینگ و تحلیل الگوی پرس‌وجو توصیه می‌شود.

 #10.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و محدودیت‌های نرخ ویژه هر کلید API را که با آستانه حفظ حافظه مدل تنظیم شده‌اند، اعمال می‌کنند.
 #10.5.2    Level: 2    Role: D/V
 تأیید کنید که آمارهای انتروپی پرس و جو و چندشکلی ورودی به یک شناسگر استخراج خودکار تغذیه می‌شوند.
 #10.5.3    Level: 2    Role: V
 تأیید کنید که نشانه‌های آبی شکننده یا احتمالاتی با p < 0.01 در ≤ 1 000 پرس و جو علیه یک نسخه مشکوک قابل اثبات باشند.
 #10.5.4    Level: 3    Role: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های تریگر در یک ماژول امنیت سخت‌افزاری ذخیره شده و سالانه تعویض می‌شوند.
 #10.5.5    Level: 3    Role: V
 تأیید کنید که رویدادهای استخراج-هشدار شامل پرس‌وجوهای متخلف بوده و با راهنماهای واکنش به رخدادها یکپارچه شده‌اند.

---

### 10.6 تشخیص داده‌های آلوده در زمان استنتاج

شناسایی و خنثی‌سازی ورودی‌های دارای درب پشتی یا آلوده شده.

 #10.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مانند STRIP، امتیازدهی سازگاری) عبور می‌کنند.
 #10.6.2    Level: 1    Role: V
 تأیید کنید که آستانه‌های آشکارساز بر روی مجموعه‌های اعتبارسنجی تمیز/آلوده تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب داشته باشند.
 #10.6.3    Level: 2    Role: D
 تأیید کنید که ورودی‌هایی که به عنوان آلوده علامت‌گذاری شده‌اند، باعث فعال شدن مسدودسازی نرم و فرآیندهای بررسی انسانی می‌شوند.
 #10.6.4    Level: 2    Role: V
 اطمینان حاصل کنید که آشکارسازها با حملات دزدراه تطبیقی و بدون محرک مورد آزمون فشار قرار گرفته‌اند.
 #10.6.5    Level: 3    Role: D
 تأیید کنید که معیارهای اثربخشی تشخیص ثبت شده و به طور دوره‌ای با اطلاعات تهدید تازه بازبینی می‌شوند.

---

### 10.7 تطبیق پویا سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی به صورت زمان واقعی بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های امنیتی می‌توانند به‌صورت پویا بدون راه‌اندازی مجدد عامل به‌روزرسانی شوند در حالی که صحت نسخه سیاست حفظ می‌شود.
 #10.7.2    Level: 2    Role: D/V
 تأیید کنید که به‌روزرسانی‌های سیاست‌ها توسط پرسنل مجاز امنیتی به‌صورت رمزنگاری‌شده امضا شده و قبل از اعمال مورد اعتبارسنجی قرار می‌گیرند.
 #10.7.3    Level: 2    Role: D/V
 تأیید کنید که تغییرات سیاست پویا با ردپای کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و رویه‌های بازگرداندن ثبت می‌شوند.
 #10.7.4    Level: 3    Role: D/V
 تأیید کنید که مکانیزم‌های امنیتی تطبیقی حساسیت تشخیص تهدید را بر اساس زمینه ریسک و الگوهای رفتاری تنظیم می‌کنند.
 #10.7.5    Level: 3    Role: D/V
 تأیید کنید که تصمیمات تطبیق سیاست قابل توضیح باشند و شامل شواهدی برای بررسی تیم امنیتی باشند.

---

### 10.8 تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خوداندیشی عامل و تحلیل فراشناختی.

 #10.8.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودمحور متمرکز بر امنیت از تصمیمات و اقدامات هستند.
 #10.8.2    Level: 2    Role: D/V
 تأیید کنید که خروجی‌های بازتابی برای جلوگیری از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های مخرب اعتبارسنجی می‌شوند.
 #10.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تحلیل امنیت فراشناختی، تعصبات بالقوه، دستکاری یا نفوذ در فرآیندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    Level: 3    Role: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب، باعث فعال شدن نظارت پیشرفته و جریان‌های کاری احتمالی مداخله انسانی می‌شوند.
 #10.8.5    Level: 3    Role: D/V
 تأیید کنید که یادگیری مداوم از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد قانونی را کاهش دهد.

---

### ۱۰.۹ امنیت توسعه و خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عامل که قادر به خودتغییری و تکامل هستند.

 #10.9.1    Level: 1    Role: D/V
 تأیید کنید که قابلیت‌های خودتغییر تنها به مناطق ایمن مشخص شده با محدوده‌های تأیید رسمی محدود شده‌اند.
 #10.9.2    Level: 2    Role: D/V
 تأیید کنید که پیشنهادهای تکاملی پیش از اجرا تحت ارزیابی تأثیر امنیتی قرار می‌گیرند.
 #10.9.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که مکانیسم‌های خودبهبودی شامل قابلیت‌های بازگشت به حالت قبلی با تأیید صحت باشند.
 #10.9.4    Level: 3    Role: D/V
 تأیید کنید که امنیت یادگیری فراگیر از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    Level: 3    Role: D/V
 تایید کنید که بهبود خودبازگشتی محدود به قیود ایمنی رسمی است با اثبات‌های ریاضی همگرایی.

---

#### مراجع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ تضمین‌های سختگیرانه حریم خصوصی در طول کل چرخه عمر هوش مصنوعی—جمع‌آوری، آموزش، استنتاج و پاسخ به حادثه—به گونه‌ای که داده‌های شخصی تنها با رضایت صریح، دامنه حداقلی لازم، امکان اثبات حذف و تضمین‌های رسمی حریم خصوصی پردازش شوند.

---

### 11.1 ناشناس‌سازی و کمینه‌سازی داده‌ها

 #11.1.1    Level: 1    Role: D/V
 تأیید کنید که شناسه‌های مستقیم و شبه‌شناسه‌ها حذف یا هش شده‌اند.
 #11.1.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که بازبینی‌های خودکار، شاخص k-ناشناس‌سازی/l-تنوع را اندازه‌گیری می‌کنند و هنگام کاهش میزان به زیر آستانه‌های تعیین شده در سیاست هشدار می‌دهند.
 #11.1.3    Level: 2    Role: V
 تأیید کنید که گزارش‌های اهمیت ویژگی مدل نشان می‌دهند هیچ نشت شناسه‌ای فراتر از ε = 0.01 اطلاعات مشترک وجود ندارد.
 #11.1.4    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی یا گواهی‌نامه داده‌های مصنوعی نشان می‌دهند که ریسک شناسایی مجدد ≤ 0.05 حتی تحت حملات پیوندی است.

---

### 11.2 حق به فراموش شدن و اجرای حذف

 #11.2.1    Level: 1    Role: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوعی به مجموعه داده‌های خام، نقاط کنترل (Checkpoint)، تعبیه‌ها، لاگ‌ها و نسخه‌های پشتیبان در بازه‌های زمانی کمتر از 30 روز طبق توافقات سطح سرویس منتقل می‌شوند.
 #11.2.2    Level: 2    Role: D
 تأیید کنید که روتین‌های «حذف یادگیری ماشین» به صورت فیزیکی دوباره آموزش می‌بینند یا حذف تقریبی را با استفاده از الگوریتم‌های حذف یادگیری تأیید شده انجام می‌دهند.
 #11.2.3    Level: 2    Role: V
 تأیید کنید که ارزیابی مدل سایه ثابت می‌کند رکوردهای فراموش شده پس از فراموشی کمتر از ۱٪ از نتایج را تحت تأثیر قرار می‌دهند.
 #11.2.4    Level: 3    Role: V
 تأیید کنید که رویدادهای حذف به صورت غیرقابل تغییر ثبت شده و برای ناظران قابل حسابرسی باشند.

---

### 11.3 تدابیر حفظ حریم خصوصی تفاضلی

 #11.3.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که داشبوردهای حسابداری خسارت حریم خصوصی زمانی که مجموع ε از آستانه‌های سیاست تجاوز می‌کند، هشدار می‌دهند.
 #11.3.2    Level: 2    Role: V
 اطمینان حاصل کنید که حسابرسی‌های حریم خصوصی جعبه‌سیاه، ε̂ را در حدود ۱۰٪ از مقدار اعلام شده تخمین می‌زنند.
 #11.3.3    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی تمام بهینه‌سازی‌ها و تعبیه‌های بعد از آموزش را پوشش می‌دهند.

---

### 11.4 محافظت در برابر محدودیت هدف و گسترش دامنه

 #11.4.1    Level: 1    Role: D
 اطمینان حاصل کنید که هر مجموعه داده و نقطه بازنگری مدل دارای برچسب هدف قابل خواندن توسط ماشین است که با رضایت اصلی همسو باشد.
 #11.4.2    Level: 1    Role: D/V
 تأیید کنید که مانیتورهای زمان اجرا کوئری‌هایی که با هدف اعلام شده ناسازگار هستند را شناسایی کرده و باعث رد نرم می‌شوند.
 #11.4.3    Level: 3    Role: D
 تأیید کنید که دروازه‌های سیاست به عنوان کد، از استقرار مجدد مدل‌ها در دامنه‌های جدید بدون بررسی DPIA جلوگیری می‌کنند.
 #11.4.4    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی ردیابی نشان می‌دهند هر چرخه عمر داده‌های شخصی در محدوده موافقت شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و پیگیری مبنای قانونی

 #11.5.1    Level: 1    Role: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت انتخاب رضایت، هدف و دوره نگهداری را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    Level: 2    Role: D
 اطمینان حاصل کنید که APIها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید قبل از استنتاج، دامنه توکن را اعتبارسنجی کنند.
 #11.5.3    Level: 2    Role: D/V
 تأیید کنید که رضایت رد شده یا پس گرفته شده، خطوط پردازش را ظرف 24 ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حفظ حریم خصوصی

 #11.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که بروزرسانی‌های کلاینت پیش از تجمع، از افزودن نویز حفظ حریم خصوصی تفاضلی محلی استفاده می‌کنند.
 #11.6.2    Level: 2    Role: D/V
 تأیید کنید که معیارهای آموزش به صورت متفاوت خصوصی هستند و هرگز خطای یک مشتری واحد را فاش نمی‌کنند.
 #11.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که تجمع مقاوم در برابر سم‌زنی (مانند Krum/میانگین مقطوع) فعال است.
 #11.6.4    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی، بودجه کلی ε را با کمتر از ۵ واحد کاهش در کارایی نشان می‌دهند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 نظارت، ثبت وقایع و شناسایی ناهنجاری‌ها

### هدف کنترل

این بخش الزامات ارائه دید زمان واقعی و قانونی درباره آنچه مدل و سایر اجزای هوش مصنوعی مشاهده، انجام و بازگردانده‌اند را ارائه می‌دهد، تا تهدیدات قابل شناسایی، اولویت‌بندی و یادگیری باشند.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه درخواست‌های کاربر و پاسخ‌های مدل با متادیتای مناسب (مانند زمان، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت می‌شوند.
 #12.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن ایمن با کنترل دسترسی مناسب و سیاست‌های نگهداری و روش‌های پشتیبان‌گیری مناسب ذخیره می‌شوند.
 #12.1.3    Level: 1    Role: D/V
 تأیید کنید که سیستم‌های ذخیره‌سازی لاگ، رمزگذاری در حالت استراحت و در حال انتقال را برای محافظت از اطلاعات حساس موجود در لاگ‌ها پیاده‌سازی می‌کنند.
 #12.1.4    Level: 1    Role: D/V
 تأیید کنید که داده‌های حساس در ورودی‌ها و خروجی‌ها قبل از ثبت به طور خودکار پاک‌سازی یا مخفی می‌شوند، با قوانین پاک‌سازی قابل تنظیم برای اطلاعات شناسایی شخصی (PII)، اطلاعات اعتبارسنجی و اطلاعات مالکیتی.
 #12.1.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت شده‌اند تا امکان بررسی و رفع اشکال سیستم‌های مدیریت محتوا فراهم شود.
 #12.1.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که یکپارچگی لاگ از طریق مثلا امضاهای رمزنگاری شده یا ذخیره‌سازی فقط‌نوشتنی محافظت می‌شود.

---

### C12.2 شناسایی سوءاستفاده و هشداردهی

 #12.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیستم الگوهای شناخته شده فرار از محدودیت (jailbreak)، تلاش‌های تزریق پرامپت و ورودی‌های خصمانه را با استفاده از تشخیص مبتنی بر امضا شناسایی و هشدار می‌دهد.
 #12.2.2    Level: 1    Role: D/V
 تأیید کنید که سیستم با استفاده از فرمت‌ها و پروتکل‌های استاندارد گزارش، با پلتفرم‌های موجود مدیریت اطلاعات و رویدادهای امنیتی (SIEM) یکپارچه می‌شود.
 #12.2.3    Level: 2    Role: D/V
 تأیید کنید که رویدادهای امنیتی غنی‌شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، امتیازهای اطمینان، و تصمیمات فیلتر ایمنی باشند.
 #12.2.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول مکالمه، تلاش‌های مکرر بیش از حد، یا رفتارهای کاوش سیستماتیک را شناسایی می‌کند.
 #12.2.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشدار دهی بلادرنگ، تیم‌های امنیتی را هنگام شناسایی نقض‌های احتمالی سیاست‌ها یا تلاش‌های حمله مطلع می‌کنند.
 #12.2.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی شامل تلاش‌های هماهنگ شده برای دور زدن (jailbreak)، کمپین‌های تزریق فرمان (prompt injection) و حملات استخراج مدل گنجانده شده‌اند.
 #12.2.7    Level: 3    Role: D/V
 تأیید کنید که گردش کارهای پاسخ خودکار به حادثه قادر به جداسازی مدل‌های به خطر افتاده، مسدود کردن کاربران مخرب و تشدید رویدادهای حیاتی امنیتی هستند.

---

### C12.3 تشخیص تغییر مدل

 #12.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیستم معیارهای عملکرد پایه‌ای مانند دقت، نمرات اطمینان، تأخیر و نرخ خطا را در نسخه‌های مدل و دوره‌های زمانی مختلف پیگیری می‌کند.
 #12.3.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که هشدارهای خودکار زمانی فعال می‌شوند که معیارهای عملکرد از آستانه‌های کاهش تعریف شده فراتر رفته یا به طور قابل توجهی از مبناها انحراف پیدا کنند.
 #12.3.3    Level: 2    Role: D/V
 تأیید کنید که مانیتورهای شناسایی توهم، نمونه‌هایی را که خروجی‌های مدل حاوی اطلاعات نادرست، ناسازگار یا ساختگی هستند، شناسایی و علامت‌گذاری می‌کنند.

---

### C12.4 عملکرد و تله‌متری رفتار

 #12.4.1    Level: 1    Role: D/V
 تأیید کنید که معیارهای عملیاتی شامل تاخیر درخواست، مصرف توکن، استفاده از حافظه و توان عملیاتی به طور مداوم جمع‌آوری و نظارت می‌شوند.
 #12.4.2    Level: 1    Role: D/V
 اطمینان حاصل شود که نرخ‌های موفقیت و شکست با دسته‌بندی انواع خطاها و علل اصلی آنها پیگیری می‌شوند.
 #12.4.3    Level: 2    Role: D/V
 تأیید کنید که پایش استفاده از منابع شامل استفاده از GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و هشدار در صورت تجاوز از آستانه‌ها ایجاد شود.

---

### برنامه‌ریزی و اجرای واکنش به حادثه هوش مصنوعی C12.5

 #12.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که برنامه‌های واکنش به حوادث به‌طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی از جمله نفوذ به مدل، آلوده‌سازی داده‌ها و حملات خصمانه می‌پردازند.
 #12.5.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که تیم‌های پاسخ به حادثه به ابزارهای جنایی خاص هوش مصنوعی و تخصص لازم برای بررسی رفتار مدل و مسیرهای حمله دسترسی دارند.
 #12.5.3    Level: 3    Role: D/V
 تأیید کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای ایمنی و ادغام آموخته‌ها در کنترل‌های امنیتی می‌باشد.

---

### C12.5 تشخیص کاهش عملکرد هوش مصنوعی

نظارت و شناسایی کاهش عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که دقت مدل، دقت (precision)، بازیابی (recall) و امتیاز F1 به طور مداوم پایش شده و با آستانه‌های پایه مقایسه می‌شوند.
 #12.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که تشخیص انحراف داده، تغییرات توزیع ورودی که ممکن است بر عملکرد مدل تاثیر بگذارد را نظارت می‌کند.
 #12.5.3    Level: 2    Role: D/V
 تأیید کنید که تشخیص تغییر مفهوم، تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    Level: 2    Role: D/V
 تأیید کنید که کاهش عملکرد باعث فعال شدن هشدارهای خودکار شده و جریان‌های کاری بازآموزی مدل یا جایگزینی آن را آغاز می‌کند.
 #12.5.5    Level: 3    Role: V
 تأیید کنید که تحلیل ریشه‌ای علت کاهش عملکرد، کاهش‌های عملکرد را با تغییرات داده‌ها، مشکلات زیرساختی یا عوامل خارجی مرتبط می‌سازد.

---

### C12.6 تجسم DAG و امنیت گردش کار

محافظت از سیستم‌های تجسم جریان کاری در برابر نشت اطلاعات و حملات دستکاری.

 #12.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های تجسم DAG برای حذف اطلاعات حساس قبل از ذخیره‌سازی یا انتقال، پاک‌سازی شده‌اند.
 #12.6.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که کنترل‌های دسترسی به تجسم گردش کار فقط به کاربران مجاز امکان می‌دهد مسیرهای تصمیم‌گیری عامل و ردیابی‌های استدلال را مشاهده کنند.
 #12.6.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که صحت داده‌های DAG از طریق امضاهای رمزنگاری‌شده و مکانیزم‌های ذخیره‌سازی مقاوم در برابر دستکاری محافظت می‌شود.
 #12.6.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که سیستم‌های تجسم گردش کار، اعتبارسنجی ورودی را انجام می‌دهند تا از حملات تزریق از طریق داده‌های سفارشی شده در گره یا یال جلوگیری کنند.
 #12.6.5    Level: 3    Role: D/V
 تأیید کنید که به‌روزرسانی‌های DAG در زمان واقعی به‌صورت محدود شده و اعتبارسنجی شده باشند تا از حملات انکار سرویس به سیستم‌های تجسم‌سازی جلوگیری شود.

---

### C12.7 پایش رفتاری امنیتی پیشگیرانه

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتار پیشگیرانه عامل.

 #12.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که رفتارهای عامل پیشگیرانه قبل از اجرا با ادغام ارزیابی ریسک از نظر امنیتی معتبر شده باشند.
 #12.7.2    Level: 2    Role: D/V
 تأیید کنید که محرک‌های ابتکار عمل خودگردان شامل ارزیابی زمینه امنیتی و ارزیابی چشم‌انداز تهدید هستند.
 #12.7.3    Level: 2    Role: D/V
 تأیید کنید که الگوهای رفتار پیشگویانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تحلیل شده‌اند.
 #12.7.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که اقدامات پیشگیرانه حیاتی برای امنیت نیازمند زنجیره‌های تأیید صریح با ردپاهای حسابرسی هستند.
 #12.7.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری رفتاری، انحرافات در الگوهای عامل فعال را که ممکن است نشان‌دهنده خطر نفوذ باشد، شناسایی می‌کند.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## نظارت انسانی C13، پاسخگویی و حاکمیت

### هدف کنترل

این فصل الزامات مربوط به حفظ نظارت انسانی و زنجیره‌های حسابرسی شفاف در سیستم‌های هوش مصنوعی را ارائه می‌دهد و اطمینان می‌دهد که قابلیت توضیح، شفافیت و مدیریت اخلاقی در سراسر چرخه عمر هوش مصنوعی رعایت شود.

---

### C13.1 مکانیزم‌های خاموش‌کننده اضطراری و بازنویسی

ارائه مسیرهای خاموش‌کردن یا بازگردانی در صورت مشاهده رفتار ناایمن سیستم هوش مصنوعی.

 #13.1.1    Level: 1    Role: D/V
 تأیید کنید که یک مکانیزم خاموش‌کننده دستی وجود دارد که فوراً استنتاج و خروجی‌های مدل هوش مصنوعی را متوقف می‌کند.
 #13.1.2    Level: 1    Role: D
 اطمینان حاصل کنید که کنترل‌های لغو فقط برای پرسنل مجاز قابل دسترسی باشند.
 #13.1.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که رویه‌های بازگشت (rollback) می‌توانند به نسخه‌های قبلی مدل یا عملیات حالت امن بازگردند.
 #13.1.4    Level: 3    Role: V
 تأیید کنید که مکانیزم‌های جایگزینی به صورت منظم آزمایش می‌شوند.

---

### C13.2 نقاط بررسی تصمیم‌گیری در حلقه انسانی

در مواقعی که میزان مخاطره از حدود ریسک از پیش تعیین شده فراتر می‌رود، نیاز به تایید انسانی است.

 #13.2.1    Level: 1    Role: D/V
 تأیید کنید که تصمیمات هوش مصنوعی با ریسک بالا نیازمند تأیید صریح انسانی قبل از اجرا هستند.
 #13.2.2    Level: 1    Role: D
 اطمینان حاصل کنید که آستانه‌های ریسک به‌وضوح تعریف شده‌اند و به‌طور خودکار فرآیندهای بررسی توسط انسان را فعال می‌کنند.
 #13.2.3    Level: 2    Role: D
 تأیید کنید که برای تصمیمات حساس به زمان، روش‌های جایگزین در صورت عدم امکان دریافت تأیید انسانی در چارچوب زمانی مورد نیاز وجود دارد.
 #13.2.4    Level: 3    Role: D/V
 تأیید کنید که رویه‌های تشدید، سطوح اختیار واضحی را برای انواع مختلف تصمیم‌گیری یا دسته‌بندی‌های ریسک، در صورت وجود، تعریف کرده‌اند.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

عملیات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمام تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با زمان‌سنجی، هویت کاربران و دلایل تصمیم‌گیری ثبت می‌شوند.
 #13.3.2    Level: 2    Role: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل دستکاری نباشند و مکانیزم‌های تأیید صحت را شامل شوند.

---

### C13.4 تکنیک‌های هوش مصنوعی توضیح‌پذیر

اهمیت ویژگی سطحی، موارد متقابل و توضیحات محلی.

 #13.4.1    Level: 1    Role: D/V
 تأیید کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای برای تصمیمات خود به صورت قابل‌فهم برای انسان ارائه می‌دهند.
 #13.4.2    Level: 2    Role: V
 تأیید کنید که کیفیت توضیح از طریق مطالعات و معیارهای ارزیابی انسانی مورد تایید قرار گرفته است.
 #13.4.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که امتیازهای اهمیت ویژگی یا روش‌های نسبت‌دهی (مانند SHAP، LIME و غیره) برای تصمیم‌های حیاتی در دسترس هستند.
 #13.4.4    Level: 3    Role: V
 تأیید کنید که توضیحات متضاد نشان می‌دهند چگونه ورودی‌ها می‌توانند تغییر کنند تا نتایج تغییر یابند، در صورت کاربرد در مورد استفاده و حوزه مربوطه.

---

### C13.5 کارت‌های مدل و افشای نحوه استفاده

نگهداری کارت‌های مدل برای استفاده مورد نظر، معیارهای عملکرد، و ملاحظات اخلاقی.

 #13.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته شده را مستند می‌کنند.
 #13.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که متریک‌های عملکرد در استفاده‌های مختلف مرتبط به طور کامل افشا شده‌اند.
 #13.5.3    Level: 2    Role: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصب، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته‌شده داده‌های آموزشی مستند شده و به‌روزرسانی می‌شوند.
 #13.5.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که کارت‌های مدل تحت کنترل نسخه قرار دارند و در طول چرخه عمر مدل با پیگیری تغییرات نگهداری می‌شوند.

---

### C13.6 کمیت‌سنجی عدم قطعیت

امتیازهای اطمینان یا اندازه‌گیری‌های آنتروپی را در پاسخ‌ها منتقل کنید.

 #13.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی با خروجی‌های خود امتیاز اطمینان یا معیارهای عدم قطعیت ارائه می‌دهند.
 #13.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که آستانه‌های عدم قطعیت باعث فعال‌سازی بررسی‌های اضافی توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که روش‌های کمیت‌سنجی عدم قطعیت کالیبره شده و در برابر داده‌های حقیقت میدانی اعتبارسنجی شده‌اند.
 #13.6.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که انتشار عدم قطعیت در طول فرآیندهای چندمرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت برای کاربران

ارائه افشای دوره‌ای درباره حوادث، انحراف و استفاده از داده‌ها.

 #13.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده‌ها و روش‌های مدیریت رضایت کاربر به وضوح به ذینفعان منتقل شده است.
 #13.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های تأثیر هوش مصنوعی انجام شده و نتایج آن در گزارش‌دهی درج شده است.
 #13.7.3    Level: 2    Role: D/V
 تأیید کنید که گزارش‌های شفافیت به طور منظم منتشر شده و حوادث هوش مصنوعی و معیارهای عملیاتی را با جزئیات معقول افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## پیوست الف: فرهنگ اصطلاحات

این واژه‌نامه جامع، تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین و امنیت را که در سراسر AISVS به کار رفته‌اند، برای اطمینان از وضوح و درک مشترک ارائه می‌دهد.
​
مثال خصمانه: ورودی‌ای که عمداً طراحی شده تا مدل هوش مصنوعی را وادار به اشتباه کند، اغلب با افزودن اختلالات ظریف و غیرقابل‌تشخیص برای انسان‌ها.
​
مقاومت مقابله‌ای – مقاومت مقابله‌ای در هوش مصنوعی به توانایی مدل در حفظ عملکرد خود و مقاومت در برابر فریب خوردن یا دستکاری توسط ورودی‌های عمدی و مخرب گفته می‌شود که با هدف ایجاد خطا طراحی شده‌اند.
​
عامل – عامل‌های هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای دنبال کردن اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آن‌ها استدلال، برنامه‌ریزی و حافظه را نشان می‌دهند و دارای سطحی از خودمختاری برای اتخاذ تصمیمات، یادگیری و سازگاری هستند.
​
هوش مصنوعی عامل‌دار (Agentic AI): سیستم‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری عمل کنند تا اهدافی را محقق سازند، اغلب با اتخاذ تصمیم‌ها و انجام اقدامات بدون مداخله مستقیم انسان.
​
کنترل دسترسی مبتنی بر ویژگی (ABAC): یک الگوی کنترل دسترسی است که تصمیمات مجوزدهی بر اساس ویژگی‌های کاربر، منبع، عمل و محیط گرفته می‌شود و در زمان درخواست ارزیابی می‌گردد.
​
حمله درب‌پشتی: نوعی حمله مسموم‌سازی داده که در آن مدل به گونه‌ای آموزش داده می‌شود که به محرک‌های خاص به صورت مخصوص پاسخ دهد در حالی که در شرایط عادی رفتار طبیعی دارد.
​
جانبداری: خطاهای سیستماتیکی در خروجی‌های مدل هوش مصنوعی که می‌توانند به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های مشخص منجر شوند.
​
سوء استفاده از تعصب: یک تکنیک حمله که از تعصبات شناخته شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
Cedar: زبان سیاست آمازون و موتور آن برای دسترسی‌های دقیق و جزئی که در پیاده‌سازی ABAC برای سیستم‌های هوش مصنوعی استفاده می‌شود.
​
زنجیره تفکر: تکنیکی برای بهبود استدلال در مدل‌های زبانی از طریق تولید مراحل میانی استدلال قبل از ارائه پاسخ نهایی.
​
شکست‌گرهای مدار: مکانیزم‌هایی که به طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های خاصی از ریسک فراتر می‌رود متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلوده‌سازی داده‌ها: تخریب عمدی داده‌های آموزشی به منظور به خطر انداختن صحت مدل، که اغلب برای نصب درهای پشتی یا کاهش عملکرد انجام می‌شود.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی چارچوبی ریاضیاتی محکم برای انتشار اطلاعات آماری درباره مجموعه داده‌ها است در حالی که حریم خصوصی افراد داده‌شده را حفظ می‌کند. این امکان را برای دارنده داده فراهم می‌کند تا الگوهای جمعی گروه را به اشتراک بگذارد در حالی که اطلاعات فاش شده درباره افراد خاص را محدود می‌کند.
​
توکارهای جاسازی شده: نمایش‌های برداری متراکم از داده‌ها (متن، تصاویر و غیره) که معنای معنایی را در یک فضای با ابعاد بالا ضبط می‌کنند.
​
قابلیت توضیح‌پذیری – قابلیت توضیح‌پذیری در هوش مصنوعی به توانایی یک سامانه هوش مصنوعی در ارائه دلایل قابل فهم برای انسان درباره تصمیمات و پیش‌بینی‌های خود اشاره دارد که دیدگاهی درباره عملکرد داخلی آن فراهم می‌کند.
​
هوش مصنوعی قابل توضیح (XAI): سیستم‌های هوش مصنوعی که برای ارائه توضیحات قابل فهم توسط انسان درباره تصمیمات و رفتارهای خود از طریق تکنیک‌ها و چارچوب‌های مختلف طراحی شده‌اند.
​
یادگیری فدراتیو: رویکردی در یادگیری ماشین که در آن مدل‌ها در چندین دستگاه غیرمتمرکز که نمونه‌های داده محلی را نگهداری می‌کنند، آموزش داده می‌شوند، بدون اینکه خود داده‌ها مبادله شوند.
​
محدودیت‌ها: محدودیت‌هایی که برای جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا غیرقابل قبول توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – توهم در هوش مصنوعی به پدیده‌ای اطلاق می‌شود که در آن مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های علمی نیست.
​
انسان در حلقه (Human-in-the-Loop - HITL): سیستم‌هایی که به گونه‌ای طراحی شده‌اند که نیاز به نظارت، تایید یا دخالت انسانی در نقاط حیاتی تصمیم‌گیری دارند.
​
زیرساخت به عنوان کد (IaC): مدیریت و تأمین زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای سازگار را فراهم می‌کند.
​
فرار از محدودیت: تکنیک‌هایی که برای دور زدن محافظ‌های ایمنی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبانی بزرگ، برای تولید محتوای ممنوعه استفاده می‌شوند.
​
حداقل امتیاز: اصل امنیتی اعطای فقط حداقل حقوق دسترسی لازم به کاربران و فرایندها.
​
LIME (توضیحات مدل-عاملی تفسیرپذیر محلی): تکنیکی برای توضیح پیش‌بینی‌های هر مدل طبقه‌بندی یادگیری ماشین با تقریب زدن محلی آن با مدلی قابل تفسیر است.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک داده خاص برای آموزش مدل یادگیری ماشین استفاده شده است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدهای خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده‌ای در مورد عملکرد مدل هوش مصنوعی، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی آن فراهم می‌کند تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج دهد.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر از مدل هدف پرسش می‌کند تا یک کپی عملکردی مشابه بدون مجوز ایجاد کند.
​
وارون‌سازی مدل: حمله‌ای که تلاش می‌کند با تحلیل خروجی‌های مدل، داده‌های آموزشی را بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرایند نظارت بر تمامی مراحل وجود یک مدل هوش مصنوعی است، از جمله طراحی، توسعه، استقرار، پایش، نگهداری و بازنشستگی نهایی آن، به منظور اطمینان از اثربخشی و تطابق مدل با اهداف.
​
آلوده‌سازی مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به طور مستقیم در مدل در طول فرآیند آموزش.
​
سرقت/دزدی مدل: استخراج یک نسخه یا تقریب از یک مدل اختصاصی از طریق پرس و جوهای مکرر.
​
سیستم چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی که با یکدیگر تعامل دارند و هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند.
​
OPA (عامل سیاست‌گذاری باز): یک موتور سیاست‌گذاری متن‌باز که امکان اجرای یکپارچه سیاست‌ها را در کل ساختار فراهم می‌کند.
​
یادگیری ماشینی حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشینی در حالی که حریم خصوصی داده‌های آموزشی حفظ می‌شود.
​
تزریق دستور: حمله‌ای که در آن دستورات مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مورد نظر مدل را نادیده بگیرند.
​
RAG (تولید تقویت‌شده با بازیابی): تکنیکی که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ بهبود می‌بخشد.
​
رد-تیمینگ: عملیاتی برای آزمایش فعال سیستم‌های هوش مصنوعی از طریق شبیه‌سازی حملات خصمانه به منظور شناسایی آسیب‌پذیری‌ها.
​
SBOM (فهرست مواد نرم‌افزاری): یک سند رسمی شامل جزئیات و روابط زنجیره تأمین اجزای مختلف مورد استفاده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (توضیحات جمع‌پذیر شاپلی): رویکردی مبتنی بر نظریه بازی‌ها برای توضیح خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تأمین: به خطر انداختن یک سیستم با هدف قرار دادن عناصر کمتر ایمن در زنجیره تأمین آن، مانند کتابخانه‌های شخص ثالث، داده‌مجموعه‌ها یا مدل‌های پیش‌آموزش دیده.
​
یادگیری انتقالی: تکنیکی که در آن مدلی که برای یک وظیفه توسعه یافته است، به عنوان نقطه شروع برای مدلی در وظیفه دوم مورد استفاده مجدد قرار می‌گیرد.
​
پایگاه داده برداری: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با ابعاد زیاد (تعبیه‌ها) و انجام جستجوهای مشابهت کارآمد.
​
اسکن آسیب‌پذیری: ابزارهای خودکار که آسیب‌پذیری‌های امنیتی شناخته‌شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
نشانه‌گذاری دیجیتال: تکنیک‌هایی برای جاسازی نشانگرهای غیرقابل تشخیص در محتوای تولید شده توسط هوش مصنوعی به منظور ردیابی منشا آن یا شناسایی تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روز: یک آسیب‌پذیری که قبلاً ناشناخته بوده و مهاجمان می‌توانند قبل از اینکه توسعه‌دهندگان وصله‌ای ایجاد و منتشر کنند، از آن سوء استفاده کنند.

## پیوست ب: منابع

### TODO

## ضمیمه ج: مدیریت امنیت هوش مصنوعی و مستندسازی

### هدف

این پیوست الزامات پایه‌ای برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها به منظور حاکمیت بر امنیت هوش مصنوعی در سراسر چرخه عمر سیستم را ارائه می‌دهد.

---

### AC.1 پذیرش چارچوب مدیریت ریسک هوش مصنوعی

ارائه یک چارچوب رسمی برای شناسایی، ارزیابی و کاهش ریسک‌های خاص هوش مصنوعی در طول چرخه عمر سیستم.

 #AC.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که یک روش ارزیابی ریسک خاص هوش مصنوعی مستند شده و اجرا می‌شود.
 #AC.1.2    Level: 2    Role: D
 تأیید کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و پیش از تغییرات مهم انجام می‌شوند.
 #AC.1.3    Level: 3    Role: D/V
 تأیید کنید که چارچوب مدیریت ریسک با استانداردهای موجود (برای مثال، NIST AI RMF) هم‌راستا باشد.

---

### سیاست‌ها و رویه‌های امنیت هوش مصنوعی AC.2

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و عملیات امن هوش مصنوعی.

 #AC.2.1    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های مستند امنیت هوش مصنوعی وجود دارند.
 #AC.2.2    Level: 2    Role: D
 تأیید کنید که سیاست‌ها حداقل سالی یکبار و پس از تغییرات قابل توجه در چشم‌انداز تهدید بررسی و به‌روزرسانی شوند.
 #AC.2.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیاست‌ها تمام دسته‌های AISVS و الزامات نظارتی قابل اجرا را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها برای امنیت هوش مصنوعی

مسئولیت‌های واضح برای امنیت هوش مصنوعی در سراسر سازمان تعیین کنید.

 #AC.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستند شده‌اند.
 #AC.3.2    Level: 2    Role: D
 اطمینان حاصل کنید که افراد مسئول تخصص کافی در زمینه امنیت دارند.
 #AC.3.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که کمیته اخلاقی هوش مصنوعی یا هیئت حاکمیتی برای سیستم‌های هوش مصنوعی با ریسک بالا تشکیل شده است.

---

### AC.4 اجرای دستورالعمل‌های اخلاقی هوش مصنوعی

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی بر اساس اصول اخلاقی تعیین شده عمل کنند.

 #AC.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که دستورالعمل‌های اخلاقی برای توسعه و استقرار هوش مصنوعی وجود دارد.
 #AC.4.2    Level: 2    Role: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای شناسایی و گزارش تخلفات اخلاقی وجود دارد.
 #AC.4.3    Level: 3    Role: D/V
 تأیید کنید که بررسی‌های اخلاقی منظم بر روی سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### نظارت بر تطابق مقررات هوش مصنوعی AC.5

حفظ آگاهی و رعایت مقررات در حال تغییر هوش مصنوعی.

 #AC.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که فرایندهایی برای شناسایی مقررات کاربردی هوش مصنوعی وجود دارد.
 #AC.5.2    Level: 2    Role: D
 اطمینان حاصل کنید که رعایت تمام الزامات قانونی ارزیابی شده است.
 #AC.5.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تغییرات مقرراتی موجب بازبینی‌ها و به‌روزرسانی‌های به‌موقع سیستم‌های هوش مصنوعی می‌شوند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## پیوست D: حاکمیت و تأیید صحت کدنویسی امن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه‌ای برای استفاده ایمن و مؤثر از ابزارهای کدنویسی تحت کمک هوش مصنوعی در طول توسعه نرم‌افزار را تعریف می‌کند، تا امنیت و قابلیت ردیابی در سراسر چرخه حیات توسعه نرم‌افزار (SDLC) تضمین شود.

---

### AD.1 جریان کاری کدگذاری امن با پشتیبانی هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن (SSDLC) سازمان ادغام کنید بدون اینکه نقاط کنترل امنیتی موجود تضعیف شوند.

 #AD.1.1    Level: 1    Role: D/V
 تأیید کنید که یک گردش کار مستند شده توضیح می‌دهد چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد را تولید، بازسازی یا بازبینی کنند.
 #AD.1.2    Level: 2    Role: D
 تأیید کنید که جریان کاری به هر مرحله از SSDLC (طراحی، پیاده‌سازی، بازبینی کد، آزمون، استقرار) مرتبط باشد.
 #AD.1.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان کشف) برای کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با مبناهای صرفاً انسانی مقایسه می‌شوند.

---

### AD.2 ارزیابی ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای کدگذاری هوش مصنوعی از نظر قابلیت‌های امنیتی، ریسک و تأثیر زنجیره تأمین قبل از استفاده ارزیابی شوند.

 #AD.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که مدل تهدید برای هر ابزار هوش مصنوعی شامل سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی باشد.
 #AD.2.2    Level: 2    Role: D
 اطمینان حاصل کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر جزء محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) باشد.
 #AD.2.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌ها طبق یک چارچوب معتبر انجام می‌شوند و پس از تغییرات بزرگ نسخه دوباره اجرا می‌شوند.

---

### AD.3 مدیریت امن درخواست و زمینه

جلوگیری از نشت اسرار، کدهای اختصاصی و داده‌های شخصی هنگام ساخت پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی.

 #AD.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که راهنمایی‌های مکتوب ارسال اسرار، مدارک شناسایی یا داده‌های طبقه‌بندی شده در درخواست‌ها را ممنوع می‌کند.
 #AD.3.2    Level: 2    Role: D
 تأیید کنید که کنترل‌های فنی (حذف داده‌ها در سمت کلاینت، فیلترهای زمینه‌ای تأیید شده) به‌صورت خودکار آثار حساس را حذف می‌کنند.
 #AD.3.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که پرسش‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت استراحت رمزگذاری شده‌اند و دوره‌های نگهداری آنها با سیاست طبقه‌بندی داده‌ها مطابقت دارد.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و برطرف کردن آسیب‌پذیری‌های وارد شده توسط خروجی هوش مصنوعی قبل از ادغام یا استقرار کد.

 #AD.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که کد تولید شده توسط هوش مصنوعی همیشه تحت بازبینی کد توسط انسان قرار می‌گیرد.
 #AD.4.2    Level: 2    Role: D
 اطمینان حاصل کنید که برنامه‌های اسکنر خودکار (SAST/IAST/DAST) بر روی هر درخواست pull که حاوی کد تولید شده توسط هوش مصنوعی است اجرا شده و در صورت وجود یافته‌های بحرانی، عملیات ادغام را مسدود می‌کنند.
 #AD.4.3    Level: 3    Role: D/V
 بررسی کنید که آزمایش‌های fuzz تفاضلی یا تست‌های مبتنی بر خصوصیت رفتارهای حیاتی امنیت (مانند اعتبارسنجی ورودی، منطق مجوزدهی) را اثبات کنند.

---

### AD.5 قابل توضیح بودن و ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان دیدگاه بدهید که چرا یک پیشنهاد ارائه شده است و چگونه تکامل یافته است.

 #AD.5.1    Level: 1    Role: D/V
 تأیید کنید که جفت‌های درخواست/پاسخ با شناسه‌های تعهد (commit IDs) ثبت شده‌اند.
 #AD.5.2    Level: 2    Role: D
 تأیید کنید که توسعه‌دهندگان می‌توانند استنادهای مدل (قطعات آموزشی، مستندات) را که پیشنهاد را پشتیبانی می‌کنند، نشان دهند.
 #AD.5.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که گزارش‌های قابل‌توضیح بودن با مصنوعات طراحی ذخیره شده و در بازبینی‌های امنیتی ارجاع داده می‌شوند، به طوری که اصول ردیابی ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مستمر و اصلاح دقیق مدل

عملکرد امنیت مدل را در طول زمان بهبود بخشید در حالی که از انحراف منفی جلوگیری می‌کنید.

 #AD.6.1    Level: 1    Role: D/V
 تأیید کنید که توسعه‌دهندگان می‌توانند پیشنهادهای ناامن یا غیرقابل تطبیق را علامت‌گذاری کنند و اینکه علامت‌ها ردیابی می‌شوند.
 #AD.6.2    Level: 2    Role: D
 تأیید کنید که بازخورد تجمیع شده برای تنظیم مجدد دوره‌ای یا تولید افزایش‌یافته با بازیابی با استفاده از مجموعه‌های کدنویسی امن مورد تأیید (مانند OWASP Cheat Sheets) مورد استفاده قرار می‌گیرد.
 #AD.6.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که یک سیستم ارزیابی حلقه‌بسته پس از هر تنظیم دقیق، تست‌های رگرسیون را اجرا می‌کند؛ معیارهای امنیتی باید قبل از استقرار با حداقل میزان پایه‌های قبلی برابر یا بهتر باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل نمونه‌هایی از ابزارها و چارچوب‌ها را ارائه می‌دهد که می‌توانند از پیاده‌سازی یا تحقق یک الزامات AISVS خاص پشتیبانی کنند. این موارد نباید به عنوان توصیه یا تاییدیه از سوی تیم AISVS یا پروژه امنیتی OWASP GenAI تلقی شوند.

---

### AE.1 حاکمیت داده‌های آموزشی و مدیریت تعصب

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت داده و مدیریت جانبداری.

 #AE.1.1    Section: 1.1
 ابزار مدیریت فهرست داده: ابزارهای مدیریت فهرست داده مانند...
 #AE.1.2    Section: 1.2
 رمزنگاری در حال انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و پایتون`ssl`کتابخانه.

---

### AE.2 اعتبارسنجی ورودی کاربر

ابزارهایی برای مدیریت و اعتبارسنجی ورودی‌های کاربران.

 #AE.2.1    Section: 2.1
 ابزارهای دفاع در برابر تزریق فرمان: از ابزارهای محافظتی مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

