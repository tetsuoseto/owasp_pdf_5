## جلد اول

### درباره استاندارد

استاندارد تأیید امنیت هوش مصنوعی (AISVS) یک فهرست جامعه محور از الزامات امنیتی است که دانشمندان داده، مهندسان MLOps، معماران نرم‌افزار، توسعه‌دهندگان، آزمایش‌کنندگان، متخصصان امنیت، فروشندگان ابزار، نهادهای نظارتی و مصرف‌کنندگان می‌توانند برای طراحی، ساخت، آزمایش و تأیید سیستم‌ها و برنامه‌های قابل اعتماد مجهز به هوش مصنوعی از آن استفاده کنند. این استاندارد زبان مشترکی برای مشخص کردن کنترل‌های امنیتی در طول چرخه عمر هوش مصنوعی — از جمع‌آوری داده‌ها و توسعه مدل تا استقرار و نظارت مداوم — فراهم می‌کند تا سازمان‌ها بتوانند مقاومت، حفظ حریم خصوصی و ایمنی راه‌حل‌های هوش مصنوعی خود را اندازه‌گیری و بهبود بخشند.

### حق نشر و مجوز

نسخه 0.1 (اولین پیش‌نویس عمومی - در حال انجام)، ۲۰۲۵  

![license](images/license.png)
کپی‌رایت © ۲۰۲۵ پروژه AISVS.  

منتشر شده تحتCreative Commons Attribution‑ShareAlike 4.0 International License.
برای هر گونه استفاده مجدد یا توزیع، باید شرایط مجوز این اثر را به طور واضح به دیگران اطلاع دهید.

### رهبران پروژه

جیم مانویکو
آراس "راس" میمیزیازچی

### مشارکت‌کنندگان و بازبین‌ها

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS یک استاندارد کاملاً جدید است که به‌طور خاص برای مقابله با چالش‌های امنیتی منحصربه‌فرد سیستم‌های هوش مصنوعی ایجاد شده است. هرچند این استاندارد از بهترین شیوه‌های کلی امنیت الهام گرفته است، اما هر نیازمندی در AISVS از پایه توسعه یافته است تا به‌درستی چشم‌انداز تهدیدات هوش مصنوعی را بازتاب دهد و به سازمان‌ها در ساخت راه‌حل‌های هوش مصنوعی امن‌تر و مقاوم‌تر کمک کند.

## پیش‌گفتار

به استاندارد تأیید امنیت هوش مصنوعی (AISVS) نسخه 1.0 خوش آمدید!

### مقدمه

AISVS که در سال ۲۰۲۵ از طریق یک تلاش جمعی جامعه‌ای تأسیس شد، الزامات امنیتی را که هنگام طراحی، توسعه، استقرار و بهره‌برداری از مدل‌های مدرن هوش مصنوعی، خطوط لوله و خدمات مجهز به هوش مصنوعی باید در نظر گرفته شود، تعریف می‌کند.

AISVS نسخه ۱.۰ نمایانگر کار مشترک رهبران پروژه، گروه کاری و مشارکت‌کنندگان گسترده‌تر جامعه برای ایجاد یک پایه عملی و قابل آزمون به منظور ایمن‌سازی سیستم‌های هوش مصنوعی است.

هدف ما در این نسخه، ساده‌سازی پذیرش AISVS در حالی است که تمرکز دقیق بر دامنه تعریف‌شده آن حفظ شده و به چشم‌انداز روبه‌تغییر ریسک منحصربه‌فرد هوش مصنوعی نیز پرداخته شود.

### اهداف کلیدی نسخه 1.0 سیستم شناسایی و تشخیص هوش مصنوعی (AISVS)

نسخه ۱.۰ با چندین اصول راهنما ایجاد خواهد شد.

#### دامنه‌ی به‌خوبی تعریف‌شده

هر الزام باید با نام و مأموریت AISVS هماهنگ باشد:

هوش مصنوعی – کنترل‌ها در لایه هوش مصنوعی/یادگیری ماشین (داده، مدل، خط لوله یا استنتاج) عمل می‌کنند و مسئولیت آن‌ها بر عهده متخصصان هوش مصنوعی است.
امنیت – الزامات به طور مستقیم خطرات شناسایی شده امنیتی، حفظ حریم خصوصی یا ایمنی را کاهش می‌دهند.
تأیید صحت – زبان به گونه‌ای نوشته می‌شود که انطباق آن به صورت عینی قابل ارزیابی باشد.
استاندارد – بخش‌ها ساختار و اصطلاحات یکسانی را دنبال می‌کنند تا مرجع منسجم و هماهنگی ایجاد کنند.
​
---

با پیروی از AISVS، سازمان‌ها می‌توانند به‌صورت نظام‌مند وضعیت امنیتی راه‌حل‌های هوش مصنوعی خود را ارزیابی و تقویت کرده و فرهنگ مهندسی امنیتی هوش مصنوعی را ترویج دهند.

## استفاده از AISVS

استاندارد تأیید امنیت هوش مصنوعی (AISVS) الزامات امنیتی را برای برنامه‌ها و خدمات هوش مصنوعی مدرن تعریف می‌کند و بر جنبه‌هایی که در کنترل توسعه‌دهندگان برنامه است تمرکز دارد.

AISVS برای هر کسی که در حال توسعه یا ارزیابی امنیت برنامه‌های هوش مصنوعی است، از جمله توسعه‌دهندگان، معماران، مهندسین امنیت و ممیزان طراحی شده است. این فصل ساختار و نحوه استفاده از AISVS از جمله سطوح تأییدیه آن و کاربردهای مورد نظر را معرفی می‌کند.

### سطوح تأیید امنیت هوش مصنوعی

AISVS سه سطح تصاعدی برای تأیید امنیت تعریف می‌کند. هر سطح عمق و پیچیدگی بیشتری می‌افزاید و به سازمان‌ها امکان می‌دهد وضعیت امنیتی خود را با سطح ریسک سیستم‌های هوش مصنوعی خود تطبیق دهند.

سازمان‌ها ممکن است از سطح ۱ شروع کنند و به تدریج سطوح بالاتر را با افزایش بلوغ امنیتی و مواجهه با تهدیدات اتخاذ کنند.

#### تعریف سطوح

هر نیازمندی در AISVS نسخه 1.0 به یکی از سطوح زیر اختصاص داده شده است:

##### نیازمندی‌های سطح ۱

سطح ۱ شامل حیاتی‌ترین و پایه‌ای‌ترین الزامات امنیتی است. این الزامات بر جلوگیری از حملات رایجی تمرکز دارند که به پیش‌شرط‌ها یا آسیب‌پذیری‌های دیگر وابسته نیستند. اکثر کنترل‌های سطح ۱ یا به‌سادگی قابل پیاده‌سازی هستند یا به قدر کافی ضروری‌اند که توجیه‌کننده صرف تلاش باشند.

##### الزامات سطح ۲

سطح ۲ به حملات پیشرفته‌تر یا کمتر رایج و همچنین دفاع‌های چندلایه در برابر تهدیدات گسترده می‌پردازد. این الزامات ممکن است شامل منطق پیچیده‌تر یا هدف قرار دادن پیش‌نیازهای خاص حمله باشند.

##### الزامات سطح ۳

سطح ۳ شامل کنترل‌هایی است که معمولاً اجرای آن‌ها دشوارتر یا کاربردی موقعیتی دارد. این کنترل‌ها اغلب مکانیزم‌های دفاع چندلایه یا تدابیر مقابله با حملات خاص، هدفمند یا با پیچیدگی بالا را نشان می‌دهند.

#### نقش (D/V)

هر الزام AISVS بر اساس مخاطب اصلی مشخص شده است:

D – الزامات متمرکز بر توسعه‌دهنده
V – نیازمندی‌های متمرکز بر تأییدکننده/حسابرسان
D/V – مرتبط با هر دو توسعه‌دهندگان و تاییدکنندگان

## آموزش مدیریت داده‌های C1 و کنترل تعصب

### هدف کنترل

داده‌های آموزشی باید به گونه‌ای تأمین، مدیریت و نگهداری شوند که اصالت، امنیت، کیفیت و عدالت حفظ شود. انجام این کار مسئولیت‌های قانونی را برآورده کرده و ریسک‌های مرتبط با تعصب، مسمومیت یا نقض حریم خصوصی در طول چرخه عمر هوش مصنوعی را کاهش می‌دهد.

---

### C1.1 منشأ داده‌های آموزشی

نگه‌داری یک فهرست قابل تأیید از تمام مجموعه داده‌ها، پذیرش تنها منابع معتبر، و ثبت هر تغییر برای قابلیت رسیدگی و بازرسی.

 #1.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که یک فهرست به‌روز از هر منبع داده‌های آموزشی (اصل، مسئول/مالک، مجوز، روش جمع‌آوری، محدودیت‌های استفاده مد نظر و تاریخچه پردازش) نگهداری می‌شود.
 #1.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که تنها مجموعه داده‌هایی که از نظر کیفیت، نمایانگری، تامین اخلاقی و تطابق با مجوز بررسی شده‌اند اجازه استفاده دارند، که این امر ریسک‌های مسمومیت داده، تعصب پنهان و نقض مالکیت فکری را کاهش می‌دهد.
 #1.1.3    Level: 1    Role: D/V
 اطمینان حاصل کنید که به حداقل رساندن داده‌ها اعمال شده باشد تا از حذف ویژگی‌های اضافی یا حساس اطمینان حاصل شود.
 #1.1.4    Level: 2    Role: D/V
 تأیید کنید که همه تغییرات مجموعه داده‌ها مشمول یک فرایند تأیید ثبت‌شده باشند.
 #1.1.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق بررسی متقابل یا توافق نظر بازبین‌ها تضمین شده است.
 #1.1.6    Level: 2    Role: D/V
 تأیید کنید که "کارت‌های داده" یا "برگه‌های مشخصات داده‌ها برای مجموعه داده‌ها" برای مجموعه داده‌های آموزشی مهم نگهداری می‌شوند که خصوصیات، انگیزه‌ها، ترکیب، فرآیندهای جمع‌آوری، پیش‌پردازش و استفاده‌های پیشنهادی یا منع‌شده را به طور دقیق توصیف می‌کنند.

---

### C1.2 امنیت و یکپارچگی داده‌های آموزشی

دسترسی را محدود کنید، داده‌ها را در حالت ذخیره‌سازی و انتقال رمزگذاری کنید و صحت آن‌ها را برای جلوگیری از دستکاری یا سرقت تأیید کنید.

 #1.2.1    Level: 1    Role: D/V
 تأیید کنید که کنترل‌های دسترسی از ذخیره‌سازی و خط لوله‌ها محافظت می‌کنند.
 #1.2.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌ها در هنگام انتقال رمزگذاری شده‌اند و برای تمام اطلاعات حساس یا اطلاعات شخصی قابل شناسایی (PII) نیز در حالت استراحت، از الگوریتم‌های رمزنگاری استاندارد صنعتی و روش‌های مدیریت کلید استفاده شده است.
 #1.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال برای تضمین صحت داده‌ها در هنگام ذخیره‌سازی و انتقال استفاده می‌شوند و تکنیک‌های کشف خودکار ناهنجاری برای محافظت در برابر تغییرات غیرمجاز یا خرابی داده‌ها، از جمله تلاش‌های هدفمند برای مسموم‌سازی داده‌ها، به‌کار گرفته شده‌اند.
 #1.2.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که نسخه‌های مجموعه داده‌ها ردیابی می‌شوند تا امکان بازگردانی فراهم شود.
 #1.2.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌های منسوخ به‌طور ایمن پاک‌سازی یا ناشناس‌سازی شده‌اند تا با سیاست‌های نگهداری داده، الزامات نظارتی مطابقت داشته باشند و سطح حمله کاهش یابد.

---

### C1.3 جامعیت و انصاف در نمایش

کجی‌های جمعیتی را شناسایی کرده و کاهش دهید تا نرخ خطاهای مدل در میان گروه‌ها به طور عادلانه توزیع شود.

 #1.3.1    Level: 1    Role: D/V
 اطمینان حاصل شود که مجموعه داده‌ها از نظر عدم تعادل نمایشی و تعصبات احتمالی در خصوصیات محافظت شده قانونی (مانند نژاد، جنسیت، سن) و سایر ویژگی‌های حساس اخلاقی مرتبط با حوزه کاربرد مدل (مانند وضعیت اجتماعی-اقتصادی، موقعیت جغرافیایی) مورد بررسی قرار گرفته‌اند.
 #1.3.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوگیری‌های شناسایی‌شده از طریق استراتژی‌های مستند شده‌ای مانند تعادل مجدد، افزایش داده‌های هدفمند، تنظیمات الگوریتمی (مثلاً تکنیک‌های پیش‌پردازش، پردازش در حین اجرا، پس‌پردازش) یا وزن‌دهی مجدد کاهش یافته‌اند، و تأثیر این کاهش بر هر دو جنبه عدالت و عملکرد کلی مدل ارزیابی شده است.
 #1.3.3    Level: 2    Role: D/V
 تأیید کنید که معیارهای انصاف پس از آموزش ارزیابی و مستندسازی شده‌اند.
 #1.3.4    Level: 3    Role: D/V
 تأیید کنید که یک سیاست مدیریت سوگیری چرخه عمر، مالکین و دوره‌بندی بررسی را تعیین می‌کند.

---

### C1.4 کیفیت، یکپارچگی و امنیت برچسب‌گذاری داده‌های آموزشی

برچسب‌ها را با رمزنگاری محافظت کنید و برای کلاس‌های حیاتی، بازبینی دو نفره را الزامی نمایید.

 #1.4.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که کیفیت برچسب‌گذاری/حاشیه‌نویسی از طریق دستورالعمل‌های واضح، بررسی‌های متقابل توسط بازبین‌ها، مکانیزم‌های اجماع (مثلاً نظارت بر توافق بین حاشیه‌نویسان) و فرآیندهای تعریف‌شده برای حل اختلافات تضمین شده است.
 #1.4.2    Level: 2    Role: D/V
 تأیید کنید که هش‌های رمزنگاری شده یا امضاهای دیجیتال بر روی آثار برچسب‌گذاری شده اعمال شده‌اند تا صحت و اصالت آن‌ها تضمین شود.
 #1.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که رابط‌ها و پلتفرم‌های برچسب‌گذاری کنترل‌های دسترسی قوی را اجرا می‌کنند، گزارش‌های حسابرسی مقاوم در برابر دستکاری از تمام فعالیت‌های برچسب‌گذاری نگهداری می‌کنند و در برابر تغییرات غیرمجاز محافظت می‌کنند.
 #1.4.4    Level: 3    Role: D/V
 تأیید کنید که برچسب‌هایی که برای ایمنی، امنیت یا عدالت حیاتی هستند (مانند شناسایی محتوای سمی، یافته‌های پزشکی حیاتی) بررسی دوگانه مستقل اجباری یا تأیید قوی معادل دریافت می‌کنند.
 #1.4.5    Level: 2    Role: D/V
 اطمینان حاصل شود که اطلاعات حساس (شامل اطلاعات شخصی قابل شناسایی) که به طور تصادفی ثبت شده یا به طور ضروری در برچسب‌ها وجود دارد، مطابق با اصول حداقل‌سازی داده‌ها، حذف، شبه‌سازی، ناشناس‌سازی یا در حالت استراحت و انتقال رمزگذاری شده باشد.
 #1.4.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که راهنمای برچسب‌گذاری و دستورالعمل‌ها جامع، نسخه‌گذاری شده و توسط همتایان بررسی شده‌اند.
 #1.4.7    Level: 2    Role: D/V
 تأیید کنید که طرح‌های داده (از جمله برچسب‌ها) به‌وضوح تعریف شده و تحت کنترل نسخه باشند.
 #1.8.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیندهای برچسب‌گذاری برون‌سپاری‌شده یا جمع‌سپاری‌شده شامل تدابیر فنی/رویّه‌ای برای تضمین محرمانگی داده‌ها، صحت داده‌ها، کیفیت برچسب‌ها و جلوگیری از نشت داده‌ها باشد.

---

### C1.5 تضمین کیفیت داده‌های آموزش

ترکیب اعتبارسنجی خودکار، بررسی‌های تصادفی دستی و اصلاحات ثبت‌شده برای تضمین قابلیت اطمینان داده‌ها.

 #1.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که تست‌های خودکار خطاهای قالب، مقادیر تهی و انحرافات برچسب را در هر ورود داده یا تبدیل مهم شناسایی کنند.
 #1.5.2    Level: 1    Role: D/V
 تأیید کنید که داده‌های ناموفق با ردگیری‌های حسابرسی قرنطینه شده‌اند.
 #1.5.3    Level: 2    Role: V
 تأیید کنید که بازبینی‌های دستی توسط کارشناسان حوزه، نمونه‌ای به اندازه آماری معنادار (مثلاً ≥1٪ یا ۱۰۰۰ نمونه، هرکدام که بیشتر باشد، یا مطابق با ارزیابی ریسک تعیین شده) را پوشش دهد تا مسائل ظریف کیفیت که توسط خودکارسازی شناسایی نشده‌اند، مشخص شود.
 #1.5.4    Level: 2    Role: D/V
 تأیید کنید که مراحل اصلاح به سوابق منشأ افزوده شده‌اند.
 #1.5.5    Level: 2    Role: D/V
 تأیید کنید که دروازه‌های کیفیت، داده‌های نامطلوب را مسدود می‌کنند مگر اینکه استثناها تأیید شده باشند.

---

### C1.6 شناسایی تزریق داده‌های مخرب

اعمال تشخیص ناهنجاری آماری و جریان‌های کاری قرنطینه برای جلوگیری از ورودهای متخاصم.

 #1.6.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تکنیک‌های شناسایی ناهنجاری (مانند روش‌های آماری، تشخیص نقاط پرت، تحلیل جاسازی) در هنگام ورود داده به سیستم و قبل از اجرای اصلی آموزش برای شناسایی حملات احتمالی مسموم‌سازی یا خرابی ناخواسته داده‌ها اعمال می‌شوند.
 #1.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که نمونه‌های علامت‌گذاری‌شده قبل از آموزش، بازبینی دستی را فعال می‌کنند.
 #1.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج پرونده امنیتی مدل را تغذیه کرده و اطلاعات تهدیدات جاری را مطلع می‌سازد.
 #1.6.4    Level: 3    Role: D/V
 تأیید کنید که منطق شناسایی با اطلاعات تهدید جدید به‌روزرسانی شده است.
 #1.6.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که خطوط لوله یادگیری آنلاین تغییر توزیع را نظارت می‌کنند.
 #1.6.6    Level: 3    Role: D/V
 اطمینان حاصل کنید که دفاع‌های خاص در برابر انواع شناخته شده حملات مسموم‌سازی داده (مانند جابجایی برچسب، درج ماشه درب‌پشتی، حملات نمونه تأثیرگذار) بر اساس نمایه ریسک سیستم و منابع داده در نظر گرفته شده و پیاده‌سازی شده‌اند.

---

### C1.7 حذف داده‌های کاربر و اجرای رضایت

درخواست‌های حذف احترام گذاشتن و انصراف از رضایت را در سراسر مجموعه داده‌ها، نسخه‌های پشتیبان و مصنوعات مشتق شده رعایت کنید.

 #1.7.1    Level: 1    Role: D/V
 تأیید کنید که گردش‌های کاری حذف داده‌های اصلی و مشتق‌شده را پاک می‌کنند و تأثیر آن بر مدل ارزیابی می‌شود، و همچنین تأثیر بر مدل‌های متاثر ارزیابی شده و در صورت لزوم مورد رسیدگی قرار می‌گیرد (برای مثال، از طریق بازآموزی یا بازتنظیم).
 #1.7.2    Level: 2    Role: D
 تأیید کنید که مکانیزم‌هایی برای ردیابی و رعایت دامنه و وضعیت رضایت کاربر (و برداشت‌های او) برای داده‌های استفاده شده در آموزش وجود دارد، و اینکه رضایت پیش از وارد کردن داده به فرایندهای آموزشی جدید یا به‌روزرسانی‌های مهم مدل، اعتبارسنجی می‌شود.
 #1.7.3    Level: 2    Role: V
 تأیید کنید که گردش‌های کاری به صورت سالانه آزمایش شده و ثبت می‌شوند.

---

### C1.8 امنیت زنجیره تأمین

ارائه‌دهندگان داده‌های خارجی را بررسی کرده و صحت آن‌ها را از طریق کانال‌های تأیید شده و رمزگذاری‌شده تأیید کنید.

 #1.8.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تامین‌کنندگان داده‌های شخص ثالث، از جمله ارائه‌دهندگان مدل‌های از پیش آموزش‌دیده و مجموعه داده‌های خارجی، پیش از ادغام داده‌ها یا مدل‌هایشان، مراحل بررسی دقیق امنیت، حریم خصوصی، تأمین اخلاقی و کیفیت داده را طی کنند.
 #1.8.2    Level: 1    Role: D
 اطمینان حاصل کنید که انتقال‌های خارجی از TLS/احراز هویت و بررسی‌های صحت استفاده می‌کنند.
 #1.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که منابع داده‌های پرخطر (مانند مجموعه‌داده‌های متن‌باز با منشاء نامشخص، تأمین‌کنندگان بدون ارزیابی) قبل از استفاده در برنامه‌های حساس، تحت بررسی‌های دقیق‌تر قرار گیرند، از جمله تحلیل در محیط ایزوله (sandbox)، بررسی‌های گسترده کیفیت/تعصب و شناسایی هدفمند آلودگی داده.
 #1.8.4    Level: 3    Role: D/V
 تأیید کنید که مدل‌های از پیش آموزش‌دیده شده که از طرف‌های سوم دریافت می‌شوند، از نظر تعصبات نهفته، پشتی‌های احتمالی، صحت معماری آن‌ها و منشاء داده‌های آموزش اصلی‌شان قبل از تنظیم دقیق یا استقرار، ارزیابی شده‌اند.

---

### C1.9 تشخیص نمونه‌های خصمانه

اجرای اقدامات در مرحله آموزش، مانند آموزش مقابله‌ای، به منظور افزایش مقاومت مدل در برابر نمونه‌های مقابله‌ای.

 #1.9.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که دفاع‌های مناسب مانند آموزش مقاومتی (با استفاده از نمونه‌های خصمانه تولید شده)، افزایش داده‌ها با ورودی‌های تغییر یافته، یا تکنیک‌های بهینه‌سازی مقاوم، برای مدل‌های مرتبط براساس ارزیابی ریسک اجرا و تنظیم شده‌اند.
 #1.9.2    Level: 2    Role: D/V
 تأیید کنید که در صورت استفاده از آموزش ضد حمله، تولید، مدیریت و نسخه‌بندی مجموعه‌داده‌های ضد حمله مستند و کنترل شده باشد.
 #1.9.3    Level: 3    Role: D/V
 تأیید کنید که تأثیر آموزش مقاومت در برابر دشمنی بر عملکرد مدل (در برابر ورودی‌های پاک و دشمنی) و معیارهای عدالت ارزیابی، مستند و پایش شود.
 #1.9.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که استراتژی‌های آموزش مقابله‌ای و مقاومت به طور دوره‌ای بازبینی و به‌روزرسانی می‌شوند تا با تکنیک‌های جدید حملات مقابله‌ای مقابله کنند.

---

### C1.10 جریان داده و قابلیت ردیابی

پیگیری کامل مسیر هر نقطه داده از منبع تا ورودی مدل برای امکان بازبینی و پاسخ به حوادث.

 #1.10.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوابق دقیق هر داده، شامل تمام تبدیلات، افزایش‌ها و ادغام‌ها ثبت شده و قابل بازیابی باشد.
 #1.10.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوابق شجره‌نامه تغییرناپذیر، به‌طور ایمن ذخیره شده و برای ممیزی‌ها یا تحقیقات قابل دسترسی باشند.
 #1.10.3    Level: 2    Role: D/V
 تأیید کنید که پیگیری منشأ داده‌ها هر دو داده‌های خام و داده‌های سنتتیک را پوشش می‌دهد.

---

### C1.11 مدیریت داده‌های مصنوعی

اطمینان حاصل کنید که داده‌های سنتزی به درستی مدیریت، برچسب‌گذاری و ارزیابی ریسک شده‌اند.

 #1.11.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمامی داده‌های مصنوعی به وضوح برچسب‌گذاری شده و در سراسر فرآیند قابل تمایز از داده‌های واقعی باشند.
 #1.11.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرآیند تولید، پارامترها و استفاده مورد نظر داده‌های مصنوعی مستند شده باشد.
 #1.11.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌های مصنوعی پیش از استفاده در آموزش، از نظر خطر سوگیری، نشت حریم خصوصی و مسائل نمایشی ارزیابی شده باشند.

---

### C1.12 نظارت بر دسترسی به داده‌ها و تشخیص ناهنجاری

نظارت و هشدار در مورد دسترسی‌های غیرمعمول به داده‌های آموزش برای شناسایی تهدیدهای داخلی یا خروج غیرمجاز اطلاعات.

 #1.12.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام دسترسی‌ها به داده‌های آموزشی ثبت می‌شوند، از جمله کاربر، زمان و عملکرد.
 #1.12.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که لاگ‌های دسترسی به طور منظم برای الگوهای غیرمعمول مانند استخراج‌های بزرگ یا دسترسی از مکان‌های جدید بررسی می‌شوند.
 #1.12.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که هشدارها برای رویدادهای دسترسی مشکوک تولید شده و به سرعت مورد بررسی قرار می‌گیرند.

---

### C1.13 سیاست‌های نگهداری و انقضای داده‌ها

تعریف و اجرای دوره‌های نگهداری داده‌ها به منظور کاهش ذخیره‌سازی غیرضروری داده‌ها.

 #1.13.1    Level: 1    Role: D/V
 بررسی کنید که دوره‌های نگهداری صریح برای همه مجموعه‌داده‌های آموزشی تعریف شده باشند.
 #1.13.2    Level: 2    Role: D/V
 تأیید کنید که مجموعه داده‌ها به‌صورت خودکار در پایان دوره عمرشان منقضی، حذف یا برای حذف بررسی می‌شوند.
 #1.13.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که اقدامات نگهداری و حذف ثبت شده و قابل بررسی باشند.

---

### C1.14 تطابق با مقررات و حوزه‌های قضایی

اطمینان حاصل کنید که تمامی داده‌های آموزشی مطابق با قوانین و مقررات قابل اجرا باشد.

 #1.14.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که نیازمندی‌های اقامت داده و انتقال داده فرامرزی برای تمام مجموعه‌داده‌ها شناسایی و اجرا شده‌اند.
 #1.14.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که مقررات خاص هر بخش (مانند بهداشت و درمان، مالی) در مدیریت داده‌ها شناسایی و رعایت شده‌اند.
 #1.14.3    Level: 2    Role: D/V
 تأیید کنید که رعایت قوانین حفظ حریم خصوصی مرتبط (مانند GDPR، CCPA) مستندسازی شده و به‌طور منظم بازبینی می‌شود.

---

### C1.15 علامت‌گذاری داده‌ها و شناسایی اثر انگشت داده‌ها

شناسایی استفاده مجدد غیرمجاز یا نشت داده‌های مالکیتی یا حساس.

 #1.15.1    Level: 3    Role: D/V
 تأیید کنید که دیتاست‌ها یا زیرمجموعه‌ها در صورت امکان، دارای واترمارک یا اثرانگشت دیجیتال باشند.
 #1.15.2    Level: 3    Role: D/V
 تأیید کنید که روش‌های نشان‌گذاری/اثر انگشتی باعث ایجاد تعصب یا خطرات حریم خصوصی نمی‌شوند.
 #1.15.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که بررسی‌های دوره‌ای برای شناسایی استفاده غیرمجاز یا نشت داده‌های دارای نشان‌گذاری انجام می‌شود.

---

### C1.16 مدیریت حقوق صاحب داده

از حقوق موضوع داده‌ها مانند دسترسی، اصلاح، محدودیت و مخالفت پشتیبانی کنید.

 #1.16.1    Level: 2    Role: D/V
 تأیید کنید که مکانیزم‌هایی برای پاسخ به درخواست‌های موضوع داده برای دسترسی، اصلاح، محدودیت یا اعتراض وجود دارد.
 #1.16.2    Level: 2    Role: D/V
 تأیید کنید که درخواست‌ها در بازه‌های زمانی مقرر قانونی ثبت، پیگیری و انجام می‌شوند.
 #1.16.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرایندهای حقوق داده‌های موضوع به طور منظم برای اثربخشی مورد آزمایش و بازبینی قرار می‌گیرند.

---

### C1.17 تحلیل تأثیر نسخه مجموعه داده

قبل به‌روزرسانی یا جایگزینی نسخه‌ها، تاثیر تغییرات مجموعه داده را ارزیابی کنید.

 #1.17.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که قبل از به‌روزرسانی یا جایگزینی نسخه داده‌ها، تحلیل تأثیر انجام شده است که شامل عملکرد مدل، عدالت و رعایت مقررات می‌باشد.
 #1.17.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که نتایج تحلیل تأثیر مستندسازی شده و توسط ذینفعان مربوطه بازبینی شده‌اند.
 #1.17.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که طرح‌های بازگشت در صورت معرفی نسخه‌های جدید با ریسک‌ها یا پس‌رفت‌های غیرقابل قبول وجود دارند.

---

### C1.18 امنیت نیروی کار برچسب‌گذاری داده‌ها

تضمین امنیت و صحت کارکنان درگیر در حاشیه‌نویسی داده‌ها.

 #1.18.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام کارکنان دخیل در حاشیه‌نویسی داده‌ها پیش‌زمینه امنیتی بررسی شده و در زمینه امنیت داده‌ها و حریم خصوصی آموزش دیده‌اند.
 #1.18.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام کارکنان حاشیه‌نویسی توافق‌نامه‌های محرمانگی و عدم افشاء را امضا کرده‌اند.
 #1.18.3    Level: 2    Role: D/V
 تأیید کنید که پلتفرم‌های حاشیه‌نویسی کنترل‌های دسترسی را اعمال می‌کنند و تهدیدهای داخلی را زیر نظر دارند.

---

### مراجع

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## اعتبارسنجی ورودی کاربر C2

### هدف کنترل

اعتبارسنجی قوی ورودی کاربر خط اول دفاع در برابر برخی از مخرب‌ترین حملات به سیستم‌های هوش مصنوعی است. حملات تزریق پرامپت می‌توانند دستورات سیستم را لغو کنند، داده‌های حساس را نشت دهند یا مدل را به سمت رفتارهای غیرمجاز هدایت کنند. تحقیقات نشان می‌دهد که مگر فیلترهای اختصاصی و سلسله مراتب دستوری برقرار باشند، حملات "چندشات" فرار از محدودیت که از پنجره‌های متنی طولانی بهره می‌برند، مؤثر خواهند بود. همچنین، حملات تغییرات جزئی خصمانه—مانند تعویض هم‌نویس‌ها (homoglyph) یا استفاده از زبان لیتی (leetspeak)—می‌توانند به‌طور پنهانی تصمیمات مدل را تغییر دهند.

---

### C2.1 دفاع در برابر تزریق پرامپت

تزریق دستورات یکی از بزرگ‌ترین ریسک‌ها برای سیستم‌های هوش مصنوعی است. تدابیر دفاعی در برابر این روش از ترکیبی از فیلترهای الگوهای ایستا، طبقه‌بندهای پویا و اجرای سلسله‌مراتبی دستورالعمل‌ها استفاده می‌کنند.

 #2.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که ورودی‌های کاربر در برابر کتابخانه‌ای به‌روز شده به صورت مداوم از الگوهای شناخته شده تزریق فرمان (کلمات کلیدی فرار از محدودیت، «نادیده گرفتن قبلی»، زنجیره‌های نقش‌آفرینی، حملات غیرمستقیم HTML/URL) بررسی می‌شوند.
 #2.1.2    Level: 1    Role: D/V
 تأیید کنید که سیستم یک سلسله مراتب دستوری را اعمال می‌کند که در آن پیام‌های سیستم یا توسعه‌دهنده بر دستورالعمل‌های کاربر اولویت دارند، حتی پس از گسترش پنجره‌ی زمینه.
 #2.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تست‌های ارزیابی خصمانه (مثلاً پرامپت‌های "چند-شات" تیم قرمز) قبل از هر انتشار مدل یا الگوی پرامپت اجرا می‌شوند، با تعیین حد آستانه نرخ موفقیت و مسدودکننده‌های خودکار برای پسرفت‌ها.
 #2.1.4    Level: 2    Role: D
 تأیید کنید که پرامپت‌های منبع از محتوای شخص ثالث (صفحات وب، فایل‌های PDF، ایمیل‌ها) در یک زمینه تجزیه جداگانه پاک‌سازی شده‌اند قبل از اینکه در پرامپت اصلی الحاق شوند.
 #2.1.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تمام به‌روزرسانی‌های قوانین فیلتر متن، نسخه‌های مدل طبقه‌بندی‌کننده و تغییرات لیست مسدودکننده تحت کنترل نسخه و قابل بررسی باشند.

---

### C2.2 مقاومت در برابر نمونه‌های مخرب

مدل‌های پردازش زبان طبیعی (NLP) همچنان در برابر تغییرات ظریف در سطح کاراکتر یا کلمه آسیب‌پذیر هستند که انسان‌ها اغلب متوجه آن‌ها نمی‌شوند ولی مدل‌ها معمولاً آن‌ها را اشتباه طبقه‌بندی می‌کنند.

 #2.2.1    Level: 1    Role: D
 اطمینان حاصل کنید که مراحل اولیه نرمال‌سازی ورودی (NFC یونیکد، نگاشت هم‌ریخت‌ها، حذف فاصله‌های اضافی) قبل از توکنیزه کردن اجرا می‌شوند.
 #2.2.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که تشخیص ناهنجاری آماری ورودی‌هایی را که فاصله ویرایشی غیرمعمولاً بالا نسبت به هنجارهای زبانی، توکن‌های تکراری بیش از حد، یا فاصله‌های نهان‌سازی غیرطبیعی دارند، علامت‌گذاری می‌کند.
 #2.2.3    Level: 2    Role: D
 اطمینان حاصل کنید که خط لوله استنتاج از انواع مدل‌های تقویت‌شده با آموزش خصمانه اختیاری یا لایه‌های دفاعی (مانند تصادفی‌سازی، تقطیر دفاعی) برای نقاط پایانی با ریسک بالا پشتیبانی می‌کند.
 #2.2.4    Level: 2    Role: V
 اطمینان حاصل کنید که ورودی‌های مشکوک به حملات خصمانه قرنطینه شده و با کل داده‌های بار (پس از حذف اطلاعات شناسایی شخصی) ثبت می‌شوند.
 #2.2.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای پایداری (نرخ موفقیت مجموعه حملات شناخته شده) در طول زمان پیگیری می‌شوند و کاهش عملکرد موجب مسدود شدن انتشار می‌شود.

---

### اعتبارسنجی طرحواره، نوع و طول C2.3

حملات هوش مصنوعی که شامل ورودی‌های نادرست یا بزرگ‌تر از حد مجاز هستند، می‌توانند باعث بروز خطاهای پارسینگ، نشت دستور به فیلدهای دیگر و خستگی منابع شوند. اعمال سخت‌گیرانه‌تر قواعد ساختاری (اسکیما) نیز پیش‌نیاز انجام فراخوانی‌های قطعی ابزارها است.

 #2.3.1    Level: 1    Role: D
 اطمینان حاصل کنید که هر نقطه پایان فراخوانی API یا تابع، یک طرح ورودی صریح (JSON Schema، Protobuf یا معادل چندوجهی آن) تعریف می‌کند و ورودی‌ها قبل از ساخت پرامپت اعتبارسنجی می‌شوند.
 #2.3.2    Level: 1    Role: D/V
 تأیید کنید که ورودی‌هایی که از بیشینه تعداد توکن یا محدودیت بایت فراتر می‌روند، با یک خطای ایمن رد می‌شوند و هرگز به‌طور بی‌صدا کوتاه نمی‌شوند.
 #2.3.3    Level: 2    Role: D/V
 تأیید کنید که بررسی‌های نوع (مثلاً بازه‌های عددی، مقادیر enum، نوع‌های MIME برای تصاویر/صدا) در سمت سرور اعمال می‌شوند، نه فقط در کد سمت کلاینت.
 #2.3.4    Level: 2    Role: D
 اطمینان حاصل کنید که اعتبارسنج‌های معنایی (مانند JSON Schema) در زمان ثابتی اجرا می‌شوند تا از حملات انکار سرویس الگوریتمی جلوگیری شود.
 #2.3.5    Level: 3    Role: V
 تأیید کنید که شکست‌های اعتبارسنجی با قطعات بارگذاری محرمانه‌شده و کدهای خطای بدون ابهام ثبت می‌شوند تا به جداسازی امنیتی کمک کنند.

---

### C2.4 غربالگری محتوا و سیاست‌ها

توسعه‌دهندگان باید قادر باشند درخواست‌های دستوری معتبر که محتوای غیرمجاز (مانند دستورالعمل‌های غیرقانونی، سخنان نفرت‌انگیز و متن‌های دارای حق نشر) را درخواست می‌کنند، تشخیص دهند و سپس از انتشار آنها جلوگیری کنند.

 #2.4.1    Level: 1    Role: D
 اطمینان حاصل کنید که یک دسته‌بند محتوا (صفر شات یا تنظیم‌شده دقیق) برای هر ورودی، امتیازهایی برای خشونت، آسیب به خود، نفرت، محتوای جنسی و درخواست‌های غیرقانونی با آستانه‌های قابل تنظیم ارائه می‌دهد.
 #2.4.2    Level: 1    Role: D/V
 تأیید کنید که ورودی‌هایی که قوانین را نقض می‌کنند، پاسخ‌های استاندارد شده یا تکمیل‌های ایمن دریافت می‌کنند تا به تماس‌های بعدی مدل‌های زبانی بزرگ منتقل نشوند.
 #2.4.3    Level: 2    Role: D
 اطمینان حاصل کنید که مدل غربالگری یا مجموعه قوانین حداقل هر سه ماه یکبار بازآموزی/به‌روزرسانی می‌شود و الگوهای جدید مشاهده‌شده در خصوص دور زدن محدودیت‌ها یا قوانین را در بر می‌گیرد.
 #2.4.4    Level: 2    Role: D
 اطمینان حاصل کنید که غربالگری قوانین خاص کاربر (سن، محدودیت‌های قانونی منطقه‌ای) را از طریق قوانین مبتنی بر ویژگی که در زمان درخواست حل می‌شوند، رعایت می‌کند.
 #2.4.5    Level: 3    Role: V
 اطمینان حاصل کنید که گزارش‌های غربالگری شامل امتیازهای اعتماد طبقه‌بند و برچسب‌های دسته‌بندی سیاست برای همبستگی SOC و بازپخش تیم قرمز آینده باشد.

---

### C2.5 محدودسازی نرخ ورودی و پیشگیری از سوءاستفاده

توسعه‌دهندگان باید از سوءاستفاده، تخلیه منابع و حملات خودکار علیه سیستم‌های هوش مصنوعی با محدود کردن نرخ ورودی‌ها و شناسایی الگوهای استفاده غیرعادی جلوگیری کنند.

 #2.5.1    Level: 1    Role: D/V
 تأیید کنید که محدودیت‌های نرخ برای هر کاربر، هر آدرس IP و هر کلید API برای تمامی نقاط ورودی اعمال می‌شوند.
 #2.5.2    Level: 2    Role: D/V
 بررسی کنید که محدودیت‌های نرخ انفجاری و مداوم به گونه‌ای تنظیم شده باشند که از حملات محروم‌سازی سرویس (DoS) و حملات حدس زدن بی‌رحمانه جلوگیری کنند.
 #2.5.3    Level: 2    Role: D/V
 تأیید کنید که الگوهای استفاده غیرعادی (به عنوان مثال، درخواست‌های پشت سر هم سریع، پر کردن ورودی) باعث فعال شدن مسدودسازی‌های خودکار یا افزایش سطح اقدامات امنیتی می‌شوند.
 #2.5.4    Level: 3    Role: V
 تأیید کنید که لاگ‌های پیشگیری از سوءاستفاده حفظ شده و برای الگوهای حمله جدید بررسی می‌شوند.

---

### C2.6 اعتبارسنجی ورودی چندوجهی

سیستم‌های هوش مصنوعی باید اعتبارسنجی قوی برای ورودی‌های غیرمتنی (تصاویر، صداها، فایل‌ها) داشته باشند تا از تزریق، دورزدن یا سوء استفاده از منابع جلوگیری کنند.

 #2.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که تمام ورودی‌های غیر متنی (تصاویر، صوت، فایل‌ها) قبل از پردازش از نظر نوع، اندازه و فرمت اعتبارسنجی شده باشند.
 #2.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فایل‌ها پیش از واردسازی برای بدافزارها و بارهای استگانوگرافیکی اسکن می‌شوند.
 #2.6.3    Level: 2    Role: D/V
 تأیید کنید که ورودی‌های تصویر/صدا برای تغییرات مخرب یا الگوهای حمله شناخته شده بررسی شده‌اند.
 #2.6.4    Level: 3    Role: V
 تأیید کنید که شکست‌های اعتبارسنجی ورودی چندوجهی ثبت شده و هشدارهایی برای بررسی فعال شوند.

---

### C2.7 منبع ورودی و نسبت‌دهی

سیستم‌های هوش مصنوعی باید با ردیابی سوءاستفاده، حسابرسی و رعایت قوانین از طریق نظارت و برچسب‌گذاری منابع تمامی ورودی‌های کاربران را پشتیبانی کنند.

 #2.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمام ورودی‌های کاربر در هنگام دریافت با فراداده‌ها (شناسه کاربر، جلسه، منبع، زمان‌مهر، آدرس IP) برچسب‌گذاری شده باشند.
 #2.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که متاداده منبع حفظ شده و برای تمام ورودی‌های پردازش شده قابل حسابرسی باشد.
 #2.7.3    Level: 2    Role: D/V
 اطمینان حاصل شود که منابع ورودی غیرعادی یا غیرقابل اعتماد علامت‌گذاری شده و تحت بررسی دقیق‌تر یا مسدودسازی قرار می‌گیرند.

---

### C2.8 شناسایی تهدید تطبیقی بلادرنگ

توسعه‌دهندگان باید از سیستم‌های پیشرفته تشخیص تهدید برای هوش مصنوعی استفاده کنند که به الگوهای جدید حمله سازگار شده و با استفاده از تطبیق الگوهای کامپایل‌شده، حفاظت بلادرنگ ارائه دهند.

 #2.8.1    Level: 1    Role: D/V
 تأیید کنید که الگوهای شناسایی تهدید به موتورهای بیان منظم بهینه شده (regex) کامپایل شده‌اند تا برای فیلترکردن لحظه‌ای با کارایی بالا و حداقل تأخیر به کار روند.
 #2.8.2    Level: 1    Role: D/V
 تأیید کنید که سیستم‌های شناسایی تهدید، کتابخانه‌های الگو جداگانه‌ای برای دسته‌بندی‌های مختلف تهدید (تزریق درخواست، محتوای مضر، داده‌های حساس، دستورات سیستم) حفظ می‌کنند.
 #2.8.3    Level: 2    Role: D/V
 تأیید کنید که تشخیص تهدید تطبیقی شامل مدل‌های یادگیری ماشین است که حساسیت تهدید را بر اساس فراوانی و نرخ موفقیت حملات به‌روزرسانی می‌کنند.
 #2.8.4    Level: 2    Role: D/V
 تأیید کنید که فیدهای اطلاعات تهدید بلادرنگ به صورت خودکار کتابخانه‌های الگو را با امضاهای جدید حمله و شاخص‌های نفوذ (IOCها) به‌روزرسانی می‌کنند.
 #2.8.5    Level: 3    Role: D/V
 تأیید کنید که نرخ‌های مثبت کاذب در تشخیص تهدید به‌طور مداوم نظارت می‌شوند و ویژگی‌های الگو به‌طور خودکار تنظیم می‌شوند تا حداقل مداخله در موارد استفاده مشروع ایجاد شود.
 #2.8.6    Level: 3    Role: D/V
 تأیید کنید که تحلیل تهدید متنی شامل منبع ورودی، الگوهای رفتار کاربر و تاریخچه نشست برای بهبود دقت شناسایی است.
 #2.8.7    Level: 3    Role: D/V
 تأیید کنید که معیارهای عملکرد تشخیص تهدید (نرخ تشخیص، تأخیر پردازش، استفاده از منابع) به صورت زمان واقعی رصد و بهینه‌سازی می‌شوند.

---

### C2.9 خط لوله اعتبارسنجی امنیت چندوجهی

توسعه‌دهندگان باید اعتبارسنجی امنیتی برای متن، تصویر، صدا و سایر حالت‌های ورودی هوش مصنوعی را با انواع خاصی از تشخیص تهدید و جداسازی منابع ارائه دهند.

 #2.9.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر حالت ورودی دارای اعتبارسنج‌های امنیتی اختصاصی با الگوهای تهدید مستند شده است (متن: تزریق درخواست، تصاویر: پنهان‌نگاری، صدا: حملات طیف‌نگاری) و آستانه‌های تشخیص مشخص می‌باشد.
 #2.9.2    Level: 2    Role: D/V
 تأیید کنید که ورودی‌های چندرسانه‌ای در محیط‌های ایزوله شده (sandbox) با محدودیت‌های منابع مشخص (حافظه، پردازنده، زمان پردازش) که برای هر نوع حالت چندرسانه‌ای تعریف شده‌اند، پردازش می‌شوند و این موارد در سیاست‌های امنیتی مستند شده‌اند.
 #2.9.3    Level: 2    Role: D/V
 تأیید کنید که شناسایی حملات چندمودالی حملات هماهنگ شده در چندین نوع ورودی (مانند بارهای پنهان در تصاویر همراه با تزریق پرامپت در متن) را با استفاده از قوانین همبستگی و تولید هشدار شناسایی می‌کند.
 #2.9.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که خطاهای اعتبارسنجی چند حالته باعث ثبت دقیق و گزارش‌های تفصیلی شامل همه حالت‌های ورودی، نتایج اعتبارسنجی، امتیازهای تهدید و تحلیل همبستگی با فرمت‌های ساختارمند گزارش برای یکپارچه‌سازی با SIEM می‌شوند.
 #2.9.5    Level: 3    Role: D/V
 اطمینان حاصل شود که طبقه‌بندی‌کننده‌های محتوای خاص هر نوع مدالیته طبق برنامه‌های مستند شده (حداقل هر سه ماه یک‌بار) با الگوهای تهدید جدید، نمونه‌های متخاصم و شاخص‌های عملکرد که بالاتر از آستانه‌های پایه نگه داشته می‌شوند، به‌روزرسانی می‌شوند.

---

### مراجع

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## مدیریت چرخه عمر مدل C3 و کنترل تغییرات

### هدف کنترل

سیستم‌های هوش مصنوعی باید فرآیندهای کنترل تغییر را پیاده‌سازی کنند که از رسیدن تغییرات غیرمجاز یا ناامن مدل به مرحله تولید جلوگیری کند. این کنترل، یکپارچگی مدل را در طول کل چرخه عمر—از توسعه تا استقرار و از کار انداختن—تضمین می‌کند که این امر پاسخ سریع به حوادث را ممکن ساخته و مسئولیت‌پذیری برای تمام تغییرات را حفظ می‌کند.

هدف اصلی امنیت: تنها مدل‌های مجاز و تأیید شده از طریق فرآیندهای کنترل‌شده که یکپارچگی، قابلیت پیگیری و قابلیت بازیابی را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### C3.1 مجوز مدل و صحت آن

تنها مدل‌های مجاز با یکپارچگی تایید شده به محیط‌های تولید وارد می‌شوند.

 #3.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل (وزن‌ها، پیکربندی‌ها، توکن‌سازها) قبل از استقرار توسط نهادهای مجاز به‌صورت رمزنگاری شده امضا شده‌اند.
 #3.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که صحت مدل در زمان استقرار تأیید می‌شود و شکست‌های تأیید امضا از بارگذاری مدل جلوگیری می‌کنند.
 #3.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که سوابق اصالت مدل شامل هویت نهاد مجوزدهنده، چکسام داده‌های آموزشی، نتایج آزمون اعتبارسنجی با وضعیت موفق/ناموفق و یک نشان زمان ایجاد باشد.
 #3.1.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تمام مصنوعات مدل از نسخه‌بندی معنایی (MAJOR.MINOR.PATCH) استفاده می‌کنند و معیارهای مستندسازی شده‌ای وجود دارد که مشخص می‌کند هر جزء نسخه در چه زمانی افزایش می‌یابد.
 #3.1.5    Level: 2    Role: V
 تأیید کنید که ردیابی وابستگی‌ها یک موجودی زمان واقعی را حفظ می‌کند که امکان شناسایی سریع تمام سیستم‌های مصرف‌کننده را فراهم می‌آورد.

---

### C3.2 اعتبارسنجی و آزمون مدل

مدل‌ها باید قبل از استقرار از اعتبارسنجی‌های امنیتی و ایمنی تعریف‌شده عبور کنند.

 #3.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که مدل‌ها پیش از استقرار، تحت آزمایش‌های خودکار امنیتی قرار می‌گیرند که شامل اعتبارسنجی ورودی، پاک‌سازی خروجی و ارزیابی‌های ایمنی با آستانه‌های قبلاً توافق‌شده سازمانی برای قبول یا رد می‌باشد.
 #3.2.2    Level: 1    Role: D/V
 تأیید کنید که خطاهای اعتبارسنجی پس از تأیید صریح و مجوز از طرف افراد مجاز پیش‌تعیین شده با دلایل مستند تجاری به طور خودکار از استقرار مدل جلوگیری می‌کنند.
 #3.2.3    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج آزمایش به صورت رمزنگاری شده امضا شده و به طور غیرقابل تغییر به هش نسخه خاص مدل که در حال اعتبارسنجی است، متصل شده‌اند.
 #3.2.4    Level: 2    Role: D/V
 تأیید کنید که استقرارهای اضطراری نیازمند ارزیابی مستند ریسک امنیتی و تأیید از سوی یک مرجع امنیتی از پیش تعیین‌شده در بازه‌های زمانی از پیش توافق شده هستند.

---

### C3.3 استقرار کنترل‌شده و بازگردانی

استقرار مدل‌ها باید کنترل شده، تحت نظارت باشند و قابلیت بازگشت داشته باشند.

 #3.3.1    Level: 1    Role: D
 تأیید کنید که استقرارهای تولید از مکانیزم‌های انتشار تدریجی (مانند استقرارهای کاناری و آبی-سبز) با راه‌اندازی خودکار بازگشت به حالت قبلی بر اساس نرخ خطاهای از پیش توافق شده، آستانه‌های تأخیر یا معیارهای هشدار امنیتی پیروی می‌کنند.
 #3.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که قابلیت‌های بازگردانی (rollback) حالت کامل مدل (وزن‌ها، پیکربندی‌ها، وابستگی‌ها) را به صورت اتمی در بازه‌های زمانی از پیش تعیین‌شده سازمانی بازیابی می‌کنند.
 #3.3.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرایندهای استقرار امضاهای رمزنگاری شده را اعتبارسنجی کرده و قبل از فعال‌سازی مدل، چک‌سام‌های یکپارچگی را محاسبه می‌کنند، و در صورت هر گونه عدم تطابق، استقرار را متوقف می‌کنند.
 #3.3.4    Level: 2    Role: D/V
 تأیید کنید که قابلیت‌های خاموشی اضطراری مدل می‌توانند نقاط انتهایی مدل را در زمان‌های پاسخ از پیش تعیین شده از طریق قطع‌کننده‌های مدار خودکار یا کلیدهای خاموشی دستی غیرفعال کنند.
 #3.3.5    Level: 2    Role: V
 تأیید کنید که آثار بازگشت (نسخه‌های قبلی مدل، تنظیمات، وابستگی‌ها) مطابق با سیاست‌های سازمانی با ذخیره‌سازی غیرقابل تغییر برای پاسخ به حوادث نگهداری می‌شوند.

---

### C3.4 تغییر مسئولیت‌پذیری و حسابرسی

تمام تغییرات چرخه عمر مدل باید قابل ردیابی و حسابرسی باشند.

 #3.4.1    Level: 1    Role: V
 تأیید کنید که تمامی تغییرات مدل (استقرار، پیکربندی، بازنشستگی) سوابق حسابرسی غیرقابل تغییر تولید کنند که شامل یک نشان زمان، هویت بازیگر تأیید شده، نوع تغییر و وضعیت‌های قبل/بعد باشد.
 #3.4.2    Level: 2    Role: D/V
 تأیید کنید که دسترسی به گزارش‌های حسابرسی نیازمند مجوز مناسب است و تمام تلاش‌های دسترسی با هویت کاربر و زمان‌بندی ثبت می‌شوند.
 #3.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که قالب‌های پرامپت و پیام‌های سیستم در مخازن گیت با کنترل نسخه قرار دارند و قبل از استقرار، بازبینی کد و تأیید اجباری توسط بازبین‌های تعیین‌شده انجام شده است.
 #3.4.4    Level: 2    Role: V
 اطمینان حاصل کنید که سوابق حسابرسی شامل جزئیات کافی (هش‌های مدل، تصاویر پیکربندی، نسخه‌های وابستگی) باشد تا امکان بازسازی کامل وضعیت مدل برای هر بازه زمانی در دوره نگهداری فراهم شود.

---

### C3.5 شیوه‌های توسعه امن

فرآیندهای توسعه و آموزش مدل باید از روش‌های امن پیروی کنند تا از به خطر افتادن جلوگیری شود.

 #3.5.1    Level: 1    Role: D
 اطمینان حاصل کنید که محیط‌های توسعه مدل، آزمایش و تولید به صورت فیزیکی یا منطقی جدا شده‌اند. این محیط‌ها زیرساخت مشترک ندارند، کنترل‌های دسترسی مجزا دارند و داده‌ها به صورت ایزوله ذخیره می‌شوند.
 #3.5.2    Level: 1    Role: D
 اطمینان حاصل کنید که آموزش مدل و تنظیم دقیق آن در محیط‌های جدا شده با دسترسی شبکه کنترل‌شده انجام می‌شود.
 #3.5.3    Level: 1    Role: D/V
 اطمینان حاصل کنید که منابع داده‌های آموزشی از طریق بررسی‌های صحت اعتبارسنجی شده و از طریق منابع معتبر با سند زنجیره نگهداری معتبر شده‌اند قبل از استفاده در توسعه مدل.
 #3.5.4    Level: 2    Role: D
 اطمینان حاصل کنید که مصنوعات توسعه مدل (ابرپارامترها، اسکریپت‌های آموزش، فایل‌های پیکربندی) در کنترل نسخه ذخیره شده‌اند و پیش از استفاده در آموزش، نیاز به تأیید بازبینی همتا دارند.

---

### C3.6 بازنشستگی و از کار انداختن مدل

مدل‌ها باید به‌طور امن بازنشسته شوند هنگامی که دیگر به آن‌ها نیازی نیست یا مشکلات امنیتی شناسایی شده‌اند.

 #3.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که فرآیندهای بازنشستگی مدل به‌صورت خودکار گراف‌های وابستگی را اسکن می‌کنند، تمام سیستم‌های مصرف‌کننده را شناسایی می‌کنند و دوره‌های اطلاع‌رسانی پیش توافق‌شده را قبل از بازنشستگی ارائه می‌دهند.
 #3.6.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که آثار مدل‌های بازنشسته به‌صورت امن با استفاده از پاک‌سازی رمزنگاری شده یا بازنویسی چندباره طبق سیاست‌های مستند نگهداری داده‌ها با گواهی‌های تأیید شده پاک می‌شوند.
 #3.6.3    Level: 2    Role: V
 تأیید کنید که رویدادهای بازنشستگی مدل با زمان‌سنجی و هویت بازیگر ثبت شده‌اند و امضاهای مدل برای جلوگیری از استفاده مجدد لغو شده‌اند.
 #3.6.4    Level: 2    Role: D/V
 تأیید کنید که بازنشستگی اضطراری مدل می‌تواند دسترسی به مدل را در چارچوب‌های زمانی پاسخ اضطراری از پیش تعیین‌شده از طریق قطع‌کننده‌های خودکار در صورت کشف آسیب‌پذیری‌های امنیتی حیاتی، غیرممکن کند.

---

### مراجع

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## امنیت زیرساخت، پیکربندی و استقرار C4

### هدف کنترل

زیرساخت‌های هوش مصنوعی باید از طریق پیکربندی ایمن، جداسازی در زمان اجرا، خط‌مشي‌های استقرار مورد اعتماد و نظارت جامع در برابر افزایش دسترسی غیرمجاز، دستکاری زنجیره تأمین و حرکت جانبی مقاوم‌سازی شوند. تنها اجزای زیرساختی مجاز و اعتبارسنجی شده و پیکربندی‌های مربوطه از طریق فرآیندهای کنترل‌شده که امنیت، صحت و قابلیت حسابرسی را حفظ می‌کنند، به تولید می‌رسند.

هدف اصلی امنیتی: تنها اجزای زیرساختی که به‌صورت رمزنگاری‌شده امضا شده و از نظر آسیب‌پذیری بررسی شده‌اند، از طریق خطوط لوله اعتبارسنجی خودکار که سیاست‌های امنیتی را اجرا می‌کنند و سوابق حسابرسی تغییرناپذیر را حفظ می‌کنند، به محیط تولید می‌رسند.

---

### محیط اجرای C4.1 ایزوله‌سازی

جلوگیری از فرار کانتینر و افزایش سطح امتیازات از طریق اصول جداسازی در سطح کرنل و کنترل‌های دسترسی اجباری.

 #4.1.1    Level: 1    Role: D/V
 تأیید کنید که تمام کانتینرهای هوش مصنوعی تمامی قابلیت‌های لینوکس را به جز CAP_SETUID، CAP_SETGID و قابلیت‌های صریحاً مورد نیاز که در استانداردهای امنیتی مستند شده‌اند، حذف کرده‌اند.
 #4.1.2    Level: 1    Role: D/V
 تأیید کنید که پروفایل‌های seccomp تمام فراخوانی‌های سیستم (syscalls) را مسدود می‌کنند، به جز آن‌هایی که در فهرست‌های سفید از پیش تایید شده قرار دارند؛ در صورت نقض این قوانین، کانتینر را متوقف کرده و هشدارهای امنیتی تولید می‌کنند.
 #4.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی با سیستم‌فایل‌های ریشه فقط‌خواندنی، tmpfs برای داده‌های موقت، و حجم‌های نام‌گذاری شده برای داده‌های پایدار با گزینه‌های mount noexec اجرا شوند.
 #4.1.4    Level: 2    Role: D/V
 تأیید کنید که نظارت زمان اجرای مبتنی بر eBPF (مانند Falco، Tetragon یا معادل آن) تلاش‌های افزایش امتیاز را شناسایی کرده و به طور خودکار فرآیندهای خاطی را در بازه زمانی پاسخگویی سازمانی خاتمه می‌دهد.
 #4.1.5    Level: 3    Role: D/V
 تأیید کنید که بارهای کاری با ریسک بالا در محیط‌های ایزوله شده سخت‌افزاری (Intel TXT، AMD SVM، یا گره‌های اختصاصی بدون سیستم‌عامل) با تأیید صحت اعتبار اجرا شوند.

---

### C4.2 خطوط لوله ساخت و استقرار امن

از طریق ساخت‌های قابل بازتولید و آثار امضاشده، صحت رمزنگاری و امنیت زنجیره تأمین را تضمین کنید.

 #4.2.1    Level: 1    Role: D/V
 اطمینان حاصل شود که زیرساخت به صورت کد با ابزارهایی مانند tfsec، Checkov یا Terrascan در هر کامیت اسکن می‌شود و ادغام‌ها در صورت وجود یافته‌های با شدت بحرانی یا بالا مسدود می‌گردند.
 #4.2.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که ساخت کانتینرها قابل بازتولید هستند و در تمامی ساخت‌ها، هش‌های SHA256 یکسانی تولید می‌کنند و سپس گواهی‌های اصالت سطح SLSA 3 را با امضای Sigstore ایجاد کنید.
 #4.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تصاویر کانتینر شامل SBOM های CycloneDX یا SPDX باشند و قبل از ارسال به رجیستری با Cosign امضا شده باشند، به طوری که تصاویر بدون امضا در مرحله استقرار رد شوند.
 #4.2.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که خطوط لوله CI/CD از توکن‌های OIDC از HashiCorp Vault، نقش‌های IAM در AWS، یا Managed Identity در Azure استفاده می‌کنند که طول عمر آنها از محدودیت‌های سیاست امنیتی سازمان تجاوز نمی‌کند.
 #4.2.5    Level: 2    Role: D/V
 تأیید کنید که امضاهای Cosign و منشأ SLSA در فرآیند استقرار پیش از اجرای کانتینر تأیید می‌شوند و خطاهای تأیید باعث شکست استقرار می‌شوند.
 #4.2.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که محیط‌های ساخت در کانتینرها یا ماشین‌های مجازی گذرا اجرا می‌شوند که فاقد ذخیره‌سازی دائمی بوده و از شبکه‌های VPC تولید جدا شده‌اند.

---

### C4.3 امنیت شبکه و کنترل دسترسی

اجرای شبکه‌سازی با اعتماد صفر با سیاست‌های پیش‌فرض امتناع و ارتباطات رمزگذاری‌شده.

 #4.3.1    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های شبکه Kubernetes یا معادل آن‌ها، اجرای پیش‌فرض ممنوعیت ورود/خروج (default-deny ingress/egress) را با قوانین اجازه‌دادن صریح برای پورت‌های مورد نیاز (۴۴۳، ۸۰۸۰ و غیره) برقرار کرده باشند.
 #4.3.2    Level: 1    Role: D/V
 تأیید کنید که پورت‌های SSH (پورت ۲۲)، RDP (پورت ۳۳۸۹) و نقاط انتهایی متادیتای کلاود (169.254.169.254) مسدود شده‌اند یا نیاز به احراز هویت مبتنی بر گواهی‌نامه دارند.
 #4.3.3    Level: 2    Role: D/V
 تأیید کنید که ترافیک خروجی از طریق پروکسی‌های HTTP/HTTPS (Squid، Istio یا دروازه‌های NAT ابری) با فهرست‌های مجاز دامنه فیلتر شده و درخواست‌های مسدود شده ثبت می‌شوند.
 #4.3.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که ارتباط بین سرویس‌ها از TLS متقابل با گواهی‌نامه‌هایی که مطابق با سیاست سازمانی چرخش داده می‌شوند استفاده می‌کند و اعتبارسنجی گواهی‌نامه اجرا می‌شود (بدون استفاده از پرچم‌های skip-verify).
 #4.3.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که زیرساخت هوش مصنوعی در VPC/VNetهای اختصاصی اجرا می‌شود که دسترسی مستقیم به اینترنت ندارند و تنها از طریق دروازه‌های NAT یا میزبان‌های بستیون ارتباط برقرار می‌کند.

---

### C4.4 مدیریت اسرار و کلیدهای رمزنگاری

حفاظت از اعتبارنامه‌ها از طریق ذخیره‌سازی مبتنی بر سخت‌افزار و چرخش خودکار با دسترسی مبتنی بر اطمینان صفر.

 #4.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که رازها در HashiCorp Vault، AWS Secrets Manager، Azure Key Vault یا Google Secret Manager با رمزنگاری در حالت ذخیره‌سازی با استفاده از AES-256 ذخیره شده‌اند.
 #4.4.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که کلیدهای رمزنگاری در HSMهای سطح 2 مطابق با استاندارد FIPS 140-2 (مانند AWS CloudHSM، Azure Dedicated HSM) تولید می‌شوند و چرخش کلیدها مطابق با سیاست رمزنگاری سازمانی انجام می‌شود.
 #4.4.3    Level: 2    Role: D/V
 تأیید کنید که چرخش اسرار به‌صورت خودکار با استقرار بدون وقفه و چرخش فوری ناشی از تغییرات کارکنان یا حوادث امنیتی انجام می‌شود.
 #4.4.4    Level: 2    Role: D/V
 تأیید کنید که تصاویر کانتینر با استفاده از ابزارهایی مانند GitLeaks، TruffleHog یا detect-secrets اسکن شده‌اند و ساخت‌هایی که شامل کلیدهای API، گذرواژه‌ها یا گواهی‌ها هستند، مسدود می‌شوند.
 #4.4.5    Level: 2    Role: D/V
 تأیید کنید که دسترسی به رازهای محیط تولید نیازمند MFA با توکن‌های سخت‌افزاری (YubiKey، FIDO2) باشد و این دسترسی‌ها توسط گزارش‌های حسابرسی غیر قابل تغییر با هویت کاربران و زمان‌های ثبت شده ضبط شوند.
 #4.4.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که رازها از طریق اسرار Kubernetes، حجم‌های نصب شده یا کانتینرهای اولیه تزریق می‌شوند و مطمئن شوید که رازها هرگز در متغیرهای محیطی یا ایمیج‌ها جاسازی نشده‌اند.

---

### ایزوله‌سازی و اعتبارسنجی بار کاری هوش مصنوعی C4.5

مدل‌های هوش مصنوعی غیرمطمئن را در محیط‌های ایزوله و امن همراه با تحلیل رفتاری جامع جدا کنید.

 #4.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که مدل‌های AI خارجی در محیط‌های اجرای gVisor، میکروVMها (مانند Firecracker، CrossVM) یا کانتینرهای داکر با گزینه‌های --security-opt=no-new-privileges و --read-only اجرا می‌شوند.
 #4.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس هیچ اتصال شبکه‌ای ندارند (--network=none) یا فقط به localhost دسترسی دارند و تمامی درخواست‌های خارجی توسط قوانین iptables مسدود شده‌اند.
 #4.5.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که اعتبارسنجی مدل هوش مصنوعی شامل آزمایش خودکار تیم قرمز با پوشش آزمون تعریف شده سازمانی و تحلیل رفتاری برای شناسایی درب پشتی است.
 #4.5.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که پیش از ارتقاء مدل هوش مصنوعی به مرحله تولید، نتایج محیط آزمایشی آن توسط پرسنل امنیتی مجاز به‌صورت رمزنگاری‌شده امضا شده و در گزارش‌های حسابرسی غیرقابل تغییر ذخیره می‌گردد.
 #4.5.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که محیط‌های سندباکس بین ارزیابی‌ها از تصاویر طلایی نابود و مجدداً ایجاد شده‌اند و پاکسازی کامل سیستم فایل و حافظه انجام شده است.

---

### C4.6 نظارت بر امنیت زیرساخت

زیرساخت را به صورت مستمر اسکن و نظارت کنید، با اصلاح خودکار و هشدارهای بلادرنگ.

 #4.6.1    Level: 1    Role: D/V
 تأیید کنید که تصویرهای کانتینر بر اساس برنامه‌های سازمانی اسکن می‌شوند و آسیب‌پذیری‌های بحرانی (CRITICAL) مطابق با آستانه‌های ریسک سازمانی مانع از استقرار می‌شوند.
 #4.6.2    Level: 1    Role: D/V
 تأیید کنید که زیرساخت با معیارهای CIS یا کنترل‌های NIST 800-53 که دارای آستانه‌های تطبیق تعریف شده سازمانی هستند، مطابقت دارد و همچنین برای بررسی‌های ناموفق، اصلاح خودکار انجام می‌شود.
 #4.6.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که آسیب‌پذیری‌های با شدت بالا مطابق با جدول زمانی مدیریت ریسک سازمانی اصلاح شده‌اند و برای CVEهای به‌طور فعال مورد سوءاستفاده قرار گرفته، رویه‌های اضطراری وجود دارد.
 #4.6.4    Level: 2    Role: V
 اطمینان حاصل کنید که هشدارهای امنیتی با پلتفرم‌های SIEM (اسپلانک، الستیک یا سنتینل) با استفاده از فرمت‌های CEF یا STIX/TAXII همراه با غنی‌سازی خودکار یکپارچه می‌شوند.
 #4.6.5    Level: 3    Role: V
 اطمینان حاصل کنید که معیارهای زیرساخت به سیستم‌های نظارتی (Prometheus، DataDog) با داشبوردهای SLA و گزارش‌دهی اجرایی صادر می‌شوند.
 #4.6.6    Level: 2    Role: D/V
 تأیید کنید که انحراف پیکربندی با استفاده از ابزارها (Chef InSpec، AWS Config) طبق الزامات نظارتی سازمان شناسایی می‌شود و به‌طور خودکار برای تغییرات غیرمجاز بازگشت انجام می‌گیرد.

---

### مدیریت منابع زیرساخت هوش مصنوعی C4.7

جلوگیری از حملات خستگی منابع و اطمینان از تخصیص عادلانه منابع از طریق سهمیه‌ها و نظارت.

 #4.7.1    Level: 1    Role: D/V
 تأیید کنید که استفاده از GPU/TPU مانیتور می‌شود و هشدارها در سطوح تعریف شده سازمانی فعال می‌شوند و مقیاس‌پذیری خودکار یا تعادل بار بر اساس سیاست‌های مدیریت ظرفیت فعال می‌گردد.
 #4.7.2    Level: 1    Role: D/V
 تأیید کنید که معیارهای بار کاری هوش مصنوعی (زمان تأخیر استنتاج، توان عملیاتی، نرخ خطا) طبق الزامات نظارتی سازمان جمع‌آوری شده و با استفاده زیرساخت مطابقت داده شده‌اند.
 #4.7.3    Level: 2    Role: D/V
 تأیید کنید که ResourceQuotaهای Kubernetes یا معادل آن‌ها، بارهای کاری فردی را مطابق با سیاست‌های تخصیص منابع سازمانی محدود می‌کنند و محدودیت‌های سخت‌گیرانه اعمال می‌شود.
 #4.7.4    Level: 2    Role: V
 اطمینان حاصل کنید که پایش هزینه‌ها، هزینه‌ها را بر اساس هر بار کاری/مستأجر ردیابی می‌کند و هشدارهایی بر اساس آستانه بودجه سازمانی و کنترل‌های خودکار برای تجاوز از بودجه ارائه می‌دهد.
 #4.7.5    Level: 3    Role: V
 اطمینان حاصل کنید که برنامه‌ریزی ظرفیت از داده‌های تاریخی با دوره‌های پیش‌بینی تعریف شده سازمانی استفاده می‌کند و تأمین منابع خودکار بر اساس الگوهای تقاضا انجام می‌شود.
 #4.7.6    Level: 2    Role: D/V
 تأیید کنید که خستگی منابع باعث فعال شدن مدارهای قطع‌کننده (circuit breakers) طبق الزامات پاسخ سازمانی می‌شود، از جمله محدودیت نرخ بر اساس سیاست‌های ظرفیت و ایزوله‌سازی بار کاری.

---

### C4.8 کنترل‌های تفکیک محیط و ارتقاء

اجرای مرزهای محیطی سختگیرانه با دروازه‌های ترفیع خودکار و اعتبارسنجی امنیتی.

 #4.8.1    Level: 1    Role: D/V
 تأیید کنید که محیط‌های توسعه/تست/تولید در VPCها/VNetهای جداگانه اجرا می‌شوند و هیچ نقش IAM، گروه امنیتی یا اتصال شبکه مشترک ندارند.
 #4.8.2    Level: 1    Role: D/V
 تأیید کنید که ارتقاء محیط نیازمند تصویب از سوی افراد مجاز تعریف‌شده سازمانی با امضاهای رمزنگاری‌شده و ردپاهای حسابرسی غیرقابل تغییر است.
 #4.8.3    Level: 2    Role: D/V
 تأیید کنید که محیط‌های تولید دسترسی SSH را مسدود کرده‌اند، نقاط اشکال‌زدایی را غیرفعال کرده‌اند و درخواست تغییر با الزامات اطلاع قبلی سازمانی به جز در مواقع اضطراری را الزامی کرده‌اند.
 #4.8.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که تغییرات زیرساخت به‌عنوان‌کد قبل از ادغام به شاخه اصلی، نیازمند بازبینی توسط همتایان همراه با تست‌های خودکار و اسکن امنیتی باشد.
 #4.8.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که داده‌های غیرتولیدی بر اساس الزامات حفظ حریم خصوصی سازمانی ناشناس‌سازی شده‌اند، تولید داده‌های مصنوعی انجام شده است، یا پوشش کامل داده‌ها با حذف اطلاعات شخصی شناسایی‌شده (PII) تأیید شده است.
 #4.8.6    Level: 2    Role: D/V
 تأیید کنید که در دروازه‌های ارتقا، آزمایش‌های امنیتی خودکار (SAST، DAST، اسکن کانتینر) با شرط عدم وجود هیچ‌گونه یافته بحرانی برای تایید گنجانده شده است.

---

### پشتیبان‌گیری و بازیابی زیرساخت C4.9

اطمینان از مقاومت زیرساخت از طریق پشتیبان‌گیری خودکار، آزمایش روش‌های بازیابی و قابلیت‌های بازیابی در مواقع بحران.

 #4.9.1    Level: 1    Role: D/V
 اطمینان حاصل شود که تنظیمات زیرساخت مطابق با برنامه‌های پشتیبان‌گیری سازمانی با اجرای استراتژی پشتیبان‌گیری ۳-۲-۱ به مناطق جغرافیایی جداگانه نسخه پشتیبان تهیه شده‌اند.
 #4.9.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که سیستم‌های پشتیبان‌گیری در شبکه‌های ایزوله با مدارک جداگانه و ذخیره‌سازی ایزوله‌شده (air-gapped) برای محافظت در برابر باج‌افزار اجرا می‌شوند.
 #4.9.3    Level: 2    Role: V
 اطمینان حاصل کنید که رویه‌های بازیابی از طریق آزمایش خودکار مطابق با برنامه‌های زمانی سازمانی و با اهداف RTO و RPO که نیازهای سازمان را برآورده می‌کنند، آزمایش و اعتبارسنجی شده‌اند.
 #4.9.4    Level: 3    Role: V
 تأیید کنید که بازیابی هنگام حادثه شامل راهنمای‌های مخصوص هوش مصنوعی با بازسازی وزن مدل، بازسازی خوشه GPU و نقشه‌برداری وابستگی سرویس‌ها باشد.

---

### انطباق و حاکمیت زیرساخت C4.10

رعایت انطباق با مقررات از طریق ارزیابی مداوم، مستندسازی و کنترل‌های خودکار را حفظ کنید.

 #4.10.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که تطابق زیرساخت طبق برنامه‌های سازمانی و بر اساس کنترل‌های SOC 2، ISO 27001، یا FedRAMP با جمع‌آوری خودکار شواهد ارزیابی می‌شود.
 #4.10.2    Level: 2    Role: V
 اطمینان حاصل کنید که مستندات زیرساخت شامل نمودارهای شبکه، نقشه‌های جریان داده و مدل‌های تهدید به‌روزرسانی شده مطابق با الزامات مدیریت تغییر سازمانی باشد.
 #4.10.3    Level: 3    Role: D/V
 تأیید کنید که تغییرات زیرساختی تحت ارزیابی خودکار تأثیر تطبیق‌پذیری با جریان‌های کاری تأیید مقررات برای تغییرات پرخطر قرار می‌گیرند.

---

### C4.11 امنیت سخت‌افزار هوش مصنوعی

قطعات سخت‌افزاری مخصوص هوش مصنوعی از جمله GPUها، TPUها و شتاب‌دهنده‌های تخصصی هوش مصنوعی را امن کنید.

 #4.11.1    Level: 2    Role: D/V
 تأیید کنید که فریمور شتاب‌دهنده هوش مصنوعی (BIOS کارت گرافیک، فریمور TPU) با امضاهای رمزنگاری شده تأیید و مطابق با زمان‌بندی مدیریت وصله‌های سازمانی به‌روزرسانی می‌شود.
 #4.11.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که قبل از اجرای بار کاری، صحت شتابدهنده هوش مصنوعی از طریق تایید هویت سخت‌افزاری با استفاده از TPM 2.0، Intel TXT یا AMD SVM بررسی می‌شود.
 #4.11.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که حافظه GPU بین بارهای کاری با استفاده از SR-IOV، MIG (GPU چند نمونه‌ای) یا تفکیک سخت‌افزاری معادل با پاک‌سازی حافظه بین وظایف جدا شده باشد.
 #4.11.4    Level: 3    Role: V
 اطمینان حاصل کنید که زنجیره تامین سخت‌افزار هوش مصنوعی شامل تایید اصالت با گواهی‌های تولیدکننده و اعتبارسنجی بسته‌بندی ضد دستکاری باشد.
 #4.11.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که ماژول‌های امنیت سخت‌افزاری (HSM ها) وزن‌های مدل هوش مصنوعی و کلیدهای رمزنگاری را با گواهینامه FIPS 140-2 سطح 3 یا معیار مشترک EAL4+ محافظت می‌کنند.

---

### زیرساخت هوش مصنوعی لبه‌ای و توزیع‌شده C4.12

استقرارهای امن هوش مصنوعی توزیع‌شده شامل محاسبات لبه، یادگیری اشتراکی و معماری‌های چندمحلی.

 #4.12.1    Level: 2    Role: D/V
 تأیید کنید که دستگاه‌های هوش لبه‌ای با استفاده از TLS متقابل و گواهی‌نامه‌های دستگاه که مطابق با سیاست مدیریت گواهی سازمانی به صورت دوره‌ای تعویض می‌شوند، به زیرساخت مرکزی احراز هویت می‌کنند.
 #4.12.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که دستگاه‌های لبه‌ای بوت امن با امضاهای تأیید شده و حفاظت از بازگشت را پیاده‌سازی می‌کنند تا از حملات کاهش نسخه سیستم‌افزار جلوگیری شود.
 #4.12.3    Level: 3    Role: D/V
 تأیید کنید که هماهنگی هوش مصنوعی توزیع‌شده از الگوریتم‌های توافق تحمل خطای بیزانتی استفاده می‌کند که شامل اعتبارسنجی مشارکت‌کنندگان و تشخیص گره‌های مخرب باشد.
 #4.12.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارتباط لبه تا ابر شامل محدودیت پهنای باند، فشرده‌سازی داده‌ها و قابلیت‌های عملیات آفلاین با ذخیره‌سازی محلی امن است.

---

### C4.13 امنیت زیرساخت چندابری و ترکیبی

بارکاری‌های هوش مصنوعی را در میان چندین ارائه‌دهنده ابر و استقرارهای ترکیبی ابر-محلی به صورت امن محافظت کنید.

 #4.13.1    Level: 2    Role: D/V
 تأیید کنید که استقرارهای هوش مصنوعی چندابری از فدراسیون هویت مستقل از ابر (OIDC، SAML) با مدیریت سیاست متمرکز در سراسر ارائه‌دهندگان استفاده می‌کنند.
 #4.13.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که انتقال داده‌های میان ابرها از رمزگذاری انتها به انتها با کلیدهای مدیریت شده توسط مشتری و کنترل‌های محل اقامت داده‌ها طبق حوزه قضایی اعمال می‌شود.
 #4.13.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بارهای کاری هوش مصنوعی ابری هیبریدی سیاست‌های امنیتی یکنواختی را در محیط‌های محلی و ابری اجرا می‌کنند و نظارت و هشداردهی یکپارچه دارند.
 #4.13.4    Level: 3    Role: V
 اطمینان حاصل کنید که جلوگیری از وابستگی به فروشنده‌ی خدمات ابری شامل زیرساخت قابل حمل به صورت کد (infrastructure-as-code)، APIهای استاندارد شده و قابلیت‌های صادرات داده با ابزارهای تبدیل فرمت است.
 #4.13.5    Level: 3    Role: V
 تأیید کنید که بهینه‌سازی هزینه چندابری شامل کنترل‌های امنیتی است که از پراکندگی منابع جلوگیری کرده و همچنین از هزینه‌های انتقال داده غیرمجاز بین ابرها جلوگیری می‌کند.

---

### C4.14 امنیت اتوماسیون زیرساخت و GitOps

خطوط لوله اتوماسیون زیرساخت امن و گردش‌های کاری GitOps برای مدیریت زیرساخت هوش مصنوعی.

 #4.14.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که مخازن GitOps نیاز به کامیت‌های امضا شده با کلیدهای GPG دارند و قوانین محافظت شاخه که مانع از ارسال مستقیم به شاخه‌های اصلی می‌شوند را اعمال کرده‌اند.
 #4.14.2    Level: 2    Role: D/V
 تأیید کنید که اتوماسیون زیرساخت شامل شناسایی انحراف با قابلیت‌های اصلاح خودکار و بازگرداندن تغییرات است که طبق الزامات پاسخ سازمانی برای تغییرات غیرمجاز فعال می‌شود.
 #4.14.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که فراهم‌آوری خودکار زیرساخت شامل اعتبارسنجی سیاست امنیتی با مسدود کردن استقرار برای پیکربندی‌های غیرمنطبق باشد.
 #4.14.4    Level: 2    Role: D/V
 تأیید کنید که اسرار مربوط به اتوماسیون زیرساخت از طریق اپراتورهای اسرار خارجی (External Secrets Operator، Bank-Vaults) با چرخش خودکار مدیریت می‌شوند.
 #4.14.5    Level: 3    Role: V
 تأیید کنید که زیرساخت خودتعمیر شامل همبستگی رویدادهای امنیتی با پاسخ خودکار به حادثه و گردش کار اطلاع‌رسانی به ذینفعان باشد.

---

### C4.15 امنیت زیرساخت مقاوم در برابر کوانتوم

زیرساخت هوش مصنوعی را برای تهدیدات محاسبات کوانتومی از طریق رمزنگاری پساکوانتمی و پروتکل‌های ایمن-کوانتمی آماده کنید.

 #4.15.1    Level: 3    Role: D/V
 تأیید کنید که زیرساخت هوش مصنوعی از الگوریتم‌های رمزنگاری پساکوانتومی مورد تأیید NIST (CRYSTALS-Kyber، CRYSTALS-Dilithium، SPHINCS+) برای تبادل کلید و امضاهای دیجیتال استفاده می‌کند.
 #4.15.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های توزیع کلید کوانتومی (QKD) برای ارتباطات هوش مصنوعی با امنیت بالا با استفاده از پروتکل‌های مدیریت کلید کوانتومی امن پیاده‌سازی شده‌اند.
 #4.15.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که چارچوب‌های چابکی رمزنگاری اجازه مهاجرت سریع به الگوریتم‌های پساکوانتومی جدید را با گردش خودکار گواهی‌نامه و کلید فراهم می‌کنند.
 #4.15.4    Level: 3    Role: V
 تأیید کنید که مدل‌سازی تهدید کوانتومی، آسیب‌پذیری زیرساخت‌های هوش مصنوعی در برابر حملات کوانتومی را با زمان‌بندی مهاجرت مستند و ارزیابی‌های ریسک بررسی می‌کند.
 #4.15.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های رمزنگاری ترکیبی کلاسیک-کوانتومی در طول دوره انتقال کوانتومی با نظارت بر عملکرد، دفاع چندلایه فراهم می‌کنند.

---

### C4.16 محاسبات محرمانه و محصورهای امن

بار کاری هوش مصنوعی و وزن‌های مدل را با استفاده از محیط‌های اجرای قابل اعتماد مبتنی بر سخت‌افزار و فناوری‌های محاسبات محرمانه محافظت کنید.

 #4.16.1    Level: 3    Role: D/V
 تأیید کنید که مدل‌های حساس هوش مصنوعی در محیط‌های محافظت شده Intel SGX، AMD SEV-SNP، یا ARM TrustZone با حافظه رمزگذاری شده و تأیید اعتبار اجرا می‌شوند.
 #4.16.2    Level: 3    Role: D/V
 تأیید کنید که کانتینرهای محرمانه (Kata Containers، gVisor با محاسبات محرمانه) بارهای کاری هوش مصنوعی را با رمزگذاری حافظه اجباری سخت‌افزاری ایزوله می‌کنند.
 #4.16.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تأیید از راه دور، اعتبار یکپارچگی انکلیو را پیش از بارگذاری مدل‌های هوش مصنوعی با اثبات رمزنگاری شده اصالت محیط اجرایی بررسی می‌کند.
 #4.16.4    Level: 3    Role: D/V
 تأیید کنید که خدمات استنتاج AI محرمانه، از استخراج مدل از طریق محاسبات رمزنگاری شده با وزن‌های مدل مهر و موم شده و اجرای محافظت شده جلوگیری می‌کنند.
 #4.16.5    Level: 3    Role: D/V
 تأیید کنید که ارکستراسیون محیط اجرای مورد اعتماد، چرخه عمر ناحیه امن را با تصدیق از راه دور و کانال‌های ارتباطی رمزنگاری شده مدیریت می‌کند.
 #4.16.6    Level: 3    Role: D/V
 اطمینان حاصل کنید که محاسبات چندجانبه امن (SMPC) امکان آموزش همکاری هوش مصنوعی را بدون افشای داده‌های فردی یا پارامترهای مدل فراهم می‌کند.

---

### C4.17 زیرساخت دانش صفر

پیاده‌سازی سیستم‌های اثبات دانش صفر برای تأیید و احراز هویت هوش مصنوعی حفظ حریم خصوصی بدون فاش کردن اطلاعات حساس.

 #4.17.1    Level: 3    Role: D/V
 تأیید کنید که اثبات‌های بدون دانش (ZK-SNARKها، ZK-STARKها) صحت مدل هوش مصنوعی و منشاء آموزش آن را بدون افشای وزن‌های مدل یا داده‌های آموزشی اعتبارسنجی می‌کنند.
 #4.17.2    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های احراز هویت مبتنی بر ZK امکان تأیید هویت کاربران با حفظ حریم خصوصی برای خدمات هوش مصنوعی را بدون افشای اطلاعات مرتبط با هویت فراهم می‌کنند.
 #4.17.3    Level: 3    Role: D/V
 تأیید کنید که پروتکل‌های اشتراک‌گذاری مجموعه خصوصی (PSI) امکان تطبیق ایمن داده‌ها برای هوش مصنوعی فدرال را بدون افشای مجموعه‌های داده فردی فراهم می‌کنند.
 #4.17.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های یادگیری ماشین دانش-صفر (ZKML) امکان ارائه استنتاج‌های هوش مصنوعی قابل راستی‌آزمایی را با اثبات رمزنگاری شده از صحت محاسبات فراهم می‌کنند.
 #4.17.5    Level: 3    Role: D/V
 تأیید کنید که زی‌کی‌رول‌آپ‌ها امکان پردازش تراکنش‌های هوش مصنوعی را با قابلیت مقیاس‌پذیری و حفظ حریم خصوصی، همراه با صحت‌سنجی دسته‌ای و کاهش بار محاسباتی فراهم می‌کنند.

---

### C4.18 پیشگیری از حملات کانال جانبی

محافظت از زیرساخت‌های هوش مصنوعی در برابر حملات کانال جانبی مبتنی بر زمان، توان، الکترومغناطیس و کش که ممکن است اطلاعات حساس را نشت دهند.

 #4.18.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که زمان‌بندی استنتاج هوش مصنوعی با استفاده از الگوریتم‌های زمان ثابت و پرکردن اطلاعات (padding) نرمال شده است تا از حملات استخراج مدل بر اساس زمان‌بندی جلوگیری شود.
 #4.18.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که حفاظت در برابر تحلیل توان شامل تزریق نویز، فیلتر کردن خط توان و الگوهای اجرای تصادفی برای سخت‌افزار هوش مصنوعی باشد.
 #4.18.3    Level: 3    Role: D/V
 تأیید کنید که کاهش اثرات کانال جانبی مبتنی بر کش، از تقسیم‌بندی کش، تصادفی‌سازی و دستورهای پاک‌سازی برای جلوگیری از نشت اطلاعات استفاده می‌کند.
 #4.18.4    Level: 3    Role: D/V
 تایید کنید که حفاظت در برابر انتشار الکترومغناطیسی شامل جلوگیری با استفاده از پوشش‌های محافظ، فیلتر کردن سیگنال و پردازش تصادفی به منظور جلوگیری از حملات نوع TEMPEST است.
 #4.18.5    Level: 3    Role: D/V
 تأیید کنید که تدابیر دفاعی کانال جانبی ریزمعماری شامل کنترل‌های اجرای حدسی و پوشش‌دهی الگوهای دسترسی حافظه هستند.

---

### C4.19 امنیت سخت‌افزار نورومورفیک و تخصصی هوش مصنوعی

امن‌سازی معماری‌های سخت‌افزاری نوظهور هوش مصنوعی شامل تراشه‌های نورومورفیک، FPGAها، ASICهای سفارشی و سیستم‌های محاسبات نوری.

 #4.19.1    Level: 3    Role: D/V
 اطمینان حاصل کنید که امنیت تراشه نورومورفیک شامل رمزگذاری الگوی پالس، حفاظت از وزن سیناپسی و اعتبارسنجی قوانین یادگیری مبتنی بر سخت‌افزار است.
 #4.19.2    Level: 3    Role: D/V
 تأیید کنید که تسریع‌کننده‌های هوش مصنوعی مبتنی بر FPGA، رمزنگاری بیت‌استریم، مکانیزم‌های ضد دستکاری و بارگذاری پیکربندی امن با به‌روزرسانی‌های احراز هویت شده را پیاده‌سازی می‌کنند.
 #4.19.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که امنیت ASIC سفارشی شامل پردازنده‌های امنیتی روی تراشه، ریشه اعتماد سخت‌افزاری و ذخیره‌سازی کلید ایمن با قابلیت تشخیص دستکاری است.
 #4.19.4    Level: 3    Role: D/V
 تأیید کنید که سیستم‌های محاسبات نوری رمزنگاری نوری کوانتومی امن، سوئیچینگ فوتونیکی ایمن و پردازش سیگنال نوری محافظت‌شده را پیاده‌سازی می‌کنند.
 #4.19.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تراشه‌های هوش مصنوعی هیبریدی آنالوگ-دیجیتال شامل محاسبات امن آنالوگ، ذخیره‌سازی وزن محافظت‌شده، و تبدیل آنالوگ به دیجیتال احراز هویت شده هستند.

---

### C4.20 زیرساخت محاسباتی حفظ حریم خصوصی

اجرای کنترل‌های زیرساختی برای محاسبات حفظ حریم خصوصی به منظور محافظت از داده‌های حساس در طول پردازش و تحلیل هوش مصنوعی.

 #4.20.1    Level: 3    Role: D/V
 تأیید کنید که زیرساخت رمزنگاری همومورفیک امکان انجام محاسبات رمزگذاری شده روی بارهای کاری حساس هوش مصنوعی را با صحت‌سنجی رمزنگاری و نظارت بر عملکرد فراهم می‌کند.
 #4.20.2    Level: 3    Role: D/V
 اطمینان حاصل کنید که سیستم‌های بازیابی اطلاعات خصوصی امکان انجام پرس‌وجوی پایگاه داده را بدون افشای الگوهای پرس‌وجو با محافظت رمزنگاری شده از الگوهای دسترسی فراهم می‌کنند.
 #4.20.3    Level: 3    Role: D/V
 تأیید کنید که پروتکل‌های محاسبات چندجانبه امن امکان استنتاج هوش مصنوعی حفظ حریم خصوصی را بدون افشای ورودی‌های فردی یا محاسبات میانی فراهم می‌کنند.
 #4.20.4    Level: 3    Role: D/V
 تأیید کنید که مدیریت کلید حفظ حریم خصوصی شامل تولید کلید توزیع‌شده، رمزنگاری آستانه‌ای و چرخش امن کلید با حفاظت مبتنی بر سخت‌افزار است.
 #4.20.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که عملکرد محاسبات حفظ حریم خصوصی از طریق دسته‌بندی، کشینگ و تسریع سخت‌افزاری بهینه شده است در حالی که تضمین‌های امنیت رمزنگاری حفظ می‌شود.

---

### چارچوب عامل C4.15 امنیت یکپارچه‌سازی ابری و استقرار ترکیبی

کنترل‌های امنیتی برای چارچوب‌های عامل یکپارچه با ابر با معماری‌های ترکیبی محلی/ابری.

 #4.15.1    Level: 1    Role: D/V
 تأیید کنید که ادغام ذخیره‌سازی ابری از رمزگذاری انتها به انتها با مدیریت کلید تحت کنترل عامل استفاده می‌کند.
 #4.15.2    Level: 2    Role: D/V
 تأیید کنید که مرزهای امنیتی استقرار ترکیبی به وضوح تعریف شده و کانال‌های ارتباطی رمزگذاری شده باشند.
 #4.15.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که دسترسی به منابع ابری شامل احراز هویت صفراعتمادی با تأیید مداوم است.
 #4.15.4    Level: 3    Role: D/V
 تأیید کنید که الزامات اقامت داده‌ها با اعتبارسنجی رمزنگاری‌شده مکان‌های ذخیره‌سازی اعمال می‌شوند.
 #4.15.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ارائه‌دهنده خدمات ابری شامل مدل‌سازی تهدیدات خاص عامل و ارزیابی ریسک باشد.

---

### مراجع

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## کنترل دسترسی C5 و هویت برای اجزاء و کاربران هوش مصنوعی

### هدف کنترل

کنترل دسترسی موثر برای سیستم‌های هوش مصنوعی نیازمند مدیریت هویت قوی، مجوزدهی آگاه به زمینه و اجرای زمان اجرا بر اساس اصول اعتماد صفر است. این کنترل‌ها تضمین می‌کنند که انسان‌ها، خدمات و عوامل خودکار تنها در محدوده‌های صریحاً مجاز، با مدل‌ها، داده‌ها و منابع محاسباتی تعامل داشته باشند، با قابلیت‌های تأیید و حسابرسی مستمر.

---

### C5.1 مدیریت هویت و احراز هویت

شناسایی‌های مبتنی بر رمزنگاری را برای تمام موجودیت‌ها با استفاده از احراز هویت چندعاملی برای عملیات دارای امتیاز ویژه برقرار کنید.

 #5.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تمامی کاربران انسانی و سرویس پرینسیپل‌ها از طریق یک ارائه‌دهنده هویت سازمانی مرکزی (IdP) با استفاده از پروتکل‌های OIDC/SAML احراز هویت می‌کنند، با نگاشت‌های منحصربه‌فرد هویت به توکن (بدون حساب‌ها یا اعتبارنامه‌های مشترک).
 #5.1.2    Level: 1    Role: D/V
 تأیید کنید که عملیات‌های پرخطر (مانند استقرار مدل، صادرات وزن، دسترسی به داده‌های آموزش، تغییرات پیکربندی در محیط تولید) نیازمند احراز هویت چندعاملی یا احراز هویت مرحله‌ای با تأیید مجدد نشست باشند.
 #5.1.3    Level: 2    Role: D
 تأیید کنید که مدیران جدید پیش از دریافت دسترسی به سیستم‌های تولید، هویت خود را با استاندارد NIST 800-63-3 IAL-2 یا استانداردهای معادل آن احراز هویت کنند.
 #5.1.4    Level: 2    Role: V
 اطمینان حاصل کنید که بررسی‌های دسترسی به صورت فصلی انجام می‌شوند و شناسایی خودکار حساب‌های غیرفعال، اعمال گردش اعتبارنامه و فرایندهای لغو دسترسی نیز انجام می‌گیرد.
 #5.1.5    Level: 3    Role: D/V
 تأیید کنید که عوامل هوش مصنوعی فدرال از طریق اظهارات JWT امضا شده احراز هویت می‌کنند که حداکثر طول عمر آن‌ها ۲۴ ساعت است و شامل اثبات رمزنگاری شده مبدا می‌باشد.

---

### C5.2 مجوز دسترسی منابع و حداقل امتیاز

پیاده‌سازی کنترل‌های دسترسی دقیق برای تمام منابع هوش مصنوعی با استفاده از مدل‌های اجازه‌نامه صریح و ردگیری‌های حسابرسی.

 #5.2.1    Level: 1    Role: D/V
 تأیید کنید که هر منبع هوش مصنوعی (مجموعه داده‌ها، مدل‌ها، نقاط پایانی، مجموعه‌های برداری، شاخص‌های تعبیه، نمونه‌های محاسباتی) کنترل دسترسی مبتنی بر نقش را با فهرست‌های مجاز صریح و سیاست‌های پیش‌فرض ممنوع اجرا می‌کند.
 #5.2.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که اصول حداقل امتیاز به طور پیش‌فرض برای حساب‌های سرویس اعمال شده‌اند، به طوری که دسترسی‌ها از مجوزهای فقط‌خواندنی آغاز شده و برای دسترسی نوشتن توجیه تجاری مستند شده مورد نیاز باشد.
 #5.2.3    Level: 1    Role: V
 اطمینان حاصل کنید که تمام تغییرات کنترل دسترسی به درخواست‌های تغییر تأیید شده مرتبط هستند و به صورت غیرقابل تغییر با زمان‌سنجی، هویت بازیگران، شناسه‌های منابع و اختلافات مجوزی ثبت شده‌اند.
 #5.2.4    Level: 2    Role: D
 اطمینان حاصل کنید که برچسب‌های طبقه‌بندی داده‌ها (اطلاعات شخصی قابل شناسایی، اطلاعات سلامت محافظت‌شده، کنترل شده برای صادرات، مالکیتی) به‌طور خودکار به منابع مشتق‌شده (برداشت‌ها، حافظه‌های نهان پرس‌وجو، خروجی مدل) منتقل شده و اجرای سیاست به‌صورت یکسان اعمال می‌شود.
 #5.2.5    Level: 2    Role: D/V
 تأیید کنید که تلاش‌های دسترسی غیرمجاز و رویدادهای افزایش امتیاز دسترسی، هشدارهای زمان واقعی با متاداده‌های متنی به سیستم‌های SIEM ظرف ۵ دقیقه ارسال می‌کنند.

---

### C5.3 ارزیابی پویا سیاست

پیاده‌سازی موتورهای کنترل دسترسی مبتنی بر ویژگی (ABAC) برای تصمیم‌گیری‌های مجوزدهی مبتنی بر زمینه همراه با قابلیت‌های حسابرسی.

 #5.3.1    Level: 1    Role: D/V
 تأیید کنید که تصمیم‌های مجوزدهی به یک موتور سیاست اختصاصی (مثل OPA، Cedar یا معادل آن) که از طریق APIهای احراز هویت شده و با حفاظت از صحت رمزنگاری شده قابل دسترسی است، واگذار شده‌اند.
 #5.3.2    Level: 1    Role: D/V
 تأیید کنید که سیاست‌ها صفات پویا را در زمان اجرا ارزیابی می‌کنند، از جمله سطح صلاحیت کاربر، طبقه‌بندی حساسیت منبع، زمینه درخواست، جداسازی مستأجر و محدودیت‌های زمانی.
 #5.3.3    Level: 2    Role: D
 اطمینان حاصل کنید که تعریف‌های سیاست‌ها کنترل نسخه شده، بررسی همتا انجام شده و از طریق تست‌های خودکار در خطوط لوله CI/CD قبل از استقرار در محیط تولید اعتبارسنجی شده‌اند.
 #5.3.4    Level: 2    Role: V
 اطمینان حاصل کنید که نتایج ارزیابی سیاست شامل توجیهات ساختاریافته تصمیم‌گیری بوده و برای تحلیل همبستگی و گزارش‌دهی انطباق به سیستم‌های SIEM ارسال می‌شوند.
 #5.3.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که مقادیر زمان زندگی (TTL) کش سیاست برای منابع با حساسیت بالا از ۵ دقیقه و برای منابع استاندارد با قابلیت ابطال کش از ۱ ساعت تجاوز نکند.

---

### اجرای امنیت در زمان پرس‌وجو C5.4

پیاده‌سازی کنترل‌های امنیتی در لایه بانک اطلاعاتی با فیلترینگ اجباری و سیاست‌های امنیتی در سطح سطر.

 #5.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه‌ی پرس‌وجوهای پایگاه داده‌های برداری و SQL شامل فیلترهای امنیتی اجباری (شناسه مستاجر، برچسب‌های حساسیت، دامنه کاربری) هستند که در سطح موتور پایگاه داده اعمال می‌شوند، نه در کد برنامه.
 #5.4.2    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های امنیت در سطح سطر (RLS) و ماسک‌گذاری در سطح فیلد با ارث‌بری سیاست برای همه پایگاه‌های داده برداری، شاخص‌های جستجو، و مجموعه داده‌های آموزشی فعال شده‌اند.
 #5.4.3    Level: 2    Role: D
 تأیید کنید که ارزیابی‌های ناموفق مجوز، با بلافاصله متوقف کردن پرس‌وجوها و بازگرداندن کدهای خطای مجوز صریح به‌جای بازگرداندن مجموعه نتایج خالی، از حملات «نماینده گیج شده» جلوگیری می‌کنند.
 #5.4.4    Level: 2    Role: V
 تأیید کنید که تأخیر در ارزیابی سیاست به طور مداوم با هشدارهای خودکار برای شرایط تایم‌اوت که ممکن است منجر به دورزدن مجوز شود، نظارت می‌شود.
 #5.4.5    Level: 3    Role: D/V
 تأیید کنید که مکانیزم‌های تلاش مجدد کوئری سیاست‌های مجوز را مجدداً ارزیابی می‌کنند تا تغییرات دینامیکی مجوزها را در طول جلسات فعال کاربران در نظر بگیرند.

---

### فیلتر خروجی C5.5 و جلوگیری از از دست رفتن داده‌ها

پیاده‌سازی کنترل‌های پس‌پردازش برای جلوگیری از افشای غیرمجاز داده‌ها در محتوای تولید شده توسط هوش مصنوعی.

 #5.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های فیلتر کردن پس از استنتاج، اطلاعات شناسایی شخصی (PII) غیرمجاز، اطلاعات طبقه‌بندی شده و داده‌های مالکیتی را پیش از ارائه محتوا به درخواست‌کنندگان، اسکن و حذف می‌کنند.
 #5.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که استنادها، مراجع و نسبت‌های منبع در خروجی‌های مدل بر اساس مجوزهای فراخواننده بررسی شده و در صورت شناسایی دسترسی غیرمجاز حذف شوند.
 #5.5.3    Level: 2    Role: D
 اطمینان حاصل کنید که محدودیت‌های قالب خروجی (PDFهای پاک‌سازی‌شده، تصاویر بدون متادیتا، انواع فایل‌های تأیید شده) بر اساس سطوح دسترسی کاربران و طبقه‌بندی داده‌ها اعمال می‌شوند.
 #5.5.4    Level: 2    Role: V
 اطمینان حاصل کنید که الگوریتم‌های سانسور قطعی، کنترل نسخه شده و دارای ثبت گزارش‌های حسابرسی برای پشتیبانی از تحقیقات تطبیقی و تحلیل‌های جرم‌شناسی هستند.
 #5.5.5    Level: 3    Role: V
 تأیید کنید که رویدادهای حذف اطلاعات با ریسک بالا، گزارش‌های تطبیقی تولید می‌کنند که شامل هش‌های رمزنگاری‌شده از محتوای اصلی برای بازیابی قضایی بدون افشای داده‌ها هستند.

---

### C5.6 جداسازی چند مستاجری

اطمینان از جداسازی رمزنگاری و منطقی بین مستأجران در زیرساخت مشترک هوش مصنوعی.

 #5.6.1    Level: 1    Role: D/V
 تأیید کنید که فضای حافظه، مخازن جاسازی، ورودی‌های کش و فایل‌های موقت به‌صورت جداگانه براساس فضای نام (namespace) برای هر مستأجر (tenant) نگهداری می‌شوند و پاک‌سازی امن در هنگام حذف مستأجر یا پایان جلسه انجام می‌شود.
 #5.6.2    Level: 1    Role: D/V
 تأیید کنید که هر درخواست API شامل یک شناسه مستأجر احراز هویت شده باشد که به صورت رمزنگاری شده در برابر زمینه جلسه و مجوزهای کاربر اعتبارسنجی شده است.
 #5.6.3    Level: 2    Role: D
 اطمینان حاصل کنید که سیاست‌های شبکه قوانین پیش‌فرض-رد برای ارتباطات بین مستأجران در شبکه‌های خدمات و پلتفرم‌های ارکستراسیون کانتینر را پیاده‌سازی می‌کنند.
 #5.6.4    Level: 3    Role: D
 تأیید کنید که کلیدهای رمزنگاری برای هر مستأجر منحصر به فرد هستند با پشتیبانی از کلید مدیریت شده توسط مشتری (CMK) و جداسازی رمزنگاری شده بین مخازن داده‌های مستأجر.

---

### C5.7 مجوز عامل خودمختار

کنترل دسترسی‌ها برای عامل‌های هوش مصنوعی و سیستم‌های خودران از طریق نشانه‌های قابلیت با حوزه محدود و مجوزدهی مداوم.

 #5.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که عامل‌های خودران توکن‌های قابلیت محدود شده‌ای دریافت می‌کنند که به‌صراحت اقدامات مجاز، منابع قابل دسترسی، محدوده‌های زمانی و محدودیت‌های عملیاتی را فهرست می‌کند.
 #5.7.2    Level: 1    Role: D/V
 تأیید کنید که امکانات با ریسک بالا (دسترسی به سیستم فایل، اجرای کد، فراخوانی APIهای خارجی، تراکنش‌های مالی) به‌صورت پیش‌فرض غیرفعال هستند و برای فعال‌سازی آن‌ها نیاز به مجوزهای صریح همراه با توجیهات کسب‌وکاری می‌باشد.
 #5.7.3    Level: 2    Role: D
 اطمینان حاصل کنید که توکن‌های قابلیت به جلسات کاربری متصل شده‌اند، حفاظت از صحت رمزنگاری را شامل می‌شوند و تضمین کنید که در سناریوهای آفلاین نمی‌توان آنها را ذخیره یا مجدداً استفاده کرد.
 #5.7.4    Level: 2    Role: V
 اطمینان حاصل کنید که اقدامات آغازشده توسط نماینده از طریق موتور سیاست ABAC با ارزیابی کامل زمینه و ضبط گزارش‌های حسابرسی، مجوز ثانویه دریافت می‌کنند.
 #5.7.5    Level: 3    Role: V
 تأیید کنید که شرایط خطای عامل و مدیریت استثناها شامل اطلاعات محدوده قابلیت برای پشتیبانی از تحلیل حادثه و بررسی‌های جنایی می‌باشد.

---

### مراجع

#### استانداردها و چارچوب‌ها

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### راهنمای پیاده‌سازی

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### امنیت مخصوص هوش مصنوعی

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## امنیت زنجیره تأمین C6 برای مدل‌ها، چارچوب‌ها و داده‌ها

### هدف کنترل

حملات زنجیره تامین هوش مصنوعی از مدل‌ها، چارچوب‌ها یا مجموعه‌داده‌های شخص ثالث سوءاستفاده می‌کنند تا درهای پشتی، تعصب یا کدهای آسیب‌پذیر را جاسازی کنند. این کنترل‌ها حفاظت کامل از منشا داده‌ها، مدیریت آسیب‌پذیری‌ها و نظارت را برای محافظت از کل چرخه عمر مدل فراهم می‌کنند.

---

### C6.1 بررسی مدل آموزش‌دیده پیشین و منشأ آن

پیش از هرگونه تنظیم دقیق یا استقرار، مبدا مدل‌های شخص ثالث، مجوزها و رفتارهای پنهان آن‌ها را ارزیابی و تأیید کنید.

 #6.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر اثر مدلی از طرف سوم شامل یک رکورد منشأ امضا شده است که مخزن منبع و هش تعهد را شناسایی می‌کند.
 #6.1.2    Level: 1    Role: D/V
 اطمینان حاصل شود که مدل‌ها قبل از واردات با استفاده از ابزارهای خودکار برای لایه‌های مخرب یا محرک‌های تروجان اسکن شده‌اند.
 #6.1.3    Level: 2    Role: D
 اطمینان حاصل کنید که آموزش دقیق مبتنی بر انتقال یادگیری، آزمایشات ضد جعل را برای شناسایی رفتارهای پنهان با موفقیت پشت سر می‌گذارد.
 #6.1.4    Level: 2    Role: V
 تأیید کنید که مجوزهای مدل، برچسب‌های کنترل صادرات و اظهارات منبع داده در یک ورودی ML-BOM ثبت شده‌اند.
 #6.1.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که مدل‌های پرخطر (وزن‌های بارگذاری شده به صورت عمومی، سازندگان تأیید نشده) تا زمان بررسی و تأیید نهایی توسط انسان در قرنطینه باقی می‌مانند.

---

### C6.2 اسکن چارچوب و کتابخانه

به طور مداوم فریمورک‌ها و کتابخانه‌های یادگیری ماشین را برای آسیب‌پذیری‌های امنیتی (CVE) و کدهای مخرب اسکن کنید تا پشته اجرای برنامه ایمن باقی بماند.

 #6.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که خطوط لوله CI اسکنرهای وابستگی را بر روی چارچوب‌های هوش مصنوعی و کتابخانه‌های حیاتی اجرا می‌کنند.
 #6.2.2    Level: 1    Role: D/V
 تأیید کنید که آسیب‌پذیری‌های بحرانی (CVSS ≥ 7.0) مانع ارتقاء به تصاویر تولید می‌شوند.
 #6.2.3    Level: 2    Role: D
 اطمینان حاصل کنید که تحلیل استاتیک کد روی کتابخانه‌های یادگیری ماشین تفکیک‌شده (forked) یا وارد شده (vendored) اجرا می‌شود.
 #6.2.4    Level: 2    Role: V
 اطمینان حاصل کنید که پیشنهادهای ارتقاء چارچوب شامل ارزیابی تأثیر امنیتی هستند که به خوراک‌های عمومی CVE ارجاع می‌دهد.
 #6.2.5    Level: 3    Role: V
 تأیید کنید که حسگرهای زمان اجرا در صورت بارگذاری‌های غیرمنتظره کتابخانه‌های پویا که از SBOM امضا شده انحراف دارند، هشدار دهند.

---

### C6.3 پین کردن و تأیید وابستگی‌ها

هر وابستگی را به شناسه‌های قطعی غیرقابل تغییر پین کنید و بازسازی‌های بیلد را انجام دهید تا تضمین شود که آثار تولید شده یکسان و دست‌نخورده هستند.

 #6.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه مدیران بسته نسخه‌ها را از طریق فایل‌های قفل شده اسیر می‌کنند.
 #6.3.2    Level: 1    Role: D/V
 بررسی کنید که در ارجاعات کانتینر، به جای برچسب‌های قابل تغییر، از خلاصه‌های غیرقابل تغییر استفاده شده باشد.
 #6.3.3    Level: 2    Role: D
 اطمینان حاصل کنید که بررسی‌های ساخت قابل تولید، هش‌ها را در بین اجراهای CI مقایسه می‌کنند تا خروجی‌های یکسان تضمین شود.
 #6.3.4    Level: 2    Role: V
 اطمینان حاصل کنید که تصدیق‌های ساخت به مدت ۱۸ ماه برای ردیابی حسابرسی ذخیره می‌شوند.
 #6.3.5    Level: 3    Role: D
 تأیید کنید که وابستگی‌های منقضی شده، درخواست‌های بازبینی خودکار (PR) برای به‌روزرسانی یا انشعاب نسخه‌های تثبیت شده را فعال می‌کنند.

---

### C6.4 اجرای منبع قابل اعتماد

اجازه دانلود آثار فقط از منابع رمزنگاری‌شده و مورد تایید سازمان را بدهید و همه منابع دیگر را مسدود کنید.

 #6.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که وزن‌های مدل، داده‌ها و کانتینرها فقط از دامنه‌های تأیید شده یا مخازن داخلی دانلود شوند.
 #6.4.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که امضاهای Sigstore/Cosign هویت ناشر را قبل از ذخیره محلی مصنوعات تأیید می‌کنند.
 #6.4.3    Level: 2    Role: D
 تأیید کنید که پراکسی‌های خروجی دانلودهای بدون احراز هویت آثار را مسدود می‌کنند تا سیاست منبع قابل اعتماد اعمال شود.
 #6.4.4    Level: 2    Role: V
 اطمینان حاصل کنید که فهرست‌های مجاز مخزن به صورت فصلی بازبینی می‌شوند و هر مورد دارای دلیل تجاری مستند باشد.
 #6.4.5    Level: 3    Role: V
 اطمینان حاصل کنید که نقض‌های سیاست باعث قرنطینه شدن مصنوعات و بازگردانی اجرای خط لوله‌های وابسته می‌شود.

---

### C6.5 ارزیابی ریسک داده‌های شخص ثالث

داده‌های خارجی را از نظر تزریق داده‌های مخرب، سوگیری و تطابق قانونی ارزیابی کرده و در طول چرخه عمر آن‌ها را پایش کنید.

 #6.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های خارجی تحت ارزیابی ریسک مسمومیت قرار می‌گیرند (به‌عنوان مثال، اثرانگشت داده‌ها، تشخیص نقطه دورافتاده).
 #6.5.2    Level: 1    Role: D
 اطمینان حاصل کنید که معیارهای تبعیض (برابری جمعیتی، فرصت برابر) قبل از تأیید مجموعه داده‌ها محاسبه شده‌اند.
 #6.5.3    Level: 2    Role: V
 اطمینان حاصل کنید که مبدأ و شرایط مجوز برای مجموعه داده‌ها در ورودی‌های ML‑BOM ثبت شده‌اند.
 #6.5.4    Level: 2    Role: V
 اطمینان حاصل شود که پایش دوره‌ای، انحراف یا فساد در مجموعه داده‌های میزبانی شده را شناسایی می‌کند.
 #6.5.5    Level: 3    Role: D
 اطمینان حاصل کنید که محتوای غیرمجاز (حق نشر، اطلاعات شناسایی شخصی) قبل از آموزش از طریق پاک‌سازی خودکار حذف شده است.

---

### C6.6 نظارت بر حملات زنجیره تامین

تهدیدهای زنجیره تامین را از طریق خوراک‌های CVE، تحلیل‌های گزارش‌های حسابرسی و شبیه‌سازی‌های تیم قرمز به موقع تشخیص دهید.

 #6.6.1    Level: 1    Role: V
 تأیید کنید که لاگ‌های حسابرسی CI/CD به طور مستقیم به تشخیص‌های SIEM برای کشیدن بسته‌های غیرعادی یا مراحل ساخت دستکاری شده ارسال می‌شوند.
 #6.6.2    Level: 2    Role: D
 اطمینان حاصل کنید که دستورالعمل‌های پاسخ به حادثه شامل روش‌های بازگرداندن برای مدل‌ها یا کتابخانه‌های آسیب‌دیده باشد.
 #6.6.3    Level: 3    Role: V
 تأیید کنید که برچسب‌های غنی‌سازی اطلاعات تهدید شاخص‌های خاص یادگیری ماشین (مانند شاخص‌های مرتبط با مسموم‌سازی مدل) را در بررسی هشدار علامت‌گذاری می‌کنند.

---

### C6.7 ML‑BOM برای آثار مدل

نسخه‌های مفصل و مخصوص ماشین لرنینگ از SBOM (ML-BOM) تولید و امضا کنید تا مصرف‌کنندگان سپس قادر باشند در زمان استقرار صحت اجزاء را تأیید کنند.

 #6.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر آرتیفکت مدل یک ML-BOM منتشر می‌کند که مجموعه داده‌ها، وزن‌ها، فرابرنامه‌ها و مجوزها را فهرست می‌کند.
 #6.7.2    Level: 1    Role: D/V
 بررسی کنید که تولید ML-BOM و امضای Cosign به صورت خودکار در CI انجام می‌شود و برای ادغام الزامی است.
 #6.7.3    Level: 2    Role: D
 اطمینان حاصل کنید که بررسی‌های کامل بودن ML-BOM در صورت فقدان هرگونه فراداده کامپوننت (هش، مجوز) ساخت را متوقف می‌کنند.
 #6.7.4    Level: 2    Role: V
 اطمینان حاصل کنید که مصرف‌کنندگان پایین‌دست می‌توانند از طریق API، لیست مواد ماشین یادگیری (ML-BOMs) را برای اعتبارسنجی مدل‌های وارد شده در زمان استقرار، پرس‌وجو کنند.
 #6.7.5    Level: 3    Role: V
 اطمینان حاصل کنید که ML-BOMها نسخه‌بندی شده و با استفاده از مقایسه تغییرات (diff) کنترل می‌شوند تا تغییرات غیرمجاز شناسایی شوند.

---

### مراجع

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## رفتار مدل C7، کنترل خروجی و تضمین ایمنی

### هدف کنترل

خروجی‌های مدل باید ساختاریافته، قابل اعتماد، ایمن، قابل توضیح و به‌طور مداوم در محیط تولید نظارت‌شده باشند. انجام این موارد باعث کاهش توهمات (hallucinations)، نشت اطلاعات خصوصی، محتوای مضر و اقدامات خارج از کنترل، و در عین حال افزایش اعتماد کاربران و رعایت مقررات می‌شود.

---

### C7.1 اجرای قالب خروجی

اسکیماهای سخت‌گیرانه، رمزگشایی محدود شده و اعتبارسنجی‌های پس‌از-فرآیند مسیر محتوای نادرست یا مخرب را قبل از انتشار متوقف می‌کنند.

 #7.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که طرح‌بندی‌های پاسخ (مانند JSON Schema) در پرامپت سیستم ارائه شده‌اند و هر خروجی به‌طور خودکار اعتبارسنجی می‌شود؛ خروجی‌های ناسازگار موجب اصلاح یا رد خودکار شوند.
 #7.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که رمزگشایی محدود شده (توکن‌های توقف، عبارات منظم، حداکثر توکن‌ها) فعال است تا از سرریز یا کانال‌های جانبی تزریق پرامپت جلوگیری شود.
 #7.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که اجزای پایین‌دست خروجی‌ها را به عنوان داده‌های غیرقابل اعتماد در نظر می‌گیرند و آن‌ها را بر اساس طرح‌واره‌ها یا دسیریالایزرهای امن در برابر تزریق، اعتبارسنجی می‌کنند.
 #7.1.4    Level: 3    Role: V
 اطمینان حاصل کنید که رویدادهای خروجی نادرست ثبت، محدودیت نرخ و به سیستم نظارت ارائه می‌شوند.

---

### C7.2 شناسایی و کاهش هالوسیناسیون

برآورد عدم قطعیت و استراتژی‌های جایگزین پاسخ‌های ساختگی را محدود می‌کنند.

 #7.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که احتمال‌های لگاریتمی در سطح توکن، انسجام خودکار مجموعه‌ای یا آشکارسازهای هالوسیناسیون تنظیم‌شده، به هر پاسخ یک نمره اطمینان اختصاص می‌دهند.
 #7.2.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که پاسخ‌هایی با سطح اطمینان پایین‌تر از آستانه قابل تنظیم، روندهای پشتیبان (مانند تولید با بازیابی اطلاعات، مدل ثانویه یا بازبینی انسانی) را فعال می‌کنند.
 #7.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که حوادث توهم‌زایی با متادیتای علت ریشه‌ای برچسب‌گذاری شده و به خطوط لوله پست‌مورتوم و تنظیم دقیق داده می‌شوند.
 #7.2.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که آستانه‌ها و آشکارسازها پس از به‌روزرسانی‌های مهم مدل یا پایگاه دانش دوباره کالیبره می‌شوند.
 #7.2.5    Level: 3    Role: V
 تأیید کنید که تصویری‌سازی‌های داشبورد نرخ‌های هذیان‌زدایی را دنبال می‌کنند.

---

### C7.3 فیلترینگ ایمنی و حفظ حریم خصوصی خروجی

فیلترهای سیاستی و پوشش تیم قرمز از کاربران و داده‌های محرمانه محافظت می‌کنند.

 #7.3.1    Level: 1    Role: D/V
 تأیید کنید که طبقه‌بندی‌کننده‌های قبل و بعد از تولید، محتوای نفرت‌انگیز، آزاردهنده، خودآسیب‌رسان، افراط‌گرایانه و صریح جنسی که منطبق با سیاست‌ها است را مسدود می‌کنند.
 #7.3.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که تشخیص اطلاعات شناسایی شخصی (PII) و کارت اعتباری (PCI) و حذف خودکار آن‌ها در هر پاسخ اجرا شود؛ تخلفات منجر به بروز حادثه محرمانگی خواهند شد.
 #7.3.3    Level: 2    Role: D
 اطمینان حاصل کنید که برچسب‌های محرمانگی (مانند اسرار تجاری) در تمام حوزه‌ها منتقل شده و از نشت اطلاعات در متن، تصاویر یا کد جلوگیری می‌کنند.
 #7.3.4    Level: 3    Role: D/V
 تأیید کنید که تلاش‌های عبور از فیلتر یا دسته‌بندی‌های پرخطر نیازمند تأیید ثانویه یا احراز هویت مجدد کاربر باشند.
 #7.3.5    Level: 3    Role: D/V
 تأیید کنید که آستانه‌های فیلترینگ بازتاب‌دهنده حوزه‌های قضایی قانونی و زمینه سنی/نقشی کاربر باشند.

---

### C7.4 محدودسازی خروجی و اقدامات

محدودیت‌های نرخ و دروازه‌های تایید از سوءاستفاده و خودمختاری بیش از حد جلوگیری می‌کنند.

 #7.4.1    Level: 1    Role: D
 تأیید کنید که سهمیه‌های هر کاربر و هر کلید API درخواست‌ها، توکن‌ها و هزینه‌ها را محدود می‌کنند و در صورت دریافت خطای 429 از مکانیزم توقف تصاعدی استفاده می‌شود.
 #7.4.2    Level: 1    Role: D/V
 تأیید کنید که اقدامات ممتاز (نوشتن فایل، اجرای کد، تماس‌های شبکه) نیازمند تأیید مبتنی بر سیاست یا دخالت انسانی هستند.
 #7.4.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که بررسی‌های سازگاری چندرسانه‌ای تضمین می‌کنند تصاویر، کد و متنی که برای یک درخواست یکسان تولید می‌شوند، نمی‌توانند برای قاچاق محتوای مخرب استفاده شوند.
 #7.4.4    Level: 2    Role: D
 بررسی کنید که عمق واگذاری عامل، محدودیت‌های بازگشت (رکورس) و فهرست‌های ابزارهای مجاز به طور صریح پیکربندی شده باشند.
 #7.4.5    Level: 3    Role: V
 تأیید کنید که نقض محدودیت‌ها رویدادهای امنیتی ساختاریافته برای دریافت توسط سیستم مدیریت اطلاعات و رویدادهای امنیتی (SIEM) ایجاد می‌کند.

---

### قابلیت توضیح‌پذیری خروجی C7.5

سیگنال‌های شفاف اعتماد کاربران و اشکال‌زدایی داخلی را بهبود می‌بخشند.

 #7.5.1    Level: 2    Role: D/V
 اطمینان حاصل کنید که امتیازهای اطمینان نمایش داده شده به کاربر یا خلاصه‌های مختصر دلایل زمانی که ارزیابی ریسک مناسب بداند، ارائه می‌شوند.
 #7.5.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که توضیحات تولید شده از افشای دستورات حساس سیستم یا داده های اختصاصی جلوگیری می‌کنند.
 #7.5.3    Level: 3    Role: D
 اطمینان حاصل کنید که سیستم احتمال‌های لاگ سطح توکن یا نقشه‌های توجه را ضبط کرده و آن‌ها را برای بررسی‌های مجاز ذخیره می‌کند.
 #7.5.4    Level: 3    Role: V
 اطمینان حاصل کنید که مصنوعات قابلیت توضیح‌دهی به همراه نسخه‌های مدل برای قابلیت حسابرسی تحت کنترل نسخه قرار دارند.

---

### C7.6 یکپارچه‌سازی نظارت

مشاهده‌پذیری در زمان واقعی حلقه بین توسعه و تولید را می‌بندد.

 #7.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که معیارها (نقض‌های طرح‌واره، نرخ توهم، سمی بودن، نشت اطلاعات شناسایی شخصی، تأخیر، هزینه) به یک پلتفرم نظارت مرکزی ارسال می‌شوند.
 #7.6.2    Level: 1    Role: V
 تأیید کنید که آستانه‌های هشدار برای هر معیار ایمنی تعریف شده باشد و مسیرهای ارتقاء در دسترس در حالت تماس اضطراری نیز مشخص شده باشند.
 #7.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که داشبوردها ناهنجاری‌های خروجی را با مدل/نسخه، پرچم ویژگی و تغییرات داده‌های بالادستی همبسته می‌کنند.
 #7.6.4    Level: 2    Role: D/V
 تأیید کنید که داده‌های نظارتی به آموزش مجدد، تنظیم دقیق یا به‌روزرسانی قوانین در چارچوب مستند شده MLOps بازخورد داده می‌شوند.
 #7.6.5    Level: 3    Role: V
 اطمینان حاصل کنید که خطوط انتقال نظارتی تحت آزمایش نفوذ قرار گرفته و کنترل‌های دسترسی برای جلوگیری از نشت لاگ‌های حساس اعمال شده‌اند.

---

### 7.7 تدابیر حفاظتی رسانه‌های مولد

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی محتوای رسانه‌ای غیرقانونی، مضر یا غیرمجاز تولید نکنند با اعمال محدودیت‌های سیاستی، اعتبارسنجی خروجی و قابلیت رهگیری.

 #7.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که دستورات سیستم و دستورالعمل‌های کاربر به‌طور صریح تولید محتوای دیپ‌فیک غیرقانونی، مضر یا بدون رضایت (مثلاً تصویر، ویدئو، صوت) را ممنوع می‌کنند.
 #7.7.2    Level: 2    Role: D/V
 تأیید کنید که درخواست‌ها برای تلاش‌های ایجاد جعل هویت، فیلم‌های عمیق جنسی صریح، یا رسانه‌هایی که افراد واقعی را بدون رضایت نشان می‌دهند بررسی و فیلتر می‌شوند.
 #7.7.3    Level: 2    Role: V
 تأیید کنید که سیستم از هشینگ ادراکی، تشخیص واترمارک، یا اثرانگشت‌گیری برای جلوگیری از تولید غیرمجاز رسانه‌های دارای حق نشر استفاده می‌کند.
 #7.7.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که تمام رسانه‌های تولید شده به‌صورت رمزنگاری شده امضا شده، علامت‌گذاری شده با واترمارک، یا مجهز به متادیتای منشاء مقاوم در برابر دستکاری برای قابلیت پیگیری در مراحل بعدی باشند.
 #7.7.5    Level: 3    Role: V
 تأیید کنید که تلاش‌های دورزدن (مانند پوشاندن درخواست، استفاده از زبان عامیانه، جملات خصمانه) شناسایی، ثبت و نرخ محدود می‌شوند؛ سوء استفاده مکرر به سیستم‌های نظارتی گزارش داده می‌شود.

### مراجع

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## امنیت حافظه C8، جاسازی‌ها و پایگاه داده‌های برداری

### هدف کنترل

توکاربردهای تعبیه و فروشگاه‌های برداری به عنوان "حافظه زنده" سیستم‌های هوش مصنوعی معاصر عمل می‌کنند، به‌طور مداوم داده‌های ارائه‌شده توسط کاربر را دریافت کرده و از طریق تولید مرتبط با بازیابی (RAG) آن را به زمینه‌های مدل بازمی‌گردانند. اگر این حافظه بدون مدیریت باقی بماند، ممکن است اطلاعات شناسایی شخصی (PII) را نشت دهد، رضایت را نقض کند یا به‌صورت معکوس برای بازسازی متن اصلی استفاده شود. هدف این خانواده کنترل، سخت‌افزاری کردن خطوط لوله حافظه و پایگاه‌های داده برداری است تا دسترسی حداقل امتیازی باشد، تعبیه‌ها حفظ حریم خصوصی را تضمین کنند، بردارهای ذخیره‌شده منقضی شده یا بر حسب تقاضا لغو شوند و حافظه هر کاربر هرگز ورودی‌ها یا خروجی‌های کاربران دیگر را آلوده نکند.

---

### C8.1 کنترل‌های دسترسی بر حافظه و شاخص‌های RAG

اعمال کنترل دسترسی دقیق و جزئی بر روی هر مجموعه برداری.

 #8.1.1    Level: 1    Role: D/V
 بررسی کنید که قوانین کنترل دسترسی در سطح سطر/فضای نام، عملیات درج، حذف و پرس‌وجو را برای هر مستأجر، مجموعه یا برچسب سند محدود می‌کنند.
 #8.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که کلیدهای API یا JWT‌ها دارای ادعاهای محدوده دار (مانند شناسه‌های مجموعه، افعال عملیاتی) هستند و حداقل هر سه ماه یکبار تعویض می‌شوند.
 #8.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که تلاش‌های افزایش امتیاز (مثلاً پرس و جوهای مشابهت بین نام‌فضاها) در کمتر از ۵ دقیقه به یک سامانه مدیریت اطلاعات و رویدادهای امنیتی (SIEM) شناسایی و ثبت شوند.
 #8.1.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که بانک اطلاعات برداری (vector DB) لاگ‌های ممیزی شامل شناسه موضوع، عملیات، شناسه بردار/نام‌فضا، آستانه تشابه و تعداد نتایج را ثبت می‌کند.
 #8.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که تصمیمات دسترسی برای نقص‌های عبور غیرمجاز هرگاه موتورهای جستجو به‌روزرسانی می‌شوند یا قوانین تقسیم‌بندی ایندکس تغییر می‌کنند، آزمایش می‌شوند.

---

### C8.2 تصفیه و اعتبارسنجی جاسازی

متن را برای اطلاعات شناسایی شخصی (PII) پیش‌تصحیح کنید، قبل از بردار‌سازی آن را مخفی یا مستعار کنید، و به طور اختیاری پس‌پردازش‌هایی روی تعبیه‌ها انجام دهید تا سیگنال‌های باقی‌مانده حذف شوند.

 #8.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های شناسایی شخصی (PII) و داده‌های تنظیم‌شده از طریق طبقه‌بندهای خودکار شناسایی شده و قبل از جاسازی، ماسک شده، توکنیزه شده یا حذف می‌شوند.
 #8.2.2    Level: 1    Role: D
 تأیید کنید که خطوط لوله جایگذاری ورودی‌هایی را که حاوی کد اجرایی یا اثرات غیر UTF-8 هستند و می‌توانند ایندکس را مسموم کنند، رد یا قرنطینه می‌کنند.
 #8.2.3    Level: 2    Role: D/V
 اعتبارسنجی شود که پاک‌سازی با حفظ حریم خصوصی تفاضلی محلی یا معیار به بردارهای جاسازی شده جملات اعمال شده باشد، مشروط بر اینکه فاصله آن‌ها با هر توکن شناخته‌شده اطلاعات شناسایی شخصی (PII) کمتر از یک آستانه قابل تنظیم باشد.
 #8.2.4    Level: 2    Role: V
 اطمینان حاصل کنید که اثربخشی تصفیه (مانند بازخوانی حذف داده‌های شخصی، انحراف معنایی) حداقل هر شش ماه یکبار در مقابل مجموعه‌های معیار بررسی می‌شود.
 #8.2.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تنظیمات پاک‌سازی تحت کنترل نسخه هستند و تغییرات تحت بررسی همتا قرار می‌گیرند.

---

### C8.3 انقضای حافظه، لغو و حذف

قانون GDPR "حق فراموش شدن" و قوانین مشابه نیازمند پاک‌سازی به موقع هستند؛ بنابراین فروشگاه‌های برداری باید از زمان‌زندگی محدود (TTL)، حذف سخت، و نشانه‌گذاری حذف (tomb-stoning) پشتیبانی کنند تا بردارهای لغو شده به هیچ‌وجه قابل بازیابی یا ایندکس مجدد نباشند.

 #8.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر رکورد داده‌های برداری و متادیتا دارای یک TTL یا برچسب نگهداری صریح است که توسط کارهای پاک‌سازی خودکار رعایت می‌شود.
 #8.3.2    Level: 1    Role: D/V
 تأیید کنید که درخواست‌های حذف توسط کاربر، بردارها، فراداده‌ها، نسخه‌های کش و شاخص‌های مشتق شده را ظرف ۳۰ روز پاک‌سازی می‌کنند.
 #8.3.3    Level: 2    Role: D
 تأیید کنید که حذف‌های منطقی توسط پاک‌سازی رمزنگاری شده بلوک‌های ذخیره‌سازی (در صورت پشتیبانی سخت‌افزار) یا با تخریب کلیدهای مخزن کلید دنبال می‌شوند.
 #8.3.4    Level: 3    Role: D/V
 تأیید کنید که بردارهای منقضی شده در کمتر از ۵۰۰ میلی‌ثانیه پس از انقضا از نتایج جستجوی نزدیک‌ترین همسایه حذف شده‌اند.

---

### C8.4 جلوگیری از معکوس‌سازی تعبیه و نشت اطلاعات

دفاع‌های اخیر—ترکیب نویز، شبکه‌های پروجکشن، اغتشاش نورون‌های حریم خصوصی، و رمزگذاری در لایه کاربرد—می‌توانند نرخ معکوس سازی در سطح توکن را به زیر ۵٪ کاهش دهند.

 #8.4.1    Level: 1    Role: V
 تأیید کنید که یک مدل تهدید رسمی شامل حملات وارونگی، عضویت و استنباط ویژگی وجود دارد و سالانه بازبینی می‌شود.
 #8.4.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که رمزنگاری در لایه برنامه یا رمزنگاری جستجوپذیر، بردارها را از خوانش مستقیم توسط مدیران زیرساخت یا کارکنان ابر محافظت می‌کند.
 #8.4.3    Level: 3    Role: V
 تأیید کنید که پارامترهای دفاعی (ε برای حریم خصوصی تفاضلی، نویز σ، رتبه پیش‌نگاره k) تعادل بین حفظ حریم خصوصی ≥ ۹۹٪ حفاظت از توکن و بهره‌وری ≤ ۳٪ افت در دقت را برقرار کنند.
 #8.4.4    Level: 3    Role: D/V
 تأیید کنید که معیارهای مقاومت در برابر وارونگی بخشی از دروازه‌های انتشار برای به‌روزرسانی مدل‌ها هستند و بودجه‌های رگرسیون تعریف شده‌اند.

---

### اجرای محدوده C8.5 برای حافظه خاص کاربر

نشت داده در میان مستاجرها همچنان یکی از بزرگترین ریسک‌های RAG است: جستجوهای مشابهت به‌درستی فیلتر نشده می‌توانند اسناد خصوصی مشتری دیگری را آشکار کنند.

 #8.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر پرس‌وجوی بازیابی قبل از فرستاده شدن به پرامپت مدل زبان بزرگ (LLM)، بر اساس شناسه مستاجری/کاربر پس‌پردازش شود.
 #8.5.2    Level: 1    Role: D
 اطمینان حاصل کنید که نام‌های مجموعه یا شناسه‌های نام‌گذاری شده به‌صورت نمک‌دار شده برای هر کاربر یا مستأجر هستند تا بردارها نتوانند در دامنه‌ها با یکدیگر تداخل کنند.
 #8.5.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که نتایج شباهت بالاتر از یک آستانه فاصله قابل تنظیم اما خارج از دامنه تماس‌گیرنده رد شده و هشدارهای امنیتی ایجاد کنند.
 #8.5.4    Level: 2    Role: V
 اطمینان حاصل کنید که تست‌های فشار چند مستأجره شبیه‌سازی پرس‌وجوهای خصمانه‌ای هستند که سعی در بازیابی اسناد خارج از دامنه دارند و نشان‌دهنده نشت صفر باشند.
 #8.5.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که کلیدهای رمزگذاری به صورت جداگانه برای هر مستاجر نگهداری می‌شوند، به گونه‌ای که جداشدگی رمزنگاری حتی در صورت اشتراک گذاری حافظه فیزیکی حفظ شود.

---

### C8.6 امنیت پیشرفته سیستم حافظه

کنترل‌های امنیتی برای معماری‌های حافظه پیشرفته شامل حافظه اپیزودیک، معنایی و کاری با نیازهای خاص جداسازی و اعتبارسنجی.

 #8.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که انواع مختلف حافظه (اپیزودیک، معنایی، کاری) دارای زمینه‌های امنیتی جداگانه با کنترل‌های دسترسی مبتنی بر نقش، کلیدهای رمزگذاری مجزا و الگوهای دسترسی مستند برای هر نوع حافظه هستند.
 #8.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که فرایندهای تثبیت حافظه شامل اعتبارسنجی امنیتی برای جلوگیری از تزریق خاطرات مخرب از طریق پاکسازی محتوا، تأیید منبع و بررسی‌های صحت قبل از ذخیره‌سازی باشد.
 #8.6.3    Level: 2    Role: D/V
 تأیید کنید که پرس‌وجوهای بازیابی حافظه اعتبارسنجی و پاک‌سازی شده‌اند تا از استخراج اطلاعات غیرمجاز از طریق تحلیل الگوی پرس‌وجو، اجرای کنترل دسترسی و فیلتر کردن نتایج جلوگیری شود.
 #8.6.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های فراموشی حافظه اطلاعات حساس را با تضمین‌های پاک‌سازی رمزنگاری شده با استفاده از حذف کلید، بازنویسی چندباره، یا حذف ایمن مبتنی بر سخت‌افزار همراه با گواهی‌های تأیید پاک‌سازی، به صورت امن حذف می‌کنند.
 #8.6.5    Level: 3    Role: D/V
 تأیید کنید که یکپارچگی سیستم حافظه به صورت مداوم برای تغییرات یا فساد غیرمجاز از طریق مجموع‌های کنترلی (checksum)، لاگ‌های حسابرسی و هشدارهای خودکار هنگام تغییر محتوای حافظه خارج از عملیات عادی، مورد پایش قرار می‌گیرد.

---

### مراجع

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 هماهنگی خودکار و امنیت اقدام عاملیت

### هدف کنترل

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی خودران یا چندعاملی فقط اقداماتی را انجام می‌دهند که به صراحت مورد نظر، تأیید شده، قابل حسابرسی و در محدوده هزینه و ریسک مشخص باشند. این امر از تهدیداتی مانند نفوذ به سیستم‌های خودران، سوءاستفاده از ابزار، تشخیص حلقه‌های عامل، ربایش ارتباطات، جعل هویت، دستکاری گروهی و دستکاری قصد، حفاظت می‌کند.

---

### 9.1 برنامه‌ریزی وظایف عامل و بودجه‌های بازگشتی

طرح‌های بازگشتی را محدود کرده و انجام اقدامات ویژه را منوط به تایید انسانی کنید.

 #9.1.1    Level: 1    Role: D/V
 تأیید کنید که حداکثر عمق بازگشت، پهنا، زمان واقعی اجرای برنامه، تعداد توکن‌ها و هزینه مالی هر اجرای عامل به صورت مرکزی پیکربندی شده و تحت کنترل نسخه قرار دارند.
 #9.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که اقدامات دارای امتیاز یا غیرقابل برگشت (مانند تعهدهای کد، انتقالات مالی) قبل از اجرا نیازمند تأیید صریح انسان از طریق یک کانال قابل حسابرسی هستند.
 #9.1.3    Level: 2    Role: D
 تأیید کنید که مانیتورهای منابع در زمان واقعی هنگام تجاوز هرگونه آستانه بودجه، وقفه مدارشکن را فعال می‌کنند و گسترش بیشتر وظایف را متوقف می‌سازند.
 #9.1.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که رویدادهای قطع‌کننده مدار با شناسه عامل، شرایط تحریک و وضعیت برنامه ضبط‌شده برای بررسی قانونی ثبت می‌شوند.
 #9.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که تست‌های امنیتی پوشش‌دهنده سناریوهای اتمام بودجه و اجرای بی‌پایان برنامه هستند، تا توقف ایمن بدون از دست دادن داده‌ها تأیید شود.
 #9.1.6    Level: 3    Role: D
 اطمینان حاصل کنید که سیاست‌های بودجه به صورت سیاست به عنوان کد بیان شده و در CI/CD اعمال می‌شوند تا از انحراف پیکربندی جلوگیری شود.

---

### 9.2 محصورسازی افزونه ابزار

تعاملات ابزار را ایزوله کنید تا از دسترسی غیرمجاز به سیستم یا اجرای کد جلوگیری شود.

 #9.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر ابزار/افزونه در داخل یک سیستم‌عامل، کانتینر، یا محیط سندباکس سطح WASM با سیاست‌های حداقلی امتیازات برای فایل‌سیستم، شبکه، و فراخوانی‌های سیستم اجرا می‌شود.
 #9.2.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که سهمیه منابع سندباکس (پردازنده، حافظه، دیسک، خروجی شبکه) و زمان‌های تایم‌اوت اجرا به‌درستی اعمال و ثبت می‌شوند.
 #9.2.3    Level: 2    Role: D/V
 تأیید کنید که باینری‌ها یا توصیف‌گرهای ابزار به‌صورت دیجیتال امضا شده‌اند؛ امضاها قبل از بارگذاری اعتبارسنجی می‌شوند.
 #9.2.4    Level: 2    Role: V
 تأیید کنید که داده‌های تله‌متری سندباکس به سامانه مدیریت و اطلاعات امنیتی (SIEM) منتقل می‌شوند؛ ناهنجاری‌ها (مثلاً تلاش برای ایجاد ارتباط‌های خروجی) هشدار تولید می‌کنند.
 #9.2.5    Level: 3    Role: V
 اطمینان حاصل کنید که افزونه‌های پرخطر قبل از استقرار در محیط تولید، مورد بازبینی امنیتی و آزمون نفوذ قرار می‌گیرند.
 #9.2.6    Level: 3    Role: D/V
 تأیید کنید که تلاش‌های فرار از محیط ایزوله به طور خودکار مسدود شده و افزونه متخلف تا زمان بررسی در قرنطینه قرار می‌گیرد.

---

### 9.3 حلقه خودگردان و تعیین حد هزینه

شناسایی و متوقف کردن بازگشت‌پذیری کنترل‌نشده بین عامل‌ها و انفجار هزینه‌ها.

 #9.3.1    Level: 1    Role: D/V
 تأیید کنید که تماس‌های بین عامل‌ها شامل حد پرش یا TTL باشند که زمان اجرای برنامه آن را کاهش داده و اعمال می‌کند.
 #9.3.2    Level: 2    Role: D
 مطمئن شوید که عوامل یک شناسه گراف فراخوانی منحصر به فرد را حفظ می‌کنند تا بتوانند خودفراخوانی یا الگوهای چرخه‌ای را شناسایی کنند.
 #9.3.3    Level: 2    Role: D/V
 تأیید کنید که شمارنده‌های تجمعی واحد محاسباتی و مصرف به ازای هر زنجیره درخواست پیگیری می‌شوند؛ نقض این محدودیت منجر به قطع زنجیره می‌شود.
 #9.3.4    Level: 3    Role: V
 تأیید کنید که تحلیل رسمی یا بررسی مدل نشان‌دهنده عدم وجود بازگشت نامحدود در پروتکل‌های عامل باشد.
 #9.3.5    Level: 3    Role: D
 اطمینان حاصل کنید که رویدادهای قطع حلقه، هشدار تولید می‌کنند و معیارهای بهبود مستمر را تغذیه می‌کنند.

---

### 9.4 حفاظت در برابر سوء استفاده در سطح پروتکل

کانال‌های ارتباطی امن بین عامل‌ها و سیستم‌های خارجی برای جلوگیری از ربودن یا دستکاری.

 #9.4.1    Level: 1    Role: D/V
 تأیید کنید که تمام پیام‌های بین عامل و ابزار و همچنین بین عوامل، احراز هویت شده‌اند (مانند TLS متقابل یا JWT) و رمزگذاری شده از ابتدا تا انتها هستند.
 #9.4.2    Level: 1    Role: D
 تأیید کنید که اسکیم‌ها به‌طور estrictly اعتبارسنجی می‌شوند؛ فیلدهای ناشناخته یا پیام‌های مشکل‌دار رد می‌شوند.
 #9.4.3    Level: 2    Role: D/V
 تأیید کنید که بررسی‌های صحت (MACها یا امضاهای دیجیتال) کل محتوای پیام از جمله پارامترهای ابزار را پوشش می‌دهند.
 #9.4.4    Level: 2    Role: D
 تأیید کنید که حفاظت در برابر تکرار (مقادیر تصادفی یا پنجره‌های زمانی) در لایه پروتکل اعمال شده است.
 #9.4.5    Level: 3    Role: V
 اطمینان حاصل کنید که پیاده‌سازی‌های پروتکل تحت آزمایش فازی و تحلیل ایستا برای شناسایی نقص‌های تزریق یا سریال‌زدایی قرار می‌گیرند.

---

### ۹.۵ هویت عامل و شواهد دستکاری

اطمینان حاصل کنید که اقدامات قابل انتساب و تغییرات قابل شناسایی باشند.

 #9.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که هر نمونه عامل دارای یک هویت رمزنگاری منحصر به فرد باشد (جفت کلید یا اعتبارسنجی مبتنی بر سخت‌افزار).
 #9.5.2    Level: 2    Role: D/V
 تأیید کنید که تمامی اقدامات عامل امضا و دارای مهر زمانی باشند؛ لاگ‌ها شامل امضا برای جلوگیری از انکار باشند.
 #9.5.3    Level: 2    Role: V
 تأیید کنید که لاگ‌های قابل تشخیص تغییر در یک رسانه فقط افزایشی یا یکبار نوشتنی ذخیره شده‌اند.
 #9.5.4    Level: 3    Role: D
 اطمینان حاصل کنید که کلیدهای هویت در یک برنامه زمان‌بندی مشخص و در صورت وجود شاخص‌های نفوذ، به‌روزرسانی می‌شوند.
 #9.5.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تلاش‌های جعل یا تعارض کلید، قرنطینه فوری عامل مورد نظر را فعال می‌کنند.

---

### ۹.۶ کاهش ریسک ازدحام چندعامل

مخاطر رفتار جمعی را از طریق جداسازی و مدل‌سازی رسمی ایمنی کاهش دهید.

 #9.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که عوامل فعال در حوزه‌های امنیتی مختلف در محیط‌های اجرایی ایزوله شده یا بخش‌های شبکه جداگانه اجرا می‌شوند.
 #9.6.2    Level: 3    Role: V
 اطمینان حاصل کنید که رفتارهای گروهی مدل‌سازی شده و پیش از استقرار، از نظر زنده‌بودن و ایمنی به صورت رسمی تأیید شده‌اند.
 #9.6.3    Level: 3    Role: D
 تأیید کنید که مانیتورهای زمان اجرا الگوهای ناایمن نوظهور (مانند نوسانات، بن‌بست‌ها) را شناسایی کرده و اقدام اصلاحی را آغاز می‌کنند.

---

### ۹.۷ احراز هویت / مجوز کاربران و ابزارها

کنترل‌های دسترسی قوی را برای هر عملی که توسط عامل‌ها فعال می‌شود، اجرا کنید.

 #9.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که عامل‌ها به عنوان اشخاص حقوقی درجه یک به سیستم‌های پایین‌دست احراز هویت می‌شوند و هرگز از مدارک کاربر نهایی مجدداً استفاده نمی‌کنند.
 #9.7.2    Level: 2    Role: D
 تأیید کنید که سیاست‌های مجوزدهی دقیق تعیین می‌کنند کدام ابزارها توسط عامل قابل فراخوانی هستند و کدام پارامترها می‌توانند ارائه شوند.
 #9.7.3    Level: 2    Role: V
 اطمینان حاصل کنید که بررسی‌های مجوز در هر فراخوانی مجدداً ارزیابی می‌شوند (مجوزدهی مستمر)، نه فقط در آغاز جلسه.
 #9.7.4    Level: 3    Role: D
 اطمینان حاصل کنید که امتیازات واگذار شده به‌طور خودکار پس از انقضای زمان یا تغییر دامنه منقضی می‌شوند و نیاز به رضایت مجدد دارند.

---

### ۹.۸ امنیت ارتباط بین عامل‌ها

تمام پیام‌های بین عوامل را رمزگذاری و از صحت آنها محافظت کنید تا از استراق سمع و دستکاری جلوگیری شود.

 #9.8.1    Level: 1    Role: D/V
 تأیید کنید که احراز هویت دو طرفه و رمزنگاری با امنیت انتقال کامل (مثلاً TLS 1.3) برای کانال‌های عامل اجباری باشند.
 #9.8.2    Level: 1    Role: D
 اطمینان حاصل کنید که تمامیت و منبع پیام قبل از پردازش تأیید شده‌اند؛ در صورت بروز خطا، هشدارها صادر شده و پیام رد می‌شود.
 #9.8.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که متادیتای ارتباط (زمان‌بندی‌ها، شماره‌های دنباله) برای پشتیبانی از بازسازی قضایی ثبت می‌شود.
 #9.8.4    Level: 3    Role: V
 تأیید کنید که تأیید رسمی یا مدل چکینگ تایید می‌کند که ماشین‌های حالت پروتکل نمی‌توانند به حالت‌های ناامن هدایت شوند.

---

### 9.9 تایید نیت و اعمال محدودیت‌ها

اعتبارسنجی کنید که اقدامات عامل با نیت اعلام‌شده کاربر و محدودیت‌های سیستم هم‌خوانی دارد.

 #9.9.1    Level: 1    Role: D
 تأیید کنید که حل‌کننده‌های قید پیش‌اجرا، اقدامات پیشنهادی را بر اساس قوانین سخت‌کد شده ایمنی و سیاست بررسی می‌کنند.
 #9.9.2    Level: 2    Role: D/V
 تأیید کنید که اقدامات با تأثیر بالا (مالی، مخرب، حساس به حریم خصوصی) نیازمند تأیید صریح قصد از سوی کاربر آغازگر هستند.
 #9.9.3    Level: 2    Role: V
 اطمینان حاصل کنید که بررسی‌های پس‌شرط تایید می‌کنند که اقدامات تکمیل شده اثرات مورد نظر را بدون عوارض جانبی به دست آورده‌اند؛ هرگونه اختلاف موجب بازگردانی (rollback) می‌شود.
 #9.9.4    Level: 3    Role: V
 تأیید کنید که روش‌های رسمی (مانند بررسی مدل، اثبات قضایا) یا تست‌های مبتنی بر ویژگی نشان دهند که برنامه‌های عامل تمامی محدودیت‌های اعلام شده را برآورده می‌کنند.
 #9.9.5    Level: 3    Role: D
 اطمینان حاصل کنید که حوادث عدم تطابق قصد یا نقض محدودیت‌ها به چرخه‌های بهبود مستمر و اشتراک‌گذاری اطلاعات تهدید تغذیه می‌کنند.

---

### ۹.۱۰ استراتژی استدلال عامل برای امنیت

انتخاب و اجرای ایمن استراتژی‌های استدلال مختلف شامل روش‌های ReAct، زنجیره‌ای از افکار (Chain-of-Thought)، و ساختار درختی از افکار (Tree-of-Thoughts).

 #9.10.1    Level: 1    Role: D/V
 تأیید کنید که انتخاب استراتژی استدلال از معیارهای قطعی (پیچیدگی ورودی، نوع وظیفه، زمینه امنیتی) استفاده می‌کند و ورودی‌های یکسان در همان زمینه امنیتی منجر به انتخاب‌های استراتژی یکسان می‌شوند.
 #9.10.2    Level: 1    Role: D/V
 تأیید کنید که هر استراتژی استدلالی (ReAct، زنجیره‌ای از تفکر، درختی از تفکرات) دارای اعتبارسنجی ورودی اختصاصی، پاک‌سازی خروجی و محدودیت‌های زمان اجرای خاص رویکرد شناختی خود باشد.
 #9.10.3    Level: 2    Role: D/V
 تأیید کنید که انتقال‌های استراتژی استدلال با زمینه کامل از جمله ویژگی‌های ورودی، مقادیر معیارهای انتخاب و فراداده‌های اجرای سیستم برای بازسازی مسیر حسابرسی ثبت شده‌اند.
 #9.10.4    Level: 2    Role: D/V
 تأیید کنید که منطق درخت افکار شامل مکانیزم‌های هرس شاخه است که هنگام شناسایی نقض سیاست‌ها، محدودیت‌های منابع یا مرزهای ایمنی، اکتشاف را متوقف می‌کنند.
 #9.10.5    Level: 2    Role: D/V
 تأیید کنید که چرخه‌های ReAct (استدلال-اقدام-مشاهده) شامل نقاط کنترل اعتبارسنجی در هر مرحله باشند: تأیید گام استدلال، مجوز اقدام، و پاک‌سازی مشاهده قبل از ادامه دادن.
 #9.10.6    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارهای عملکرد استراتژی استدلال (زمان اجرا، مصرف منابع، کیفیت خروجی) با هشدارهای خودکار زمانی که معیارها از آستانه‌های تنظیم شده تجاوز می‌کنند، پایش می‌شوند.
 #9.10.7    Level: 3    Role: D/V
 تأیید کنید که رویکردهای استدلال ترکیبی که چندین استراتژی را با هم ترکیب می‌کنند، اعتبارسنجی ورودی و محدودیت‌های خروجی همه استراتژی‌های مؤلف را حفظ می‌کنند بدون اینکه هیچ کنترل امنیتی را دور بزنند.
 #9.10.8    Level: 3    Role: D/V
 تأیید کنید که آزمایش امنیت استراتژی استدلال شامل استفاده از فازینگ با ورودی‌های ناقص، پرامپت‌های خصمانه طراحی شده برای اجباری کردن تغییر استراتژی، و تست شرایط مرزی برای هر رویکرد شناختی می‌باشد.

---

### 9.11 مدیریت و امنیت وضعیت چرخه عمر عامل

راه‌اندازی امن عامل، انتقال حالت‌ها، و خاتمه با سوابق حسابرسی رمزنگاری شده و رویه‌های بازیابی تعریف‌شده.

 #9.11.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که راه‌اندازی عامل شامل ایجاد هویت رمزنگاری شده با گواهی‌های مبتنی بر سخت‌افزار و گزارش‌های حسابرسی راه‌اندازی غیرقابل تغییر است که شامل شناسه عامل، مهر زمان، هش پیکربندی و پارامترهای راه‌اندازی می‌باشد.
 #9.11.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که انتقال وضعیت عامل‌ها به‌صورت رمزنگاری‌شده امضا شده، زمان‌گذاری شده و با زمینه کامل شامل رویدادهای محرک، هش وضعیت قبلی، هش وضعیت جدید و اعتبارسنجی‌های امنیتی انجام‌شده، ثبت و لاگ شده‌اند.
 #9.11.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که رویه‌های خاموش‌سازی عامل شامل پاک‌سازی ایمن حافظه با استفاده از حذف رمزنگاری یا بازنویسی چندباره، لغو اعتبارنامه‌ها با اطلاع‌رسانی به مرجع صدور گواهی، و تولید گواهی‌های خاتمه با قابلیت تشخیص دستکاری می‌باشد.
 #9.11.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های بازیابی عامل صحت یکپارچگی وضعیت را با استفاده از چک‌سام‌های رمزنگاری‌شده (حداقل SHA-256) بررسی می‌کنند و هنگام شناسایی خرابی، به وضعیت‌های شناخته‌شده سالم بازمی‌گردند، همراه با اطلاع‌رسانی خودکار و نیاز به تأیید دستی.
 #9.11.5    Level: 3    Role: D/V
 تأیید کنید که مکانیسم‌های پایداری عامل داده‌های حالت حساس را با کلیدهای AES-256 اختصاصی هر عامل رمزگذاری می‌کنند و چرخش امن کلیدها را بر اساس برنامه‌های قابل تنظیم (حداکثر ۹۰ روز) با استقرار بدون توقف اجرا می‌کنند.

---

### چارچوب امنیتی یکپارچه‌سازی ابزار ۹.۱۲

کنترل‌های امنیتی برای بارگذاری دینامیک ابزار، اجرا و اعتبارسنجی نتایج با فرآیندهای ارزیابی ریسک تعریف شده و تصویب.

 #9.12.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که توصیف‌گرهای ابزار شامل متادیتای امنیتی هستند که دسترسی‌های مورد نیاز (خواندن/نوشتن/اجرا)، سطوح ریسک (کم/متوسط/زیاد)، محدودیت‌های منابع (پردازنده، حافظه، شبکه) و الزامات اعتبارسنجی را که در مستندات ابزار ثبت شده‌اند، مشخص می‌کنند.
 #9.12.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که نتایج اجرای ابزار بر اساس طرح‌های مورد انتظار (طرح‌های JSON، طرح‌های XML) و سیاست‌های امنیتی (پاک‌سازی خروجی، طبقه‌بندی داده‌ها) قبل از یکپارچه‌سازی با محدودیت‌های زمان‌بندی و روندهای مدیریت خطا، اعتبارسنجی می‌شوند.
 #9.12.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که گزارش‌های تعامل ابزار شامل زمینه امنیتی دقیق از جمله استفاده از امتیازات، الگوهای دسترسی به داده‌ها، زمان اجرا، مصرف منابع و کدهای بازگشتی با ثبت ساختاریافته برای ادغام با سیستم‌های مدیریت اطلاعات و رویدادهای امنیتی (SIEM) باشد.
 #9.12.4    Level: 2    Role: D/V
 تأیید کنید که سازوکارهای بارگذاری ابزارهای پویا، امضاهای دیجیتالی را با استفاده از زیرساخت کلید عمومی (PKI) اعتبارسنجی می‌کنند و پروتکل‌های بارگذاری ایمن با جداسازی محیط اجرایی (sandbox) و تأیید مجوزها قبل از اجرا را پیاده‌سازی می‌نمایند.
 #9.12.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های امنیتی ابزار به‌طور خودکار برای نسخه‌های جدید با دروازه‌های تأیید اجباری شامل تحلیل استاتیک، تست پویا و بازبینی تیم امنیتی با معیارهای تأیید مستند و الزامات SLA فعال می‌شوند.

---

#### مراجع

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 مقاومت مقابل حملات متخاصم و دفاع حریم خصوصی

### هدف کنترل

اطمینان حاصل کنید که مدل‌های هوش مصنوعی هنگام مواجهه با حملات اجتناب، استنتاج، استخراج یا مسموم‌سازی، قابل اعتماد، محافظت‌کننده از حریم خصوصی و مقاوم در برابر سوءاستفاده باقی می‌مانند.

---

### ۱۰.۱ هم‌راستایی مدل و ایمنی

از تولید خروجی‌های مضر یا خلاف سیاست‌ها جلوگیری کنید.

 #10.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که یک مجموعه آزمایش هم‌راستایی (پرسش‌های تیم قرمز، آزمایش‌های فرار از زندان، محتوای ممنوعه) تحت کنترل نسخه قرار دارد و در هر نسخه جدید مدل اجرا می‌شود.
 #10.1.2    Level: 1    Role: D
 تأیید کنید که قوانین حفاظتی مربوط به رد درخواست و اتمام ایمن به درستی اعمال شده باشند.
 #10.1.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که یک ارزیاب خودکار نرخ محتوای مضر را اندازه‌گیری کرده و پسرفت‌ها را فراتر از یک حد آستانه مشخص علامت‌گذاری می‌کند.
 #10.1.4    Level: 2    Role: D
 اطمینان حاصل کنید که آموزش مقابله با دور زدن محدودیت‌ها مستند و قابل تکرار است.
 #10.1.5    Level: 3    Role: V
 اطمینان حاصل کنید که اثبات‌های رعایت سیاست‌های رسمی یا نظارت‌های گواهی‌شده حوزه‌های حیاتی را پوشش می‌دهند.

---

### ۱۰.۲ سخت‌سازی در برابر نمونه‌های خصمانه

افزایش مقاومت در برابر ورودی‌های دستکاری شده. آموزش مقاوم در برابر حملات مخالف و امتیازدهی معیار فعلی بهترین روش‌ها هستند.

 #10.2.1    Level: 1    Role: D
 تأیید کنید که مخازن پروژه شامل پیکربندی‌های آموزش متخاصم با دانه‌های تولید مجدد‌پذیر هستند.
 #10.2.2    Level: 2    Role: D/V
 تأیید کنید که تشخیص مثال‌های مخرب در خطوط تولید هشدارهای مسدودکننده ایجاد می‌کند.
 #10.2.4    Level: 3    Role: V
 اطمینان حاصل کنید که اثبات‌های پایداری تاییدشده یا گواهی‌های بازه‌ای حداقل کلاس‌های بحرانی برتر را پوشش می‌دهند.
 #10.2.5    Level: 3    Role: V
 تأیید کنید که آزمون‌های رگرسیون از حملات تطبیقی برای اطمینان از عدم افت قابل اندازه‌گیری در پایداری استفاده می‌کنند.

---

### ۱۰.۳ کاهش حملات استنباط عضویت

محدود کردن توانایی تصمیم‌گیری درباره اینکه آیا یک رکورد در داده‌های آموزش بوده است یا خیر. حفظ حریم خصوصی تفاضلی و ماسک کردن نمره اطمینان همچنان مؤثرترین روش‌های دفاعی شناخته‌شده هستند.

 #10.3.1    Level: 1    Role: D
 تأیید کنید که تنظیم منظم انتروپی به ازای هر پرسش یا مقیاس‌بندی دما، پیش‌بینی‌های بیش‌اعتماد به نفس را کاهش می‌دهد.
 #10.3.2    Level: 2    Role: D
 اطمینان حاصل کنید که آموزش از بهینه‌سازی با حفظ حریم خصوصی تفاضلی با کران ε برای مجموعه داده‌های حساس استفاده می‌کند.
 #10.3.3    Level: 2    Role: V
 اطمینان حاصل کنید که شبیه‌سازی‌های حمله (مدل سایه یا جعبه سیاه) نشان دهندۀ مقدار AUC حمله ≤ 0.60 روی داده‌های نگهداری شده باشد.

---

### 10.4 مقاومت در برابر وارون‌سازی مدل

جلوگیری از بازسازی ویژگی‌های خصوصی. نظرسنجی‌های اخیر بر برش خروجی و تضمین‌های حریم خصوصی تفاضلی (DP) به عنوان روش‌های عملی دفاع تأکید دارند.

 #10.4.1    Level: 1    Role: D
 تأیید کنید که ویژگی‌های حساس هرگز به طور مستقیم خروجی داده نشوند؛ در صورت نیاز، از دسته‌بندی‌ها یا تبدیل‌های یک طرفه استفاده کنید.
 #10.4.2    Level: 1    Role: D/V
 تأیید کنید که محدودیت‌های نرخ پرس و جو، پرس و جوهای تطبیقی تکراری از همان نهاد اصلی را محدود می‌کنند.
 #10.4.3    Level: 2    Role: D
 اطمینان حاصل کنید که مدل با نویز حفظ‌کننده حریم خصوصی آموزش داده شده است.

---

### 10.5 دفاع در برابر استخراج مدل

شناسایی و جلوگیری از کلونینگ غیرمجاز. استفاده از علامت‌گذاری (واترمارکینگ) و تحلیل الگوی پرسش‌ها توصیه می‌شود.

 #10.5.1    Level: 1    Role: D
 تأیید کنید که دروازه‌های استنتاج محدودیت‌های نرخ کلی و به‌ازای هر کلید API را اعمال می‌کنند که بر اساس آستانه حفظ حافظه مدل تنظیم شده‌اند.
 #10.5.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که آمارهای انتروپی پرس‌وجو و کثرت ورودی به یک آشکارساز استخراج خودکار تغذیه می‌شوند.
 #10.5.3    Level: 2    Role: V
 تأیید کنید که واترمارک‌های شکننده یا احتمالی می‌توانند با p < 0.01 در ≤ ۱۰۰۰ پرس‌وجو علیه کلون مشکوک ثابت شوند.
 #10.5.4    Level: 3    Role: D
 اطمینان حاصل کنید که کلیدهای واترمارک و مجموعه‌های محرک در یک ماژول امنیت سخت‌افزاری ذخیره شده و سالیانه تعویض می‌شوند.
 #10.5.5    Level: 3    Role: V
 اطمینان حاصل کنید که رویدادهای استخراج-هشدار شامل پرس‌وجوهای متخلف بوده و با راهنماهای پاسخ به حادثه یکپارچه شده‌اند.

---

### ۱۰.۶ تشخیص داده‌های آلوده در زمان استنتاج

ورودی‌های دارای درِ پشتی یا مسموم را شناسایی و خنثی کنید.

 #10.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که ورودی‌ها قبل از استنتاج مدل از طریق یک آشکارساز ناهنجاری (مانند STRIP، نمره‌دهی سازگاری) عبور کنند.
 #10.6.2    Level: 1    Role: V
 اطمینان حاصل کنید که آستانه‌های آشکارساز روی مجموعه‌های اعتبارسنجی پاک/سمی تنظیم شده‌اند تا کمتر از ۵٪ مثبت کاذب داشته باشند.
 #10.6.3    Level: 2    Role: D
 اطمینان حاصل کنید که ورودی‌های علامت‌گذاری شده به عنوان آلوده، فرآیندهای مسدودسازی نرم و بررسی انسانی را فعال می‌کنند.
 #10.6.4    Level: 2    Role: V
 اطمینان حاصل کنید که آشکارسازها با حملات پشتی غیرمستقیم تطبیقی بدون نیاز به ماشه تحت فشار قرار گرفته‌اند.
 #10.6.5    Level: 3    Role: D
 اطمینان حاصل کنید که معیارهای اثربخشی تشخیص ثبت می‌شوند و به‌طور دوره‌ای با اطلاعات روز تهدید مجدداً ارزیابی می‌گردند.

---

### ۱۰.۷ تطبیق پویا سیاست امنیتی

به‌روزرسانی‌های سیاست امنیتی به‌صورت بلادرنگ بر اساس اطلاعات تهدید و تحلیل رفتاری.

 #10.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیاست‌های امنیتی می‌توانند به‌طور پویا به‌روزرسانی شوند بدون نیاز به راه‌اندازی مجدد عامل، در حالی که صحت نسخه سیاست حفظ می‌شود.
 #10.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های سیاست‌ها به صورت رمزنگاری شده توسط افراد مجاز امنیتی امضا شده و قبل از اعمال تأیید شوند.
 #10.7.3    Level: 2    Role: D/V
 تأیید کنید که تغییرات سیاست پویا با مسیرهای کامل حسابرسی شامل توجیه، زنجیره‌های تأیید و رویه‌های بازگشت به عقب ثبت می‌شوند.
 #10.7.4    Level: 3    Role: D/V
 تأیید کنید که مکانیزم‌های امنیت تطبیقی حساسیت تشخیص تهدید را بر اساس زمینه ریسک و الگوهای رفتار تنظیم می‌کنند.
 #10.7.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که تصمیمات تطبیق سیاست قابل توضیح بوده و شامل شواهد مستندی برای بازبینی تیم امنیتی باشند.

---

### ۱۰.۸ تحلیل امنیت مبتنی بر بازتاب

اعتبارسنجی امنیت از طریق خود بازتابی عامل و تحلیل فراشناختی.

 #10.8.1    Level: 1    Role: D/V
 تأیید کنید که مکانیزم‌های بازتاب عامل شامل ارزیابی خودمحور با تمرکز بر امنیت برای تصمیمات و اقدامات باشد.
 #10.8.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که خروجی‌های بازتابی اعتبارسنجی شده‌اند تا از دستکاری مکانیزم‌های خودارزیابی توسط ورودی‌های مخرب جلوگیری شود.
 #10.8.3    Level: 2    Role: D/V
 تأیید کنید که تحلیل امنیت فراشناختی، تعصبات احتمالی، دستکاری یا تضعیف در فرایندهای استدلال عامل را شناسایی می‌کند.
 #10.8.4    Level: 3    Role: D/V
 تأیید کنید که هشدارهای امنیتی مبتنی بر بازتاب، نظارت پیشرفته و روندهای احتمالی مداخله انسانی را فعال می‌کنند.
 #10.8.5    Level: 3    Role: D/V
 تأیید کنید که یادگیری پیوسته از بازتاب‌های امنیتی، تشخیص تهدید را بهبود می‌بخشد بدون اینکه عملکرد قانونی را کاهش دهد.

---

### ۱۰.۹ امنیت تکامل و خودبهبودی

کنترل‌های امنیتی برای سیستم‌های عامل با قابلیت خودتغییری و تکامل.

 #10.9.1    Level: 1    Role: D/V
 تایید کنید که قابلیت‌های خودتغییری محدود به مناطق امن مشخص شده با مرزهای رسمی تایید هستند.
 #10.9.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که پیشنهادهای توسعه قبل از اجرا تحت ارزیابی تأثیر امنیتی قرار می‌گیرند.
 #10.9.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های خودبهبودی شامل قابلیت بازگشت با تأیید صحت هستند.
 #10.9.4    Level: 3    Role: D/V
 تأیید کنید که امنیت یادگیری فرامتا از دستکاری خصمانه الگوریتم‌های بهبود جلوگیری می‌کند.
 #10.9.5    Level: 3    Role: D/V
 اثبات کنید که بهبود بازگشتی خودکار توسط محدودیت‌های ایمنی رسمی محافظت می‌شود و با شواهد ریاضی همگرایی آن تایید شود.

---

#### منابع

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 حفاظت از حریم خصوصی و مدیریت داده‌های شخصی

### هدف کنترل

حفظ تضمین‌های سختگیرانه حریم خصوصی در سراسر چرخه حیات هوش مصنوعی—جمع‌آوری، آموزش، استنتاج و پاسخ به رخداد—به طوری که داده‌های شخصی تنها با رضایت صریح، دامنه حداقلی لازم، امکان اثبات حذف و تضمین‌های رسمی حریم خصوصی پردازش شود.

---

### 11.1 ناشناس‌سازی و حداقل‌سازی داده‌ها

 #11.1.1    Level: 1    Role: D/V
 تأیید کنید که شناسه‌های مستقیم و شبه‌نشانه‌ها حذف شده یا هش شده‌اند.
 #11.1.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که بازرسی‌های خودکار میزان k-ناشناس بودن / l-تنوع را اندازه‌گیری کرده و هنگامی که آستانه‌ها زیر سیاست تنظیم شده قرار می‌گیرند، هشدار می‌دهند.
 #11.1.3    Level: 2    Role: V
 اطمینان حاصل کنید که گزارش‌های اهمیت ویژگی مدل، هیچ نشتی شناسه‌ای بیش از ε = 0.01 اطلاعات متقابل را اثبات نمی‌کنند.
 #11.1.4    Level: 3    Role: V
 اطمینان حاصل کنید که اثبات‌های رسمی یا گواهی داده‌های مصنوعی نشان می‌دهد که ریسک شناسایی مجدد ≤ 0.05 حتی در صورت حملات لینک‌دهی باشد.

---

### ۱۱.۲ حق فراموش شدن و اجرای حذف

 #11.2.1    Level: 1    Role: D/V
 تأیید کنید که درخواست‌های حذف داده‌های موضوعی به مجموعه‌های داده خام، نقاط بازبینی، جاسازی‌ها، گزارش‌ها و پشتیبان‌ها با توافق‌نامه‌های سطح خدمات کمتر از ۳۰ روز منتقل می‌شوند.
 #11.2.2    Level: 2    Role: D
 تأیید کنید که روش‌های «یادگیری-پاک‌کردن ماشینی» به‌طور فیزیکی مجدداً آموزش داده می‌شوند یا حذف تقریبی را با استفاده از الگوریتم‌های تأییدشده یادگیری پاک انجام می‌دهند.
 #11.2.3    Level: 2    Role: V
 تأیید کنید که ارزیابی مدل سایه ثابت می‌کند سوابق فراموش شده کمتر از ۱٪ از خروجی‌ها را پس از فراموشی تحت تأثیر قرار می‌دهند.
 #11.2.4    Level: 3    Role: V
 اطمینان حاصل کنید که رویدادهای حذف به صورت غیرقابل تغییر ثبت شده و برای ناظران قابل حسابرسی هستند.

---

### 11.3 حفاظت‌های حفظ حریم خصوصی تفاضلی

 #11.3.1    Level: 2    Role: D/V
 بررسی کنید که داشبوردهای حسابداری از دست رفتن حریم خصوصی هنگامی که مقدار تجمعی ε از آستانه‌های سیاست فراتر می‌رود، هشدار دهند.
 #11.3.2    Level: 2    Role: V
 اطمینان حاصل کنید که حسابرسی‌های حفظ حریم خصوصی جعبه سیاه، ε̂ را در حدود ۱۰٪ از مقدار اعلام‌شده تخمین می‌زنند.
 #11.3.3    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی تمامی تنظیمات پس از آموزش و جاسازی‌ها را پوشش می‌دهند.

---

### 11.4 محدودیت هدف و حفاظت در برابر گسترش دامنه

 #11.4.1    Level: 1    Role: D
 اطمینان حاصل کنید که هر داده‌مجموعه و نقطه بازبینی مدل دارای برچسب هدف قابل خواندن توسط ماشین است که با رضایت اصلی همسو باشد.
 #11.4.2    Level: 1    Role: D/V
 تأیید کنید که نظارت‌کننده‌های زمان اجرا، پرس‌وجوهای ناسازگار با هدف اعلام‌شده را شناسایی کرده و پاسخ نرم (رد محترمانه) را فعال می‌کنند.
 #11.4.3    Level: 3    Role: D
 اطمینان حاصل کنید که دروازه‌های سیاست‌به‌عنوان-کد، از استقرار مجدد مدل‌ها به دامنه‌های جدید بدون بازبینی DPIA جلوگیری می‌کنند.
 #11.4.4    Level: 3    Role: V
 تأیید کنید که اثبات‌های ردیابی رسمی نشان می‌دهند هر چرخه عمر داده‌های شخصی در محدوده موافقت‌شده باقی می‌ماند.

---

### 11.5 مدیریت رضایت و ردیابی مبتنی بر مبنای قانونی

 #11.5.1    Level: 1    Role: D/V
 تأیید کنید که یک پلتفرم مدیریت رضایت (CMP) وضعیت رضایت، هدف و دوره نگهداری داده‌ها را برای هر موضوع داده ثبت می‌کند.
 #11.5.2    Level: 2    Role: D
 اطمینان حاصل کنید که APIها توکن‌های رضایت را افشا می‌کنند؛ مدل‌ها باید قبل از استنتاج، حوزه توکن را اعتبارسنجی کنند.
 #11.5.3    Level: 2    Role: D/V
 تأیید کنید که رد یا پس‌گیری رضایت، خطوط پردازش را ظرف ۲۴ ساعت متوقف می‌کند.

---

### 11.6 یادگیری فدرال با کنترل‌های حفظ حریم خصوصی

 #11.6.1    Level: 1    Role: D
 تأیید کنید که به‌روزرسانی‌های کلاینت قبل از تجمیع، از افزودن نویز حفظ حریم خصوصی موضعی (local differential privacy) استفاده می‌کنند.
 #11.6.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که معیارهای آموزش به صورت خصوصی تفاضلی هستند و هرگز میزان خطای یک مشتری منفرد را فاش نمی‌کنند.
 #11.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که جمع‌آوری مقاوم در برابر مسمومیت (مانند Krum/Trimmed-Mean) فعال شده است.
 #11.6.4    Level: 3    Role: V
 تأیید کنید که اثبات‌های رسمی، بودجه کلی ε را با کمتر از ۵ واحد کاهش کاربردی نشان می‌دهند.

---

#### مراجع

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## نظارت، ثبت وقایع و تشخیص ناهنجاری در C12

### هدف کنترل

این بخش الزامات ارائه دید بلادرنگ و جرم‌یابی را در مورد آنچه مدل و سایر اجزای هوش مصنوعی می‌بینند، انجام می‌دهند و بازمی‌گردانند، فراهم می‌کند تا تهدیدات بتوانند شناسایی، طبقه‌بندی و از آن‌ها درس گرفته شود.

### C12.1 ثبت درخواست و پاسخ

 #12.1.1    Level: 1    Role: D/V
 تأیید کنید که تمامی درخواست‌های کاربر و پاسخ‌های مدل با فراداده‌های مناسب (مثلاً زمان‌ثبت، شناسه کاربر، شناسه جلسه، نسخه مدل) ثبت شده‌اند.
 #12.1.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که لاگ‌ها در مخازن امن با کنترل دسترسی مناسب همراه با سیاست‌های نگهداری و روش‌های پشتیبان‌گیری مناسب ذخیره می‌شوند.
 #12.1.3    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیستم‌های ذخیره‌سازی لاگ، رمزنگاری در حالت استراحت و در انتقال را برای محافظت از اطلاعات حساس موجود در لاگ‌ها پیاده‌سازی کرده‌اند.
 #12.1.4    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های حساس در درخواست‌ها و خروجی‌ها به‌طور خودکار قبل از ثبت گزارش حذف یا مخفی می‌شوند، با قوانین قابل تنظیم برای حذف اطلاعات شناسایی شخصی (PII)، مدارک و اطلاعات اختصاصی.
 #12.1.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که تصمیمات سیاستی و اقدامات فیلترینگ ایمنی با جزئیات کافی ثبت می‌شوند تا امکان بررسی و اشکال‌زدایی سیستم‌های نظارت بر محتوا فراهم شود.
 #12.1.6    Level: 2    Role: D/V
 اطمینان حاصل کنید که صحت لاگ‌ها از طریق امضاهای رمزنگاری شده یا ذخیره‌سازی فقط‌ برای نوشتن محافظت می‌شود.

---

### C12.2 تشخیص و هشدار سوءاستفاده

 #12.2.1    Level: 1    Role: D/V
 تأیید کنید که سیستم الگوهای شناخته‌شدهٔ فرار از محدودیت، تلاش‌های تزریق فرمان و ورودی‌های خصمانه را با استفاده از شناسایی مبتنی بر امضا تشخیص داده و هشدار می‌دهد.
 #12.2.2    Level: 1    Role: D/V
 تأیید کنید که سیستم با استفاده از فرمت‌ها و پروتکل‌های استاندارد گزارش‌ها، با پلتفرم‌های مدیریت اطلاعات و رویدادهای امنیتی (SIEM) موجود ادغام شود.
 #12.2.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که رویدادهای امنیتی غنی شده شامل زمینه‌های خاص هوش مصنوعی مانند شناسه‌های مدل، امتیازهای اطمینان و تصمیمات فیلتر ایمنی هستند.
 #12.2.4    Level: 2    Role: D/V
 تأیید کنید که تشخیص ناهنجاری رفتاری الگوهای غیرمعمول گفتگو، تلاش‌های مکرر بیش از حد، یا رفتارهای جستجوی سیستماتیک را شناسایی می‌کند.
 #12.2.5    Level: 2    Role: D/V
 اطمینان حاصل کنید که مکانیزم‌های هشداردهی در زمان واقعی تیم‌های امنیتی را هنگام شناسایی تخلفات احتمالی از سیاست‌ها یا تلاش‌های حمله مطلع می‌کنند.
 #12.2.6    Level: 2    Role: D/V
 تأیید کنید که قوانین سفارشی برای شناسایی الگوهای تهدید خاص هوش مصنوعی شامل تلاش‌های هماهنگ شده برای دور زدن محدودیت‌ها (jailbreak)، کمپین‌های تزریق درخواست (prompt injection) و حملات استخراج مدل (model extraction) گنجانده شده باشند.
 #12.2.7    Level: 3    Role: D/V
 اطمینان حاصل کنید که جریان‌های کاری پاسخ به حادثه خودکار قادر به ایزوله کردن مدل‌های به خطر افتاده، مسدود کردن کاربران مخرب و افزایش رویدادهای امنیتی حیاتی هستند.

---

### C12.3 تشخیص رانش مدل

 #12.3.1    Level: 1    Role: D/V
 تأیید کنید که سیستم معیارهای عملکرد پایه مانند دقت، نمرات اطمینان، تاخیر و نرخ خطاها را در نسخه‌های مدل و بازه‌های زمانی مختلف ردیابی می‌کند.
 #12.3.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که هشداردهی خودکار هنگام عبور معیارهای عملکرد از آستانه‌های کاهش از پیش تعیین شده یا انحراف قابل توجه از مبناها فعال شود.
 #12.3.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که سیستم‌های تشخیص توهم، مواردی را که خروجی‌های مدل حاوی اطلاعات نادرست، ناسازگار یا ساختگی هستند، شناسایی و علامت‌گذاری می‌کنند.

---

### C12.4 تلماتری عملکرد و رفتار

 #12.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که معیارهای عملیاتی شامل تأخیر درخواست، مصرف توکن، استفاده از حافظه و توان عملیاتی به طور مستمر جمع‌آوری و نظارت می‌شوند.
 #12.4.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که نرخ‌های موفقیت و شکست با دسته‌بندی نوع خطاها و علل ریشه‌ای آن‌ها ردیابی می‌شوند.
 #12.4.3    Level: 2    Role: D/V
 تأیید کنید که مانیتورینگ استفاده از منابع شامل مصرف GPU/CPU، مصرف حافظه و نیازهای ذخیره‌سازی باشد و اعلان‌ها هنگام تجاوز از آستانه‌ها ارسال شود.

---

### C12.5 برنامه‌ریزی و اجرای پاسخ به حوادث هوش مصنوعی

 #12.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که برنامه‌های واکنش به حوادث به طور خاص به رویدادهای امنیتی مرتبط با هوش مصنوعی از جمله نفوذ به مدل، مسمومیت داده‌ها و حملات خصمانه پرداخته‌اند.
 #12.5.2    Level: 2    Role: D/V
 تأیید کنید که تیم‌های پاسخ به حادثه به ابزارها و تخصص‌های قانونی دیجیتال خاص هوش مصنوعی دسترسی دارند تا رفتار مدل و مسیرهای حمله را بررسی کنند.
 #12.5.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تحلیل پس از حادثه شامل ملاحظات بازآموزی مدل، به‌روزرسانی فیلترهای امنیتی و ادغام درس‌های آموخته شده در کنترل‌های امنیتی باشد.

---

### C12.5 شناسایی کاهش عملکرد هوش مصنوعی

نظارت و تشخیص افت در عملکرد و کیفیت مدل هوش مصنوعی در طول زمان.

 #12.5.1    Level: 1    Role: D/V
 تأیید کنید که دقت مدل، صحت، بازخوانی و نمرات F1 به طور مداوم پایش شده و با آستانه‌های معیار مقایسه می‌شوند.
 #12.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که تشخیص تغییر داده، تغییرات توزیع ورودی را که ممکن است بر عملکرد مدل تأثیر بگذارد، نظارت می‌کند.
 #12.5.3    Level: 2    Role: D/V
 تأیید کنید که شناسایی انحراف مفهوم تغییرات در رابطه بین ورودی‌ها و خروجی‌های مورد انتظار را شناسایی می‌کند.
 #12.5.4    Level: 2    Role: D/V
 تأیید کنید که کاهش عملکرد منجر به فعال‌سازی هشدارهای خودکار شده و فرآیندهای آموزش مجدد مدل یا جایگزینی آن را آغاز می‌کند.
 #12.5.5    Level: 3    Role: V
 اطمینان حاصل کنید که تحلیل ریشه‌ای علت کاهش کیفیت، افت‌های عملکرد را با تغییرات داده‌ها، مشکلات زیرساخت یا عوامل خارجی همبستگی می‌دهد.

---

### C12.6 تجسم گراف جهت‌دار بدون حلقه (DAG) و امنیت جریان کاری

سیستم‌های نمایش جریان کاری را در برابر نشت اطلاعات و حملات دستکاری محافظت کنید.

 #12.6.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که داده‌های تجسم DAG پیش از ذخیره‌سازی یا انتقال، پاک‌سازی شده و اطلاعات حساس از آنها حذف شده باشد.
 #12.6.2    Level: 1    Role: D/V
 تأیید کنید که کنترل‌های دسترسی به تجسم گردش کار فقط به کاربران مجاز اجازه می‌دهد مسیرهای تصمیم‌گیری عامل و ردپای استدلال‌ها را مشاهده کنند.
 #12.6.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که سلامت داده‌های DAG از طریق امضاهای رمزنگاری شده و مکانیزم‌های ذخیره‌سازی ضد دستکاری محافظت می‌شود.
 #12.6.4    Level: 2    Role: D/V
 تأیید کنید که سیستم‌های تجسم گردش کار اعتبارسنجی ورودی را پیاده‌سازی می‌کنند تا از حملات تزریق از طریق داده‌های ساخته شده‌ی گره یا یال جلوگیری شود.
 #12.6.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که به‌روزرسانی‌های DAG در زمان واقعی محدودیت نرخ دارند و برای جلوگیری از حملات انکار خدمت بر روی سیستم‌های بصری‌سازی، اعتبارسنجی می‌شوند.

---

### C12.7 پایش رفتار امنیتی پیشگیرانه

شناسایی و پیشگیری از تهدیدات امنیتی از طریق تحلیل رفتاری پیش‌بینانه عامل‌ها.

 #12.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که رفتارهای فعال عامل پیش از اجرا با ادغام ارزیابی ریسک از نظر امنیتی تأیید شده‌اند.
 #12.7.2    Level: 2    Role: D/V
 تأیید کنید که محرک‌های ابتکار خودکار شامل ارزیابی زمینه امنیتی و بررسی چشم‌انداز تهدیدات می‌شود.
 #12.7.3    Level: 2    Role: D/V
 اطمینان حاصل شود که الگوهای رفتار پیشگیرانه برای پیامدهای احتمالی امنیتی و عواقب ناخواسته تحلیل شده‌اند.
 #12.7.4    Level: 3    Role: D/V
 اطمینان حاصل کنید که اقدامات پیشگیرانه حیاتی برای امنیت نیازمند زنجیره‌های تایید صریح با سوابق ممیزی هستند.
 #12.7.5    Level: 3    Role: D/V
 اطمینان حاصل کنید که شناسایی ناهنجاری رفتاری انحرافات در الگوهای عامل پیشگیرانه که ممکن است نشان‌دهنده‌ی نفوذ باشد را تشخیص می‌دهد.

---

### مراجع

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 نظارت انسانی، پاسخگویی و حاکمیت

### هدف کنترل

این فصل الزامات حفظ نظارت انسانی و زنجیره‌های شفاف مسئولیت در سیستم‌های هوش مصنوعی را ارائه می‌دهد و تضمین‌کننده قابلیت توضیح، شفافیت و مدیریت اخلاقی در طول چرخه عمر هوش مصنوعی است.

---

### C13.1 مکانیسم‌های کلید خاموش و جایگزینی

در صورت مشاهده رفتار ناامن سیستم هوش مصنوعی، مسیرهای خاموش‌سازی یا بازگشت را فراهم کنید.

 #13.1.1    Level: 1    Role: D/V
 تأیید کنید که مکانیزم قطع‌کن دستی وجود دارد که فوراً استنتاج و خروجی‌های مدل هوش مصنوعی را متوقف کند.
 #13.1.2    Level: 1    Role: D
 اطمینان حاصل کنید که کنترل‌های جایگزین فقط برای افراد مجاز قابل دسترسی هستند.
 #13.1.3    Level: 3    Role: D/V
 تأیید کنید که رویه‌های بازگردانی قادر به بازگرداندن به نسخه‌های قبلی مدل یا عملیات در حالت امن هستند.
 #13.1.4    Level: 3    Role: V
 اطمینان حاصل کنید که مکانیزم‌های جایگزینی به طور منظم آزمایش می‌شوند.

---

### C13.2 نقاط بررسی تصمیم‌گیری با حضور انسان در حلقه

در صورت عبور خطرات از آستانه‌های ریسک از پیش تعریف شده، تاییدهای انسانی را الزامی کنید.

 #13.2.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که تصمیمات پرخطر هوش مصنوعی قبل از اجرا نیازمند تأیید صریح انسانی هستند.
 #13.2.2    Level: 1    Role: D
 اطمینان حاصل کنید که آستانه‌های ریسک به‌وضوح تعریف شده‌اند و به‌طور خودکار کارهای بررسی انسانی را فعال می‌کنند.
 #13.2.3    Level: 2    Role: D
 اطمینان حاصل کنید که تصمیم‌های حساس به زمان دارای روش‌های جایگزین هستند زمانی که تایید انسانی در بازه‌های زمانی لازم قابل دریافت نباشد.
 #13.2.4    Level: 3    Role: D/V
 تأیید کنید که رویه‌های ارتقاء سطوح، سطوح اختیار واضحی برای انواع مختلف تصمیم‌گیری یا دسته‌بندی‌های ریسک تعریف کرده باشند، در صورت قابل اجرا بودن.

---

### C13.3 زنجیره مسئولیت و قابلیت حسابرسی

عملیات اپراتور و تصمیمات مدل را ثبت کنید.

 #13.3.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که همه تصمیمات سیستم هوش مصنوعی و مداخلات انسانی با زمان‌بندی، هویت کاربران و دلایل تصمیم‌گیری ثبت شده‌اند.
 #13.3.2    Level: 2    Role: D
 اطمینان حاصل کنید که لاگ‌های حسابرسی قابل دستکاری نباشند و شامل مکانیزم‌های تأیید یکپارچگی باشند.

---

### C13.4 تکنیک‌های هوش مصنوعی قابل توضیح

اهمیت ویژگی‌های سطحی، مثُل نقض‌ها (کانتر فکتوال‌ها)، و توضیحات محلی.

 #13.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی توضیحات پایه‌ای برای تصمیمات خود به صورت قابل فهم برای انسان ارائه می‌دهند.
 #13.4.2    Level: 2    Role: V
 تأیید کنید که کیفیت توضیح از طریق مطالعات ارزیابی انسانی و معیارها مورد بررسی قرار گرفته است.
 #13.4.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که امتیازهای اهمیت ویژگی یا روش‌های انتساب (مانند SHAP، LIME و غیره) برای تصمیم‌گیری‌های حیاتی در دسترس هستند.
 #13.4.4    Level: 3    Role: V
 تأیید کنید که توضیحات متضاد نشان می‌دهند چگونه ورودی‌ها می‌توانند تغییر کنند تا نتایج تغییر یابند، در صورتی که به مورد استفاده و حوزه مربوطه اعمال شود.

---

### C13.5 کارت‌های مدل و افشای نحوه استفاده

کارت‌های مدل را برای استفاده مورد نظر، معیارهای عملکرد و ملاحظات اخلاقی نگهداری کنید.

 #13.5.1    Level: 1    Role: D
 تأیید کنید که کارت‌های مدل موارد استفاده مورد نظر، محدودیت‌ها و حالت‌های شکست شناخته شده را مستند می‌کنند.
 #13.5.2    Level: 1    Role: D/V
 اطمینان حاصل کنید که معیارهای عملکرد در موارد استفاده مختلف قابل اعمال افشا شده‌اند.
 #13.5.3    Level: 2    Role: D
 اطمینان حاصل کنید که ملاحظات اخلاقی، ارزیابی‌های تعصب، ارزیابی‌های عدالت، ویژگی‌های داده‌های آموزشی و محدودیت‌های شناخته شده داده‌های آموزشی مستند شده و به‌روزرسانی می‌شوند.
 #13.5.4    Level: 2    Role: D/V
 اطمینان حاصل کنید که کارت‌های مدل در طول چرخه عمر مدل کنترل نسخه شده و با ردیابی تغییرات نگهداری می‌شوند.

---

### C13.6 کمی‌سازی عدم قطعیت

امتیازهای اطمینان یا معیارهای آنتروپی در پاسخ‌ها انتشار دهید.

 #13.6.1    Level: 1    Role: D
 اطمینان حاصل کنید که سیستم‌های هوش مصنوعی با خروجی‌های خود امتیازهای اطمینان یا معیارهای عدم قطعیت ارائه می‌دهند.
 #13.6.2    Level: 2    Role: D/V
 بررسی کنید که آیا آستانه‌های عدم قطعیت باعث فعال‌سازی بررسی بیشتر توسط انسان یا مسیرهای تصمیم‌گیری جایگزین می‌شوند.
 #13.6.3    Level: 2    Role: V
 اطمینان حاصل کنید که روش‌های کمی‌سازی عدم قطعیت، کالیبره شده و در برابر داده‌های حقیقت زمین معتبرسازی شده‌اند.
 #13.6.4    Level: 3    Role: D/V
 تأیید کنید که انتشار عدم قطعیت در جریان‌های کاری چندمرحله‌ای هوش مصنوعی حفظ می‌شود.

---

### C13.7 گزارش‌های شفافیت مواجهه با کاربر

به صورت دوره‌ای اطلاع‌رسانی‌هایی درباره حوادث، انحراف و استفاده از داده‌ها ارائه دهید.

 #13.7.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که سیاست‌های استفاده از داده‌ها و روش‌های مدیریت رضایت کاربران به وضوح به ذینفعان منتقل شده‌اند.
 #13.7.2    Level: 2    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌های تاثیر هوش مصنوعی انجام شده و نتایج آن‌ها در گزارش‌دهی درج شده است.
 #13.7.3    Level: 2    Role: D/V
 اطمینان حاصل کنید که گزارش‌های شفافیت منتشر شده به‌طور منظم، حوادث هوش مصنوعی و معیارهای عملیاتی را با جزئیات معقول افشا می‌کنند.

#### مراجع

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## پیوست الف: واژه‌نامه

این فرهنگ لغت جامع تعاریف اصطلاحات کلیدی هوش مصنوعی، یادگیری ماشین، و امنیت را که در سراسر AISVS استفاده شده‌اند، برای اطمینان از وضوح و فهم مشترک ارائه می‌دهد.
​
نمونه مخرب: ورودی که به‌طور عمدی ساخته شده است تا باعث اشتباه یک مدل هوش مصنوعی شود، اغلب با افزودن تغییرات جزئی که برای انسان‌ها قابل‌تشخیص نیستند.
​
مقاومت در برابر حملات خصمانه – مقاومت در برابر حملات خصمانه در هوش مصنوعی به توانایی یک مدل برای حفظ عملکرد خود و مقاومت در برابر فریب خوردن یا دستکاری توسط ورودی‌های مخرب، که به عمد طراحی شده‌اند تا خطا ایجاد کنند، اشاره دارد.
​
عامل – عوامل هوش مصنوعی سیستم‌های نرم‌افزاری هستند که از هوش مصنوعی برای پیگیری اهداف و انجام وظایف به نمایندگی از کاربران استفاده می‌کنند. آنها توانایی استدلال، برنامه‌ریزی و حافظه دارند و درجه‌ای از خودمختاری برای اتخاذ تصمیم، یادگیری و سازگاری را دارا هستند.
​
هوش مصنوعی عاملی: سیستم‌های هوش مصنوعی که می‌توانند با درجه‌ای از خودمختاری عمل کنند تا اهداف را دنبال کنند، اغلب تصمیم‌گیری کرده و اقداماتی را بدون دخالت مستقیم انسان انجام می‌دهند.
​
کنترل دسترسی مبتنی بر ویژگی‌ها (ABAC): یک الگوی کنترل دسترسی که تصمیم‌گیری‌های مجوزدهی بر اساس ویژگی‌های کاربر، منبع، اقدام و محیط انجام می‌شود و در زمان پرس‌وجو ارزیابی می‌گردد.
​
حمله درب‌پشتی: نوعی حمله مسموم‌سازی داده که در آن مدل به گونه‌ای آموزش می‌بیند که به محرک‌های خاصی به شکل مشخصی پاسخ دهد در حالی که در سایر موارد به طور عادی رفتار می‌کند.
​
تعصب: خطاهای سیستماتیکی در خروجی مدل‌های هوش مصنوعی که می‌توانند منجر به نتایج ناعادلانه یا تبعیض‌آمیز برای گروه‌های خاص یا در زمینه‌های مشخص شوند.
​
بهره‌برداری از تعصبات: تکنیکی حمله که از تعصبات شناخته‌شده در مدل‌های هوش مصنوعی برای دستکاری خروجی‌ها یا نتایج استفاده می‌کند.
​
Cedar: زبان سیاست و موتور آمازون برای مجوزهای دقیق در اعمال ABAC برای سیستم‌های هوش مصنوعی.
​
زنجیره تفکر: یک تکنیک برای بهبود استدلال در مدل‌های زبانی با تولید گام‌های میانی استدلال قبل از ارائه پاسخ نهایی.
​
قطع‌کننده‌ها: مکانیزم‌هایی که به‌طور خودکار عملیات سیستم هوش مصنوعی را زمانی که آستانه‌های ریسک خاصی بیشتر شوند، متوقف می‌کنند.
​
نشت داده: افشای ناخواسته اطلاعات حساس از طریق خروجی‌ها یا رفتار مدل هوش مصنوعی.
​
آلوده‌سازی داده‌ها: فساد عمدی داده‌های آموزشی به منظور آسیب رساندن به یکپارچگی مدل، که اغلب به منظور نصب درهای پشتی یا کاهش عملکرد انجام می‌شود.
​
حریم خصوصی تفاضلی – حریم خصوصی تفاضلی چارچوبی ریاضیاتی دقیق برای انتشار اطلاعات آماری درباره داده‌ها است در حالی که حریم خصوصی افراد را حفظ می‌کند. این چارچوب به دارنده داده امکان می‌دهد الگوهای تجمعی گروه را به اشتراک بگذارد در حالی که اطلاعاتی که درباره افراد خاص فاش می‌شود را محدود می‌کند.
​
بردارهای جاسازی شده: نمایش‌های برداری متراکم از داده‌ها (متن، تصاویر و غیره) که معنای معنایی را در فضای با ابعاد بالا ثبت می‌کنند.
​
توضیح‌پذیری – توضیح‌پذیری در هوش مصنوعی به توانایی یک سیستم هوش مصنوعی در ارائه دلایل قابل فهم برای انسان‌ها درباره تصمیمات و پیش‌بینی‌هایش گفته می‌شود، که بینشی در مورد عملکرد درونی آن ارائه می‌دهد.
​
هوش مصنوعی قابل تبیین (XAI): سیستم‌های هوش مصنوعی که به منظور ارائه توضیحات قابل درک برای انسان درباره تصمیمات و رفتارهای خود، از طریق تکنیک‌ها و چارچوب‌های مختلف طراحی شده‌اند.
​
یادگیری فدرال: رویکردی در یادگیری ماشین که در آن مدل‌ها بر روی دستگاه‌های غیرمتمرکز متعدد که نمونه‌های داده محلی را نگه می‌دارند آموزش داده می‌شوند، بدون اینکه خود داده‌ها مبادله شوند.
​
محدودیت‌ها: قیدهایی که به منظور جلوگیری از تولید خروجی‌های مضر، جانبدارانه یا سایر خروجی‌های نامطلوب توسط سیستم‌های هوش مصنوعی اعمال می‌شوند.
​
توهم – توهم هوش مصنوعی به پدیده‌ای اطلاق می‌شود که در آن یک مدل هوش مصنوعی اطلاعات نادرست یا گمراه‌کننده‌ای تولید می‌کند که بر اساس داده‌های آموزشی یا واقعیت‌های عینی نیست.
​
انسان در حلقه (HITL): سیستم‌هایی که برای نیاز به نظارت، تأیید یا مداخله انسانی در نقاط تصمیم‌گیری حیاتی طراحی شده‌اند.
​
زیرساخت به عنوان کد (IaC): مدیریت و تأمین زیرساخت از طریق کد به جای فرآیندهای دستی، که امکان اسکن امنیتی و استقرارهای سازگار را فراهم می‌کند.
​
جیل‌بریک: تکنیک‌هایی که برای دور زدن سدهای ایمنی در سیستم‌های هوش مصنوعی، به‌ویژه در مدل‌های زبان بزرگ، استفاده می‌شوند تا محتوای ممنوعه تولید کنند.
​
حداقل امتیاز: اصل امنیتی اعطای فقط حداقل حقوق دسترسی لازم به کاربران و فرایندها.
​
LIME (توضیحات قابل تفسیر مدل-عام محلی): تکنیکی برای توضیح پیش‌بینی‌های هر طبقه‌بند یادگیری ماشین با تقریب زدن محلی آن با یک مدل قابل تفسیر.
​
حمله استنتاج عضویت: حمله‌ای که هدف آن تعیین این است که آیا یک داده مشخص در آموزش مدل یادگیری ماشین استفاده شده است یا خیر.
​
MITRE ATLAS: چشم‌انداز تهدیدات خصمانه برای سیستم‌های هوش مصنوعی؛ یک پایگاه دانش از تاکتیک‌ها و تکنیک‌های خصمانه علیه سیستم‌های هوش مصنوعی.
​
کارت مدل – کارت مدل یک سند است که اطلاعات استاندارد شده‌ای درباره عملکرد مدل هوش مصنوعی، محدودیت‌ها، کاربردهای مورد نظر و ملاحظات اخلاقی آن ارائه می‌دهد تا شفافیت و توسعه مسئولانه هوش مصنوعی را ترویج کند.
​
استخراج مدل: حمله‌ای که در آن یک مهاجم به طور مکرر به مدل هدف پرسش می‌دهد تا نسخه‌ای عملکردی مشابه و بدون اجازه از آن ایجاد کند.
​
معکوس‌سازی مدل: حمله‌ای که با تحلیل خروجی‌های مدل تلاش می‌کند داده‌های آموزشی را بازسازی کند.
​
مدیریت چرخه عمر مدل – مدیریت چرخه عمر مدل هوش مصنوعی فرآیند نظارت بر تمام مراحل وجود یک مدل هوش مصنوعی است، از جمله طراحی، توسعه، استقرار، نظارت، نگهداری و نهایتاً بازنشستگی آن، به منظور اطمینان از اینکه مدل همچنان مؤثر و هم‌راستا با اهداف باقی می‌ماند.
​
آلوده‌سازی مدل: وارد کردن آسیب‌پذیری‌ها یا درهای پشتی به طور مستقیم در یک مدل طی فرآیند آموزش.
​
سرقت/دزدیدن مدل: استخراج نسخه یا تقریب مدل اختصاصی از طریق پرس‌وجوهای مکرر.
​
سامانه چندعامله: سیستمی متشکل از چندین عامل هوش مصنوعی تعاملی که هر کدام ممکن است قابلیت‌ها و اهداف متفاوتی داشته باشند.
​
OPA (اپن پالیسی ایجنت): یک موتور سیاست منبع باز که امکان اجرای یکپارچه سیاست‌ها در سراسر پشته را فراهم می‌کند.
​
یادگیری ماشین حفظ حریم خصوصی (PPML): تکنیک‌ها و روش‌هایی برای آموزش و استقرار مدل‌های یادگیری ماشین با حفظ حریم خصوصی داده‌های آموزشی.
​
تزریق پرامپت: حمله‌ای که در آن دستورالعمل‌های مخرب در ورودی‌ها جاسازی می‌شوند تا رفتار مورد نظر مدل را لغو کنند.
​
RAG (تولید تقویت‌شده با بازیابی): تکنیکی که مدل‌های زبان بزرگ را با بازیابی اطلاعات مرتبط از منابع دانش خارجی قبل از تولید پاسخ، بهبود می‌بخشد.
​
رد تیمینگ: عملیاتی که شامل آزمایش فعال سیستم‌های هوش مصنوعی با شبیه‌سازی حملات خصمانه برای شناسایی آسیب‌پذیری‌ها است.
​
فهرست مواد نرم‌افزاری (SBOM): یک سند رسمی حاوی جزئیات و روابط زنجیره تأمین اجزای مختلف استفاده شده در ساخت نرم‌افزار یا مدل‌های هوش مصنوعی.
​
SHAP (توضیحات جبرانی شاپلی): رویکردی مبتنی بر نظریه بازی‌ها برای تبیین خروجی هر مدل یادگیری ماشین با محاسبه سهم هر ویژگی در پیش‌بینی.
​
حمله زنجیره تامین: به خطر انداختن یک سیستم با هدف قرار دادن عناصر کمتر امن در زنجیره تامین آن، مانند کتابخانه‌های شخص ثالث، مجموعه داده‌ها یا مدل‌های پیش‌آموزش‌دیده.
​
یادگیری انتقالی: تکنیکی که در آن مدل توسعه یافته برای یک وظیفه به عنوان نقطه شروع برای مدل‌سازی روی وظیفه دوم مورد استفاده مجدد قرار می‌گیرد.
​
پایگاه داده برداری: یک پایگاه داده تخصصی طراحی شده برای ذخیره بردارهای با ابعاد بالا (برداشت‌ها) و انجام جستجوی مشابهت به صورت کارآمد.
​
اسکن آسیب‌پذیری: ابزارهای خودکار که آسیب‌پذیری‌های امنیتی شناخته‌شده در اجزای نرم‌افزاری، از جمله چارچوب‌ها و وابستگی‌های هوش مصنوعی را شناسایی می‌کنند.
​
واترمارکینگ: تکنیک‌هایی برای جاسازی نشانگرهای غیرقابل‌تشخیص در محتوای تولیدشده توسط هوش مصنوعی به منظور ردیابی منبع آن یا شناسایی تولید توسط هوش مصنوعی.
​
آسیب‌پذیری صفر روزه: آسیب‌پذیری‌ای که قبلاً ناشناخته بوده و مهاجمان می‌توانند پیش از آنکه توسعه‌دهندگان وصله‌ای ایجاد و اعمال کنند، از آن سوءاستفاده نمایند.

## پیوست ب: مراجع

### TODO

## ضمیمه ج: حاکمیت و مستندسازی امنیت هوش مصنوعی

### هدف

این پیوست الزامات بنیادی برای ایجاد ساختارهای سازمانی، سیاست‌ها و فرآیندها به منظور حاکمیت امنیت هوش مصنوعی در طول چرخه عمر سیستم را ارائه می‌دهد.

---

### AC.1 پذیرش چارچوب مدیریت ریسک هوش مصنوعی

ارائه چارچوبی رسمی برای شناسایی، ارزیابی و کاهش خطرات خاص هوش مصنوعی در طول چرخه عمر سیستم.

 #AC.1.1    Level: 1    Role: D/V
 تأیید کنید که روش‌شناسی ارزیابی ریسک مخصوص هوش مصنوعی مستند شده و اجرا می‌شود.
 #AC.1.2    Level: 2    Role: D
 اطمینان حاصل کنید که ارزیابی‌های ریسک در نقاط کلیدی چرخه عمر هوش مصنوعی و پیش از تغییرات مهم انجام می‌شود.
 #AC.1.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که چارچوب مدیریت ریسک با استانداردهای پذیرفته شده (مانند چارچوب مدیریت ریسک هوش مصنوعی NIST) هماهنگ است.

---

### AC.2 سیاست‌ها و رویه‌های امنیتی هوش مصنوعی

تعریف و اجرای استانداردهای سازمانی برای توسعه، استقرار و عملکرد امن هوش مصنوعی.

 #AC.2.1    Level: 1    Role: D/V
 تأیید کنید که سیاست‌های مستند امنیت هوش مصنوعی وجود دارد.
 #AC.2.2    Level: 2    Role: D
 اطمینان حاصل کنید که سیاست‌ها حداقل سالی یک‌بار و پس از تغییرات قابل توجه در منظره تهدیدها مرور و به‌روزرسانی شوند.
 #AC.2.3    Level: 3    Role: D/V
 تأیید کنید که سیاست‌ها تمام دسته‌بندی‌های AISVS و الزامات قانونی مرتبط را پوشش می‌دهند.

---

### AC.3 نقش‌ها و مسئولیت‌ها در امنیت هوش مصنوعی

مسئولیت‌پذیری روشن برای امنیت هوش مصنوعی در سراسر سازمان برقرار کنید.

 #AC.3.1    Level: 1    Role: D/V
 تأیید کنید که نقش‌ها و مسئولیت‌های امنیتی هوش مصنوعی مستند شده‌اند.
 #AC.3.2    Level: 2    Role: D
 تأیید کنید که افراد مسئول دارای تخصص امنیتی مناسب هستند.
 #AC.3.3    Level: 3    Role: D/V
 تأیید کنید که یک کمیته اخلاق هوش مصنوعی یا هیئت حاکمیتی برای سیستم‌های هوش مصنوعی با ریسک بالا تشکیل شده است.

---

### اجرای دستورالعمل‌های اخلاقی هوش مصنوعی AC.4

اطمینان حاصل کنید که سیستم‌های هوش مصنوعی مطابق با اصول اخلاقی تعیین‌شده عمل کنند.

 #AC.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که دستورالعمل‌های اخلاقی برای توسعه و استقرار هوش مصنوعی وجود دارد.
 #AC.4.2    Level: 2    Role: D
 اطمینان حاصل کنید که مکانیزم‌هایی برای شناسایی و گزارش نقض‌های اخلاقی وجود دارد.
 #AC.4.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که مرورهای اخلاقی منظم بر روی سیستم‌های هوش مصنوعی مستقر شده انجام می‌شود.

---

### نظارت بر انطباق با مقررات هوش مصنوعی AC.5

آگاهی و رعایت قوانین در حال تکامل هوش مصنوعی را حفظ کنید.

 #AC.5.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که فرآیندهایی برای شناسایی مقررات قابل‌اجرا در زمینه هوش مصنوعی وجود دارد.
 #AC.5.2    Level: 2    Role: D
 اطمینان حاصل کنید که رعایت تمام الزامات قانونی ارزیابی شده است.
 #AC.5.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تغییرات نظارتی موجب بررسی‌ها و به‌روزرسانی‌های به‌موقع سیستم‌های هوش مصنوعی می‌شوند.

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## پیوست د: حاکمیت و تأیید کدگذاری امن با کمک هوش مصنوعی

### هدف

این فصل کنترل‌های سازمانی پایه را برای استفاده ایمن و مؤثر از ابزارهای کدنویسی مبتنی بر هوش مصنوعی در طول توسعه نرم‌افزار تعریف می‌کند تا امنیت و قابل ردیابی بودن در سراسر چرخه عمر توسعه نرم‌افزار را تضمین کند.

---

### AD.1 جریان کاری رمزگذاری ایمن با کمک هوش مصنوعی

ابزارهای هوش مصنوعی را در چرخه عمر توسعه نرم‌افزار امن سازمان (SSDLC) ادغام کنید بدون اینکه نقاط کنترل امنیتی موجود را تضعیف کنید.

 #AD.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که یک روند کاری مستند شده شرح می‌دهد چه زمانی و چگونه ابزارهای هوش مصنوعی ممکن است کد را تولید، بازسازی یا مرور کنند.
 #AD.1.2    Level: 2    Role: D
 تأیید کنید که جریان کاری به هر مرحله از چرخه توسعه نرم‌افزار امن شده (SSDLC) مرتبط باشد (طراحی، پیاده‌سازی، بازبینی کد، تست، استقرار).
 #AD.1.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که معیارها (مانند چگالی آسیب‌پذیری، میانگین زمان تشخیص) بر روی کد تولید شده توسط هوش مصنوعی جمع‌آوری شده و با معیارهای پایه‌ی صرفاً انسانی مقایسه می‌شوند.

---

### AD.2 صلاحیت ابزار هوش مصنوعی و مدل‌سازی تهدید

اطمینان حاصل کنید که ابزارهای برنامه‌نویسی هوش مصنوعی قبل از استفاده، از نظر قابلیت‌های امنیتی، ریسک و تأثیر بر زنجیره تامین ارزیابی شوند.

 #AD.2.1    Level: 1    Role: D/V
 تأیید کنید که مدل تهدید برای هر ابزار هوش مصنوعی، سوءاستفاده، وارونگی مدل، نشت داده و خطرات زنجیره وابستگی را شناسایی می‌کند.
 #AD.2.2    Level: 2    Role: D
 تأیید کنید که ارزیابی‌های ابزار شامل تحلیل ایستا/پویا از هر مؤلفه محلی و ارزیابی نقاط انتهایی SaaS (TLS، احراز هویت/مجوزدهی، ثبت لاگ) باشد.
 #AD.2.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که ارزیابی‌ها بر اساس یک چارچوب شناخته‌شده انجام می‌شوند و پس از تغییرات عمده نسخه مجدداً انجام می‌گیرند.

---

### AD.3 مدیریت امن نمایش و زمینه

از نشت اسرار، کد اختصاصی و داده‌های شخصی هنگام ساختن پرامپت‌ها یا زمینه‌ها برای مدل‌های هوش مصنوعی جلوگیری کنید.

 #AD.3.1    Level: 1    Role: D/V
 تأیید کنید که دستورالعمل‌های مکتوب ارسال اسرار، مدارک شناسایی یا داده‌های محرمانه در درخواست‌ها را ممنوع می‌کند.
 #AD.3.2    Level: 2    Role: D
 تأیید کنید که کنترل‌های فنی (حذف اطلاعات در سمت کاربر، فیلترهای زمینه تأیید شده) به‌صورت خودکار آثار حساس را حذف می‌کنند.
 #AD.3.3    Level: 3    Role: D/V
 تأیید کنید که پرسش‌ها و پاسخ‌ها توکنیزه شده، در حین انتقال و در حالت ذخیره رمزگذاری شده‌اند و دوره‌های نگهداری مطابق با سیاست دسته‌بندی داده‌ها هستند.

---

### AD.4 اعتبارسنجی کد تولیدشده توسط هوش مصنوعی

شناسایی و رفع آسیب‌پذیری‌های ایجاد شده توسط خروجی هوش مصنوعی پیش از ادغام یا استقرار کد.

 #AD.4.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که کد تولیدشده توسط هوش مصنوعی همواره تحت بازبینی کد توسط انسان قرار می‌گیرد.
 #AD.4.2    Level: 2    Role: D
 اطمینان حاصل کنید که اسکنرهای خودکار (SAST/IAST/DAST) بر روی هر درخواست کششی که شامل کد تولید شده توسط هوش مصنوعی است اجرا می‌شوند و ادغام‌ها را در صورت وجود یافته‌های بحرانی مسدود می‌کنند.
 #AD.4.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که تست‌های فازینگ تفاضلی یا تست‌های مبتنی بر ویژگی، رفتارهای حیاتی امنیتی مانند اعتبارسنجی ورودی و منطق تأیید هویت را اثبات می‌کنند.

---

### AD.5 قابل تبیین بودن و قابلیت ردیابی پیشنهادات کد

به حسابرسان و توسعه‌دهندگان دیدگاهی ارائه دهید درباره اینکه چرا یک پیشنهاد مطرح شده است و چگونه توسعه یافته است.

 #AD.5.1    Level: 1    Role: D/V
 تأیید کنید که جفت‌های درخواست/پاسخ با شناسه‌های تعهد (commit IDs) ثبت شده‌اند.
 #AD.5.2    Level: 2    Role: D
 تأیید کنید که توسعه‌دهندگان می‌توانند ارجاعات مدل (بخش‌های آموزشی، مستندات) که پیشنهاد را پشتیبانی می‌کنند، نمایش دهند.
 #AD.5.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که گزارش‌های تبیینی همراه با مستندات طراحی ذخیره شده و در بازبینی‌های امنیتی ارجاع داده می‌شوند، به طوری که اصول قابلیت ردیابی استاندارد ISO/IEC 42001 را برآورده کنند.

---

### AD.6 بازخورد مستمر و تنظیم دقیق مدل

بهبود عملکرد امنیت مدل در طول زمان در حالی که از انحراف منفی جلوگیری می‌شود.

 #AD.6.1    Level: 1    Role: D/V
 بررسی کنید که توسعه‌دهندگان بتوانند پیشنهادات ناامن یا غیرسازگار را علامت‌گذاری کنند و اینکه این علامت‌گذاری‌ها پیگیری می‌شوند.
 #AD.6.2    Level: 2    Role: D
 اطمینان حاصل کنید که بازخورد تجمیع شده به آموزش دقیق دوره‌ای یا تولید با بازیابی تقویت‌شده با مجموعه داده‌های کدنویسی امن بررسی شده (مانند OWASP Cheat Sheets) اطلاع می‌دهد.
 #AD.6.3    Level: 3    Role: D/V
 اطمینان حاصل کنید که بسترسنجی ارزیابی حلقه بسته پس از هر بار تنظیم دقیق، آزمایش‌های رگرسیون را اجرا می‌کند؛ شاخص‌های امنیتی باید قبل از استقرار با یا بهتر از معیارهای پایه قبلی باشند.

---

#### مراجع

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## ضمیمه E: نمونه ابزارها و چارچوب‌ها

### هدف

این فصل نمونه‌هایی از ابزارها و چارچوب‌هایی را ارائه می‌دهد که می‌توانند از پیاده‌سازی یا تحقق یک نیازمندی مشخص شده در AISVS پشتیبانی کنند. این موارد نباید به عنوان توصیه یا تائید از سوی تیم AISVS یا پروژه امنیتی OWASP GenAI تلقی شوند.

---

### آموزش حاکمیت داده‌ها و مدیریت تعصب (AE.1)

ابزارهای مورد استفاده برای تحلیل داده‌ها، حاکمیت و مدیریت تعصب.

 #AE.1.1    Section: 1.1
 ابزار مدیریت موجودی داده: ابزارهایی برای مدیریت موجودی داده مانند...
 #AE.1.2    Section: 1.2
 رمزنگاری در حین انتقال از TLS برای برنامه‌های مبتنی بر HTTPS استفاده کنید، با ابزارهایی مانند openSSL و کتابخانه پایتون`ssl`کتابخانه.

---

### اعتبارسنجی ورودی کاربر AE.2

ابزاری برای مدیریت و اعتبارسنجی ورودی‌های کاربر.

 #AE.2.1    Section: 2.1
 ابزارهای دفاع در برابر تزریق فرمان: از ابزارهای حفاظتی مانند NeMo شرکت NVIDIA یا Guardrails AI استفاده کنید.

---

## مدیریت داده‌های آموزشی C1 و مدیریت تعصب

### C1.1 منشأ داده‌های آموزش

نگهداری فهرست قابل تایید از تمامی مجموعه داده‌ها، پذیرش تنها منابع معتبر، و ثبت هر تغییر برای قابلیت ممیزی.

 #1.1.1    Level: 1    Role: D/V
 اطمینان حاصل کنید که یک فهرست به‌روز از هر منبع داده آموزشی (مبدا، مسئول/مالک، مجوز، روش گردآوری، محدودیت‌های استفاده مورد نظر، و تاریخچه پردازش) نگهداری می‌شود.

