# Priekšteikums

Laipni lūdzam Mākslīgā intelekta drošības pārbaudes standartā (AISVS) versija 1.0!

## Ievads

Izveidota 2025. gadā kā kopīgs kopienas centiens, AISVS nosaka drošības prasības, kuras jāņem vērā, izstrādājot, izstrādājot, ieviešot un pārvaldot modernas mākslīgā intelekta (MI) modeļus, datu apstrādes ķēdes un MI iespējas nodrošinošus pakalpojumus.

AISVS v1.0 apvieno tā projekta vadītāju, darba grupas un plašākas kopienas līdzgaitnieku kopīgo darbu, lai izveidotu pragmatisku, pārbaudāmu bāzi AI sistēmu drošības nodrošināšanai.

Mūsu mērķis ar šo versiju ir padarīt AISVS viegli pieejamu, vienlaikus stingri koncentrējoties uz tā noteikto darbības jomu un risinot strauji mainīgo AI īpašo risku ainavu.

## Galvenie mērķi AISVS 1.0 versijai

Versija 1.0 tiks izveidota, balstoties uz vairākām vadlīnijām.

### Precīzi definēts darbības lauks

Katram prasījumam jāatbilst AISVS nosaukumam un misijai:

* Mākslīgais intelekts – Kontroles darbojas AI/ML slānī (datu, modeļa, cauruļvada vai secinājuma līmenī) un ir AI praktiķu atbildība.
* Drošība – prasības tieši mazinās identificētos drošības, privātuma vai drošības riskus.
* Verifikācija – valoda ir rakstīta tā, lai atbilstību varētu objektīvi pārbaudīt.
* Standarts – sadaļas seko konsekventai struktūrai un terminoloģijai, veidojot saskaņotu atsauci.
  ​
---

Sekojot AISVS, organizācijas var sistemātiski novērtēt un stiprināt savu AI risinājumu drošības stāvokli, veicinot drošas AI izstrādes kultūru.

