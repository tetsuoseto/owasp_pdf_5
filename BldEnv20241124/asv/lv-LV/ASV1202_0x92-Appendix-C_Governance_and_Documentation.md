# Pielikums C: Mākslīgā intelekta drošības pārvaldība un dokumentācija

## Mērķis

Šī pielikuma sadaļa sniedz pamatprasības organizatorisko struktūru, politiku un procesu izveidei, lai pārvaldītu mākslīgā intelekta drošību visā sistēmas dzīves ciklā.

---

## AC.1 Mākslīgā intelekta riska pārvaldības ietvara pieņemšana

Nodrošināt formālu ietvaru, lai identificētu, novērtētu un mazinātu mākslīgā intelekta specifiskos riskus visā sistēmas dzīves ciklā.

|   #    | Description                                                                                                   | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.1.1 | Pārliecinieties, ka ir dokumentēta un ieviesta AI specifiska riska novērtēšanas metodoloģija.                 |   1   | D/V  |
| AC.1.2 | Pārliecinieties, ka riska novērtējumi tiek veikti svarīgos AI dzīves cikla posmos un pirms būtiskām izmaiņām. |   2   |  D   |
| AC.1.3 | Pārbaudiet, vai riska pārvaldības sistēma atbilst noteiktajiem standartiem (piemēram, NIST AI RMF).           |   3   | D/V  |

---

## AC.2 Mākslīgā intelekta drošības politika un procedūras

Noteikt un īstenot organizācijas standartus drošai mākslīgā intelekta izstrādei, izvietošanai un darbībai.

|   #    | Description                                                                                                               | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.2.1 | Pārliecinieties, ka pastāv dokumentētas mākslīgā intelekta drošības politikas.                                            |   1   | D/V  |
| AC.2.2 | Pārliecinieties, ka politikas tiek pārskatītas un atjauninātas vismaz reizi gadā un pēc būtiskām draudu ainavas izmaiņām. |   2   |  D   |
| AC.2.3 | Pārbaudiet, vai politikas aptver visas AISVS kategorijas un piemērojamas normatīvās prasības.                             |   3   | D/V  |

---

## AC.3 Lomas un atbildība par Mākslīgā intelekta drošību

Nodrošiniet skaidru atbildību par mākslīgā intelekta drošību visā organizācijā.

|   #    | Description                                                                                          | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.3.1 | Pārliecinieties, ka AI drošības lomas un atbildības ir dokumentētas.                                 |   1   | D/V  |
| AC.3.2 | Pārbaudiet, vai atbildīgajām personām ir atbilstoša drošības ekspertīze.                             |   2   |  D   |
| AC.3.3 | Pārliecinieties, ka ir izveidota AI ētikas komiteja vai pārvaldības padome augsta riska AI sistēmām. |   3   | D/V  |

---

## AC.4 Ētiskās Mākslīgā Intelekta Vadlīniju Ievērošana

Nodrošiniet, ka AI sistēmas darbojas saskaņā ar izveidotajiem ētiskajiem principiem.

|   #    | Description                                                                                        | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.4.1 | Pārliecinieties, ka pastāv ētikas vadlīnijas mākslīgā intelekta izstrādei un ieviešanai.           |   1   | D/V  |
| AC.4.2 | Pārliecinieties, ka ir ieviesti mehānismi, lai atklātu un ziņotu par ētikas pārkāpumiem.           |   2   |  D   |
| AC.4.3 | Pārliecinieties, ka veikti regulāri ētiskie pārskati par izvietotajām mākslīgā intelekta sistēmām. |   3   | D/V  |

---

## AC.5 Mākslīgā intelekta normatīvās atbilstības uzraudzība

Uzturi apziņu un atbilstību mainīgajiem mākslīgā intelekta regulējumiem.

|   #    | Description                                                                                                         | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| AC.5.1 | Pārbaudiet, vai pastāv procesi, lai identificētu piemērojamos AI regulējumus.                                       |   1   | D/V  |
| AC.5.2 | Pārliecinieties, ka tiek veikta atbilstības pārbaude visām reglamenta prasībām.                                     |   2   |  D   |
| AC.5.3 | Pārbaudiet, vai normatīvo aktu izmaiņas izsauc savlaicīgas pārbaudes un atjauninājumus mākslīgā intelekta sistēmās. |   3   | D/V  |

### Atsauces

* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)

