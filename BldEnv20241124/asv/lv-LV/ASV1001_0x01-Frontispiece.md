# Priekšvāks

## Par standartu

Mākslīgā intelekta drošības pārbaudes standarts (AISVS) ir kopienas vadīts drošības prasību katalogs, ko var izmantot datu zinātnieki, MLOps inženieri, programmatūras arhitekti, izstrādātāji, testētāji, drošības speciālisti, rīku piegādātāji, regulatori un patērētāji, lai izstrādātu, būvētu, testētu un pārbaudītu uzticamas mākslīgā intelekta sistēmas un lietojumprogrammas. Tas nodrošina kopīgu valodu drošības kontroles prasību noteikšanai visā MI dzīves ciklā — no datu vākšanas un modeļa izstrādes līdz izvietošanai un pastāvīgai uzraudzībai — ļaujot organizācijām novērtēt un uzlabot sava mākslīgā intelekta risinājumu izturību, privātumu un drošību.

## Autortiesības un licence

Versija 0.1 (Pirmais publiskais melnraksts - Darba procesā), 2025  

![license](../images/license.png)

Autortiesības © 2025 AISVS projekts.  

Izlaists zem[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Jebkurai atkārtotai izmantošanai vai izplatīšanai jums skaidri jānorāda šī darba licences nosacījumi citiem.

## Projektu vadītāji

|              |                         |
| ------------ | ----------------------- |
| Džims Maniko | Aras “Russ” Memisyazici |

## Līdzdarbinieki un recenzenti

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS ir pilnīgi jauns standarts, kas izveidots īpaši, lai risinātu mākslīgā intelekta sistēmu unikālās drošības problēmas. Lai gan tas iedvesmojas no vispārīgākām drošības labākās prakses vadlīnijām, katrs AISVS prasības punkts ir izstrādāts no jauna, lai atspoguļotu mākslīgā intelekta draudu ainavu un palīdzētu organizācijām izveidot drošākus, izturīgākus AI risinājumus.

