# Phụ lục A: Bảng chú giải thuật ngữ

> Bảng thuật ngữ toàn diện này cung cấp định nghĩa các thuật ngữ chính về trí tuệ nhân tạo (AI), học máy (ML) và bảo mật được sử dụng trong toàn bộ AISVS nhằm đảm bảo sự rõ ràng và hiểu biết chung.
> ​
* Ví dụ đối kháng: Một đầu vào được tạo ra có chủ ý nhằm khiến mô hình AI mắc lỗi, thường bằng cách thêm các biến đổi tinh vi mà con người không thể nhận thấy.
  ​
* Độ bền chống lại tấn công đối kháng – Độ bền chống lại tấn công đối kháng trong AI đề cập đến khả năng của một mô hình duy trì hiệu suất và chống lại việc bị đánh lừa hoặc thao túng bởi các đầu vào độc hại được tạo ra có chủ ý nhằm gây ra lỗi.
  ​
* Tác nhân – Tác nhân AI là các hệ thống phần mềm sử dụng trí tuệ nhân tạo để theo đuổi các mục tiêu và hoàn thành các nhiệm vụ thay mặt người dùng. Chúng thể hiện khả năng lý luận, lập kế hoạch và ghi nhớ, đồng thời có mức độ tự chủ để đưa ra quyết định, học hỏi và thích nghi.
  ​
* AI có tính tác nhân: Các hệ thống AI có thể hoạt động với một mức độ tự chủ nhất định để đạt được mục tiêu, thường đưa ra quyết định và thực hiện hành động mà không cần sự can thiệp trực tiếp của con người.
  ​
* Kiểm soát Truy cập Dựa trên Thuộc tính (ABAC): Một mô hình kiểm soát truy cập trong đó các quyết định ủy quyền dựa trên các thuộc tính của người dùng, tài nguyên, hành động và môi trường, được đánh giá tại thời điểm truy vấn.
  ​
* Tấn công Cửa hậu: Một loại tấn công đầu độc dữ liệu trong đó mô hình được huấn luyện để phản ứng theo một cách cụ thể với các kích hoạt nhất định trong khi vẫn hoạt động bình thường ở các trường hợp khác.
  ​
* Định kiến: Các lỗi hệ thống trong đầu ra của mô hình AI có thể dẫn đến kết quả không công bằng hoặc phân biệt đối xử đối với một số nhóm hoặc trong các bối cảnh cụ thể.
  ​
* Khai thác định kiến: Một kỹ thuật tấn công lợi dụng các định kiến đã biết trong các mô hình AI để điều khiển kết quả đầu ra hoặc kết quả tổng thể.
  ​
* Cedar: Ngôn ngữ và công cụ chính sách của Amazon cho các quyền truy cập chi tiết được sử dụng trong việc triển khai ABAC cho các hệ thống AI.
  ​
* Chuỗi suy nghĩ: Một kỹ thuật để cải thiện khả năng lý luận trong các mô hình ngôn ngữ bằng cách tạo ra các bước suy luận trung gian trước khi đưa ra câu trả lời cuối cùng.
  ​
* Rơle ngắt mạch: Cơ chế tự động dừng hoạt động của hệ thống AI khi vượt quá ngưỡng rủi ro cụ thể.
  ​
* Rò rỉ dữ liệu: Tiếp xúc không mong muốn với thông tin nhạy cảm thông qua kết quả hoặc hành vi của mô hình AI.
  ​
* Độc hại dữ liệu: Việc cố ý làm hỏng dữ liệu huấn luyện để làm suy giảm tính toàn vẹn của mô hình, thường nhằm cài đặt cửa hậu hoặc làm giảm hiệu suất.
  ​
* Bảo mật vi sai – Bảo mật vi sai là một khuôn khổ toán học nghiêm ngặt để công bố thông tin thống kê về các bộ dữ liệu trong khi bảo vệ quyền riêng tư của các cá nhân trong dữ liệu. Nó cho phép người giữ dữ liệu chia sẻ các mẫu tổng hợp của nhóm trong khi giới hạn thông tin bị rò rỉ về các cá nhân cụ thể.
  ​
* Embedding: Biểu diễn vector dày đặc của dữ liệu (văn bản, hình ảnh, v.v.) để nắm bắt ý nghĩa ngữ nghĩa trong không gian chiều cao.
  ​
* Giải thích được – Giải thích được trong AI là khả năng của hệ thống AI cung cấp các lý do dễ hiểu đối với con người cho các quyết định và dự đoán của nó, đồng thời cung cấp cái nhìn sâu sắc về cách hoạt động bên trong của hệ thống.
  ​
* Trí tuệ nhân tạo có thể giải thích được (XAI): Hệ thống AI được thiết kế để cung cấp các giải thích mà con người có thể hiểu được về các quyết định và hành vi của chúng thông qua các kỹ thuật và khung làm việc khác nhau.
  ​
* Học Liên Liên Đới: Một phương pháp học máy trong đó các mô hình được huấn luyện trên nhiều thiết bị phân tán giữ các mẫu dữ liệu cục bộ, mà không trao đổi dữ liệu gốc.
  ​
* Hàng rào bảo vệ: Các giới hạn được áp dụng để ngăn hệ thống AI tạo ra các kết quả gây hại, thiên vị hoặc không mong muốn khác.
  ​
* Ảo giác – Ảo giác AI đề cập đến hiện tượng một mô hình AI tạo ra thông tin không chính xác hoặc gây hiểu lầm, không dựa trên dữ liệu đào tạo của nó hoặc thực tế khách quan.
  ​
* Con người tham gia trực tiếp (HITL): Hệ thống được thiết kế đòi hỏi sự giám sát, xác minh hoặc can thiệp của con người tại các điểm quyết định quan trọng.
  ​
* Hạ tầng dưới dạng mã (IaC): Quản lý và cung cấp hạ tầng thông qua mã thay vì quy trình thủ công, cho phép quét bảo mật và triển khai nhất quán.
  ​
* Jailbreak: Các kỹ thuật được sử dụng để vượt qua các hàng rào an toàn trong hệ thống AI, đặc biệt là trong các mô hình ngôn ngữ lớn, nhằm tạo ra nội dung bị cấm.
  ​
* Nguyên tắc Ít Quyền: Nguyên tắc bảo mật chỉ cấp quyền truy cập tối thiểu cần thiết cho người dùng và các tiến trình.
  ​
* LIME (Giải thích Mô hình Độc lập tại cục bộ): Một kỹ thuật để giải thích các dự đoán của bất kỳ bộ phân loại học máy nào bằng cách xấp xỉ nó tại khu vực cục bộ với một mô hình có thể giải thích được.
  ​
* Cuộc tấn công suy luận thành viên: Một cuộc tấn công nhằm xác định xem một điểm dữ liệu cụ thể có được sử dụng để đào tạo mô hình học máy hay không.
  ​
* MITRE ATLAS: Cảnh quan mối đe dọa đối kháng cho hệ thống Trí tuệ Nhân tạo; một cơ sở tri thức về các chiến thuật và kỹ thuật đối kháng chống lại hệ thống AI.
  ​
* Thẻ Mô Hình – Thẻ mô hình là một tài liệu cung cấp thông tin chuẩn hóa về hiệu suất của mô hình AI, các hạn chế, các mục đích sử dụng dự kiến và các cân nhắc đạo đức nhằm thúc đẩy sự minh bạch và phát triển AI có trách nhiệm.
  ​
* Chiết xuất mô hình: Một cuộc tấn công mà kẻ thù liên tục truy vấn một mô hình mục tiêu để tạo ra một bản sao có chức năng tương tự mà không được phép.
  ​
* Đảo ngược mô hình: Một cuộc tấn công cố gắng tái tạo dữ liệu huấn luyện bằng cách phân tích đầu ra của mô hình.
  ​
* Quản lý Vòng đời Mô hình – Quản lý vòng đời mô hình AI là quá trình giám sát tất cả các giai đoạn tồn tại của một mô hình AI, bao gồm thiết kế, phát triển, triển khai, giám sát, bảo trì và cuối cùng là loại bỏ, nhằm đảm bảo mô hình luôn hiệu quả và phù hợp với các mục tiêu.
  ​
* Đầu độc mô hình: Giới thiệu các lỗ hổng hoặc cửa hậu trực tiếp vào mô hình trong quá trình huấn luyện.
  ​
* Trộm/Cắp Mô Hình: Trích xuất bản sao hoặc xấp xỉ của một mô hình độc quyền thông qua các truy vấn lặp lại.
  ​
* Hệ thống đa tác nhân: Một hệ thống bao gồm nhiều tác nhân AI tương tác với nhau, mỗi tác nhân có thể có các khả năng và mục tiêu khác nhau.
  ​
* OPA (Open Policy Agent): Một công cụ chính sách mã nguồn mở cho phép thi hành chính sách thống nhất trên toàn bộ hệ thống.
  ​
* Học Máy Bảo Vệ Quyền Riêng Tư (PPML): Các kỹ thuật và phương pháp để huấn luyện và triển khai các mô hình học máy trong khi bảo vệ quyền riêng tư của dữ liệu huấn luyện.
  ​
* Chèn Lệnh Gợi Ý: Một cuộc tấn công trong đó các chỉ dẫn độc hại được nhúng trong đầu vào nhằm ghi đè hành vi dự định của mô hình.
  ​
* RAG (Sinh Tạo Bổ Sung Tìm Kiếm): Một kỹ thuật nâng cao các mô hình ngôn ngữ lớn bằng cách truy xuất thông tin liên quan từ các nguồn kiến thức bên ngoài trước khi tạo ra phản hồi.
  ​
* Red-Teaming: Thực hành kiểm tra chủ động các hệ thống AI bằng cách mô phỏng các cuộc tấn công đối kháng nhằm xác định các điểm yếu.
  ​
* SBOM (Bảng kê nguyên vật liệu phần mềm): Một bản ghi chính thức chứa chi tiết và các mối quan hệ trong chuỗi cung ứng của các thành phần khác nhau được sử dụng trong việc xây dựng phần mềm hoặc mô hình AI.
  ​
* SHAP (Giải thích cộng thêm Shapley): Một phương pháp lý thuyết trò chơi để giải thích kết quả của bất kỳ mô hình học máy nào bằng cách tính đóng góp của từng đặc trưng vào dự đoán.
  ​
* Tấn công Chuỗi Cung Ứng: Xâm nhập hệ thống bằng cách nhắm vào các thành phần có bảo mật thấp hơn trong chuỗi cung ứng của nó, chẳng hạn như thư viện bên thứ ba, bộ dữ liệu hoặc mô hình được huấn luyện trước.
  ​
* Học chuyển tiếp: Một kỹ thuật trong đó một mô hình được phát triển cho một nhiệm vụ được tái sử dụng làm điểm khởi đầu cho một mô hình cho nhiệm vụ thứ hai.
  ​
* Cơ sở dữ liệu Vector: Một cơ sở dữ liệu chuyên dụng được thiết kế để lưu trữ các vector có chiều cao (embedding) và thực hiện các tìm kiếm tương đồng hiệu quả.
  ​
* Quét lỗ hổng bảo mật: Công cụ tự động xác định các lỗ hổng bảo mật đã biết trong các thành phần phần mềm, bao gồm các khung AI và các phụ thuộc.
  ​
* Đóng dấu bản quyền: Các kỹ thuật nhúng các dấu hiệu không thể nhận thấy vào nội dung do AI tạo ra để theo dõi nguồn gốc hoặc phát hiện sự tạo ra bởi AI.
  ​
* Lỗ hổng Zero-Day: Một lỗ hổng chưa được biết đến trước đây mà kẻ tấn công có thể khai thác trước khi các nhà phát triển tạo và triển khai bản vá.

