# Préface

Bienvenue dans la norme de vérification de la sécurité de l'intelligence artificielle (AISVS) version 1.0 !

## Introduction

Établi en 2025 grâce à un effort communautaire collaboratif, AISVS définit les exigences de sécurité à prendre en compte lors de la conception, du développement, du déploiement et de l'exploitation des modèles d'IA modernes, des pipelines et des services activés par l'IA.

AISVS v1.0 représente le travail combiné de ses chefs de projet, du groupe de travail et des contributeurs de la communauté élargie pour produire une base pragmatique et testable pour la sécurisation des systèmes d'IA.

Notre objectif avec cette version est de rendre l’adoption de l’AISVS simple tout en restant strictement concentrés sur son périmètre défini et en répondant au paysage des risques en rapide évolution propre à l’IA.

## Objectifs clés pour AISVS Version 1.0

La version 1.0 sera créée selon plusieurs principes directeurs.

### Portée bien définie

Chaque exigence doit être conforme au nom et à la mission d’AISVS :

* Intelligence artificielle – Les contrôles opèrent au niveau de la couche IA/ML (données, modèle, pipeline ou inférence) et sont sous la responsabilité des praticiens de l'IA.
* Sécurité – Les exigences atténuent directement les risques identifiés en matière de sécurité, de confidentialité ou de sûreté.
* Vérification – Le langage est écrit de manière à ce que la conformité puisse être validée de manière objective.
* Norme – Les sections suivent une structure et une terminologie cohérentes pour former une référence cohérente.
  ​
---

En suivant AISVS, les organisations peuvent évaluer systématiquement et renforcer la posture de sécurité de leurs solutions d’IA, favorisant ainsi une culture d’ingénierie IA sécurisée.

