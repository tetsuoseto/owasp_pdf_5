# Forord

Velkommen til standarden for sikkerhetsverifisering av kunstig intelligens (AISVS) versjon 1.0!

## Introduksjon

Etablert i 2025 gjennom et samarbeidende fellesskapsinitiativ, definerer AISVS sikkerhetskravene som må vurderes ved utforming, utvikling, distribusjon og drift av moderne AI-modeller, arbeidsflyter og AI-aktiverte tjenester.

AISVS v1.0 representerer det samlede arbeidet til prosjektlederne, arbeidsgruppen og det bredere fellesskapet av bidragsytere for å produsere en pragmatisk og testbar baseline for å sikre AI-systemer.

Målet vårt med denne utgivelsen er å gjøre AISVS enkelt å ta i bruk samtidig som vi holder oss nøye fokusert på dets definerte omfang og håndterer det raskt utviklende risikobildet som er unikt for AI.

## Hovedmål for AISVS Versjon 1.0

Versjon 1.0 vil bli utviklet med flere veiledende prinsipper.

### Veldefinert omfang

Hvert krav må være i samsvar med AISVS’ navn og oppdrag:

* Kunstig intelligens – Kontrollene opererer på AI/ML-laget (data, modell, pipeline eller inferens) og er ansvaret til AI-utøvere.
* Sikkerhet – Kravene reduserer direkte identifiserte sikkerhets-, personvern- eller sikkerhetsrisikoer.
* Verifikasjon – Språket er skrevet slik at samsvar kan objektivt valideres.
* Standard – Seksjoner følger en konsekvent struktur og terminologi for å danne en sammenhengende referanse.
  ​
---

Ved å følge AISVS kan organisasjoner systematisk evaluere og styrke sikkerhetsnivået i sine AI-løsninger, og fremme en kultur for sikker AI-ingeniørkunst.

