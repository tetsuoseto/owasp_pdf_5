# Forside

## Om standarden

Artificial Intelligence Security Verification Standard (AISVS) er en fellesskapsdrevet katalog over sikkerhetskrav som dataforskere, MLOps-ingeniører, programvarearkitekter, utviklere, testere, sikkerhetsprofesjonelle, verktøyleverandører, reguleringsmyndigheter og brukere kan benytte for å designe, bygge, teste og verifisere pålitelige AI‑aktiverte systemer og applikasjoner. Den gir et felles språk for å spesifisere sikkerhetskontroller gjennom hele AI-livssyklusen — fra datainnsamling og modellutvikling til distribusjon og løpende overvåking — slik at organisasjoner kan måle og forbedre motstandsdyktigheten, personvernet og sikkerheten til sine AI-løsninger.

## Opphavsrett og lisens

Versjon 0.1 (Første offentlige utkast - Under arbeid), 2025  

![license](../images/license.png)

Opphavsrett © 2025 The AISVS Project.  

Utgitt under[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
For all gjenbruk eller distribusjon må du tydelig formidle lisensbetingelsene for dette verket til andre.

## Prosjektledere

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras "Russ" Memisyazici |

## Bidragsytere og Anmeldere

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS er en helt ny standard utviklet spesifikt for å håndtere de unike sikkerhetsutfordringene ved kunstige intelligenssystemer. Selv om den tar inspirasjon fra bredere sikkerhetsbeste praksiser, er hvert krav i AISVS utviklet fra grunnen av for å gjenspeile trussellandskapet innen AI og for å hjelpe organisasjoner med å bygge sikrere, mer robuste AI-løsninger.

