# Прадмова

Сардэчна запрашаем у Стандарт ВерЫфікацыІ Бяспекі Штучнага Інтэлекту (AISVS) версія 1.0!

## Уводзіны

Створаны ў 2025 годзе ў выніку сумесных намаганняў супольнасці, AISVS вызначае патрабаванні да бяспекі, якія трэба ўлічваць пры праектаванні, распрацоўцы, разгортванні і эксплуатацыі сучасных мадэляў штучнага інтэлекту, канвеераў і паслуг з падтрымкай штучнага інтэлекту.

AISVS v1.0 уяўляе сабой сумесную працу кіраўнікоў праекта, рабочай групы і шырокага кола ўдзельнікаў супольнасці, накіраваную на стварэнне практычнага і выпрабавальнага базавага ўзроўню для забеспячэння бяспекі сістэм штучнага інтэлекту.

Наша мэта з гэтым выпуском — зрабіць AISVS простым для ўкаранення, заставацца дакладна сфакусаванымі на яго вызначаным ахопе і адначасова рэагаваць на хутка што змяняецца ландшафт рызык, унікальны для штучнага інтэлекту.

## Ключавыя мэты для AISVS Версіі 1.0

Версія 1.0 будзе створана з улікам некалькіх асноўных прынцыпаў.

### Добра Вызначаная Сфера

Кожная патрабаванне павінна адпавядаць назве і місіі AISVS:

* Штучны інтэлект – Кантролі працуюць на ўзроўні AI/ML (даныя, мадэль, канвеер або высновы) і з’яўляюцца адказнасцю спецыялістаў у галіне штучнага інтэлекту.
* Бяспека – патрабаванні непасрэдна змяншаюць выяўленыя рызыкі бяспекі, прыватнасці або бяспекі.
* Праверка – мова напісана так, каб адпаведнасць магла быць аб’ектыўна праверана.
* Стандарт – Раздзелы маюць ўстойлівую структуру і тэрміналогію, утвараючы зладжаную спасылку.
  ​
---

Сачы выкананню AISVS, арганізацыі могуць сістэматычна ацэньваць і ўмацоўваць бяспеку сваіх AI-рашэнняў, спрыяючы стварэнню культуры бяспечнай інжынерыі AI.

