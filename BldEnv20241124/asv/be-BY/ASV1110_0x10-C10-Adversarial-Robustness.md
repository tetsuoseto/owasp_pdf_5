# 10 Супраціўнасць да атак і абарона прыватнасці

## Мэта Кантролю

Забяспечце, каб мадэлі ШІ заставаліся надзейнымі, паважлівымі да прыватнасці і ўстойлівымі да злоўжыванняў пры сутыкненні з атакамі ўхілення, высвятлення, выцягвання або таксікатарства.

---

## 10.1 Выраўноўванне мадэлі і бяспека

Абароніцеся ад шкодных або такіх, што парушаюць палітыку, вынікаў.

|   #    | Description                                                                                                                                                                   | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.1.1 | Праверце, каб набор тэстаў узгаднення (запыты чырвонай каманды, пранікненні ў jailbreak, забаронены кантэнт) быў пад кантролем версій і запускаўся пры кожным выпуску мадэлі. |   1   | D/V  |
| 10.1.2 | Праверце, што адмову і ахоўныя механізмы бяспечнага завяршэння ўжываюцца.                                                                                                     |   1   |  D   |
| 10.1.3 | Праверце, што аўтаматычны ацэньвальнік вымярае ўзровень шкоднаснага кантэнту і адзначае рэгрэсіі, якія перавышаюць усталяваны парог.                                          |   2   | D/V  |
| 10.1.4 | Праверце, ці дакументавана і аднаўляльна навучанне супраць уцёкаў з турмы.                                                                                                    |   2   |  D   |
| 10.1.5 | Праверце, ці ахопліваюць фармальныя доказы выканання палітыкі або сертыфікаваны маніторынг крытычныя дамены.                                                                  |   3   |  V   |

---

## 10.2 Умацаванне супраць адвэрсарыяльных прыкладаў

Павялічце ўстойлівасць да змянёных уваходных дадзеных. Надзейнае супрацьдзеянне атак і ацэнка па эталонных паказчыках з’яўляюцца цяперашнімі найлепшымі практыкамі.

|   #    | Description                                                                                                                           | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.2.1 | Праверце, што рэпазітары праекта ўключаюць канфігурацыі супрацьлеглага трэніроўкі з аднаўляльнымі сідамі.                             |   1   |  D   |
| 10.2.2 | Праверце, ці выклікае выяўленне адвэрсарыяльных прыкладаў папераджальныя сігналы блакіроўкі ў вытворчых канвеерах.                    |   2   | D/V  |
| 10.2.4 | Праверце, што сертыфікаваныя даказанні ўстойлівасці або сертыфікаты інтэрвальных межаў ахопліваюць прынамсі найбольш крытычныя класы. |   3   |  V   |
| 10.2.5 | Праверце, што рэгрэсійныя тэсты выкарыстоўваюць адаптыўныя атакі для пацверджання адсутнасці вымяральнай стратэгічнай устойлівасці.   |   3   |  V   |

---

## 10.3 Меры па змяншэнні рызыкі выяўлення ўдзельнікаў

Абмежаваць магчымасць вызначыць, ці быў запіс у навучальных дадзеных. Диферэнцыяльная прыватнасць і маскіраванне па адзнаках упэўненасці застаюцца найбольш эфектыўнымі вядомымі сродкамі абароны.

|   #    | Description                                                                                                                  | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.3.1 | Праверце, што рэгулярызацыя энтрапіі для кожнага запыту або маштабаванне тэмпературы змяншаюць празмерна ўпэўненыя прагнозы. |   1   |  D   |
| 10.3.2 | Праверце, што навучанне выкарыстоўвае ε-абмежаваную дыферэнцыяльна прыватную аптымізацыю для адчувальных набораў даных.      |   2   |  D   |
| 10.3.3 | Праверце, што мадэляванне атак (ценявы мадэль або чорны ящик) паказвае AUC атакі ≤ 0,60 на асобных дадзеных.                 |   2   |  V   |

---

## 10.4 Супраціўнасць мадэляў інверсіі

Перашкаджаць аднаўленню прыватных атрыбутаў. Апошнія даследаванні вылучаюць скарачэнне вываду і гарантыі дыферэнцыяльнай прыватнасці (DP) як эфектыўныя абароны.

|   #    | Description                                                                                                                                                   | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.4.1 | Праверце, каб канфідэнцыяльныя атрыбуты ніколі не выводзіліся наўпрост; там, дзе неабходна, выкарыстоўвайце дыяпазоны (бакеты) або аднабаковыя пераўтварэнні. |   1   |  D   |
| 10.4.2 | Праверце, што абмежаванні па частаце запытаў абмяжоўваюць паўторныя адаптыўныя запыты ад аднаго і таго ж прынцыпаала.                                         |   1   | D/V  |
| 10.4.3 | Праверце, што мадэль навучаецца з выкарыстаннем шуму, які захоўвае прыватнасць.                                                                               |   2   |  D   |

---

## 10.5 Абарона ад мадэльнага выцягвання

Выяўляйце і перашкаджайце несанкцыянаванаму кланіраванню. Рэкамендуюцца водныя знакі і аналіз шаблонаў запытаў.

|   #    | Description                                                                                                                                                        | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 10.5.1 | Праверце, што шлюзы вываду забяспечваюць агульназастасаваныя і індывідуальныя па кожнаму API-ключы абмежаванні хуткасці, адаптаваныя да парогу запамінання мадэлі. |   1   |  D   |
| 10.5.2 | Праверце, што статыстыка энтрапіі запытаў і множнасці ўводу падаюць інфармацыю ў аўтаматызаваны дэтэктар здабычы.                                                  |   2   | D/V  |
| 10.5.3 | Праверце, што далікатныя або верагоднасныя вадзяныя знакі можна даказаць з p < 0,01 пры не больш чым 1000 запытах супраць падазронага клона.                       |   2   |  V   |
| 10.5.4 | Праверце, што ключы водных знакаў і наборы трыгераў захоўваюцца ў модулі апаратнай бяспекі і зменяюцца штогод.                                                     |   3   |  D   |
| 10.5.5 | Праверце, што падзеі extraction-alert ўключаюць непрымальныя запыты і інтэграваныя з прайбуксамі рэагавання на інцыдэнты.                                          |   3   |  V   |

---

## 10.6 Вызначэнне атручаных дадзеных падчас выканання ў высновах

Ідэнтыфікаваць і нейтралізаваць задзейнічаныя або атручаныя ўваходныя дадзеныя.

|   #    | Description                                                                                                                               | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.6.1 | Праверце, ці працягваюцца ўваходныя даныя праз выяўленне анамалій (напрыклад, STRIP, ацэнка паслядоўнасці) перад інферэнцыяй мадэлі.      |   1   |  D   |
| 10.6.2 | Праверце, што парогі дэтэктара настроены на чыстых/заражаных наборах для праверкі, каб дасягнуць менш за 5% ілжывых спрацоўванняў.        |   1   |  V   |
| 10.6.3 | Праверце, ці выклікаюць уведзеныя даныя, пазначаныя як заражаныя, актывацыю мяккай блакацыі і працэсы праверкі чалавекам.                 |   2   |  D   |
| 10.6.4 | Праверце, што дэтэктары падвяргаюцца стрэс-тэставанню з адаптыўнымі, бесчарапнымі бэкдоровымі атакамі.                                    |   2   |  V   |
| 10.6.5 | Праверце, што метрыкі эфектыўнасці выяўлення рэгіструюцца і перыядычна пераацэньваюцца з выкарыстаннем актуальнай інфармацыі аб пагрозах. |   3   |  D   |

---

## 10.7 Дынамічная адаптацыя палітыкі бяспекі

Абнаўленні палітыкі бяспекі ў рэальным часе на аснове інтэлекту пагроз і паводніцкага аналізу.

|   #    | Description                                                                                                                                         | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.7.1 | Праверце, што палітыкі бяспекі могуць абнаўляцца дынамічна без перазагрузкі агента, захоўваючы цэласнасць версіі палітыкі.                          |   1   | D/V  |
| 10.7.2 | Праверце, што абнаўленні палітык крыптаграфічна падпісаны ўпаўнаважаным персаналам бяспекі і правераны перад ужываннем.                             |   2   | D/V  |
| 10.7.3 | Праверце, што дынамічныя змены палітыкі рэгіструюцца з поўнымі аўдытарскімі слядамі, уключаючы апраўданне, ланцугі зацвярджэння і працэдуры адкату. |   2   | D/V  |
| 10.7.4 | Праверце, ці рэгулююць адаптыўныя механізмы бяспекі адчувальнасць выяўлення пагроз у залежнасці ад кантэксту рызыкі і паводзінных узораў.           |   3   | D/V  |
| 10.7.5 | Праверце, што рашэнні па адаптацыі палітыкі тлумачальныя і ўключаюць слядовыя доказы для агляду камандай бяспекі.                                   |   3   | D/V  |

---

## 10.8 Аналіз бяспекі на аснове рэфлексіі

Праверка бяспекі праз самаадлюстраванне агента і метакагнітыўны аналіз.

|   #    | Description                                                                                                                              | Level | Role |
| :----: | ---------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.8.1 | Праверце, што механізмы рэфлексіі агента ўключаюць самаацэнку рашэнняў і дзеянняў з акцэнтам на бяспеку.                                 |   1   | D/V  |
| 10.8.2 | Праверце, ці правяраюцца вынікі рэфлексіі для прадухілення маніпуляцый механізмамі самаацэнкі з дапамогай адвэрсарыяльных уводных даных. |   2   | D/V  |
| 10.8.3 | Праверце, ці выяўляе мета-кагнітыўны аналіз бяспекі магчымыя прадузятасці, маніпуляцыі або кампраметацыі ў працэсах разважання агента.   |   2   | D/V  |
| 10.8.4 | Праверце, ці выклікаюць папярэджанні бяспекі на аснове рэфлексіі паузоранае маніторынг і патэнцыйныя працэсы ўмяшання чалавека.          |   3   | D/V  |
| 10.8.5 | Праверце, ці паляпшае бесперапыннае навучанне на аснове аналізу бяспекі выяўленне пагроз без пагаршэння легітымнай функцыянальнасці.     |   3   | D/V  |

---

## 10.9 Бяспека эвалюцыі і самаўдасканалення

Кантроль бяспекі для агенцкіх сістэм, здольных да самамадыфікацыі і эвалюцыі.

|   #    | Description                                                                                                                          | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------ | :---: | :--: |
| 10.9.1 | Праверце, што магчымасці самамадыфікацыі абмежаваны прызначанымі бяспечнымі зонамі з фармальнымі межамі верыфікацыі.                 |   1   | D/V  |
| 10.9.2 | Праверце, ці праходзяць прапановы па эвалюцыі ацэнку ўздзеяння на бяспеку перад іх рэалізацыяй.                                      |   2   | D/V  |
| 10.9.3 | Праверце, што механізмы самаўдасканалення ўключаюць магчымасці адкату з праверкай цэласнасці.                                        |   2   | D/V  |
| 10.9.4 | Праверце, што бяспека мета-навучання прадухіляе адвэрсарыяльныя маніпуляцыі алгарытмамі паляпшэння.                                  |   3   | D/V  |
| 10.9.5 | Праверце, што рэкурсіўнае самаўдасканаленне абмежавана фармальнымі абмежаваннямі бяспекі з дапамогай матэматычных даказаў збліжэння. |   3   | D/V  |

---

### Спіс літаратуры

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

