# Предисловие

Добро пожаловать в стандарт верификации безопасности искусственного интеллекта (AISVS) версии 1.0!

## Введение

Основанная в 2025 году в результате совместных усилий сообщества, AISVS определяет требования к безопасности, которые необходимо учитывать при проектировании, разработке, внедрении и эксплуатации современных AI-моделей, конвейеров и сервисов с поддержкой искусственного интеллекта.

AISVS v1.0 представляет собой совместную работу руководителей проекта, рабочей группы и более широкого круга участников сообщества, направленную на создание прагматичной и проверяемой основы для обеспечения безопасности систем искусственного интеллекта.

Наша цель с этим выпуском — сделать AISVS простым для внедрения, при этом сохраняя четкую фокусировку на его определенном объеме и реагируя на быстро меняющийся ландшафт рисков, уникальных для ИИ.

## Ключевые цели AISVS версии 1.0

Версия 1.0 будет создана на основе нескольких руководящих принципов.

### Четко определенная область применения

Каждое требование должно соответствовать названию и миссии AISVS:

* Искусственный интеллект – Контроли функционируют на уровне ИИ/МО (данные, модель, конвейер или вывод) и находятся в ведении специалистов по ИИ.
* Безопасность – Требования напрямую устраняют выявленные риски безопасности, конфиденциальности или безопасности жизнедеятельности.
* Верификация – Язык написан таким образом, чтобы соответствие могло быть объективно подтверждено.
* Стандарт – Разделы следуют последовательной структуре и терминологии для создания согласованного справочного материала.
  ​
---

Следуя AISVS, организации могут систематически оценивать и укреплять безопасность своих AI-решений, способствуя развитию культуры безопасной инженерии AI.

