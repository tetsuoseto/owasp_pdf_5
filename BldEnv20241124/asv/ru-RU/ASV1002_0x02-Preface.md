# Предисловие

Добро пожаловать в стандарт проверки безопасности искусственного интеллекта (AISVS) версии 1.0!

## Введение

Основанное в 2025 году в результате совместных усилий сообщества, AISVS определяет требования безопасности, которые необходимо учитывать при проектировании, разработке, развертывании и эксплуатации современных моделей ИИ, конвейеров и сервисов с поддержкой ИИ.

AISVS v1.0 представляет собой совместную работу руководителей проекта, рабочей группы и более широкого круга участников сообщества по созданию прагматичной, проверяемой основы для обеспечения безопасности ИИ-систем.

Наша цель с этим выпуском — сделать AISVS простым для внедрения, при этом сохраняя четкий фокус на его определенном объеме и учитывая быстро меняющийся ландшафт рисков, уникальный для ИИ.

## Основные цели AISVS версии 1.0

Версия 1.0 будет создана с использованием нескольких руководящих принципов.

### Четко определенный объем работы

Каждое требование должно соответствовать названию и миссии AISVS:

* Искусственный интеллект – Контроли работают на уровне ИИ/МО (данные, модель, конвейер или вывод) и находятся в зоне ответственности специалистов по ИИ.
* Безопасность – требования непосредственно снижают выявленные риски безопасности, конфиденциальности или безопасности.
* Верификация – язык написан таким образом, чтобы соответствие можно было объективно проверить.
* Стандарт – разделы следуют последовательной структуре и терминологии, образуя единый справочный материал.
  ​
---

Следуя AISVS, организации могут систематически оценивать и укреплять уровень безопасности своих AI-решений, способствуя формированию культуры безопасной разработки AI.

