# Титульный лист

## О стандартe

Стандарт проверки безопасности искусственного интеллекта (AISVS) — это каталог требований безопасности, разработанный сообществом, который специалисты по данным, инженеры MLOps, архитекторы программного обеспечения, разработчики, тестировщики, специалисты по безопасности, поставщики инструментов, регуляторы и пользователи могут использовать для проектирования, создания, тестирования и проверки надежных систем и приложений с искусственным интеллектом. Он обеспечивает общий язык для определения мер безопасности на всех этапах жизненного цикла ИИ — от сбора данных и разработки модели до развертывания и постоянного мониторинга — чтобы организации могли измерять и повышать устойчивость, конфиденциальность и безопасность своих ИИ-решений.

## Авторское право и лицензия

Версия 0.1 (Первый публичный черновик - Работа в процессе), 2025  

![license](../images/license.png)

Авторское право © 2025 Проект AISVS.  

Выпущено под лицензией [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Для любого повторного использования или распространения вы должны четко сообщать условия лицензии этой работы другим.

## Руководители проекта

|              |                        |
| ------------ | ---------------------- |
| Джим Мэником | Арас «Русс» Мемисязичи |

## Участники и рецензенты

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS — это совершенно новый стандарт, созданный специально для решения уникальных задач безопасности систем искусственного интеллекта. Хотя он черпает вдохновение из общих лучших практик безопасности, каждое требование в AISVS разработано с нуля с учётом специфики угроз в области ИИ и для помощи организациям в создании более безопасных и устойчивых ИИ-решений.

