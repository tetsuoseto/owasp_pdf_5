# Титульный лист

## О стандарте

Стандарт проверки безопасности искусственного интеллекта (AISVS) — это созданный сообществом каталог требований к безопасности, который могут использовать дата-сайентисты, инженеры MLOps, архитекторы программного обеспечения, разработчики, тестировщики, специалисты по безопасности, поставщики инструментов, регуляторы и потребители для проектирования, создания, тестирования и проверки надежных систем и приложений на базе ИИ. Он предоставляет общий язык для определения управляющих мер безопасности на протяжении всего жизненного цикла ИИ — от сбора данных и разработки моделей до развертывания и постоянного мониторинга, чтобы организации могли измерять и улучшать устойчивость, конфиденциальность и безопасность своих ИИ-решений.

## Авторское право и лицензия

Версия 0.1 (Первый публичный черновик - в процессе работы), 2025  

![license](../images/license.png)

Авторские права © 2025 Проект AISVS.  

Выпущено под лицензией[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Для любого повторного использования или распространения вы должны чётко сообщить другим условия лицензии на эту работу.

## Руководители проекта

|             |                         |
| ----------- | ----------------------- |
| Джим Манико | Арас «Русс» Мемисиязичи |

## Участники и рецензенты

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS — это совершенно новый стандарт, созданный специально для решения уникальных проблем безопасности систем искусственного интеллекта. Хотя он черпает вдохновение из общих лучших практик в области безопасности, каждое требование в AISVS разработано с нуля с учётом особенностей угроз в области ИИ и для помощи организациям в создании более безопасных и устойчивых AI-решений.

