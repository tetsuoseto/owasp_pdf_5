# 10 Противодействие враждебной устойчивости и защита конфиденциальности

## Цель управления

Обеспечьте, чтобы модели ИИ оставались надежными, сохраняющими конфиденциальность и устойчивыми к злоупотреблениям при столкновении с атаками уклонения, вывода, извлечения или отравления.

---

## 10.1 Выравнивание модели и безопасность

Защищайте от вредоносных или нарушающих политику результатов.

|   #    | Description                                                                                                                                                                                 | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.1.1 | Проверьте, что набор тестов для проверки согласованности (red-team запросы, jailbreak-пробы, запрещенный контент) находится под управлением версий и запускается при каждом выпуске модели. |   1   | D/V  |
| 10.1.2 | Проверьте, что механизмы отказа и защитные ограничения для безопасного завершения применяются.                                                                                              |   1   |  D   |
| 10.1.3 | Проверьте, что автоматический оценщик измеряет уровень вредоносного контента и помечает регрессии, превышающие установленный порог.                                                         |   2   | D/V  |
| 10.1.4 | Убедитесь, что обучение против обхода защиты задокументировано и воспроизводимо.                                                                                                            |   2   |  D   |
| 10.1.5 | Проверьте, что формальные доказательства соблюдения политики или сертифицированный мониторинг охватывают критические области.                                                               |   3   |  V   |

---

## 10.2 Укрепление против атак с использованием враждебных примеров

Увеличьте устойчивость к манипулируемым входным данным. Надежное обучение с противником и оценка по эталонным показателям являются текущей лучшей практикой.

|   #    | Description                                                                                                                                  | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.2.1 | Проверьте, что репозитории проектов включают конфигурации adversarial-training с воспроизводимыми семенами.                                  |   1   |  D   |
| 10.2.2 | Проверьте, что обнаружение атак с помощью контрпримера вызывает сигналы блокировки в производственных конвейерах.                            |   2   | D/V  |
| 10.2.4 | Проверьте, что доказательства сертифицированной устойчивости или сертификаты с интервалами охватывают как минимум наиболее критичные классы. |   3   |  V   |
| 10.2.5 | Проверьте, что регрессионные тесты используют адаптивные атаки для подтверждения отсутствия заметной потери устойчивости.                    |   3   |  V   |

---

## 10.3 Смягчение последствий атак на вывод членства

Ограничьте возможность определения, был ли объект в данных для обучения. Дифференциальная приватность и маскирование оценок уверенности остаются наиболее эффективными известными методами защиты.

|   #    | Description                                                                                                                         | Level | Role |
| :----: | ----------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.3.1 | Проверьте, что регуляризация энтропии для каждого запроса или масштабирование температуры уменьшает излишне уверенные предсказания. |   1   |  D   |
| 10.3.2 | Проверьте, что обучение использует ε-ограниченную дифференциально-приватную оптимизацию для чувствительных наборов данных.          |   2   |  D   |
| 10.3.3 | Проверьте, что имитации атак (теневая модель или черный ящик) показывают AUC атаки ≤ 0,60 на отложенных данных.                     |   2   |  V   |

---

## 10.4 Устойчивость к инверсии модели

Предотвращение восстановления приватных атрибутов. Недавние исследования подчеркивают усечение вывода и гарантии дифференциальной приватности (DP) как практические методы защиты.

|   #    | Description                                                                                                                                             | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.4.1 | Убедитесь, что конфиденциальные атрибуты никогда не выводятся напрямую; при необходимости используйте группы (бакеты) или односторонние преобразования. |   1   |  D   |
| 10.4.2 | Проверьте, что ограничения по частоте запросов регулируют повторяющиеся адаптивные запросы от одного и того же субъекта.                                |   1   | D/V  |
| 10.4.3 | Проверьте, что модель обучена с использованием шума, сохраняющего конфиденциальность.                                                                   |   2   |  D   |

---

## 10.5 Защита от извлечения модели

Обнаружение и предотвращение несанкционированного клонирования. Рекомендуются методы водяных знаков и анализа шаблонов запросов.

|   #    | Description                                                                                                                                                               | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.5.1 | Проверьте, что шлюзы вывода обеспечивают глобальные и индивидуальные для каждого API-ключа ограничения скорости, настроенные в соответствии с порогом запоминания модели. |   1   |  D   |
| 10.5.2 | Проверьте, что статистики энтропии запросов и плюральности входных данных поступают в автоматический детектор извлечения.                                                 |   2   | D/V  |
| 10.5.3 | Проверьте, что хрупкие или вероятностные водяные знаки можно доказать с p < 0,01 при ≤ 1000 запросах к предполагаемому клону.                                             |   2   |  V   |
| 10.5.4 | Проверьте, что ключи водяных знаков и наборы триггеров хранятся в модуле аппаратной безопасности и обновляются ежегодно.                                                  |   3   |  D   |
| 10.5.5 | Убедитесь, что события extraction-alert включают вредоносные запросы и интегрированы с планами реагирования на инциденты.                                                 |   3   |  V   |

---

## 10.6 Обнаружение загрязнённых данных во время вывода (инференса)

Обнаружение и нейтрализация заражённых или отравленных входных данных.

|   #    | Description                                                                                                                                                         | Level | Role |
| :----: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.6.1 | Проверьте, что входные данные проходят через детектор аномалий (например, STRIP, оценка согласованности) перед выполнением вывода модели.                           |   1   |  D   |
| 10.6.2 | Убедитесь, что пороги детектора настроены на чистых/заражённых валидационных наборах данных для достижения уровня ложных срабатываний меньше 5%.                    |   1   |  V   |
| 10.6.3 | Проверьте, что входные данные, помеченные как заражённые, вызывают срабатывание мягкой блокировки и процедуры проверки человеком.                                   |   2   |  D   |
| 10.6.4 | Проверьте, что детекторы подвергаются стресс-тестированию с использованием адаптивных, безтриггерных атак с задней дверью.                                          |   2   |  V   |
| 10.6.5 | Убедитесь, что метрики эффективности обнаружения регистрируются и периодически переоцениваются с использованием обновленной разведывательной информации об угрозах. |   3   |  D   |

---

## 10.7 Динамическая адаптация политики безопасности

Обновления политики безопасности в режиме реального времени на основе разведки угроз и поведенческого анализа.

|   #    | Description                                                                                                                                               | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.7.1 | Проверьте, что политики безопасности могут обновляться динамически без перезапуска агента при сохранении целостности версии политики.                     |   1   | D/V  |
| 10.7.2 | Проверяйте, что обновления политики криптографически подписаны уполномоченным персоналом службы безопасности и проверяются перед применением.             |   2   | D/V  |
| 10.7.3 | Проверьте, что изменения динамической политики фиксируются с полным аудитом, включая обоснование, цепочки утверждения и процедуры отката.                 |   2   | D/V  |
| 10.7.4 | Проверьте, что адаптивные механизмы безопасности регулируют чувствительность обнаружения угроз в зависимости от контекста риска и поведенческих шаблонов. |   3   | D/V  |
| 10.7.5 | Убедитесь, что решения по адаптации политики объяснимы и содержат доказательства для проверки командой безопасности.                                      |   3   | D/V  |

---

## 10.8 Анализ безопасности на основе рефлексии

Проверка безопасности через самоанализ агента и метакогнитивный анализ.

|   #    | Description                                                                                                                                              | Level | Role |
| :----: | -------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.8.1 | Проверьте, что механизмы рефлексии агента включают ориентированную на безопасность самооценку решений и действий.                                        |   1   | D/V  |
| 10.8.2 | Проверьте, что результаты отражения проверяются для предотвращения манипуляций механизмами самооценки злонамеренными входными данными.                   |   2   | D/V  |
| 10.8.3 | Проверьте, что мета-когнитивный анализ безопасности выявляет потенциальные предвзятость, манипуляцию или нарушение в процессах рассуждения агента.       |   2   | D/V  |
| 10.8.4 | Проверьте, что основанные на рефлексии предупреждения о безопасности вызывают усиленный мониторинг и потенциальные рабочие процессы с участием человека. |   3   | D/V  |
| 10.8.5 | Проверьте, что непрерывное обучение на основе анализа инцидентов безопасности улучшает обнаружение угроз без ухудшения легитимной функциональности.      |   3   | D/V  |

---

## 10.9 Безопасность эволюции и самоусовершенствования

Контроль безопасности для агентных систем, способных к самомодификации и эволюции.

|   #    | Description                                                                                                                                         | Level | Role |
| :----: | --------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.9.1 | Убедитесь, что возможности самоизменения ограничены назначенными безопасными зонами с формальными границами верификации.                            |   1   | D/V  |
| 10.9.2 | Убедитесь, что предложения по эволюции проходят оценку влияния на безопасность перед внедрением.                                                    |   2   | D/V  |
| 10.9.3 | Проверьте, что механизмы самоулучшения включают возможности отката с проверкой целостности.                                                         |   2   | D/V  |
| 10.9.4 | Проверьте, что безопасность метаобучения предотвращает враждебное вмешательство в алгоритмы улучшения.                                              |   3   | D/V  |
| 10.9.5 | Подтвердите, что рекурсивное самосовершенствование ограничено формальными ограничениями безопасности с математическими доказательствами сходимости. |   3   | D/V  |

---

### Ссылки

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

