# Приложение A: Глоссарий

> Этот всеобъемлющий глоссарий содержит определения ключевых терминов в области ИИ, МО и безопасности, используемых в AISVS, для обеспечения ясности и общего понимания.
> ​
* Враждебный пример: входные данные, специально созданные для того, чтобы вызвать ошибку в модели ИИ, часто путем добавления тонких и незаметных для человека искажений.
  ​
* Адвверсарная устойчивость – адвверсарная устойчивость в ИИ относится к способности модели сохранять свою производительность и сопротивляться обману или манипуляциям с помощью специально созданных, злонамеренных входных данных, предназначенных для вызова ошибок.
  ​
* Агент — ИИ-агенты — это программные системы, которые используют искусственный интеллект для достижения целей и выполнения задач от имени пользователей. Они демонстрируют способности к рассуждению, планированию и запоминанию, а также обладают уровнем автономии для принятия решений, обучения и адаптации.
  ​
* Агентный ИИ: системы ИИ, которые могут функционировать с некоторой степенью автономии для достижения целей, часто принимая решения и предпринимая действия без прямого вмешательства человека.
  ​
* Управление доступом на основе атрибутов (ABAC): парадигма управления доступом, при которой решения об авторизации принимаются на основе атрибутов пользователя, ресурса, действия и окружающей среды, оцениваемых во время запроса.
  ​
* Атака с закладкой: тип атаки с отравлением данных, при которой модель обучается реагировать определённым образом на определённые триггеры, при этом в остальном ведёт себя нормально.
  ​
* Смещение: Систематические ошибки в выходных данных модели ИИ, которые могут приводить к несправедливым или дискриминационным результатам для определённых групп или в конкретных контекстах.
  ​
* Эксплуатация смещения: техника атаки, которая использует известные смещения в моделях ИИ для манипулирования результатами или выходными данными.
  ​
* Cedar: язык политики и механизм Amazon для детализированных разрешений, используемый при реализации ABAC для систем ИИ.
  ​
* Цепочка рассуждений: техника улучшения логического вывода в языковых моделях путем генерации промежуточных этапов рассуждения перед получением окончательного ответа.
  ​
* Автоматические выключатели (Circuit Breakers): Механизмы, которые автоматически останавливают работу ИИ-систем при превышении определённых порогов риска.
  ​
* Утечка данных: непреднамеренное раскрытие конфиденциальной информации через выходные данные или поведение модели ИИ.
  ​
* Отравление данных: преднамеренное искажение обучающих данных с целью компрометации целостности модели, часто для установки "черных ходов" или ухудшения производительности.
  ​
* Дифференциальная приватность — это математически строгая концепция для предоставления статистической информации о наборах данных с защитой приватности отдельных субъектов данных. Она позволяет владельцу данных делиться сводными паттернами группы, ограничивая при этом утечку информации о конкретных лицах.
  ​
* Эмбеддинги: плотные векторные представления данных (текста, изображений и др.), которые захватывают семантический смысл в пространстве с большим числом измерений.
  ​
* Объяснимость – объяснимость в ИИ — это способность системы искусственного интеллекта предоставлять человеку понятные причины своих решений и прогнозов, предоставляя понимание внутренних процессов.
  ​
* Объяснимая ИИ (XAI): системы ИИ, разработанные для предоставления человекопонятных объяснений своих решений и поведения с использованием различных техник и структур.
  ​
* Федеративное обучение: подход машинного обучения, при котором модели обучаются на нескольких децентрализованных устройствах, хранящих локальные данные, без обмена самими данными.
  ​
* Ограждения: Ограничения, внедренные для предотвращения генерации ИИ-системами вредоносных, предвзятых или иным образом нежелательных результатов.
  ​
* Галлюцинация — галлюцинацией ИИ называют явление, при котором модель ИИ генерирует некорректную или вводящую в заблуждение информацию, не основанную на ее обучающих данных или фактической реальности.
  ​
* Человек в цикле (HITL): Системы, разработанные с требованием человеческого надзора, проверки или вмешательства в ключевых точках принятия решений.
  ​
* Инфраструктура как код (IaC): управление и предоставление инфраструктуры с помощью кода вместо ручных процессов, что позволяет проводить сканирование безопасности и обеспечивать последовательные развертывания.
  ​
* Jailbreak: Техники, используемые для обхода защитных ограничений в системах ИИ, особенно в больших языковых моделях, с целью создания запрещённого контента.
  ​
* Минимально необходимые привилегии: принцип безопасности, предусматривающий предоставление пользователям и процессам только минимально необходимых прав доступа.
  ​
* LIME (локально интерпретируемые объяснения, независимые от модели): метод для объяснения предсказаний любого классификатора машинного обучения путем локального приближения его интерпретируемой моделью.
  ​
* Атака на выявление членства: атака, направленная на определение, использовалась ли конкретная точка данных для обучения модели машинного обучения.
  ​
* MITRE ATLAS: Ландшафт враждебных угроз для систем искусственного интеллекта; база знаний враждебных тактик и техник против систем ИИ.
  ​
* Модельная карта — это документ, который предоставляет стандартизированную информацию о производительности модели ИИ, ее ограничениях, предназначенных применениях и этических аспектах для содействия прозрачности и ответственной разработке ИИ.
  ​
* Извлечение модели: атака, при которой злоумышленник неоднократно запрашивает целевую модель с целью создания функционально аналогичной копии без разрешения.
  ​
* Инверсия модели: атака, пытающаяся восстановить обучающие данные путем анализа выходных данных модели.
  ​
* Управление жизненным циклом модели – управление жизненным циклом модели ИИ – это процесс контроля всех этапов существования модели ИИ, включая её проектирование, разработку, внедрение, мониторинг, обслуживание и окончательный вывод из эксплуатации, с целью обеспечения её эффективности и соответствия поставленным целям.
  ​
* Отравление модели: внедрение уязвимостей или закладок напрямую в модель в процессе обучения.
  ​
* Воровство/Кража модели: Извлечение копии или приближения проприетарной модели путем многократных запросов.
  ​
* Мультиагентная система: система, состоящая из нескольких взаимодействующих ИИ-агентов, каждый из которых может обладать разными возможностями и целями.
  ​
* OPA (Open Policy Agent): Открытый механизм управления политиками, который обеспечивает единое применение политик во всем стеке.
  ​
* Машинное обучение с сохранением конфиденциальности (PPML): методы и техники для обучения и развертывания моделей машинного обучения при обеспечении конфиденциальности данных обучения.
  ​
* Внедрение подсказок: атака, при которой вредоносные инструкции встраиваются в входные данные для переопределения намеренного поведения модели.
  ​
* RAG (Генерация с дополнением за счёт извлечения): Техника, которая улучшает большие языковые модели за счёт извлечения релевантной информации из внешних источников знаний перед генерацией ответа.
  ​
* Ред-тиминг: практика активного тестирования ИИ-систем путем моделирования атак злоумышленников для выявления уязвимостей.
  ​
* SBOM (Спецификация состава программного обеспечения): Официальная запись, содержащая детали и цепочки поставок различных компонентов, используемых при создании программного обеспечения или ИИ-моделей.
  ​
* SHAP (SHapley Additive exPlanations): Теоретический подход из теории игр для объяснения результата любой модели машинного обучения путем вычисления вклада каждого признака в предсказание.
  ​
* Атака на цепочку поставок: компрометация системы путем нацеливания на менее защищенные элементы в ее цепочке поставок, такие как сторонние библиотеки, наборы данных или предварительно обученные модели.
  ​
* Трансферное обучение: техника, при которой модель, разработанная для одной задачи, используется в качестве отправной точки для модели по второй задаче.
  ​
* Векторная база данных: специализированная база данных, предназначенная для хранения высокоразмерных векторов (встраиваний) и выполнения эффективных поисков по сходству.
  ​
* Сканирование на уязвимости: Автоматизированные инструменты, которые выявляют известные уязвимости безопасности в компонентах программного обеспечения, включая AI-фреймворки и зависимости.
  ​
* Водяные знаки: техники встраивания незаметных меток в контент, сгенерированный ИИ, для отслеживания его происхождения или обнаружения его создания ИИ.
  ​
* Уязвимость нулевого дня: ранее неизвестная уязвимость, которую злоумышленники могут использовать до того, как разработчики создадут и внедрят исправление.

