# Vorwort

Willkommen beim Standard zur Sicherheitsüberprüfung Künstlicher Intelligenz (AISVS) Version 1.0!

## Einführung

AISVS wurde 2025 durch eine gemeinschaftliche Zusammenarbeit gegründet und definiert die Sicherheitsanforderungen, die bei der Gestaltung, Entwicklung, Implementierung und dem Betrieb moderner KI-Modelle, Pipelines und KI-gestützter Dienste zu berücksichtigen sind.

AISVS v1.0 stellt die gemeinsame Arbeit der Projektleiter, der Arbeitsgruppe und der breiteren Gemeinschaft von Mitwirkenden dar, um eine pragmatische, überprüfbare Grundlage für die Absicherung von KI-Systemen zu schaffen.

Unser Ziel mit dieser Veröffentlichung ist es, AISVS leicht verständlich und einfach anwendbar zu machen, dabei jedoch konsequent auf seinen definierten Umfang fokussiert zu bleiben und das sich schnell entwickelnde, KI-spezifische Risikoumfeld zu adressieren.

## Hauptziele für AISVS Version 1.0

Version 1.0 wird nach mehreren Leitprinzipien erstellt.

### Gut definierter Umfang

Jede Anforderung muss mit dem Namen und der Mission von AISVS übereinstimmen:

* Künstliche Intelligenz – Kontrollen werden auf der KI/ML-Ebene (Daten, Modell, Pipeline oder Inferenz) durchgeführt und sind die Verantwortung der KI-Anwender.
* Sicherheit – Anforderungen mindern direkt erkannte Sicherheits-, Datenschutz- oder Sicherheitsrisiken.
* Verifikation – Die Sprache ist so verfasst, dass die Konformität objektiv validiert werden kann.
* Standard – Abschnitte folgen einer konsistenten Struktur und Terminologie, um ein zusammenhängendes Referenzwerk zu bilden.
  ​
---

Durch die Einhaltung von AISVS können Organisationen systematisch die Sicherheitslage ihrer KI-Lösungen bewerten und stärken, wodurch eine Kultur der sicheren KI-Entwicklung gefördert wird.

