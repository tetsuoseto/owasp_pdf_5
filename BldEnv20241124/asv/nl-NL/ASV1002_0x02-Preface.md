# Voorwoord

Welkom bij de Artificial Intelligence Security Verification Standard (AISVS) versie 1.0!

## Inleiding

Opgericht in 2025 door een gezamenlijke inzet van de gemeenschap, definieert AISVS de beveiligingseisen die in acht moeten worden genomen bij het ontwerpen, ontwikkelen, implementeren en exploiteren van moderne AI-modellen, pijplijnen en AI-gestuurde diensten.

AISVS v1.0 vertegenwoordigt het gezamenlijke werk van zijn projectleiders, werkgroep en bredere gemeenschap van bijdragers om een pragmatische, toetsbare basislijn te creëren voor het beveiligen van AI-systemen.

Ons doel met deze release is om AISVS gemakkelijk toepasbaar te maken, terwijl we scherp gericht blijven op de gedefinieerde scope en de snel veranderende risicolandschap die uniek is voor AI aanpakken.

## Belangrijkste doelstellingen voor AISVS versie 1.0

Versie 1.0 zal worden gemaakt met meerdere leidende principes.

### Duidelijk Afgebakende Reikwijdte

Elke eis moet in overeenstemming zijn met de naam en missie van AISVS:

* Kunstmatige Intelligentie – Controles worden uitgevoerd op de AI/ML-laag (gegevens, model, pijplijn of inferentie) en zijn de verantwoordelijkheid van AI-beoefenaars.
* Beveiliging – Vereisten verminderen rechtstreeks de vastgestelde beveiligings-, privacy- of veiligheidsrisico's.
* Verificatie – Taal is geschreven zodat naleving objectief kan worden geverifieerd.
* Standaard – Secties volgen een consistente structuur en terminologie om een samenhangende referentie te vormen.
  ​
---

Door AISVS te volgen, kunnen organisaties systematisch de beveiligingspositie van hun AI-oplossingen evalueren en versterken, waardoor een cultuur van veilige AI-engineering wordt bevorderd.

