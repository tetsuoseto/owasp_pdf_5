# 序文

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

## はじめに

AISVSは2025年に共同コミュニティの取り組みにより設立され、現代のAIモデル、パイプライン、およびAI対応サービスの設計、開発、展開、運用時に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、プロジェクトリーダー、作業グループ、および広範なコミュニティ貢献者の協力によって作成されたものであり、AIシステムのセキュリティ確保のための実用的で検証可能な基準を提供します。

このリリースの目的は、AISVSを簡単に導入できるようにすると同時に、その定義された範囲に厳密に集中し、AI特有の急速に進化するリスク環境に対応することです。

## AISVSバージョン1.0の主要目標

バージョン1.0は、いくつかの指針となる原則に基づいて作成されます。

### 明確に定義されたスコープ

各要件はAISVSの名称および使命に沿っている必要があります:

* 人工知能 – 制御はAI/ML層（データ、モデル、パイプライン、または推論）で行われ、AI実務者の責任です。
* セキュリティ – 要件は特定されたセキュリティ、プライバシー、または安全リスクを直接的に軽減します。
* 検証 – 言語は適合性が客観的に検証できるように記述されている。
* 標準 – セクションは一貫した構造と用語を用いて、整合性のある参照を形成します。
  ​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、セキュアなAIエンジニアリングの文化を促進することができます。

