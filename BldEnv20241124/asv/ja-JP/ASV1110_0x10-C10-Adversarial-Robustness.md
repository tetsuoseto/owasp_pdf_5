# 10 敵対的ロバストネスとプライバシー防御

## 管理目標

回避、推論、抽出、または毒性攻撃に直面した際に、AIモデルが信頼性を維持し、プライバシーを保護し、悪用に強いことを保証する。

---

## 10.1 モデル整合性と安全性

有害またはポリシー違反の出力を防止する。

|   #    | Description                                                                                   | Level | Role |
| :----: | --------------------------------------------------------------------------------------------- | :---: | :--: |
| 10.1.1 | アライメントテストスイート（レッドチームプロンプト、ジェイルブレイクプローブ、不許可コンテンツ）がバージョン管理されており、すべてのモデルリリースで実行されていることを確認してください。 |   1   | D/V  |
| 10.1.2 | 拒否と安全完了ガードレールが適用されていることを確認してください。                                                             |   1   |  D   |
| 10.1.3 | 自動評価者が有害コンテンツ率を測定し、設定された閾値を超えるリグレッションを検出することを確認してください。                                        |   2   | D/V  |
| 10.1.4 | カウンタージェイルブレイクトレーニングが文書化され、再現可能であることを確認してください。                                                 |   2   |  D   |
| 10.1.5 | 正式なポリシー遵守の証明または認定された監視が重要なドメインをカバーしていることを確認してください。                                            |   3   |  V   |

---

## 10.2 敵対的サンプルの耐性強化

操作された入力に対するレジリエンスを高める。堅牢な敵対的トレーニングとベンチマークスコアリングが現在の最良の方法である。

|   #    | Description                                              | Level | Role |
| :----: | -------------------------------------------------------- | :---: | :--: |
| 10.2.1 | プロジェクトのリポジトリに再現可能なシードを用いた敵対的トレーニングの設定が含まれていることを確認してください。 |   1   |  D   |
| 10.2.2 | 本番パイプラインにおいて、敵対的サンプル検出がブロッキングアラートを発生させることを検証してください。      |   2   | D/V  |
| 10.2.4 | 認証された堅牢性証明または区間境界証明が、少なくとも最も重要なクラスをカバーしていることを確認してください。   |   3   |  V   |
| 10.2.5 | 回帰テストが適応攻撃を用いて測定可能なロバスト性の低下がないことを確認していることを検証する。          |   3   |  V   |

---

## 10.3 メンバーシップ推論緩和

レコードがトレーニングデータに含まれているかどうかを判断する能力を制限する。差分プライバシーおよび信頼度スコアのマスキングが、最も効果的な既知の防御策のままである。

|   #    | Description                                                         | Level | Role |
| :----: | ------------------------------------------------------------------- | :---: | :--: |
| 10.3.1 | クエリごとのエントロピー正則化または温度スケーリングが過度に自信のある予測を減少させることを検証する。                 |   1   |  D   |
| 10.3.2 | 機密データセットに対しては、ε-制限付き差分プライバシー最適化を使用していることを検証してください。                  |   2   |  D   |
| 10.3.3 | 攻撃シミュレーション（シャドーモデルまたはブラックボックス）が保留データに対して攻撃AUC ≤ 0.60を示すことを確認してください。 |   2   |  V   |

---

## 10.4 モデル反転耐性

プライベート属性の再構築を防ぐ。最近の調査では、実用的な防御策として出力の切り捨てと差分プライバシー（DP）保証が強調されている。

|   #    | Description                                              | Level | Role |
| :----: | -------------------------------------------------------- | :---: | :--: |
| 10.4.1 | 機密属性が直接出力されることがないことを確認してください。必要に応じて、バケットや一方向変換を使用してください。 |   1   |  D   |
| 10.4.2 | 同じ主体からの繰り返しの適応クエリがクエリレート制限によって制御されていることを検証してください。        |   1   | D/V  |
| 10.4.3 | モデルがプライバシー保護ノイズでトレーニングされていることを検証してください。                  |   2   |  D   |

---

## 10.5 モデル抽出防御

不正なクローン作成を検出し抑止します。ウォーターマーキングとクエリパターン分析が推奨されます。

|   #    | Description                                                                  | Level | Role |
| :----: | ---------------------------------------------------------------------------- | :---: | :--: |
| 10.5.1 | 推論ゲートウェイがモデルの記憶閾値に調整されたグローバルおよびAPIキーごとのレート制限を適用していることを確認してください。              |   1   |  D   |
| 10.5.2 | クエリエントロピーと入力複数性の統計が自動抽出検出器に入力されていることを確認してください。                               |   2   | D/V  |
| 10.5.3 | 疑わしいクローンに対して最大1,000回の問い合わせで、p < 0.01の確率で壊れやすい、または確率的透かしの証明が可能であることを検証してください。 |   2   |  V   |
| 10.5.4 | ウォーターマークキーとトリガーセットがハードウェアセキュリティモジュールに保存され、毎年ローテーションされていることを確認してください。         |   3   |  D   |
| 10.5.5 | 抽出アラートイベントに問題のあるクエリが含まれており、インシデント対応プレイブックと統合されていることを確認してください。                |   3   |  V   |

---

## 10.6 推論時の毒物データ検出

バックドアや毒入り入力を検出して無効化します。

|   #    | Description                                                      | Level | Role |
| :----: | ---------------------------------------------------------------- | :---: | :--: |
| 10.6.1 | モデル推論の前に、入力が異常検知器（例：STRIP、一貫性スコアリング）を通過することを確認してください。            |   1   |  D   |
| 10.6.2 | 検出器のしきい値が、5%未満の誤検知を達成するために、クリーンおよび汚染された検証セットで調整されていることを確認してください。 |   1   |  V   |
| 10.6.3 | 毒されたとフラグ付けされた入力がソフトブロッキングおよび人間のレビューのワークフローをトリガーすることを確認してください。    |   2   |  D   |
| 10.6.4 | 検出器が適応的でトリガーレスのバックドア攻撃によってストレステストされていることを確認してください。               |   2   |  V   |
| 10.6.5 | 検出効果指標が記録され、新しい脅威インテリジェンスとともに定期的に再評価されていることを確認してください。            |   3   |  D   |

---

## 10.7 動的セキュリティポリシー適応

脅威インテリジェンスと行動分析に基づくリアルタイムのセキュリティポリシー更新。

|   #    | Description                                                        | Level | Role |
| :----: | ------------------------------------------------------------------ | :---: | :--: |
| 10.7.1 | エージェントの再起動なしにセキュリティポリシーを動的に更新でき、ポリシーバージョンの整合性が保たれていることを確認してください。   |   1   | D/V  |
| 10.7.2 | ポリシーの更新が認可されたセキュリティ担当者によって暗号的に署名され、適用前に検証されていることを確認してください。         |   2   | D/V  |
| 10.7.3 | 動的ポリシーの変更が、正当化、承認チェーン、およびロールバック手順を含む完全な監査証跡とともに記録されていることを確認してください。 |   2   | D/V  |
| 10.7.4 | 適応型セキュリティ機構がリスクの状況や行動パターンに基づいて脅威検知感度を調整することを検証してください。              |   3   | D/V  |
| 10.7.5 | ポリシー適応の決定が説明可能であり、セキュリティチームのレビューのために証拠のトレイルを含むことを確認してください。         |   3   | D/V  |

---

## 10.8 リフレクションベースのセキュリティ分析

エージェントの自己反省とメタ認知分析によるセキュリティ検証。

|   #    | Description                                                    | Level | Role |
| :----: | -------------------------------------------------------------- | :---: | :--: |
| 10.8.1 | エージェントの反省メカニズムには、決定と行動のセキュリティに焦点を当てた自己評価が含まれていることを確認する。        |   1   | D/V  |
| 10.8.2 | 反射出力が検証され、不正な入力による自己評価メカニズムの操作を防止することを確認してください。                |   2   | D/V  |
| 10.8.3 | メタ認知的セキュリティ分析が、エージェントの推論プロセスにおける潜在的なバイアス、操作、または妥協を特定することを検証する。 |   2   | D/V  |
| 10.8.4 | リフレクションベースのセキュリティ警告が高度な監視および潜在的な人間の介入ワークフローを引き起こすことを確認してください。  |   3   | D/V  |
| 10.8.5 | セキュリティ反省からの継続的学習が、正当な機能を損なうことなく脅威検出を向上させることを検証する。              |   3   | D/V  |

---

## 10.9 進化と自己改善のセキュリティ

自己改変および進化が可能なエージェントシステムのためのセキュリティ制御。

|   #    | Description                                      | Level | Role |
| :----: | ------------------------------------------------ | :---: | :--: |
| 10.9.1 | 自己修正機能が指定された安全領域内に制限されていることを、形式的検証の境界で確認してください。  |   1   | D/V  |
| 10.9.2 | 進化提案が実装される前に、セキュリティ影響評価を受けることを確認してください。          |   2   | D/V  |
| 10.9.3 | 自己改善メカニズムには、整合性検証を伴うロールバック機能が含まれていることを確認してください。  |   2   | D/V  |
| 10.9.4 | メタラーニングのセキュリティが改善アルゴリズムの敵対的操作を防止することを検証してください。   |   3   | D/V  |
| 10.9.5 | 再帰的な自己改良が収束の数学的証明とともに形式的な安全制約によって制限されていることを検証する。 |   3   | D/V  |

---

### 参考文献

* [MITRE ATLAS adversary tactics for ML](https://atlas.mitre.org/)
* [NIST AI Risk Management Framework 1.0, 2023](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [OWASP Top 10 for LLM Applications, 2025](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Adversarial Training: A Survey — Zhao et al., 2024](https://arxiv.org/abs/2410.15042)
* [RobustBench adversarial-robustness benchmark](https://robustbench.github.io/)
* [Membership-Inference & Model-Inversion Risk Survey, 2025](https://www.sciencedirect.com/science/article/abs/pii/S0950705125003867)
* [PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023](https://ojs.aaai.org/index.php/AAAI/article/view/26289)
* [Model-Inversion Attacks & Defenses Survey — AI Review, 2025](https://link.springer.com/article/10.1007/s10462-025-11248-0)
* [Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024](https://doi.org/10.1109/TDSC.2023.3261327)
* [Fragile Model Watermarking Survey — 2025](https://www.sciencedirect.com/science/article/abs/pii/S0165168425002026)
* [Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025](https://arxiv.org/abs/2503.22759)
* [BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024](https://arxiv.org/abs/2405.15269)

