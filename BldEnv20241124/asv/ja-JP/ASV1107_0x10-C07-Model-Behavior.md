# C7 モデルの動作、出力制御および安全保証

## 管理目標

モデルの出力は構造化され、信頼性が高く、安全で説明可能であり、運用環境で継続的に監視されなければなりません。これにより、幻覚（ハルシネーション）、プライバシー漏洩、有害なコンテンツ、暴走行動が減少し、ユーザーの信頼と規制遵守が向上します。

---

## C7.1 出力形式の強制

厳格なスキーマ、制約付きデコーディング、および下流の検証は、不正な形式や悪意のあるコンテンツが拡散するのを防ぎます。

|   #   | Description                                                                               | Level | Role |
| :---: | ----------------------------------------------------------------------------------------- | :---: | :--: |
| 7.1.1 | レスポンススキーマ（例：JSONスキーマ）がシステムプロンプトに提供されており、すべての出力が自動的に検証されることを確認してください。不適合な出力は修正または拒否が行われます。 |   1   | D/V  |
| 7.1.2 | オーバーフローやプロンプトインジェクションのサイドチャネルを防ぐために、制約付きデコーディング（停止トークン、正規表現、最大トークン数）が有効になっていることを確認してください。 |   1   | D/V  |
| 7.1.3 | 下流コンポーネントが出力を信用しないものとして扱い、スキーマやインジェクション安全なデシリアライザーに対して検証することを確認してください。                    |   2   | D/V  |
| 7.1.4 | 不適切な出力イベントがログに記録され、レート制限され、監視に反映されていることを確認してください。                                         |   3   |  V   |

---

## C7.2 幻覚検出と軽減

不確実性の推定とフォールバック戦略により、虚偽の回答を抑制します。

|   #   | Description                                                                                  | Level | Role |
| :---: | -------------------------------------------------------------------------------------------- | :---: | :--: |
| 7.2.1 | トークンレベルの対数確率、アンサンブル自己一貫性、または微調整された幻覚検出器が各回答に対して信頼度スコアを割り当てることを確認してください。                      |   1   | D/V  |
| 7.2.2 | 応答の信頼度が設定可能な閾値を下回った場合に、フォールバックワークフロー（例えば、リトリーバル強化生成、セカンダリモデル、または人間のレビュー）がトリガーされることを検証してください。 |   1   | D/V  |
| 7.2.3 | 幻覚発生事例が根本原因のメタデータでタグ付けされ、ポストモーテムおよびファインチューニングのパイプラインにフィードされていることを確認してください。                   |   2   | D/V  |
| 7.2.4 | 主要なモデルまたは知識ベースのアップデート後に、しきい値と検出器が再校正されていることを確認してください。                                        |   3   | D/V  |
| 7.2.5 | ダッシュボードの可視化が幻覚率を追跡していることを確認してください。                                                           |   3   |  V   |

---

## C7.3 出力の安全性とプライバシーフィルタリング

ポリシーフィルターとレッドチームのカバレッジは、ユーザーと機密データを保護します。

|   #   | Description                                                              | Level | Role |
| :---: | ------------------------------------------------------------------------ | :---: | :--: |
| 7.3.1 | ポリシーに沿ったヘイト、嫌がらせ、自傷行為、過激派、および性的に露骨なコンテンツを、生成前および生成後の分類器がブロックしていることを確認する。 |   1   | D/V  |
| 7.3.2 | PII/PCIの検出と自動修正がすべての応答で実行されることを確認してください。違反があった場合はプライバシーインシデントを発生させます。    |   1   | D/V  |
| 7.3.3 | 機密性タグ（例：営業秘密）がモダリティを超えて伝播し、テキスト、画像、コードにおける情報漏洩を防止することを検証する。              |   2   |  D   |
| 7.3.4 | フィルターバイパスの試みや高リスク分類の場合には、二次承認またはユーザーの再認証が必要であることを確認してください。               |   3   | D/V  |
| 7.3.5 | フィルタリングしきい値が法的管轄区域およびユーザーの年齢・役割のコンテキストを反映していることを確認してください。                |   3   | D/V  |

---

## C7.4 出力およびアクション制限

レート制限と承認ゲートは、悪用や過剰な自律性を防ぎます。

|   #   | Description                                                                             | Level | Role |
| :---: | --------------------------------------------------------------------------------------- | :---: | :--: |
| 7.4.1 | ユーザーごとおよびAPIキーごとのクォータがリクエスト数、トークン数、およびコストを制限し、429エラー発生時には指数関数的バックオフを適用することを検証してください。    |   1   |  D   |
| 7.4.2 | 特権操作（ファイル書き込み、コード実行、ネットワーク呼び出し）がポリシーベースの承認または人間の介入を必要とすることを検証してください。                    |   1   | D/V  |
| 7.4.3 | 同じリクエストに対して生成された画像、コード、テキストが悪意のあるコンテンツを密輸するために使用されないことを保証するために、クロスモーダル一貫性チェックを検証してください。 |   2   | D/V  |
| 7.4.4 | エージェントの委任深度、再帰制限、および許可されたツールリストが明示的に設定されていることを確認してください。                                 |   2   |  D   |
| 7.4.5 | 制限違反がSIEM取り込み用の構造化されたセキュリティイベントを発行することを検証してください。                                        |   3   |  V   |

---

## C7.5 出力の説明可能性

透明なシグナルはユーザーの信頼と内部のデバッグを向上させます。

|   #   | Description                                                     | Level | Role |
| :---: | --------------------------------------------------------------- | :---: | :--: |
| 7.5.1 | リスク評価で適切と判断された場合、ユーザー向けの信頼度スコアや簡潔な推論要約が表示されることを確認してください。        |   2   | D/V  |
| 7.5.2 | 生成された説明が、機密性の高いシステムプロンプトや独自のデータを明かさないように確認してください。               |   2   | D/V  |
| 7.5.3 | システムがトークンレベルのログ確率またはアテンションマップを取得し、認可された検査のために保存していることを確認してください。 |   3   |  D   |
| 7.5.4 | 説明可能性アーティファクトがモデルリリースとともに監査可能性のためにバージョン管理されていることを確認してください。      |   3   |  V   |

---

## C7.6 モニタリング統合

リアルタイムの可観測性は、開発と本番環境の間のループを閉じます。

|   #   | Description                                                              | Level | Role |
| :---: | ------------------------------------------------------------------------ | :---: | :--: |
| 7.6.1 | メトリクス（スキーマ違反、幻覚率、毒性、個人情報漏洩、レイテンシ、コスト）が中央監視プラットフォームに送信されていることを確認してください。   |   1   |  D   |
| 7.6.2 | 各安全指標に対して警告閾値が定義されており、オンコールエスカレーション経路が設定されていることを確認してください。                |   1   |  V   |
| 7.6.3 | ダッシュボードが出力の異常をモデル/バージョン、機能フラグ、および上流データの変更と関連付けていることを確認してください。            |   2   |  V   |
| 7.6.4 | 監視データが文書化されたMLOpsワークフロー内で再訓練、ファインチューニング、またはルールの更新にフィードバックされることを確認してください。 |   2   | D/V  |
| 7.6.5 | 監視パイプラインがペネトレーションテストされ、アクセス制御されていることを確認し、機密ログの漏洩を防止してください。               |   3   |  V   |

---

## 7.7 ジェネレーティブメディアのセーフガード

ポリシー制約、出力の検証、および追跡可能性を強化することで、AIシステムが違法、有害、または許可されていないメディアコンテンツを生成しないようにします。

|   #   | Description                                                                                | Level | Role |
| :---: | ------------------------------------------------------------------------------------------ | :---: | :--: |
| 7.7.1 | システムプロンプトとユーザー指示が、違法、有害、または同意なしのディープフェイクメディア（例：画像、動画、音声）の生成を明確に禁止していることを確認してください。          |   1   | D/V  |
| 7.7.2 | プロンプトがなりすましの生成、性的に露骨なディープフェイク、または本人の同意なしに実在の個人を描写するメディアの試みに対してフィルタリングされていることを確認してください。     |   2   | D/V  |
| 7.7.3 | システムが無断複製を防ぐために、知覚ハッシュ、ウォーターマーク検出、またはフィンガープリンティングを使用していることを確認してください。                       |   2   |  V   |
| 7.7.4 | すべての生成されたメディアが、下流のトレーサビリティのために暗号署名されているか、透かしが入れられているか、改ざん耐性のある起源メタデータが埋め込まれていることを確認してください。 |   3   | D/V  |
| 7.7.5 | バイパス試行（例：プロンプトの難読化、スラング、敵対的な表現）が検出、記録され、レート制限されることを確認する。繰り返される悪用は監視システムに通知される。             |   3   |  V   |

## 参考文献

* [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
* [ISO/IEC 42001:2023 – AI Management System](https://www.iso.org/obp/ui/en/)
* [OWASP Top-10 for Large Language Model Applications (2025)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
* [Improper Output Handling – OWASP LLM05:2025](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
* [Practical Techniques to Constrain LLM Output](https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670)
* [Dataiku – Structured Text Generation Guide](https://blog.dataiku.com/your-guide-to-structured-text-generation)
* [VL-Uncertainty: Detecting Hallucinations](https://arxiv.org/abs/2411.11919)
* [HaDeMiF: Hallucination Detection & Mitigation](https://openreview.net/forum?id=VwOYxPScxB)
* [Building Confidence in LLM Outputs](https://www.alkymi.io/data-science-room/building-confidence-in-llm-outputs)
* [Explainable AI & LLMs](https://duncsand.medium.com/explainable-ai-140912d31b3b)
* [LLM Red-Teaming Guide](https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide)
* [Sensitive Information Disclosure in LLMs](https://virtualcyberlabs.com/llm-sensitive-information-disclosure/)
* [LangChain – Chat Model Rate Limiting](https://python.langchain.com/docs/how_to/chat_model_rate_limiting/)
* [OpenAI Rate-Limit & Exponential Back-off](https://hackernoon.com/openais-rate-limit-a-guide-to-exponential-backoff-for-llm-evaluation)
* [Arize AI – LLM Observability Platform](https://arize.com/)

