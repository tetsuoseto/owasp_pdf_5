## 扉絵

### 標準について

人工知能セキュリティ検証標準（AISVS）は、データサイエンティスト、MLOpsエンジニア、ソフトウェアアーキテクト、開発者、テスター、セキュリティ専門家、ツールベンダー、規制当局、消費者が信頼できるAI対応システムおよびアプリケーションを設計、構築、テスト、検証するために利用できるコミュニティ主導のセキュリティ要件カタログです。これは、データ収集やモデル開発から展開および継続的な監視に至るAIライフサイクル全体にわたるセキュリティコントロールを指定するための共通言語を提供し、組織がAIソリューションのレジリエンス、プライバシー、および安全性を測定・改善できるようにします。

### 著作権とライセンス

バージョン0.1（初公開ドラフト - 作業進行中）、2025年  

![license](images/license.png)
著作権 © 2025 AISVSプロジェクト。  

の下でリリースされましたCreative Commons Attribution‑ShareAlike 4.0 International License.
この作品の再利用や配布を行う場合は、そのライセンス条件を他者に明確に伝えなければなりません。

### プロジェクトリーダー

ジム・マニコ
アラス・「ラス」・メミシャジチ

### 寄稿者およびレビュアー

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVSは、人工知能システムの特有のセキュリティ課題に対応するために特別に作られた全く新しい基準です。広範なセキュリティのベストプラクティスから着想を得ていますが、AISVSのすべての要件はAIの脅威環境を反映し、組織がより安全で強靭なAIソリューションを構築するのを支援するためにゼロから開発されています。

## 序文

人工知能セキュリティ検証標準（AISVS）バージョン1.0へようこそ！

### はじめに

AISVSは2025年に共同コミュニティの取り組みにより設立され、現代のAIモデル、パイプライン、およびAI対応サービスの設計、開発、展開、運用時に考慮すべきセキュリティ要件を定義しています。

AISVS v1.0は、プロジェクトリーダー、作業グループ、および広範なコミュニティ貢献者の協力によって作成されたものであり、AIシステムのセキュリティ確保のための実用的で検証可能な基準を提供します。

このリリースの目的は、AISVSを簡単に導入できるようにすると同時に、その定義された範囲に厳密に集中し、AI特有の急速に進化するリスク環境に対応することです。

### AISVSバージョン1.0の主要目標

バージョン1.0は、いくつかの指針となる原則に基づいて作成されます。

#### 明確に定義されたスコープ

各要件はAISVSの名称および使命に沿っている必要があります:

人工知能 – 制御はAI/ML層（データ、モデル、パイプライン、または推論）で行われ、AI実務者の責任です。
セキュリティ – 要件は特定されたセキュリティ、プライバシー、または安全リスクを直接的に軽減します。
検証 – 言語は適合性が客観的に検証できるように記述されている。
標準 – セクションは一貫した構造と用語を用いて、整合性のある参照を形成します。
​
---

AISVSに従うことで、組織はAIソリューションのセキュリティ体制を体系的に評価・強化し、セキュアなAIエンジニアリングの文化を促進することができます。

## AISVSを使用して

人工知能セキュリティ検証標準（AISVS）は、現代のAIアプリケーションおよびサービスに対するセキュリティ要件を定義しており、アプリケーション開発者の管理下にある側面に焦点を当てています。

AISVSは、開発者、アーキテクト、セキュリティエンジニア、監査人など、AIアプリケーションのセキュリティを開発または評価するすべての関係者を対象としています。本章では、AISVSの構造と使用方法、検証レベルおよび想定される利用ケースについて紹介します。

### 人工知能セキュリティ検証レベル

AISVSは、3つの上位レベルのセキュリティ検証を定義しています。各レベルは深さと複雑さを増し、組織がAIシステムのリスクレベルに応じてセキュリティ態勢を調整できるようにします。

組織はレベル1から開始し、セキュリティ成熟度と脅威への曝露が増加するにつれて、順次より高いレベルを採用していく場合があります。

#### レベルの定義

AISVS v1.0の各要件は、以下のいずれかのレベルに割り当てられます:

 レベル1の要件

レベル1には、最も重要で基盤となるセキュリティ要件が含まれています。これらは他の前提条件や脆弱性に依存しない一般的な攻撃を防ぐことに焦点を当てています。ほとんどのレベル1のコントロールは、実装が比較的簡単であるか、努力に見合うほど重要です。

 レベル 2 の要件

レベル2は、より高度またはあまり一般的でない攻撃に対処するとともに、広範な脅威に対する多層防御を扱います。これらの要件は、より複雑なロジックを含んだり、特定の攻撃前提条件をターゲットにする場合があります。

 レベル3の要件

レベル3には、通常実装が難しいか適用状況が限定される制御が含まれます。これらは多くの場合、深層防御メカニズムや、特定のニッチな攻撃、ターゲットを絞った攻撃、高度な複雑性を持つ攻撃に対する緩和策を表しています。

#### 役割（D/V）

各AISVS要件は主な対象読者に応じてマークされています。

D – 開発者向け要件
V – 検証者／監査者向け要件
D/V – 開発者および検証者の両方に関連する

## C1 トレーニングデータガバナンスとバイアス管理

### 管理目標

トレーニングデータは出所、セキュリティ、品質、公平性を保持する方法で収集、取り扱い、および管理されなければなりません。これにより、法的義務を果たし、AIのライフサイクル全体でのバイアス、データ汚染、プライバシー侵害のリスクを低減します。

---

### C1.1 訓練データの出所

すべてのデータセットの検証可能なインベントリを維持し、信頼できるソースのみを受け入れ、監査可能性のためにすべての変更を記録します。

 #1.1.1    Level: 1    Role: D/V
 すべてのトレーニングデータソース（起源、管理者/所有者、ライセンス、収集方法、使用制約、処理履歴）について最新のインベントリが維持されていることを確認してください。
 #1.1.2    Level: 1    Role: D/V
 品質、代表性、倫理的な調達、およびライセンス遵守が確認されたデータセットのみを許可し、データ中毒、内在するバイアス、および知的財産権侵害のリスクを低減することを確認してください。
 #1.1.3    Level: 1    Role: D/V
 不要または機密性の高い属性が除外されるように、データ最小化が適用されていることを確認してください。
 #1.1.4    Level: 2    Role: D/V
 すべてのデータセットの変更が記録された承認ワークフローの対象であることを確認してください。
 #1.1.5    Level: 2    Role: D/V
 レビュアーの相互チェックまたは合意により、ラベリング／アノテーションの品質が確保されていることを確認してください。
 #1.1.6    Level: 2    Role: D/V
 重要なトレーニングデータセットについては、「データカード」または「データセット用データシート」が維持されていることを確認し、それらが特性、目的、構成、収集プロセス、前処理、推奨される利用方法および推奨されない利用方法を詳細に記述していることを検証してください。

---

### C1.2 トレーニングデータのセキュリティと完全性

アクセス制限を行い、保存時および通信時に暗号化し、改ざんや盗難を防ぐために整合性を検証します。

 #1.2.1    Level: 1    Role: D/V
 アクセス制御がストレージおよびパイプラインを保護していることを確認する。
 #1.2.2    Level: 2    Role: D/V
 データセットが転送中に暗号化されていること、そしてすべての機密情報または個人を特定できる情報（PII）が保存時にも業界標準の暗号アルゴリズムおよび鍵管理手法を用いて暗号化されていることを確認してください。
 #1.2.3    Level: 2    Role: D/V
 ストレージおよび転送中のデータの整合性を確保するために、暗号ハッシュまたはデジタル署名が使用されていることを確認し、さらに標的型データ汚染攻撃を含む不正な改ざんや破損に対して、自動化された異常検知技術が適用されていることを確認してください。
 #1.2.4    Level: 3    Role: D/V
 データセットのバージョンが追跡されており、ロールバックが可能であることを確認してください。
 #1.2.5    Level: 2    Role: D/V
 データ保持ポリシー、規制要件に準拠し、攻撃対象領域を縮小するために、不要なデータが安全に消去または匿名化されていることを確認してください。

---

### C1.3 表現の完全性と公平性

人口統計の偏りを検出し、モデルの誤差率がグループ間で公平になるように緩和策を適用する。

 #1.3.1    Level: 1    Role: D/V
 データセットが法的に保護された属性（例：人種、性別、年齢）およびモデルの適用領域に関連するその他の倫理的に敏感な特徴（例：社会経済的地位、所在地）における表現の不均衡や潜在的なバイアスについてプロファイリングされていることを確認してください。
 #1.3.2    Level: 2    Role: D/V
 特定されたバイアスが、再バランス、ターゲットを絞ったデータ拡張、アルゴリズム調整（例：前処理、処理中、後処理の技術）、または再重み付けなどの文書化された戦略によって軽減されていることを確認し、軽減策が公平性および全体的なモデル性能の両方に与える影響を評価する。
 #1.3.3    Level: 2    Role: D/V
 トレーニング後の公平性指標が評価され、文書化されていることを確認してください。
 #1.3.4    Level: 3    Role: D/V
 ライフサイクルバイアスマネジメントポリシーが所有者とレビューの頻度を割り当てていることを確認してください。

---

### C1.4 トレーニングデータのラベリング品質、完全性、およびセキュリティ

ラベルを暗号化で保護し、重要なクラスには二重レビューを必須とする。

 #1.4.1    Level: 2    Role: D/V
 ラベリング/アノテーションの品質が、明確なガイドライン、レビュアーによる相互チェック、コンセンサスメカニズム（例：アノテーター間一致の監視）、および不一致を解決するために定義されたプロセスを通じて確保されていることを検証してください。
 #1.4.2    Level: 2    Role: D/V
 ラベルアーティファクトの整合性と真正性を確保するために、暗号ハッシュまたはデジタル署名が適用されていることを確認してください。
 #1.4.3    Level: 2    Role: D/V
 ラベリングインターフェースおよびプラットフォームが強力なアクセス制御を実施し、すべてのラベリング活動の改ざん検知可能な監査ログを維持し、不正な修正から保護していることを確認してください。
 #1.4.4    Level: 3    Role: D/V
 安全性、セキュリティ、公平性にとって重要なラベル（例：有害なコンテンツの識別、重要な医療所見）については、必ず独立した二重レビューまたは同等の厳格な検証を受けることを確認してください。
 #1.4.5    Level: 2    Role: D/V
 ラベルに意図せず含まれた、または必然的に含まれる機微な情報（個人識別情報（PII）を含む）が、データ最小化の原則に従い、保存時および転送時にマスキング、仮名化、匿名化、または暗号化されていることを確認してください。
 #1.4.6    Level: 2    Role: D/V
 ラベリングガイドと指示が包括的で、バージョン管理され、ピアレビューされていることを確認してください。
 #1.4.7    Level: 2    Role: D/V
 データスキーマ（ラベルを含む）が明確に定義され、バージョン管理されていることを確認してください。
 #1.8.2    Level: 2    Role: D/V
 アウトソースまたはクラウドソースされたラベリングワークフローが、データの機密性、完全性、ラベル品質を保証し、データ漏洩を防ぐための技術的および手続き的な保護策を含んでいることを確認してください。

---

### C1.5 トレーニングデータ品質保証

自動検証、手動スポットチェック、記録された修復を組み合わせて、データセットの信頼性を保証します。

 #1.5.1    Level: 1    Role: D
 自動テストが、すべての取り込みや重要な変換時にフォーマットエラー、ヌル値、およびラベルのずれを検出することを確認してください。
 #1.5.2    Level: 1    Role: D/V
 失敗したデータセットが監査証跡付きで隔離されていることを確認します。
 #1.5.3    Level: 2    Role: V
 ドメイン専門家による手動のスポットチェックが、統計的に有意なサンプル（例：1%以上または1,000サンプルのいずれか大きい方、またはリスク評価により決定された量）をカバーしており、自動化で検出されない微妙な品質問題を特定していることを確認してください。
 #1.5.4    Level: 2    Role: D/V
 修復手順が出典記録に追加されていることを確認してください。
 #1.5.5    Level: 2    Role: D/V
 品質ゲートが例外が承認されていない限り、品質の劣るデータセットをブロックすることを確認してください。

---

### C1.6 データポイズニング検出

統計的異常検知と隔離ワークフローを適用して、敵対的挿入を阻止します。

 #1.6.1    Level: 2    Role: D/V
 トレーニングデータの取り込み時および主要なトレーニング実行前に、異常検知技術（例：統計的手法、外れ値検出、埋め込み分析）が適用され、潜在的な毒物攻撃や意図しないデータ汚染が識別されていることを確認してください。
 #1.6.2    Level: 2    Role: D/V
 フラグ付きサンプルがトレーニング前に手動レビューをトリガーすることを確認してください。
 #1.6.3    Level: 2    Role: V
 結果がモデルのセキュリティドシエにフィードされ、継続的な脅威インテリジェンスに役立つことを確認します。
 #1.6.4    Level: 3    Role: D/V
 検出ロジックが新しい脅威インテリジェンスで更新されていることを確認してください。
 #1.6.5    Level: 3    Role: D/V
 オンライン学習パイプラインが分布ドリフトを監視していることを確認してください。
 #1.6.6    Level: 3    Role: D/V
 既知のデータポイズニング攻撃タイプ（例：ラベル反転、バックドアトリガー挿入、影響力のあるインスタンス攻撃）に対する特定の防御策が、システムのリスクプロファイルおよびデータソースに基づいて検討および実装されていることを確認してください。

---

### C1.7 ユーザーデータの削除と同意の強制

データセット、バックアップ、および派生アーティファクト全体で削除および同意撤回の要求を遵守してください。

 #1.7.1    Level: 1    Role: D/V
 削除ワークフローがプライマリおよび派生データを完全に消去し、その影響がモデルに与える影響を評価し、必要に応じて影響を受けたモデルについて再訓練や再校正などの対応が行われていることを確認する。
 #1.7.2    Level: 2    Role: D
 ユーザーの同意（および撤回）の範囲と状態を追跡し尊重する仕組みが整っていることを確認し、データが新しいトレーニングプロセスや重要なモデルの更新に組み込まれる前に同意が検証されていることを確認してください。
 #1.7.3    Level: 2    Role: V
 ワークフローが年に一度テストされ、ログが記録されていることを確認してください。

---

### C1.8 サプライチェーンセキュリティ

外部データプロバイダーを審査し、認証済みかつ暗号化されたチャネルを通じてデータの完全性を検証する。

 #1.8.1    Level: 2    Role: D/V
 第三者のデータ供給者（事前学習済みモデルの提供者や外部データセットの提供者を含む）が、そのデータやモデルが統合される前に、セキュリティ、プライバシー、倫理的調達、およびデータ品質のデューデリジェンスを受けていることを確認する。
 #1.8.2    Level: 1    Role: D
 外部転送がTLS認証および整合性チェックを使用していることを確認してください。
 #1.8.3    Level: 2    Role: D/V
 高リスクのデータソース（例：出所不明のオープンソースデータセット、未検証の供給者）については、機密性の高いアプリケーションで使用する前に、サンドボックス分析、徹底した品質・バイアスチェック、標的型汚染検出などの強化された精査を行うことを確認する。
 #1.8.4    Level: 3    Role: D/V
 第三者から入手した事前学習済みモデルは、微調整や展開の前に、埋め込まれたバイアス、潜在的なバックドア、アーキテクチャの整合性、および元のトレーニングデータの出所について評価されていることを確認してください。

---

### C1.9 敵対的サンプル検出

トレーニング段階で敵対的トレーニングなどの対策を実施し、敵対的サンプルに対するモデルの耐性を強化する。

 #1.9.1    Level: 3    Role: D/V
 生成された敵対的例を使用した敵対的トレーニング、摂動された入力によるデータ拡張、または堅牢な最適化技術などの適切な防御策が、リスク評価に基づいて関連モデルに実装され、調整されていることを確認してください。
 #1.9.2    Level: 2    Role: D/V
 敵対的トレーニングが使用されている場合、敵対的データセットの生成、管理、およびバージョン管理が文書化され、制御されていることを確認します。
 #1.9.3    Level: 3    Role: D/V
 敵対的ロバストネス訓練がモデル性能（クリーン入力および敵対的入力の両方に対して）および公平性指標に与える影響が評価され、文書化され、監視されていることを確認する。
 #1.9.4    Level: 3    Role: D/V
 敵対的トレーニングおよびロバストネスに関する戦略が、進化する敵対的攻撃技術に対応するために定期的に見直され、更新されていることを確認してください。

---

### C1.10 データの系譜と追跡可能性

監査可能性とインシデント対応のために、各データポイントのソースからモデル入力に至るまでの完全な経路を追跡する。

 #1.10.1    Level: 2    Role: D/V
 各データポイントの系統が、すべての変換、増強、およびマージを含めて記録され、再構築可能であることを確認してください。
 #1.10.2    Level: 2    Role: D/V
 系譜記録が不変で、安全に保存されており、監査や調査のためにアクセス可能であることを検証してください。
 #1.10.3    Level: 2    Role: D/V
 系統追跡が生のデータと合成データの両方をカバーしていることを確認してください。

---

### C1.11 合成データ管理

合成データが適切に管理され、ラベル付けされ、リスク評価されていることを確保してください。

 #1.11.1    Level: 2    Role: D/V
 パイプライン全体で、すべての合成データが明確にラベル付けされ、実データと区別できることを確認してください。
 #1.11.2    Level: 2    Role: D/V
 生成プロセス、パラメータ、および合成データの意図された使用目的が文書化されていることを確認してください。
 #1.11.3    Level: 2    Role: D/V
 合成データがトレーニングに使用される前に、バイアス、プライバシー漏えい、および表現上の問題についてリスク評価されていることを確認してください。

---

### C1.12 データアクセス監視および異常検知

トレーニングデータへの異常なアクセスを監視し、内部関係者の脅威や情報持ち出しを検出するためにアラートを発する。

 #1.12.1    Level: 2    Role: D/V
 トレーニングデータへのすべてのアクセスが、ユーザー、時間、および操作を含めて記録されていることを確認してください。
 #1.12.2    Level: 2    Role: D/V
 アクセスログが、大量のエクスポートや新しい場所からのアクセスなど、異常なパターンについて定期的に確認されていることを検証してください。
 #1.12.3    Level: 2    Role: D/V
 疑わしいアクセスイベントに対してアラートが生成され、迅速に調査されていることを確認してください。

---

### C1.13 データ保持および期限切れポリシー

不要なデータ保存を最小限に抑えるために、データ保持期間を定義し、強制する。

 #1.13.1    Level: 1    Role: D/V
 すべてのトレーニングデータセットに対して明示的な保存期間が定義されていることを確認してください。
 #1.13.2    Level: 2    Role: D/V
 データセットがライフサイクルの終了時に自動的に期限切れ、削除、または削除のためのレビューが行われることを確認してください。
 #1.13.3    Level: 2    Role: D/V
 保持および削除の操作が記録され、監査可能であることを確認してください。

---

### C1.14 規制および管轄の遵守

すべてのトレーニングデータが適用される法令および規制に準拠していることを保証してください。

 #1.14.1    Level: 2    Role: D/V
 すべてのデータセットについて、データ居住および越境転送の要件が特定され、遵守されていることを確認してください。
 #1.14.2    Level: 2    Role: D/V
 セクター別の規制（例：医療、金融）が特定され、データ処理において対処されていることを確認してください。
 #1.14.3    Level: 2    Role: D/V
 関連するプライバシー法（例：GDPR、CCPA）への準拠が文書化され、定期的にレビューされていることを確認してください。

---

### C1.15 データウォーターマーキングおよびフィンガープリンティング

専有または機密データの無許可の再利用や漏洩を検出する。

 #1.15.1    Level: 3    Role: D/V
 可能な場合は、データセットやサブセットにウォーターマークまたはフィンガープリントが施されていることを確認してください。
 #1.15.2    Level: 3    Role: D/V
 ウォーターマーキング／フィンガープリンティング手法がバイアスやプライバシーリスクを引き起こさないことを確認する。
 #1.15.3    Level: 3    Role: D/V
 ウォーターマーク付きデータの不正な再利用や漏洩を検出するために、定期的なチェックが行われていることを確認してください。

---

### C1.16 データ主体の権利管理

アクセス、訂正、制限、および異議申し立てなどのデータ主体の権利をサポートします。

 #1.16.1    Level: 2    Role: D/V
 データ主体からのアクセス、訂正、制限、または異議申し立ての要求に対応するためのメカニズムが存在することを確認してください。
 #1.16.2    Level: 2    Role: D/V
 リクエストが法的に定められた期間内に記録、追跡、履行されていることを検証してください。
 #1.16.3    Level: 2    Role: D/V
 データ主体の権利に関するプロセスが効果的であることを確認するため、定期的にテストおよびレビューが行われていることを検証してください。

---

### C1.17 データセットバージョン影響分析

データセットのバージョンを更新または置き換える前に、変更の影響を評価してください。

 #1.17.1    Level: 2    Role: D/V
 データセットのバージョンを更新または置き換える前に、モデルの性能、公平性、およびコンプライアンスを含むインパクト分析が実施されていることを確認してください。
 #1.17.2    Level: 2    Role: D/V
 インパクト分析の結果が文書化され、関連する利害関係者によってレビューされていることを確認してください。
 #1.17.3    Level: 2    Role: D/V
 新しいバージョンが許容できないリスクや後退をもたらした場合に備え、ロールバック計画が存在することを確認してください。

---

### C1.18 データ注釈作業員のセキュリティ

データ注釈に関与する人員の安全性と完全性を確保する。

 #1.18.1    Level: 2    Role: D/V
 データ注釈に関与する全ての担当者が、バックグラウンドチェックを受け、データセキュリティおよびプライバシーに関する訓練を受けていることを確認してください。
 #1.18.2    Level: 2    Role: D/V
 すべてのアノテーション担当者が機密保持および秘密保持契約に署名していることを確認してください。
 #1.18.3    Level: 2    Role: D/V
 注釈プラットフォームがアクセス制御を実施し、内部脅威を監視していることを確認してください。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 ユーザー入力検証

### 管理目的

ユーザー入力の堅牢な検証は、AIシステムに対する最も破壊的な攻撃のいくつかに対する最前線の防御手段です。プロンプトインジェクション攻撃は、システムの指示を上書きしたり、機密データを漏洩させたり、モデルを許可されていない動作に誘導したりする可能性があります。専用のフィルターや指示の階層構造が整備されていない限り、研究によれば非常に長いコンテキストウィンドウを悪用する「マルチショット」ジェイルブレイクが効果的であることが示されています。また、ホモグリフの置換やリートスピークのような微妙な敵対的摂動攻撃も、モデルの判断を密かに変更する可能性があります。

---

### C2.1 プロンプトインジェクション防御

プロンプトインジェクションはAIシステムにおける主要なリスクの一つです。これに対する防御策は、静的パターンフィルター、動的分類器、および指示階層の強制を組み合わせて実施されます。

 #2.1.1    Level: 1    Role: D/V
 ユーザーの入力が、継続的に更新される既知のプロンプトインジェクションパターン（ジャイルブレイクキーワード、「以前を無視」、ロールプレイチェーン、間接的なHTML/URL攻撃）に対して検査されていることを確認してください。
 #2.1.2    Level: 1    Role: D/V
 システムがコンテキストウィンドウの拡張後でも、システムまたは開発者のメッセージがユーザーの指示に優先する指示階層を強制していることを確認してください。
 #2.1.3    Level: 2    Role: D/V
 敵対的評価テスト（例：レッドチームの「多数ショット」プロンプト）が、すべてのモデルやプロンプトテンプレートのリリース前に実施され、成功率のしきい値および回帰を防ぐ自動ブロッカーが設定されていることを確認してください。
 #2.1.4    Level: 2    Role: D
 サードパーティのコンテンツ（ウェブページ、PDF、メール）から発信されるプロンプトが、メインプロンプトに連結される前に、分離されたパースコンテキストで適切にサニタイズされていることを確認してください。
 #2.1.5    Level: 3    Role: D/V
 すべてのプロンプトフィルタールールの更新、分類器モデルのバージョン、およびブロックリストの変更がバージョン管理され、監査可能であることを確認してください。

---

### C2.2 対抗例耐性

自然言語処理（NLP）モデルは、ヒトが見逃しがちな微妙な文字または単語レベルの摂動に対して依然として脆弱であり、モデルはそれを誤分類する傾向があります。

 #2.2.1    Level: 1    Role: D
 基本的な入力正規化手順（Unicode NFC、類似文字マッピング、空白のトリミング）がトークン化の前に実行されることを確認してください。
 #2.2.2    Level: 2    Role: D/V
 統計的異常検出が言語の規範から著しく離れた編集距離、不自然に繰り返されるトークン、または異常な埋め込み距離を持つ入力を検出することを確認してください。
 #2.2.3    Level: 2    Role: D
 推論パイプラインが、オプションの敵対的トレーニング耐性モデルバリアントや防御レイヤー（例：ランダム化、防御的蒸留）を高リスクのエンドポイント向けにサポートしていることを検証してください。
 #2.2.4    Level: 2    Role: V
 疑わしい敵対的入力が隔離され、（PIIの削除後に）完全なペイロードとともにログ記録されていることを確認してください。
 #2.2.5    Level: 3    Role: D/V
 既知の攻撃スイートの成功率などの堅牢性指標が時間経過で追跡されており、回帰が発生した場合にはリリースのブロッカーがトリガーされることを確認してください。

---

### C2.3 スキーマ、型および長さの検証

不正な形式や過大な入力を伴うAI攻撃は、パースエラー、フィールド間のプロンプトの漏れ、リソース枯渇を引き起こす可能性があります。厳格なスキーマの適用は、決定論的なツール呼び出しを行う際にも必須条件です。

 #2.3.1    Level: 1    Role: D
 すべてのAPIまたは関数呼び出しのエンドポイントが明確な入力スキーマ（JSONスキーマ、Protobuf、またはマルチモーダルに相当するもの）を定義し、プロンプトの組み立て前に入力が検証されていることを確認してください。
 #2.3.2    Level: 1    Role: D/V
 入力が最大トークン数またはバイト数の制限を超えた場合、安全なエラーで拒否され、決して静かに切り詰められないことを確認してください。
 #2.3.3    Level: 2    Role: D/V
 型チェック（例：数値範囲、列挙型の値、画像や音声のMIMEタイプ）がクライアント側コードだけでなく、サーバー側でも確実に実施されていることを確認してください。
 #2.3.4    Level: 2    Role: D
 セマンティックバリデーター（例：JSONスキーマ）がアルゴリズム的なDoSを防ぐために一定時間で実行されることを検証してください。
 #2.3.5    Level: 3    Role: V
 検証失敗が、セキュリティトリアージを支援するために、修正済みペイロードの抜粋と明確なエラーコードとともにログ記録されていることを確認してください。

---

### C2.4 コンテンツおよびポリシースクリーニング

開発者は、許可されていない内容（違法な指示、ヘイトスピーチ、著作権で保護されたテキストなど）を要求する、構文的に有効なプロンプトを検出し、それらが拡散するのを防止できるようにする必要があります。

 #2.4.1    Level: 1    Role: D
 コンテンツ分類器（ゼロショットまたはファインチューニング済み）が、暴力、自傷行為、ヘイト、性的内容、違法な要求について、設定可能なしきい値で全ての入力を評価することを確認してください。
 #2.4.2    Level: 1    Role: D/V
 ポリシーに違反する入力が、標準化された拒否応答または安全な補完を受け取り、それが下流の大規模言語モデル（LLM）呼び出しに伝播しないことを確認してください。
 #2.4.3    Level: 2    Role: D
 スクリーニングモデルまたはルールセットが、少なくとも四半期ごとに、新たに観察されたジャイルブレイクやポリシーバイパスのパターンを取り入れて再学習・更新されていることを確認してください。
 #2.4.4    Level: 2    Role: D
 属性ベースのルールを使用してリクエスト時に解決されるユーザー固有のポリシー（年齢、地域の法的制約）を遵守していることを検証します。
 #2.4.5    Level: 3    Role: V
 スクリーニングログに分類器の信頼度スコアとポリシーカテゴリタグが含まれていることを確認し、SOCの相関分析および将来のレッドチーム再現に役立てます。

---

### C2.5 入力レート制限と悪用防止

開発者は、入力速度を制限し、異常な使用パターンを検出することで、AIシステムに対する悪用、リソースの枯渇、自動化された攻撃を防止すべきです。

 #2.5.1    Level: 1    Role: D/V
 すべての入力エンドポイントに対して、ユーザーごと、IPごと、APIキーごとのレート制限が適用されていることを確認してください。
 #2.5.2    Level: 2    Role: D/V
 DoS（サービス拒否）攻撃やブルートフォース攻撃を防ぐために、バーストおよび持続的なレート制限が適切に調整されていることを検証してください。
 #2.5.3    Level: 2    Role: D/V
 異常な使用パターン（例：短時間に多数のリクエスト、入力の氾濫）が自動的なブロックまたはエスカレーションを引き起こすことを確認してください。
 #2.5.4    Level: 3    Role: V
 悪用防止ログが保持され、新たな攻撃パターンのためにレビューされていることを確認してください。

---

### C2.6 マルチモーダル入力検証

AIシステムは、注入、回避、またはリソースの乱用を防ぐために、非テキスト入力（画像、音声、ファイル）に対して堅牢な検証を含めるべきです。

 #2.6.1    Level: 1    Role: D
 すべての非テキスト入力（画像、音声、ファイル）が処理前にタイプ、サイズ、およびフォーマットについて検証されていることを確認してください。
 #2.6.2    Level: 2    Role: D/V
 ファイルが取り込み前にマルウェアおよびステガノグラフィックペイロードのスキャンを受けていることを確認してください。
 #2.6.3    Level: 2    Role: D/V
 画像/音声入力が敵対的摂動や既知の攻撃パターンに対して検査されていることを確認してください。
 #2.6.4    Level: 3    Role: V
 マルチモーダル入力検証の失敗がログに記録され、調査のためのアラートがトリガーされることを確認してください。

---

### C2.7 入力の出所と帰属

AIシステムは、すべてのユーザー入力の起源を監視およびタグ付けすることによって、監査、悪用追跡、およびコンプライアンスをサポートすべきです。

 #2.7.1    Level: 1    Role: D/V
 すべてのユーザー入力が取り込み時にメタデータ（ユーザーID、セッション、ソース、タイムスタンプ、IPアドレス）でタグ付けされていることを確認してください。
 #2.7.2    Level: 2    Role: D/V
 すべての処理された入力に対して、出所メタデータが保持され、監査可能であることを確認してください。
 #2.7.3    Level: 2    Role: D/V
 異常または信頼できない入力ソースが検出され、強化された監視またはブロックの対象となることを確認してください。

---

### C2.8 リアルタイム適応型脅威検出

開発者は、新しい攻撃パターンに適応し、コンパイルされたパターンマッチングによるリアルタイム保護を提供する高度な脅威検出システムをAIに対して導入すべきです。

 #2.8.1    Level: 1    Role: D/V
 脅威検出パターンが、レイテンシの影響を最小限に抑えた高性能なリアルタイムフィルタリングのために、最適化された正規表現エンジンにコンパイルされていることを確認してください。
 #2.8.2    Level: 1    Role: D/V
 脅威検出システムが異なる脅威カテゴリ（プロンプトインジェクション、有害コンテンツ、機密データ、システムコマンド）ごとに別々のパターンライブラリを維持していることを確認してください。
 #2.8.3    Level: 2    Role: D/V
 適応型脅威検出が、攻撃頻度および成功率に基づいて脅威感度を更新する機械学習モデルを組み込んでいることを確認してください。
 #2.8.4    Level: 2    Role: D/V
 リアルタイムの脅威インテリジェンスフィードが、新しい攻撃シグネチャやIOC（侵害の指標）を用いてパターンライブラリを自動的に更新することを確認してください。
 #2.8.5    Level: 3    Role: D/V
 脅威検出の誤検知率が継続的に監視されており、正当な使用ケースへの干渉を最小限に抑えるためにパターンの特異性が自動的に調整されていることを確認してください。
 #2.8.6    Level: 3    Role: D/V
 コンテキスト脅威分析が、検出精度を向上させるために、入力ソース、ユーザー行動パターン、およびセッション履歴を考慮していることを確認してください。
 #2.8.7    Level: 3    Role: D/V
 脅威検出のパフォーマンス指標（検出率、処理遅延、リソース利用率）がリアルタイムで監視および最適化されていることを確認する。

---

### C2.9 マルチモーダルセキュリティ検証パイプライン

開発者は、特定の脅威検出とリソース分離を用いて、テキスト、画像、音声、およびその他のAI入力モダリティに対するセキュリティ検証を提供する必要があります。

 #2.9.1    Level: 1    Role: D/V
 各入力モダリティに対して、専用のセキュリティバリデータが存在し、文書化された脅威パターン（テキスト：プロンプトインジェクション、画像：ステガノグラフィー、音声：スペクトログラム攻撃）および検出閾値が設定されていることを確認してください。
 #2.9.2    Level: 2    Role: D/V
 マルチモーダル入力が、それぞれのモダリティタイプに特有のリソース制限（メモリ、CPU、処理時間）を定めた隔離されたサンドボックス環境で処理されていることを確認し、その内容がセキュリティポリシーに文書化されていることを検証してください。
 #2.9.3    Level: 2    Role: D/V
 クロスモーダル攻撃検出が、複数の入力タイプ（例：画像内のステガノグラフィックペイロードとテキスト内のプロンプトインジェクションの組み合わせ）にまたがる協調攻撃を相関ルールとアラート生成によって特定することを検証してください。
 #2.9.4    Level: 3    Role: D/V
 マルチモーダル検証の失敗が、すべての入力モダリティ、検証結果、脅威スコア、および相関分析を含む詳細なログ記録をトリガーし、SIEM統合のための構造化ログ形式であることを確認してください。
 #2.9.5    Level: 3    Role: D/V
 モダリティ固有のコンテンツ分類器が、記録されたスケジュール（最低でも四半期ごと）に従って、新しい脅威パターン、敵対的事例、およびベースライン閾値を上回る性能ベンチマークで更新されていることを確認してください。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3モデルライフサイクル管理と変更管理

### 管理目標

AIシステムは、承認されていないまたは安全でないモデルの変更が本番環境に反映されることを防ぐ変更管理プロセスを実装しなければなりません。この管理は、開発から展開、廃止に至るライフサイクル全体を通じてモデルの完全性を確保し、迅速なインシデント対応を可能にし、すべての変更に対する責任を維持します。

コアセキュリティ目標：整合性、追跡可能性、および回復可能性を維持する管理されたプロセスを採用することにより、認可され検証されたモデルのみが本番環境に到達するようにすること。

---

### C3.1 モデル認証と完全性

認証された完全性が検証されたモデルのみが本番環境に到達します。

 #3.1.1    Level: 1    Role: D/V
 展開前に、すべてのモデルアーティファクト（重み、設定、トークナイザー）が認可されたエンティティによって暗号的に署名されていることを検証してください。
 #3.1.2    Level: 1    Role: D/V
 モデルの整合性が展開時に検証され、署名検証の失敗がモデルの読み込みを防止することを確認してください。
 #3.1.3    Level: 2    Role: D/V
 モデルの出所記録に、認証機関の身元、トレーニングデータのチェックサム、合否判定付きの検証テスト結果、および作成タイムスタンプが含まれていることを確認してください。
 #3.1.4    Level: 2    Role: D/V
 すべてのモデルアーティファクトがセマンティックバージョニング（MAJOR.MINOR.PATCH）を使用しており、各バージョン要素が増分される条件が文書化されていることを確認してください。
 #3.1.5    Level: 2    Role: V
 依存関係の追跡が、すべての消費システムを迅速に特定できるリアルタイムのインベントリを維持していることを確認してください。

---

### C3.2 モデルの検証とテスト

モデルは展開前に定義されたセキュリティおよび安全性の検証を通過しなければなりません。

 #3.2.1    Level: 1    Role: D/V
 モデルが展開前に、事前に合意された組織の合否基準に基づき、入力検証、出力のサニタイズ、安全性評価を含む自動セキュリティテストを受けることを確認してください。
 #3.2.2    Level: 1    Role: D/V
 検証失敗が、事前に指定された権限を持つ担当者による明示的なオーバーライド承認と文書化された事業上の正当な理由がある場合を除き、自動的にモデル展開をブロックすることを確認してください。
 #3.2.3    Level: 2    Role: V
 テスト結果が暗号的に署名され、検証対象の特定モデルバージョンのハッシュに不変的にリンクされていることを確認してください。
 #3.2.4    Level: 2    Role: D/V
 緊急展開には、予め合意された期間内に、事前に指定されたセキュリティ権限者からの文書化されたセキュリティリスク評価および承認が必要であることを確認してください。

---

### C3.3 管理された展開とロールバック

モデルの展開は制御され、監視され、かつ元に戻せるものでなければなりません。

 #3.3.1    Level: 1    Role: D
 本番環境へのデプロイメントが、事前に合意されたエラー率、遅延閾値、またはセキュリティアラート基準に基づく自動ロールバックトリガーを備えた段階的な展開メカニズム（カナリアデプロイメント、ブルーグリーンデプロイメント）を実装していることを確認してください。
 #3.3.2    Level: 1    Role: D/V
 ロールバック機能が、あらかじめ定められた組織の時間枠内でモデルの完全な状態（重み、構成、依存関係）を原子性を保って復元することを確認してください。
 #3.3.3    Level: 2    Role: D/V
 展開プロセスが暗号署名を検証し、モデルの有効化前に整合性チェックサムを計算することを確認し、不一致がある場合は展開を失敗させてください。
 #3.3.4    Level: 2    Role: D/V
 緊急モデルシャットダウン機能が、あらかじめ定義された応答時間内に自動回路遮断器または手動停止スイッチを介してモデルエンドポイントを無効にできることを確認してください。
 #3.3.5    Level: 2    Role: V
 インシデント対応のために、不変ストレージを用いて、ロールバックアーティファクト（以前のモデルバージョン、構成、依存関係）が組織のポリシーに従って保持されていることを確認する。

---

### C3.4 変更の説明責任と監査

すべてのモデルのライフサイクル変更は追跡可能で監査可能でなければなりません。

 #3.4.1    Level: 1    Role: V
 すべてのモデル変更（展開、構成、廃止）が、タイムスタンプ、認証された実行者の身元、変更タイプ、および変更前後の状態を含む不変の監査記録を生成することを検証してください。
 #3.4.2    Level: 2    Role: D/V
 監査ログへのアクセスには適切な認可が必要であり、すべてのアクセス試行はユーザーの識別情報とタイムスタンプとともに記録されていることを確認してください。
 #3.4.3    Level: 2    Role: D/V
 プロンプトテンプレートおよびシステムメッセージが、必須のコードレビューおよび指定されたレビュアーによる承認を経てデプロイされる前に、gitリポジトリでバージョン管理されていることを確認してください。
 #3.4.4    Level: 2    Role: V
 監査記録に、保持期間内の任意のタイムスタンプにおけるモデル状態を完全に再構築できるように、十分な詳細（モデルハッシュ、設定スナップショット、依存関係のバージョン）を含んでいることを確認する。

---

### C3.5 セキュア開発プラクティス

モデルの開発およびトレーニングプロセスは、侵害を防ぐために安全な手法に従う必要があります。

 #3.5.1    Level: 1    Role: D
 モデルの開発、テスト、および本番環境が物理的または論理的に分離されていることを確認します。これらは共有インフラストラクチャを持たず、アクセス制御が異なり、データストアも分離されています。
 #3.5.2    Level: 1    Role: D
 モデルのトレーニングおよびファインチューニングが、制御されたネットワークアクセスを持つ分離環境で行われていることを確認してください。
 #3.5.3    Level: 1    Role: D/V
 モデル開発に使用する前に、トレーニングデータソースが完全性チェックを通じて検証され、信頼されたソースによる認証が行われ、文書化された供給連鎖が確認されていることを検証してください。
 #3.5.4    Level: 2    Role: D
 モデル開発の成果物（ハイパーパラメータ、トレーニングスクリプト、設定ファイル）がバージョン管理に保存され、トレーニングで使用する前にピアレビューの承認が必要であることを確認してください。

---

### C3.6 モデルの廃止および退役

モデルは、もはや不要になった場合やセキュリティ上の問題が発見された場合に、安全に廃棄されなければなりません。

 #3.6.1    Level: 1    Role: D
 モデルリタイアメントプロセスが依存関係グラフを自動的にスキャンし、すべての依存システムを特定し、廃止前に事前に合意された通知期間を提供することを確認してください。
 #3.6.2    Level: 1    Role: D/V
 退役したモデルアーティファクトが、文書化されたデータ保持ポリシーに従って、検証済みの破棄証明書を用いて暗号消去または多重上書きによって安全に消去されていることを確認してください。
 #3.6.3    Level: 2    Role: V
 モデルの廃止イベントがタイムスタンプと実行者の識別情報とともに記録され、モデルの署名が再利用を防ぐために取り消されていることを確認してください。
 #3.6.4    Level: 2    Role: D/V
 緊急モデル退役が、重大なセキュリティ脆弱性が発見された場合に、自動化されたキルスイッチを通じて、事前に設定された緊急対応時間内にモデルへのアクセスを無効化できることを検証してください。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 インフラストラクチャ、構成および展開セキュリティ

### 管理目的

AIインフラストラクチャは、権限昇格、サプライチェーンの改ざん、および横方向移動に対して堅牢化されなければならず、安全な構成、ランタイムの分離、信頼されたデプロイメントパイプライン、および包括的な監視を通じて実現される必要があります。認可され検証されたインフラストラクチャコンポーネントと構成のみが、セキュリティ、整合性、および監査可能性を維持する管理されたプロセスを通じて本番環境に到達します。

コアセキュリティ目標：暗号的に署名され、脆弱性スキャンが実施されたインフラストラクチャコンポーネントのみが、自動化された検証パイプラインを通じて本番環境に到達し、セキュリティポリシーを強制し、不変の監査証跡を維持すること。

---

### C4.1 実行環境の隔離

カーネルレベルの分離原語および強制アクセス制御を通じて、コンテナの脱出や権限昇格を防止します。

 #4.1.1    Level: 1    Role: D/V
 すべてのAIコンテナが、CAP_SETUID、CAP_SETGID、およびセキュリティベースラインで明示的に要求されている権限を除き、すべてのLinux権限を削除していることを確認してください。
 #4.1.2    Level: 1    Role: D/V
 seccompプロファイルが、事前に承認された許可リストにあるシステムコール以外をすべてブロックし、違反があった場合にはコンテナを終了させてセキュリティアラートを生成することを検証してください。
 #4.1.3    Level: 2    Role: D/V
 AIワークロードが読み取り専用のルートファイルシステム、テンポラリデータ用のtmpfs、およびnoexecマウントオプションが適用された永続データ用の名前付きボリュームで実行されていることを確認してください。
 #4.1.4    Level: 2    Role: D/V
 eBPFベースのランタイムモニタリング（Falco、Tetragon、または同等のもの）が、権限昇格の試みを検出し、組織の対応時間要件内で問題のあるプロセスを自動的に終了することを検証してください。
 #4.1.5    Level: 3    Role: D/V
 ハイリスクなAIワークロードが、アテステーション検証付きでハードウェア分離環境（Intel TXT、AMD SVM、または専用ベアメタルノード）で実行されていることを確認してください。

---

### C4.2 セキュアなビルドおよびデプロイメントパイプライン

再現可能なビルドと署名付きアーティファクトを通じて、暗号学的整合性とサプライチェーンのセキュリティを確保します。

 #4.2.1    Level: 1    Role: D/V
 インフラストラクチャ・アズ・コードが各コミットごとにツール（tfsec、Checkov、またはTerrascan）を使用してスキャンされ、CRITICALまたはHIGHの重大度の検出事項がある場合はマージをブロックすることを確認してください。
 #4.2.2    Level: 1    Role: D/V
 コンテナビルドがビルド間で同一のSHA256ハッシュを持つ再現可能なものであることを検証し、Sigstoreで署名されたSLSAレベル3のプロビナンス証明書を生成します。
 #4.2.3    Level: 2    Role: D/V
 コンテナイメージがレジストリにプッシュされる前に、CycloneDXまたはSPDX SBOMを埋め込み、Cosignで署名されていることを確認し、署名されていないイメージはデプロイ時に拒否されるようにしてください。
 #4.2.4    Level: 2    Role: D/V
 CI/CDパイプラインが、HashiCorp Vault、AWS IAMロール、またはAzureマネージドアイデンティティからのOIDCトークンを使用し、その有効期間が組織のセキュリティポリシーの制限を超えていないことを検証します。
 #4.2.5    Level: 2    Role: D/V
 コンテナ実行前のデプロイメントプロセスにおいて、Cosign署名およびSLSAプルーブナンスが検証され、検証エラーが発生した場合はデプロイメントが失敗することを確認してください。
 #4.2.6    Level: 2    Role: D/V
 ビルド環境が一時的なコンテナまたは仮想マシン（VM）で実行され、永続的なストレージがなく、本番VPCからのネットワーク分離が確保されていることを検証してください。

---

### C4.3 ネットワークセキュリティとアクセス制御

ゼロトラストネットワーキングを、デフォルト拒否ポリシーと暗号化された通信で実装します。

 #4.3.1    Level: 1    Role: D/V
 KubernetesのNetworkPoliciesまたは同等のものが、必要なポート（443、8080など）に対する明示的な許可ルールを用いて、デフォルトでの受信/送信トラフィック拒否を実装していることを確認してください。
 #4.3.2    Level: 1    Role: D/V
 SSH（ポート22）、RDP（ポート3389）、およびクラウドメタデータエンドポイント（169.254.169.254）がブロックされているか、証明書ベースの認証を要求していることを確認してください。
 #4.3.3    Level: 2    Role: D/V
 egressトラフィックがドメイン許可リストを使用したHTTP/HTTPSプロキシ（Squid、Istio、またはクラウドNATゲートウェイ）を経由してフィルタリングされていること、およびブロックされたリクエストがログに記録されていることを確認してください。
 #4.3.4    Level: 2    Role: D/V
 インターサービス通信が相互TLSを使用していることを確認し、証明書が組織のポリシーに従ってローテーションされ、証明書検証が強制されていること（skip-verifyフラグを使用しないこと）を確認してください。
 #4.3.5    Level: 2    Role: D/V
 AIインフラストラクチャが専用のVPC/VNet内で実行されており、直接のインターネットアクセスがなく、NATゲートウェイまたはバスティオンホストを通じてのみ通信していることを確認してください。

---

### C4.4 シークレットおよび暗号鍵管理

ゼロトラストアクセスを用いて、ハードウェア対応のストレージおよび自動ローテーションにより資格情報を保護します。

 #4.4.1    Level: 1    Role: D/V
 秘密情報がHashiCorp Vault、AWS Secrets Manager、Azure Key Vault、またはGoogle Secret Managerに保存され、AES-256を使用した保存時の暗号化が行われていることを確認してください。
 #4.4.2    Level: 1    Role: D/V
 暗号鍵がFIPS 140-2 レベル2のHSM（AWS CloudHSM、Azure Dedicated HSM）内で生成され、組織の暗号ポリシーに従って鍵のローテーションが行われていることを確認してください。
 #4.4.3    Level: 2    Role: D/V
 秘密情報のローテーションがゼロダウンタイムでのデプロイメントにより自動化されており、担当者の変更やセキュリティインシデントが発生した際に即時にローテーションが開始されることを確認してください。
 #4.4.4    Level: 2    Role: D/V
 APIキー、パスワード、または証明書を含むビルドをブロックするために、コンテナイメージがGitLeaks、TruffleHog、またはdetect-secretsなどのツールでスキャンされていることを確認してください。
 #4.4.5    Level: 2    Role: D/V
 本番環境のシークレットアクセスがハードウェアトークン（YubiKey、FIDO2）による多要素認証（MFA）を必要とし、ユーザーの識別情報とタイムスタンプを含む不変の監査ログによって記録されていることを確認してください。
 #4.4.6    Level: 2    Role: D/V
 シークレットがKubernetesシークレット、マウントされたボリューム、またはイニットコンテナを介して注入されていることを確認し、シークレットが環境変数やイメージに組み込まれることがないようにしてください。

---

### C4.5 AIワークロードのサンドボックス化と検証

包括的な挙動分析を用いて、信頼されていないAIモデルを安全なサンドボックス内に隔離します。

 #4.5.1    Level: 1    Role: D/V
 外部AIモデルがgVisor、FirecrackerやCrossVMなどのmicroVM、または--security-opt=no-new-privilegesおよび--read-onlyフラグを使用したDockerコンテナ内で実行されることを確認してください。
 #4.5.2    Level: 1    Role: D/V
 サンドボックス環境にネットワーク接続がないこと（--network=none）またはローカルホストへのアクセスのみ許可され、すべての外部リクエストがiptablesルールによってブロックされていることを確認してください。
 #4.5.3    Level: 2    Role: D/V
 AIモデルの検証には、組織で定義されたテスト範囲とバックドア検出のための行動解析を含む、自動化されたレッドチームテストが含まれていることを確認してください。
 #4.5.4    Level: 2    Role: D/V
 AIモデルが本番環境に昇格される前に、そのサンドボックスの結果が認可されたセキュリティ担当者によって暗号的に署名され、不変の監査ログに保存されていることを検証してください。
 #4.5.5    Level: 2    Role: D/V
 サンドボックス環境が評価間にゴールデンイメージから破棄および再作成され、ファイルシステムとメモリが完全にクリーンアップされていることを確認してください。

---

### C4.6 インフラストラクチャセキュリティモニタリング

自動修復とリアルタイムアラート機能を備えたインフラストラクチャの継続的なスキャンと監視。

 #4.6.1    Level: 1    Role: D/V
 コンテナイメージが組織のスケジュールに従ってスキャンされ、組織のリスク閾値に基づいてCRITICALな脆弱性がある場合は展開がブロックされることを確認してください。
 #4.6.2    Level: 1    Role: D/V
 組織で定義されたコンプライアンス基準および失敗したチェックに対する自動修復を用いて、インフラストラクチャがCISベンチマークまたはNIST 800-53コントロールに合格していることを検証します。
 #4.6.3    Level: 2    Role: D/V
 組織のリスク管理タイムラインに従って、高重大度の脆弱性が修正されていることを確認し、積極的に悪用されているCVEに対する緊急対応手順を適用すること。
 #4.6.4    Level: 2    Role: V
 セキュリティアラートがCEFまたはSTIX/TAXII形式を使用し、自動エンリッチメントを伴ってSIEMプラットフォーム（Splunk、Elastic、またはSentinel）と統合されていることを確認してください。
 #4.6.5    Level: 3    Role: V
 インフラストラクチャのメトリクスがSLAダッシュボードおよび経営報告とともに監視システム（Prometheus、DataDog）にエクスポートされていることを確認してください。
 #4.6.6    Level: 2    Role: D/V
 組織の監視要件に従って、設定のドリフトがツール（Chef InSpec、AWS Config）を使用して検出され、無許可の変更に対して自動ロールバックが行われることを検証する。

---

### C4.7 AIインフラストラクチャリソース管理

リソース枯渇攻撃を防止し、クォータおよび監視を通じて公平なリソース配分を確保します。

 #4.7.1    Level: 1    Role: D/V
 GPU/TPUの利用状況が監視されており、組織で定められたしきい値でアラートが発動され、容量管理ポリシーに基づいて自動スケーリングまたは負荷分散が有効化されていることを確認してください。
 #4.7.2    Level: 1    Role: D/V
 組織の監視要件に従ってAIワークロードのメトリクス（推論レイテンシ、スループット、エラー率）が収集されていることを確認し、それらがインフラストラクチャの使用状況と相関していることを検証する。
 #4.7.3    Level: 2    Role: D/V
 Kubernetes ResourceQuotas または同等の機能が、組織のリソース配分ポリシーに従って個々のワークロードを制限し、厳格なハードリミットを適用していることを検証してください。
 #4.7.4    Level: 2    Role: V
 コスト監視がワークロード/テナントごとの支出を追跡し、組織の予算しきい値に基づくアラートと予算超過に対する自動制御を備えていることを確認してください。
 #4.7.5    Level: 3    Role: V
 容量計画が、組織で定義された予測期間の過去データを使用し、需要パターンに基づく自動リソースプロビジョニングを行っていることを確認してください。
 #4.7.6    Level: 2    Role: D/V
 リソース枯渇が容量ポリシーに基づくレート制限やワークロードの分離を含む組織の対応要件に従ってサーキットブレーカーをトリガーすることを検証する。

---

### C4.8 環境分離および昇格管理

自動化されたプロモーションゲートとセキュリティ検証によって厳格な環境境界を強制します。

 #4.8.1    Level: 1    Role: D/V
 開発・テスト・本番環境が、それぞれ独立したVPC/VNetで稼働しており、IAMロール、セキュリティグループ、ネットワーク接続を共有していないことを確認してください。
 #4.8.2    Level: 1    Role: D/V
 環境の昇格には、組織で定義された承認権限者による暗号署名および不変の監査記録を伴う承認が必要であることを確認してください。
 #4.8.3    Level: 2    Role: D/V
 本番環境ではSSHアクセスをブロックし、デバッグエンドポイントを無効化し、緊急時を除き組織の事前通知要件を伴う変更要求を必須とすることを確認してください。
 #4.8.4    Level: 2    Role: D/V
 インフラストラクチャー・アズ・コードの変更は、メインブランチへのマージ前に、ピアレビューと自動テストおよびセキュリティスキャンが必須であることを確認してください。
 #4.8.5    Level: 2    Role: D/V
 組織のプライバシー要件に従って、本番環境外のデータが匿名化されていること、合成データ生成が行われていること、またはPII（個人識別情報）の削除による完全なデータマスキングが検証されていることを確認する。
 #4.8.6    Level: 2    Role: D/V
 昇格ゲートに、承認に必要なゼロの重大な所見を条件とした自動化セキュリティテスト（SAST、DAST、コンテナスキャン）が含まれていることを確認してください。

---

### C4.9 インフラストラクチャのバックアップとリカバリー

自動バックアップ、検証済みの復旧手順、および災害復旧機能を通じてインフラのレジリエンスを確保します。

 #4.9.1    Level: 1    Role: D/V
 インフラストラクチャ構成が、組織のバックアップスケジュールに従って、地理的に分散した地域へ3-2-1バックアップ戦略を実装してバックアップされていることを確認してください。
 #4.9.2    Level: 2    Role: D/V
 バックアップシステムが、ランサムウェア対策のために、分離されたネットワーク上で別々の資格情報とエアギャップストレージを使用して稼働していることを確認してください。
 #4.9.3    Level: 2    Role: V
 回復手順が組織のスケジュールに従って、自動化テストによりテストおよび検証されており、RTOおよびRPOの目標が組織の要件を満たしていることを確認する。
 #4.9.4    Level: 3    Role: V
 災害復旧にAI固有のランブックが含まれていることを確認してください。具体的には、モデル重みの復元、GPUクラスターの再構築、およびサービス依存関係のマッピングが含まれています。

---

### C4.10 インフラストラクチャコンプライアンスとガバナンス

継続的な評価、文書化、および自動化された制御を通じて規制遵守を維持します。

 #4.10.1    Level: 2    Role: D/V
 インフラストラクチャの準拠が、組織のスケジュールに従ってSOC 2、ISO 27001、またはFedRAMPの管理基準に対して評価され、自動化された証拠収集が行われていることを確認してください。
 #4.10.2    Level: 2    Role: V
 インフラストラクチャのドキュメントに、組織の変更管理要件に従って更新されたネットワーク図、データフローマップ、および脅威モデルが含まれていることを確認してください。
 #4.10.3    Level: 3    Role: D/V
 インフラストラクチャの変更が、ハイリスクの修正に対して規制承認ワークフローを伴う自動化されたコンプライアンス影響評価を受けていることを確認してください。

---

### C4.11 AIハードウェアセキュリティ

GPU、TPU、特化型AIアクセラレータを含むAI専用ハードウェアコンポーネントを保護する。

 #4.11.1    Level: 2    Role: D/V
 AIアクセラレーターファームウェア（GPU BIOS、TPUファームウェア）が暗号署名で検証され、組織のパッチ管理スケジュールに従って更新されていることを確認してください。
 #4.11.2    Level: 2    Role: D/V
 ワークロード実行前に、TPM 2.0、Intel TXT、または AMD SVM を使用したハードウェア認証により AI アクセラレータの完全性が検証されていることを確認してください。
 #4.11.3    Level: 2    Role: D/V
 SR-IOV、MIG（マルチインスタンスGPU）または同等のハードウェアパーティショニングを使用して、ジョブ間でメモリのサニタイゼーションを行い、GPUメモリがワークロード間で分離されていることを検証してください。
 #4.11.4    Level: 3    Role: V
 AIハードウェアのサプライチェーンが、製造元の証明書による出所確認および改ざん防止包装の検証を含んでいることを確認してください。
 #4.11.5    Level: 3    Role: D/V
 ハードウェアセキュリティモジュール（HSM）が、AIモデルの重みと暗号鍵をFIPS 140-2レベル3またはCommon Criteria EAL4+認証で保護していることを確認してください。

---

### C4.12 エッジ＆分散AIインフラストラクチャ

エッジコンピューティング、連合学習、およびマルチサイトアーキテクチャを含む安全な分散AI展開。

 #4.12.1    Level: 2    Role: D/V
 エッジAIデバイスが中央インフラストラクチャに対して相互TLSを使用して認証し、デバイス証明書が組織の証明書管理ポリシーに従ってローテーションされていることを確認してください。
 #4.12.2    Level: 2    Role: D/V
 エッジデバイスが、検証済み署名によるセキュアブートと、ファームウェアのダウングレード攻撃を防ぐロールバック保護を実装していることを確認してください。
 #4.12.3    Level: 3    Role: D/V
 分散AIの調整が、参加者の検証と悪意のあるノードの検出を備えたビザンチン障害耐性コンセンサスアルゴリズムを使用していることを確認してください。
 #4.12.4    Level: 3    Role: D/V
 エッジからクラウドへの通信が、帯域幅制限、データ圧縮、および安全なローカルストレージを備えたオフライン操作機能を含んでいることを確認してください。

---

### C4.13 マルチクラウドおよびハイブリッドインフラストラクチャセキュリティ

複数のクラウドプロバイダーおよびハイブリッドクラウドオンプレミス展開にわたるAIワークロードを安全に保護します。

 #4.13.1    Level: 2    Role: D/V
 マルチクラウドAI展開が、プロバイダー間での集中管理ポリシーとともに、クラウド非依存のアイデンティティフェデレーション（OIDC、SAML）を使用していることを確認してください。
 #4.13.2    Level: 2    Role: D/V
 クロスクラウド間のデータ転送が顧客管理の鍵によるエンドツーエンド暗号化を使用し、各法域ごとにデータ居住性の制御が適用されていることを検証してください。
 #4.13.3    Level: 2    Role: D/V
 ハイブリッドクラウドAIワークロードがオンプレミス環境とクラウド環境の両方で一貫したセキュリティポリシーを実装し、統一された監視とアラートを行っていることを検証します。
 #4.13.4    Level: 3    Role: V
 クラウドベンダーロックイン防止には、ポータブルなインフラストラクチャ・アズ・コード、標準化されたAPI、およびフォーマット変換ツールを備えたデータエクスポート機能が含まれていることを確認してください。
 #4.13.5    Level: 3    Role: V
 マルチクラウドのコスト最適化には、リソースの拡散を防ぐセキュリティ制御だけでなく、不正なクラウド間データ転送料金を防止する制御が含まれていることを確認してください。

---

### C4.14 インフラストラクチャ自動化およびGitOpsセキュリティ

AIインフラ管理のための安全なインフラストラクチャ自動化パイプラインとGitOpsワークフロー。

 #4.14.1    Level: 2    Role: D/V
 GitOpsリポジトリが、GPGキーによる署名付きコミットを要求し、メインブランチへの直接プッシュを防ぐブランチ保護ルールを設けていることを確認してください。
 #4.14.2    Level: 2    Role: D/V
 インフラストラクチャ自動化において、不正な変更に対する組織の対応要件に従ってトリガーされる自動修復およびロールバック機能を備えたドリフト検出が含まれていることを検証してください。
 #4.14.3    Level: 2    Role: D/V
 自動インフラストラクチャプロビジョニングには、セキュリティポリシーの検証が含まれ、非準拠の構成に対しては展開がブロックされることを確認してください。
 #4.14.4    Level: 2    Role: D/V
 インフラストラクチャの自動化に関わるシークレットが、外部シークレットオペレーター（External Secrets Operator、Bank-Vaults）を通じて管理され、自動ローテーションが行われていることを確認してください。
 #4.14.5    Level: 3    Role: V
 自己修復型インフラストラクチャが、自動化されたインシデント対応およびステークホルダー通知ワークフローを備えたセキュリティイベント相関を含んでいることを確認してください。

---

### C4.15 量子耐性インフラストラクチャセキュリティ

ポスト量子暗号と量子安全プロトコルを通じて、量子コンピューティングの脅威に対するAIインフラストラクチャを準備する。

 #4.15.1    Level: 3    Role: D/V
 AIインフラストラクチャが、鍵交換およびデジタル署名のために、NIST承認のポスト量子暗号アルゴリズム（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）を実装していることを確認してください。
 #4.15.2    Level: 3    Role: D/V
 量子安全な鍵管理プロトコルを用いて、高セキュリティのAI通信向けに量子鍵配送（QKD）システムが実装されていることを検証してください。
 #4.15.3    Level: 3    Role: D/V
 暗号機能の柔軟性フレームワークが、新しいポスト量子アルゴリズムへの迅速な移行を、自動化された証明書および鍵のローテーションとともに可能にすることを検証してください。
 #4.15.4    Level: 3    Role: V
 量子脅威モデリングは、文書化された移行スケジュールとリスク評価を伴って、量子攻撃に対するAIインフラストラクチャの脆弱性を評価することを確認してください。
 #4.15.5    Level: 3    Role: D/V
 ハイブリッドクラシカル・量子暗号システムが、量子移行期間中にパフォーマンスモニタリングを伴う多層防御（ディフェンス・イン・デプス）を提供することを検証する。

---

### C4.16 機密コンピューティングとセキュアエンクレーブ

ハードウェアベースの信頼実行環境および機密コンピューティング技術を使用して、AIワークロードとモデルの重みを保護します。

 #4.16.1    Level: 3    Role: D/V
 機密性の高いAIモデルが、暗号化メモリと認証検証を備えたIntel SGXエンクレーブ、AMD SEV-SNP、またはARM TrustZone内で実行されていることを検証してください。
 #4.16.2    Level: 3    Role: D/V
 機密コンテナ（Kata Containers、gVisorを使用した機密コンピューティング）が、ハードウェアによって強制されるメモリ暗号化によってAIワークロードを分離していることを検証してください。
 #4.16.3    Level: 3    Role: D/V
 リモートアテステーションが、実行環境の真正性の暗号的証明を用いて、AIモデルをロードする前にエンクレーブの完全性を検証することを確認してください。
 #4.16.4    Level: 3    Role: D/V
 機密のAI推論サービスが、暗号化計算によるモデル抽出を、シールドされたモデル重みと保護された実行環境を通じて防止していることを検証する。
 #4.16.5    Level: 3    Role: D/V
 信頼された実行環境のオーケストレーションが、リモート認証および暗号化通信チャネルを用いてセキュアエンクレーブのライフサイクルを管理していることを検証する。
 #4.16.6    Level: 3    Role: D/V
 セキュアマルチパーティ計算（SMPC）が、個々のデータセットやモデルパラメータを公開することなく共同AIトレーニングを可能にすることを検証してください。

---

### C4.17 ゼロ知識インフラストラクチャ

機密情報を公開せずにプライバシー保護を実現するためのAI検証および認証のゼロ知識証明システムを実装する。

 #4.17.1    Level: 3    Role: D/V
 ゼロ知識証明（ZK-SNARKs、ZK-STARKs）が、モデルの重みやトレーニングデータを公開することなく、AIモデルの完全性とトレーニングの起源を検証することを確認する。
 #4.17.2    Level: 3    Role: D/V
 ZKベースの認証システムが、AIサービスにおいて身元に関する情報を明らかにすることなく、プライバシーを保護したユーザー認証を可能にしていることを検証してください。
 #4.17.3    Level: 3    Role: D/V
 プライベートセットインターセクション（PSI）プロトコルが、個々のデータセットを公開することなく、フェデレーテッドAIにおける安全なデータ照合を可能にすることを検証してください。
 #4.17.4    Level: 3    Role: D/V
 ゼロ知識機械学習（ZKML）システムが、正確な計算の暗号学的証明を伴う検証可能なAI推論を可能にすることを確認する。
 #4.17.5    Level: 3    Role: D/V
 ZKロールアップがバッチ検証と計算負荷の軽減を伴うスケーラブルでプライバシー保護されたAIトランザクション処理を提供することを検証してください。

---

### C4.18 サイドチャネル攻撃防止

タイミング、電力、電磁気、およびキャッシュベースのサイドチャネル攻撃からAIインフラストラクチャを保護し、機密情報の漏洩を防ぎます。

 #4.18.1    Level: 3    Role: D/V
 AI推論のタイミングが定数時間アルゴリズムとパディングを用いて正規化され、タイミングに基づくモデル抽出攻撃を防止していることを検証してください。
 #4.18.2    Level: 3    Role: D/V
 AIハードウェアの電力解析防護には、ノイズ注入、電源ラインフィルタリング、およびランダム化実行パターンが含まれていることを確認してください。
 #4.18.3    Level: 3    Role: D/V
 キャッシュベースのサイドチャネル緩和が、情報漏洩を防ぐためにキャッシュパーティショニング、ランダム化、およびフラッシュ命令を使用していることを検証してください。
 #4.18.4    Level: 3    Role: D/V
 電磁波漏洩防護には、TEMPESTスタイルの攻撃を防ぐために、シールド、信号フィルタリング、およびランダム化処理が含まれていることを確認してください。
 #4.18.5    Level: 3    Role: D/V
 マイクロアーキテクチャのサイドチャネル防御には、投機的実行制御およびメモリアクセスパターンの難読化が含まれていることを確認してください。

---

### C4.19 ニューロモルフィックおよび特殊AIハードウェアセキュリティ

ニューロモルフィックチップ、FPGA、カスタムASIC、および光コンピューティングシステムを含む、新興のAIハードウェアアーキテクチャのセキュリティを確保する。

 #4.19.1    Level: 3    Role: D/V
 ニューロモルフィックチップのセキュリティには、スパイクパターンの暗号化、シナプス重みの保護、およびハードウェアベースの学習規則の検証が含まれていることを確認してください。
 #4.19.2    Level: 3    Role: D/V
 FPGAベースのAIアクセラレータがビットストリーム暗号化、改ざん防止機構、および認証された更新による安全な構成ローディングを実装していることを確認してください。
 #4.19.3    Level: 3    Role: D/V
 カスタムASICのセキュリティには、オンチップセキュリティプロセッサ、ハードウェアルートオブトラスト、および改ざん検出機能を備えた安全なキー保管が含まれていることを確認してください。
 #4.19.4    Level: 3    Role: D/V
 光学コンピューティングシステムが量子耐性の光学暗号化、安全なフォトニックスイッチング、および保護された光信号処理を実装していることを検証してください。
 #4.19.5    Level: 3    Role: D/V
 ハイブリッドアナログ・デジタルAIチップには、安全なアナログ計算、保護された重みの保存、および認証されたアナログからデジタルへの変換が含まれていることを確認してください。

---

### C4.20 プライバシー保護計算インフラストラクチャ

AI処理および解析中の機密データを保護するために、プライバシー保護計算のためのインフラストラクチャ制御を実装する。

 #4.20.1    Level: 3    Role: D/V
 ホモモルフィック暗号基盤が、暗号学的整合性検証およびパフォーマンス監視を備えた機密性の高いAIワークロード上での暗号化計算を可能にすることを検証する。
 #4.20.2    Level: 3    Role: D/V
 プライベート情報検索システムは、アクセスパターンの暗号保護により、クエリパターンを明らかにすることなくデータベースクエリを可能にすることを検証してください。
 #4.20.3    Level: 3    Role: D/V
 安全なマルチパーティ計算プロトコルが、個々の入力や中間計算を公開することなくプライバシーを保護したAI推論を可能にすることを検証する。
 #4.20.4    Level: 3    Role: D/V
 プライバシー保護型の鍵管理には、分散鍵生成、しきい値暗号技術、およびハードウェアに基づく保護を備えた安全な鍵ローテーションが含まれていることを確認してください。
 #4.20.5    Level: 3    Role: D/V
 プライバシー保護計算のパフォーマンスが、暗号学的セキュリティの保証を維持しながら、バッチ処理、キャッシュ、およびハードウェアアクセラレーションを通じて最適化されていることを検証する。

---

### C4.15 エージェントフレームワーク クラウド統合セキュリティとハイブリッド展開

ハイブリッドなオンプレミス／クラウドアーキテクチャを持つクラウド統合エージェントフレームワークのセキュリティ制御。

 #4.15.1    Level: 1    Role: D/V
 クラウドストレージの統合がエージェント制御の鍵管理によるエンドツーエンド暗号化を使用していることを検証してください。
 #4.15.2    Level: 2    Role: D/V
 ハイブリッド展開のセキュリティ境界が明確に定義され、通信チャネルが暗号化されていることを確認してください。
 #4.15.3    Level: 2    Role: D/V
 クラウドリソースへのアクセスが、継続的な認証を伴うゼロトラスト検証を含んでいることを確認してください。
 #4.15.4    Level: 3    Role: D/V
 データの所在地要件が、保存場所の暗号学的証明によって強制されていることを検証してください。
 #4.15.5    Level: 3    Role: D/V
 クラウドプロバイダーのセキュリティ評価に、エージェント固有の脅威モデリングとリスク評価が含まれていることを確認してください。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## AIコンポーネントおよびユーザーのためのC5アクセス制御とアイデンティティ管理

### 管理目標

AIシステムにおける効果的なアクセス制御には、堅牢なアイデンティティ管理、コンテキスト認識型の認可、およびゼロトラスト原則に基づく実行時の強制が必要です。これらの制御により、人間、サービス、自律エージェントは、明示的に許可された範囲内でのみモデル、データ、計算資源とやり取りし、継続的な検証および監査機能が確保されます。

---

### C5.1 アイデンティティ管理と認証

特権操作のために多要素認証を用い、すべてのエンティティに対して暗号的に裏付けられたアイデンティティを確立する。

 #5.1.1    Level: 1    Role: D/V
 すべての人間ユーザーおよびサービスプリンシパルが、OIDC/SAMLプロトコルを使用して一元化されたエンタープライズアイデンティティプロバイダー（IdP）を通じて認証され、ユニークなアイデンティティとトークンのマッピング（共有アカウントや資格情報なし）が行われていることを確認してください。
 #5.1.2    Level: 1    Role: D/V
 高リスク操作（モデルのデプロイ、重みのエクスポート、トレーニングデータアクセス、プロダクション設定変更）には、多要素認証またはセッション再検証を伴うステップアップ認証が必要であることを確認してください。
 #5.1.3    Level: 2    Role: D
 新しい管理者が本番システムアクセスを受ける前に、NIST 800-63-3 IAL-2または同等の基準に準拠した本人確認が行われていることを確認してください。
 #5.1.4    Level: 2    Role: V
 アクセスレビューが四半期ごとに実施され、休眠アカウントの自動検出、資格情報のローテーション強制、およびプロビジョニング解除のワークフローが行われていることを確認してください。
 #5.1.5    Level: 3    Role: D/V
 連携AIエージェントが、最長有効期間24時間の署名付きJWTアサーションを介して認証され、かつ発信元の暗号的証明が含まれていることを確認してください。

---

### C5.2 リソース認可と最小権限

すべてのAIリソースに対して明示的な許可モデルと監査証跡を備えた詳細なアクセス制御を実装する。

 #5.2.1    Level: 1    Role: D/V
 すべてのAIリソース（データセット、モデル、エンドポイント、ベクターコレクション、埋め込みインデックス、計算インスタンス）が明示的な許可リストとデフォルト拒否ポリシーを用いた役割ベースアクセス制御を実施していることを確認してください。
 #5.2.2    Level: 1    Role: D/V
 サービスアカウントに対して、デフォルトで最小権限の原則が適用されていることを確認し、読み取り専用の権限から開始し、書き込みアクセスには文書化された業務上の正当な理由が必要とされていることを保証してください。
 #5.2.3    Level: 1    Role: V
 すべてのアクセス制御の変更が承認された変更要求に関連付けられていること、およびタイムスタンプ、実行者の識別情報、リソース識別子、権限の差分とともに不変的に記録されていることを確認する。
 #5.2.4    Level: 2    Role: D
 データ分類ラベル（PII、PHI、輸出管理対象、機密情報）が、派生リソース（埋め込み、プロンプトキャッシュ、モデル出力）に自動的に伝播し、一貫したポリシー適用が行われることを検証してください。
 #5.2.5    Level: 2    Role: D/V
 不正アクセス試行および権限昇格イベントが、文脈メタデータとともに5分以内にSIEMシステムへリアルタイムアラートをトリガーすることを確認してください。

---

### C5.3 動的ポリシー評価

監査機能を備えたコンテキスト認識の認可決定のために、属性ベースアクセス制御（ABAC）エンジンを展開します。

 #5.3.1    Level: 1    Role: D/V
 認可の決定が、認証されたAPIを介してアクセス可能な専用のポリシーエンジン（OPA、Cedar、または同等のもの）に外部委譲され、暗号的な完全性保護が施されていることを確認してください。
 #5.3.2    Level: 1    Role: D/V
 ポリシーがユーザーのクリアランスレベル、リソースの機密性分類、リクエストのコンテキスト、テナント分離、および時間的制約を含む動的属性を実行時に評価することを検証してください。
 #5.3.3    Level: 2    Role: D
 ポリシー定義がバージョン管理されており、ピアレビューを経て、CI/CDパイプライン内の自動テストによって検証された後に本番環境へ展開されることを確認してください。
 #5.3.4    Level: 2    Role: V
 ポリシー評価結果に構造化された意思決定の根拠が含まれていることを確認し、それが相関分析およびコンプライアンス報告のためにSIEMシステムに送信されていることを検証してください。
 #5.3.5    Level: 3    Role: D/V
 高感度リソースに対してはポリシーキャッシュの有効期間（TTL）が5分を超えないこと、標準リソースに対してはキャッシュ無効化機能付きで1時間を超えないことを確認してください。

---

### C5.4 クエリ時のセキュリティ強制

必須のフィルタリングおよび行レベルのセキュリティポリシーを用いて、データベース層のセキュリティ制御を実装する。

 #5.4.1    Level: 1    Role: D/V
 すべてのベクターデータベースおよびSQLクエリに、データベースエンジンレベルで強制される必須のセキュリティフィルター（テナントID、機密ラベル、ユーザースコープ）が含まれていることを確認してください。アプリケーションコードではなく。
 #5.4.2    Level: 1    Role: D/V
 すべてのベクトルデータベース、検索インデックス、トレーニングデータセットに対して、ポリシー継承を伴う行レベルセキュリティ（RLS）ポリシーおよびフィールドレベルのマスキングが有効になっていることを確認してください。
 #5.4.3    Level: 2    Role: D
 認証失敗の評価が、「混乱した代理攻撃（confused deputy attacks）」を防止するために、クエリを直ちに中止し、空の結果セットを返すのではなく、明確な認証エラーコードを返すことを確認してください。
 #5.4.4    Level: 2    Role: V
 ポリシー評価のレイテンシが継続的に監視され、承認バイパスを可能にするタイムアウト条件に対して自動アラートが設定されていることを確認してください。
 #5.4.5    Level: 3    Role: D/V
 クエリの再試行メカニズムが、アクティブなユーザーセッション内での動的な権限変更を考慮するために認可ポリシーを再評価することを検証してください。

---

### C5.5 出力フィルタリングとデータ損失防止

AI生成コンテンツにおける不正なデータ露出を防止するため、後処理制御を展開する。

 #5.5.1    Level: 1    Role: D/V
 推論後のフィルタリング機構が、要求者にコンテンツを提供する前に無許可の個人識別情報（PII）、機密情報、および専有データをスキャンし、検閲していることを確認してください。
 #5.5.2    Level: 1    Role: D/V
 モデル出力における引用、参考文献、および情報源の帰属が呼び出し元の権限に照らして検証され、権限外アクセスが検出された場合は削除されることを確認してください。
 #5.5.3    Level: 2    Role: D
 ユーザーの権限レベルおよびデータの分類に基づいて、出力フォーマット制限（サニタイズされたPDF、メタデータが削除された画像、承認されたファイルタイプ）が適用されていることを検証します。
 #5.5.4    Level: 2    Role: V
 検閲アルゴリズムが決定的であり、バージョン管理されていて、コンプライアンス調査およびフォレンジック分析を支援するための監査ログを維持していることを確認してください。
 #5.5.5    Level: 3    Role: V
 高リスクの改ざんイベントが、データを露出させることなく、フォレンジックのための復元に使用可能な元のコンテンツの暗号ハッシュを含む適応型ログを生成することを検証してください。

---

### C5.6 マルチテナント分離

共有AIインフラストラクチャにおけるテナント間の暗号的および論理的分離を確保する。

 #5.6.1    Level: 1    Role: D/V
 メモリ空間、埋め込みストア、キャッシュエントリ、および一時ファイルがテナントごとに名前空間で分離されており、テナントの削除またはセッション終了時に安全に消去されることを検証してください。
 #5.6.2    Level: 1    Role: D/V
 すべてのAPIリクエストに、セッションコンテキストおよびユーザー権限と暗号学的に検証された認証済みテナント識別子が含まれていることを確認してください。
 #5.6.3    Level: 2    Role: D
 サービスメッシュおよびコンテナオーケストレーションプラットフォーム内でのテナント間通信に対して、ネットワークポリシーがデフォルト拒否ルールを実装していることを検証してください。
 #5.6.4    Level: 3    Role: D
 顧客管理キー（CMK）サポートとテナントのデータストア間の暗号的分離を伴い、テナントごとに暗号化キーが一意であることを確認してください。

---

### C5.7 自律エージェント認可

スコープ付き能力トークンと継続的認可を通じて、AIエージェントおよび自律システムの制御権限を管理します。

 #5.7.1    Level: 1    Role: D/V
 自律エージェントが許可されたアクション、アクセス可能なリソース、時間の制限、および運用上の制約を明示的に列挙したスコープ付き能力トークンを受け取っていることを確認してください。
 #5.7.2    Level: 1    Role: D/V
 高リスク機能（ファイルシステムアクセス、コード実行、外部APIコール、金融取引）はデフォルトで無効化されており、有効化には明確な承認と業務上の正当な理由が必要であることを確認してください。
 #5.7.3    Level: 2    Role: D
 機能トークンがユーザーセッションに紐付けられていることを確認し、暗号学的な完全性保護が含まれていること、そしてオフライン環境での永続化や再利用ができないことを保証してください。
 #5.7.4    Level: 2    Role: V
 エージェント発動のアクションが、完全なコンテキスト評価と監査ログ記録を伴うABACポリシーエンジンによる二次認可を受けていることを確認してください。
 #5.7.5    Level: 3    Role: V
 エージェントのエラー条件と例外処理に、インシデント分析およびフォレンジック調査をサポートするための能力範囲情報が含まれていることを確認してください。

---

### 参考文献

#### 標準とフレームワーク

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 実装ガイド

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### AI特有のセキュリティ

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## モデル、フレームワーク、およびデータのためのC6サプライチェーンセキュリティ

### 制御目標

AIサプライチェーン攻撃は、サードパーティのモデル、フレームワーク、またはデータセットを悪用してバックドア、バイアス、または悪用可能なコードを埋め込みます。これらの制御は、エンドツーエンドの出自管理、脆弱性管理、監視を提供し、モデルのライフサイクル全体を保護します。

---

### C6.1 事前学習モデルの検証と由来

微調整や展開の前に、サードパーティモデルの起源、ライセンス、および隠れた挙動を評価し認証してください。

 #6.1.1    Level: 1    Role: D/V
 すべてのサードパーティモデルアーティファクトに、ソースリポジトリとコミットハッシュを特定する署名付きの由来記録が含まれていることを確認してください。
 #6.1.2    Level: 1    Role: D/V
 モデルをインポートする前に、悪意のあるレイヤーやトロイの木馬トリガーが自動化ツールを用いてスキャンされていることを確認してください。
 #6.1.3    Level: 2    Role: D
 転移学習のファインチューニングが隠れた動作を検出するための敵対的評価に合格することを確認してください。
 #6.1.4    Level: 2    Role: V
 モデルライセンス、輸出管理タグ、およびデータ起源の声明がML-BOMエントリに記録されていることを確認してください。
 #6.1.5    Level: 3    Role: D/V
 高リスクモデル（公開されている重み、未検証の作成者）は、人間によるレビューと承認が行われるまで検疫状態を維持することを確認してください。

---

### C6.2 フレームワークおよびライブラリのスキャン

MLフレームワークおよびライブラリを継続的にスキャンし、CVEおよび悪意のあるコードを検出してランタイムスタックのセキュリティを維持します。

 #6.2.1    Level: 1    Role: D/V
 CIパイプラインがAIフレームワークおよび重要なライブラリに対して依存関係スキャナーを実行していることを確認してください。
 #6.2.2    Level: 1    Role: D/V
 重要な脆弱性（CVSS ≥ 7.0）が本番用イメージへの昇格をブロックすることを確認してください。
 #6.2.3    Level: 2    Role: D
 フォークされたまたはベンダリングされたMLライブラリで、静的コード解析が実行されることを確認してください。
 #6.2.4    Level: 2    Role: V
 フレームワークのアップグレード提案に、公的なCVEフィードを参照したセキュリティ影響評価が含まれていることを確認してください。
 #6.2.5    Level: 3    Role: V
 署名されたSBOMから逸脱する予期しない動的ライブラリの読み込みに対して、ランタイムセンサーが警告を発することを確認してください。

---

### C6.3 依存関係のピン留めと検証

すべての依存関係を不変のダイジェストに固定し、ビルドを再現して同一で改ざんされていない成果物を保証します。

 #6.3.1    Level: 1    Role: D/V
 すべてのパッケージマネージャーがロックファイルによるバージョン固定を強制していることを確認してください。
 #6.3.2    Level: 1    Role: D/V
 コンテナ参照において、変更可能なタグの代わりに不変のダイジェストが使用されていることを確認してください。
 #6.3.3    Level: 2    Role: D
 再現可能ビルドのチェックが、CI実行間でハッシュを比較して同一の出力を確保していることを検証してください。
 #6.3.4    Level: 2    Role: V
 監査トレーサビリティのために、ビルド証明が18か月間保存されていることを確認してください。
 #6.3.5    Level: 3    Role: D
 期限切れの依存関係が、自動的なプルリクエストをトリガーして、固定されたバージョンの更新またはフォークを行うことを確認してください。

---

### C6.4 信頼できるソースの強制

暗号的に検証され、組織によって承認されたソースからのアーティファクトのダウンロードのみを許可し、それ以外はすべてブロックします。

 #6.4.1    Level: 1    Role: D/V
 モデルの重み、データセット、およびコンテナが、承認されたドメインまたは内部レジストリからのみダウンロードされることを確認してください。
 #6.4.2    Level: 1    Role: D/V
 Sigstore/Cosignの署名が、アーティファクトがローカルにキャッシュされる前に公開者の身元を検証することを確認してください。
 #6.4.3    Level: 2    Role: D
 アーティファクトの未認証ダウンロードをブロックして、信頼できるソースのポリシーを強制することを確認してください。
 #6.4.4    Level: 2    Role: V
 リポジトリの許可リストが四半期ごとにレビューされ、各エントリに対して業務上の正当な理由の証拠があることを確認してください。
 #6.4.5    Level: 3    Role: V
 ポリシー違反がアーティファクトの隔離および依存するパイプライン実行のロールバックを引き起こすことを確認してください。

---

### C6.5 第三者データセットリスク評価

外部データセットを毒性、バイアス、法的遵守の観点から評価し、そのライフサイクル全体を通じて監視します。

 #6.5.1    Level: 1    Role: D/V
 外部データセットがポイズニングリスクスコアリング（例：データフィンガープリンティング、外れ値検出）を受けていることを検証してください。
 #6.5.2    Level: 1    Role: D
 バイアス指標（人口統計的均等性、機会均等性）がデータセット承認前に計算されていることを確認してください。
 #6.5.3    Level: 2    Role: V
 ML-BOMエントリにおいて、データセットの発生元およびライセンス条項が正確に記録されていることを確認してください。
 #6.5.4    Level: 2    Role: V
 ホストされたデータセットのドリフトや破損を定期的な監視で検出することを確認してください。
 #6.5.5    Level: 3    Role: D
 学習前に自動スクラビングにより、許可されていないコンテンツ（著作権、個人識別情報）が削除されていることを確認してください。

---

### C6.6 サプライチェーン攻撃監視

CVEフィード、監査ログ分析、レッドチームのシミュレーションを通じて、サプライチェーンの脅威を早期に検出します。

 #6.6.1    Level: 1    Role: V
 CI/CDの監査ログが異常なパッケージの取得や改ざんされたビルドステップの検出のためにSIEMにストリーミングされていることを検証してください。
 #6.6.2    Level: 2    Role: D
 インシデント対応プレイブックに、侵害されたモデルやライブラリのロールバック手順が含まれていることを確認してください。
 #6.6.3    Level: 3    Role: V
 アラートトリアージにおいて、脅威インテリジェンスの強化がML特有の指標（例：モデル汚染IoC）にタグ付けされていることを確認してください。

---

### C6.7 モデルアーティファクトのためのML-BOM

詳細な機械学習（ML）専用ソフトウェア部品表（SBOM）（ML-BOM）を生成および署名し、下流の利用者が展開時にコンポーネントの完全性を検証できるようにします。

 #6.7.1    Level: 1    Role: D/V
 すべてのモデルアーティファクトが、データセット、重み、ハイパーパラメータ、およびライセンスを一覧化したML‑BOMを公開していることを確認してください。
 #6.7.2    Level: 1    Role: D/V
 ML-BOMの生成とCosign署名がCIで自動化されており、マージに必須であることを確認してください。
 #6.7.3    Level: 2    Role: D
 コンポーネントのメタデータ（ハッシュ、ライセンス）のいずれかが欠如している場合、ML-BOMの完全性チェックがビルドを失敗させることを確認してください。
 #6.7.4    Level: 2    Role: V
 ダウンストリームの利用者がAPIを介してML-BOMを照会し、デプロイ時にインポートされたモデルを検証できることを確認してください。
 #6.7.5    Level: 3    Role: V
 ML-BOM（機械学習部品表）がバージョン管理され、差分比較されて不正な改変を検出できることを確認してください。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 モデルの動作、出力制御および安全保証

### 管理目標

モデルの出力は構造化され、信頼性が高く、安全で説明可能であり、運用環境で継続的に監視されなければなりません。これにより、幻覚（ハルシネーション）、プライバシー漏洩、有害なコンテンツ、暴走行動が減少し、ユーザーの信頼と規制遵守が向上します。

---

### C7.1 出力形式の強制

厳格なスキーマ、制約付きデコーディング、および下流の検証は、不正な形式や悪意のあるコンテンツが拡散するのを防ぎます。

 #7.1.1    Level: 1    Role: D/V
 レスポンススキーマ（例：JSONスキーマ）がシステムプロンプトに提供されており、すべての出力が自動的に検証されることを確認してください。不適合な出力は修正または拒否が行われます。
 #7.1.2    Level: 1    Role: D/V
 オーバーフローやプロンプトインジェクションのサイドチャネルを防ぐために、制約付きデコーディング（停止トークン、正規表現、最大トークン数）が有効になっていることを確認してください。
 #7.1.3    Level: 2    Role: D/V
 下流コンポーネントが出力を信用しないものとして扱い、スキーマやインジェクション安全なデシリアライザーに対して検証することを確認してください。
 #7.1.4    Level: 3    Role: V
 不適切な出力イベントがログに記録され、レート制限され、監視に反映されていることを確認してください。

---

### C7.2 幻覚検出と軽減

不確実性の推定とフォールバック戦略により、虚偽の回答を抑制します。

 #7.2.1    Level: 1    Role: D/V
 トークンレベルの対数確率、アンサンブル自己一貫性、または微調整された幻覚検出器が各回答に対して信頼度スコアを割り当てることを確認してください。
 #7.2.2    Level: 1    Role: D/V
 応答の信頼度が設定可能な閾値を下回った場合に、フォールバックワークフロー（例えば、リトリーバル強化生成、セカンダリモデル、または人間のレビュー）がトリガーされることを検証してください。
 #7.2.3    Level: 2    Role: D/V
 幻覚発生事例が根本原因のメタデータでタグ付けされ、ポストモーテムおよびファインチューニングのパイプラインにフィードされていることを確認してください。
 #7.2.4    Level: 3    Role: D/V
 主要なモデルまたは知識ベースのアップデート後に、しきい値と検出器が再校正されていることを確認してください。
 #7.2.5    Level: 3    Role: V
 ダッシュボードの可視化が幻覚率を追跡していることを確認してください。

---

### C7.3 出力の安全性とプライバシーフィルタリング

ポリシーフィルターとレッドチームのカバレッジは、ユーザーと機密データを保護します。

 #7.3.1    Level: 1    Role: D/V
 ポリシーに沿ったヘイト、嫌がらせ、自傷行為、過激派、および性的に露骨なコンテンツを、生成前および生成後の分類器がブロックしていることを確認する。
 #7.3.2    Level: 1    Role: D/V
 PII/PCIの検出と自動修正がすべての応答で実行されることを確認してください。違反があった場合はプライバシーインシデントを発生させます。
 #7.3.3    Level: 2    Role: D
 機密性タグ（例：営業秘密）がモダリティを超えて伝播し、テキスト、画像、コードにおける情報漏洩を防止することを検証する。
 #7.3.4    Level: 3    Role: D/V
 フィルターバイパスの試みや高リスク分類の場合には、二次承認またはユーザーの再認証が必要であることを確認してください。
 #7.3.5    Level: 3    Role: D/V
 フィルタリングしきい値が法的管轄区域およびユーザーの年齢・役割のコンテキストを反映していることを確認してください。

---

### C7.4 出力およびアクション制限

レート制限と承認ゲートは、悪用や過剰な自律性を防ぎます。

 #7.4.1    Level: 1    Role: D
 ユーザーごとおよびAPIキーごとのクォータがリクエスト数、トークン数、およびコストを制限し、429エラー発生時には指数関数的バックオフを適用することを検証してください。
 #7.4.2    Level: 1    Role: D/V
 特権操作（ファイル書き込み、コード実行、ネットワーク呼び出し）がポリシーベースの承認または人間の介入を必要とすることを検証してください。
 #7.4.3    Level: 2    Role: D/V
 同じリクエストに対して生成された画像、コード、テキストが悪意のあるコンテンツを密輸するために使用されないことを保証するために、クロスモーダル一貫性チェックを検証してください。
 #7.4.4    Level: 2    Role: D
 エージェントの委任深度、再帰制限、および許可されたツールリストが明示的に設定されていることを確認してください。
 #7.4.5    Level: 3    Role: V
 制限違反がSIEM取り込み用の構造化されたセキュリティイベントを発行することを検証してください。

---

### C7.5 出力の説明可能性

透明なシグナルはユーザーの信頼と内部のデバッグを向上させます。

 #7.5.1    Level: 2    Role: D/V
 リスク評価で適切と判断された場合、ユーザー向けの信頼度スコアや簡潔な推論要約が表示されることを確認してください。
 #7.5.2    Level: 2    Role: D/V
 生成された説明が、機密性の高いシステムプロンプトや独自のデータを明かさないように確認してください。
 #7.5.3    Level: 3    Role: D
 システムがトークンレベルのログ確率またはアテンションマップを取得し、認可された検査のために保存していることを確認してください。
 #7.5.4    Level: 3    Role: V
 説明可能性アーティファクトがモデルリリースとともに監査可能性のためにバージョン管理されていることを確認してください。

---

### C7.6 モニタリング統合

リアルタイムの可観測性は、開発と本番環境の間のループを閉じます。

 #7.6.1    Level: 1    Role: D
 メトリクス（スキーマ違反、幻覚率、毒性、個人情報漏洩、レイテンシ、コスト）が中央監視プラットフォームに送信されていることを確認してください。
 #7.6.2    Level: 1    Role: V
 各安全指標に対して警告閾値が定義されており、オンコールエスカレーション経路が設定されていることを確認してください。
 #7.6.3    Level: 2    Role: V
 ダッシュボードが出力の異常をモデル/バージョン、機能フラグ、および上流データの変更と関連付けていることを確認してください。
 #7.6.4    Level: 2    Role: D/V
 監視データが文書化されたMLOpsワークフロー内で再訓練、ファインチューニング、またはルールの更新にフィードバックされることを確認してください。
 #7.6.5    Level: 3    Role: V
 監視パイプラインがペネトレーションテストされ、アクセス制御されていることを確認し、機密ログの漏洩を防止してください。

---

### 7.7 ジェネレーティブメディアのセーフガード

ポリシー制約、出力の検証、および追跡可能性を強化することで、AIシステムが違法、有害、または許可されていないメディアコンテンツを生成しないようにします。

 #7.7.1    Level: 1    Role: D/V
 システムプロンプトとユーザー指示が、違法、有害、または同意なしのディープフェイクメディア（例：画像、動画、音声）の生成を明確に禁止していることを確認してください。
 #7.7.2    Level: 2    Role: D/V
 プロンプトがなりすましの生成、性的に露骨なディープフェイク、または本人の同意なしに実在の個人を描写するメディアの試みに対してフィルタリングされていることを確認してください。
 #7.7.3    Level: 2    Role: V
 システムが無断複製を防ぐために、知覚ハッシュ、ウォーターマーク検出、またはフィンガープリンティングを使用していることを確認してください。
 #7.7.4    Level: 3    Role: D/V
 すべての生成されたメディアが、下流のトレーサビリティのために暗号署名されているか、透かしが入れられているか、改ざん耐性のある起源メタデータが埋め込まれていることを確認してください。
 #7.7.5    Level: 3    Role: V
 バイパス試行（例：プロンプトの難読化、スラング、敵対的な表現）が検出、記録され、レート制限されることを確認する。繰り返される悪用は監視システムに通知される。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8メモリ、埋め込みベクトルおよびベクトルデータベースのセキュリティ

### 管理目標

埋め込み（エンベディング）とベクトルストアは、現代のAIシステムの「ライブメモリ」として機能し、ユーザーから提供されたデータを継続的に受け入れ、Retrieval-Augmented Generation（RAG）を通じてモデルのコンテキストに再提示します。これらのメモリが管理されていない場合、個人識別情報（PII）が漏洩したり、同意違反が発生したり、元のテキストを再構築されるリスクがあります。この制御ファミリーの目的は、メモリパイプラインとベクトルデータベースを強化し、アクセス権を最小特権に限定し、埋め込み情報のプライバシーを保護し、保存されたベクトルが期限切れとなったり、要求に応じて取り消し可能であり、ユーザーごとのメモリが他のユーザーのプロンプトや生成結果に影響を及ぼさないようにすることです。

---

### C8.1 メモリおよびRAGインデックスに対するアクセス制御

すべてのベクターコレクションに対して細粒度のアクセス制御を強制します。

 #8.1.1    Level: 1    Role: D/V
 テナント、コレクション、またはドキュメントタグごとに、行レベル/名前空間レベルのアクセス制御ルールが挿入、削除、およびクエリ操作を制限していることを確認してください。
 #8.1.2    Level: 1    Role: D/V
 APIキーやJWTがスコープ付きクレーム（例：コレクションID、アクション動詞）を持ち、少なくとも四半期ごとにローテーションされていることを確認してください。
 #8.1.3    Level: 2    Role: D/V
 特権昇格試行（例：クロスネームスペース類似性クエリ）が検出され、5分以内にSIEMに記録されることを確認してください。
 #8.1.4    Level: 2    Role: D/V
 ベクターデータベースの監査ログが、サブジェクト識別子、操作、ベクターID/名前空間、類似度閾値、および結果数を記録していることを確認してください。
 #8.1.5    Level: 3    Role: V
 エンジンがアップグレードされるか、インデックスシャーディングルールが変更されるたびに、アクセス決定がバイパスの欠陥についてテストされていることを確認してください。

---

### C8.2 埋め込みのサニタイズと検証

ベクトル化の前にテキストを事前スクリーニングして個人識別情報（PII）を検出し、削除または仮名化し、必要に応じて埋め込みの後処理を行い残存信号を除去します。

 #8.2.1    Level: 1    Role: D/V
 PIIおよび規制対象データが自動分類器によって検出され、埋め込み前にマスク処理、トークナイズ、または削除されていることを確認してください。
 #8.2.2    Level: 1    Role: D
 埋め込みパイプラインが、インデックスを汚染する可能性のある実行可能コードや非UTF-8アーティファクトを含む入力を拒否または隔離することを確認してください。
 #8.2.3    Level: 2    Role: D/V
 既知のPIIトークンとの距離が設定可能な閾値を下回る文埋め込みに対して、局所的または計量的差分プライバシーのサニタイズ処理が適用されていることを検証してください。
 #8.2.4    Level: 2    Role: V
 サニタイズの有効性（例：個人識別情報（PII）削除の再現率、意味的ドリフト）が、ベンチマークコーパスに対して少なくとも半期ごとに検証されていることを確認してください。
 #8.2.5    Level: 3    Role: D/V
 サニタイズ設定がバージョン管理されており、変更がピアレビューを経ていることを確認してください。

---

### C8.3 メモリの有効期限切れ、取り消し、および削除

GDPRの「忘れられる権利」および類似の法律は迅速な消去を要求するため、ベクターストアはTTL（有効期間）、ハードデリート、およびトーンストーニングに対応し、取り消されたベクターが回復または再インデックスされないようにする必要があります。

 #8.3.1    Level: 1    Role: D/V
 すべてのベクトルおよびメタデータレコードが、TTL（Time To Live）または自動クリーンアップジョブで尊重される明示的な保持ラベルを持っていることを確認してください。
 #8.3.2    Level: 1    Role: D/V
 ユーザーが開始した削除リクエストが、30日以内にベクトル、メタデータ、キャッシュコピー、および派生インデックスを完全に削除することを検証してください。
 #8.3.3    Level: 2    Role: D
 ハードウェアが対応している場合はストレージブロックの暗号的消去、またはキーボールトの鍵破棄を伴う論理削除が実施されていることを検証してください。
 #8.3.4    Level: 3    Role: D/V
 期限切れのベクトルが、期限切れ後500ミリ秒以内に最近傍検索結果から除外されることを検証してください。

---

### C8.4 埋め込みの逆転および漏洩の防止

最近の防御策であるノイズ重畳、射影ネットワーク、プライバシーニューロン摂動、およびアプリケーション層暗号化により、トークンレベルの逆変換率を5%未満に低減できます。

 #8.4.1    Level: 1    Role: V
 反転攻撃、メンバーシップ推論攻撃、および属性推論攻撃を網羅した正式な脅威モデルが存在し、毎年レビューされていることを確認する。
 #8.4.2    Level: 2    Role: D/V
 アプリケーション層の暗号化または検索可能な暗号化が、インフラ管理者やクラウドスタッフによるベクトルの直接読み取りから保護していることを検証してください。
 #8.4.3    Level: 3    Role: V
 防御パラメータ（差分プライバシーのε、ノイズのσ、射影ランクk）がプライバシー ≥ 99%のトークン保護とユーティリティ ≤ 3%の精度損失のバランスを保っていることを検証してください。
 #8.4.4    Level: 3    Role: D/V
 モデル更新のリリースゲートに反転耐性メトリクスが含まれていることを確認し、回帰予算が定義されていることを確認する。

---

### C8.5 ユーザー固有メモリに対するスコープ強制

テナント間の情報漏えいは依然として主要なRAGリスクであり、不適切にフィルタリングされた類似性検索が他の顧客の機密ドキュメントを露出させる可能性があります。

 #8.5.1    Level: 1    Role: D/V
 すべての検索クエリが、LLMプロンプトに渡される前にテナント/ユーザーIDによってポストフィルタリングされていることを確認してください。
 #8.5.2    Level: 1    Role: D
 コレクション名または名前空間付きIDがユーザーまたはテナントごとにソルト処理されていることを確認し、スコープ間でベクトルが衝突しないようにしてください。
 #8.5.3    Level: 2    Role: D/V
 類似度結果が設定可能な距離閾値を上回り、かつ呼び出し元の範囲外である場合、それらは破棄されセキュリティアラートが発生することを確認してください。
 #8.5.4    Level: 2    Role: V
 マルチテナントのストレステストが、アクセス権外のドキュメントを取得しようとする敵対的クエリをシミュレートし、情報漏洩が全くないことを検証してください。
 #8.5.5    Level: 3    Role: D/V
 暗号鍵がテナントごとに分離されていることを確認し、物理的なストレージが共有されている場合でも暗号的な分離が確保されていることを保証してください。

---

### C8.6 高度なメモリシステムセキュリティ

エピソード記憶、意味記憶、作業記憶を含む高度なメモリアーキテクチャに対する、特定の分離および検証要件を備えたセキュリティ制御。

 #8.6.1    Level: 1    Role: D/V
 異なるメモリタイプ（エピソード記憶、意味記憶、作業記憶）が、ロールベースのアクセス制御、個別の暗号化キー、および各メモリタイプのアクセスパターンの文書化により、分離されたセキュリティコンテキストを持っていることを検証してください。
 #8.6.2    Level: 2    Role: D/V
 メモリ統合プロセスには、コンテンツのサニタイズ、情報源の検証、そして保存前の整合性チェックを通じて悪意のあるメモリの注入を防ぐためのセキュリティ検証が含まれていることを確認してください。
 #8.6.3    Level: 2    Role: D/V
 メモリ検索クエリが検証およびサニタイズされ、不正な情報の抽出を防ぐために、クエリパターンの分析、アクセス制御の実施、および結果のフィルタリングが行われていることを確認してください。
 #8.6.4    Level: 3    Role: D/V
 キー削除、多重上書き、または検証証明書付きのハードウェアベースの安全な削除を用いて、暗号消去の保証を伴う機密情報がメモリ忘却メカニズムによって安全に削除されることを検証してください。
 #8.6.5    Level: 3    Role: D/V
 メモリシステムの整合性が、チェックサム、監査ログ、および正常な操作外でメモリ内容が変更された際の自動アラートを通じて、不正な変更や破損が継続的に監視されていることを検証してください。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自律オーケストレーションとエージェント行動のセキュリティ

### 管理目標

自律型またはマルチエージェントAIシステムが、明示的に意図され、認証され、監査可能であり、かつコストとリスクの境界内でのみ行動を実行できるようにします。これにより、自律システムの乗っ取り、ツールの誤使用、エージェントループの検出、通信のハイジャック、身元のなりすまし、群れの操作、意図の操作などの脅威から保護します。

---

### 9.1 エージェントのタスク計画と再帰予算

再帰的なプランを制限し、権限のある操作に対しては人間のチェックポイントを強制する。

 #9.1.1    Level: 1    Role: D/V
 最大再帰深度、幅、実時間、トークン、およびエージェント実行ごとの金銭的コストが中央で設定され、バージョン管理されていることを確認する。
 #9.1.2    Level: 1    Role: D/V
 特権的または取り消し不能な行動（例：コードのコミット、資金の送金）については、実行前に監査可能なチャネルを通じて明示的な人間の承認が必要であることを確認してください。
 #9.1.3    Level: 2    Role: D
 リアルタイムリソースモニターが、任意の予算閾値を超えた場合にサーキットブレーカーを作動させて中断し、さらなるタスクの拡張を停止することを検証してください。
 #9.1.4    Level: 2    Role: D/V
 回路遮断器のイベントが、エージェントID、トリガ条件、およびフォレンジックレビューのためにキャプチャされたプラン状態とともにログに記録されていることを確認してください。
 #9.1.5    Level: 3    Role: V
 セキュリティテストが予算消耗および暴走プランのシナリオをカバーし、データ損失なく安全に停止することを確認してください。
 #9.1.6    Level: 3    Role: D
 予算ポリシーがポリシー・アズ・コードとして表現され、CI/CDで強制されて構成のドリフトを防止していることを確認してください。

---

### 9.2 ツールプラグインのサンドボックス化

ツールの相互作用を隔離し、不正なシステムアクセスやコードの実行を防止します。

 #9.2.1    Level: 1    Role: D/V
 すべてのツール／プラグインが、最小権限のファイルシステム、ネットワーク、およびシステムコールポリシーを備えたOS、コンテナ、またはWASMレベルのサンドボックス内で実行されることを確認してください。
 #9.2.2    Level: 1    Role: D/V
 サンドボックスのリソース割り当て（CPU、メモリ、ディスク、ネットワーク送信）および実行タイムアウトが適用され、ログに記録されていることを確認してください。
 #9.2.3    Level: 2    Role: D/V
 ツールのバイナリまたは記述子がデジタル署名されていることを確認し、ロードする前に署名の検証を行います。
 #9.2.4    Level: 2    Role: V
 サンドボックスのテレメトリがSIEMにストリームされていることを検証し、異常（例：試みられたアウトバウンド接続）がアラートを発生させることを確認します。
 #9.2.5    Level: 3    Role: V
 高リスクプラグインが本番展開前にセキュリティレビューとペネトレーションテストを受けることを確認してください。
 #9.2.6    Level: 3    Role: D/V
 サンドボックスの脱出試行が自動的にブロックされ、問題のあるプラグインが調査待ちで隔離されることを確認してください。

---

### 9.3 自律ループとコスト制限

制御不能なエージェント間の再帰およびコスト爆発を検出し、防止します。

 #9.3.1    Level: 1    Role: D/V
 エージェント間呼び出しがホップ制限またはTTLを含み、ランタイムがそれを減算および適用することを確認してください。
 #9.3.2    Level: 2    Role: D
 エージェントが自己呼び出しや循環パターンを検出するために、一意のインボケーショングラフIDを保持していることを確認してください。
 #9.3.3    Level: 2    Role: D/V
 累積の計算ユニットと支出カウンターがリクエストチェーンごとに追跡されていることを確認してください。制限を超えるとチェーンが中断されます。
 #9.3.4    Level: 3    Role: V
 エージェントプロトコルにおいて、形式解析またはモデル検査により無限再帰が存在しないことを検証する。
 #9.3.5    Level: 3    Role: D
 ループ中断イベントがアラートを生成し、継続的改善の指標に反映されることを確認してください。

---

### 9.4 プロトコルレベルの誤用防止

乗っ取りや操作を防ぐために、エージェントと外部システム間の通信チャネルを安全に保護する。

 #9.4.1    Level: 1    Role: D/V
 すべてのエージェント間およびエージェントからツールへのメッセージが認証されていること（例えば、相互TLSまたはJWT）およびエンドツーエンドで暗号化されていることを確認してください。
 #9.4.2    Level: 1    Role: D
 スキーマが厳密に検証されていることを確認する。未知のフィールドや不正な形式のメッセージは拒否される。
 #9.4.3    Level: 2    Role: D/V
 整合性チェック（MACまたはデジタル署名）がツールパラメータを含むメッセージペイロード全体をカバーしていることを確認してください。
 #9.4.4    Level: 2    Role: D
 リプレイ防止（ノンスまたはタイムスタンプウィンドウ）がプロトコル層で強制されていることを確認してください。
 #9.4.5    Level: 3    Role: V
 プロトコル実装がインジェクションや逆シリアル化の脆弱性に対してファズテストおよび静的解析を受けていることを確認してください。

---

### 9.5 エージェントの識別および改ざん検知

操作が誰によるものか特定でき、変更が検出可能であることを保証してください。

 #9.5.1    Level: 1    Role: D/V
 各エージェントインスタンスが一意の暗号学的アイデンティティ（鍵ペアまたはハードウェアに根ざした資格情報）を所有していることを検証します。
 #9.5.2    Level: 2    Role: D/V
 すべてのエージェントのアクションに署名とタイムスタンプが付与されていることを確認し、ログには否認防止のために署名が含まれていることを確認してください。
 #9.5.3    Level: 2    Role: V
 改ざん検知可能なログが追記専用または一度書き込み専用の媒体に保存されていることを確認してください。
 #9.5.4    Level: 3    Role: D
 識別キーが定められたスケジュールおよび侵害指標に基づいてローテーションされることを確認する。
 #9.5.5    Level: 3    Role: D/V
 スプーフィングやキー競合の試みが発生した際、影響を受けたエージェントが即座に隔離されることを確認してください。

---

### 9.6 マルチエージェント群知能リスク低減

集合行動の危険を隔離と正式な安全モデリングを通じて軽減する。

 #9.6.1    Level: 1    Role: D/V
 異なるセキュリティドメインで動作するエージェントが、分離されたランタイムサンドボックスまたはネットワークセグメント内で実行されていることを確認する。
 #9.6.2    Level: 3    Role: V
 群知能行動が、展開前にライブネスと安全性の観点からモデリングされ、形式的に検証されていることを確認してください。
 #9.6.3    Level: 3    Role: D
 ランタイムモニターが新たに出現する危険なパターン（例：振動、デッドロック）を検出し、是正措置を開始することを確認してください。

---

### 9.7 ユーザーおよびツールの認証／認可

すべてのエージェント起動アクションに対して堅牢なアクセス制御を実装してください。

 #9.7.1    Level: 1    Role: D/V
 エージェントがファーストクラスの主体として下流のシステムに認証し、エンドユーザーの資格情報を再利用しないことを検証してください。
 #9.7.2    Level: 2    Role: D
 細分化された認可ポリシーが、エージェントが呼び出せるツールと、そのツールに渡すことができるパラメーターを制限していることを確認してください。
 #9.7.3    Level: 2    Role: V
 特権チェックがセッション開始時だけでなく、すべての呼び出し時に再評価される（継続的な認可）ことを確認してください。
 #9.7.4    Level: 3    Role: D
 委任された権限が自動的に期限切れとなり、タイムアウトまたはスコープの変更後に再同意が必要であることを確認してください。

---

### 9.8 エージェント間通信のセキュリティ

盗聴や改ざんを防ぐために、すべてのエージェント間メッセージを暗号化し、完全性保護を行うこと。

 #9.8.1    Level: 1    Role: D/V
 エージェントチャネルに対して、相互認証および完全前方秘匿暗号化（例：TLS 1.3）が必須であることを検証してください。
 #9.8.2    Level: 1    Role: D
 メッセージの整合性と送信元が処理前に検証されることを確認してください。検証に失敗した場合は警告を発し、メッセージを破棄します。
 #9.8.3    Level: 2    Role: D/V
 通信のメタデータ（タイムスタンプ、シーケンス番号）が、フォレンジック再構築をサポートするために記録されていることを確認してください。
 #9.8.4    Level: 3    Role: V
 プロトコル状態機械が安全でない状態に駆動されないことを、形式検証またはモデル検査によって確認します。

---

### 9.9 意図検証と制約の強制

エージェントの行動がユーザーの明示した意図およびシステムの制約に合致していることを検証する。

 #9.9.1    Level: 1    Role: D
 事前実行の制約ソルバーが、提案されたアクションをハードコーディングされた安全性およびポリシールールに照らして検証することを確認してください。
 #9.9.2    Level: 2    Role: D/V
 高影響の操作（財務的、破壊的、プライバシーに関わるもの）については、実行ユーザーからの明示的な意図確認を必須とすることを検証する。
 #9.9.3    Level: 2    Role: V
 事後条件の検証により、完了したアクションが意図した効果を副作用なしに達成したことを確認し、不一致があった場合はロールバックをトリガーします。
 #9.9.4    Level: 3    Role: V
 形式手法（例：モデル検査、定理証明）またはプロパティベースのテストによって、エージェントの計画がすべての宣言された制約を満たしていることを検証してください。
 #9.9.5    Level: 3    Role: D
 意図の不一致や制約違反の事象が、継続的改善サイクルおよび脅威インテリジェンス共有にフィードバックされることを確認してください。

---

### 9.10 エージェント推論戦略のセキュリティ

ReAct、Chain-of-Thought、Tree-of-Thoughtsなどの異なる推論戦略の安全な選択と実行。

 #9.10.1    Level: 1    Role: D/V
 推論戦略の選択が決定論的な基準（入力の複雑さ、タスクの種類、セキュリティコンテキスト）を使用しており、同一のセキュリティコンテキスト内で同一の入力が同一の戦略選択を生み出すことを検証してください。
 #9.10.2    Level: 1    Role: D/V
 各推論戦略（ReAct、Chain-of-Thought、Tree-of-Thoughts）に対して、それぞれの認知アプローチに特化した入力検証、出力のサニタイズ、および実行時間制限が確実に設けられていることを確認してください。
 #9.10.3    Level: 2    Role: D/V
 推論戦略の遷移が、入力特性、選択基準の値、および実行メタデータを含む完全なコンテキストとともに記録され、監査トレイルの再構築が可能であることを検証してください。
 #9.10.4    Level: 2    Role: D/V
 Tree-of-Thoughts推論には、ポリシー違反、リソース制限、安全境界が検出された場合に探索を終了する枝刈りメカニズムが含まれていることを検証してください。
 #9.10.5    Level: 2    Role: D/V
 ReAct（推論-行動-観察）サイクルには、各段階での検証チェックポイントが含まれていることを確認します：推論ステップの検証、行動の承認、および次の段階に進む前の観察のサニタイズ。
 #9.10.6    Level: 3    Role: D/V
 推論戦略のパフォーマンス指標（実行時間、リソース使用量、出力品質）が設定されたしきい値を超えて逸脱した場合に、自動アラートで監視されていることを確認してください。
 #9.10.7    Level: 3    Role: D/V
 複数の戦略を組み合わせたハイブリッド推論アプローチが、いかなるセキュリティ制御も回避することなく、すべての構成戦略の入力検証および出力制約を維持していることを確認してください。
 #9.10.8    Level: 3    Role: D/V
 推論戦略のセキュリティテストには、誤った形式の入力を用いたファジング、戦略の切り替えを強制するよう設計された敵対的プロンプト、および各認知的アプローチの境界条件テストが含まれることを検証してください。

---

### 9.11 エージェントライフサイクルの状態管理とセキュリティ

暗号監査証跡および定義された回復手順を備えた、安全なエージェントの初期化、状態遷移、および終了。

 #9.11.1    Level: 1    Role: D/V
 エージェントの初期化において、ハードウェア対応の証明書を用いた暗号学的識別の確立と、エージェントID、タイムスタンプ、構成ハッシュ、および初期化パラメータを含む不変の起動監査ログが含まれていることを確認してください。
 #9.11.2    Level: 2    Role: D/V
 エージェントの状態遷移が暗号学的に署名され、タイムスタンプが付けられ、トリガーイベント、前の状態ハッシュ、新しい状態ハッシュ、および実行されたセキュリティ検証を含む完全なコンテキストとともにログ記録されていることを確認してください。
 #9.11.3    Level: 2    Role: D/V
 エージェントのシャットダウン手順に、暗号消去または多重上書きによる安全なメモリ消去、証明書機関への通知を伴う資格情報の取り消し、および改ざん防止型終了証明書の生成が含まれていることを確認してください。
 #9.11.4    Level: 3    Role: D/V
 エージェントの回復メカニズムが、暗号学的チェックサム（最低でもSHA-256）を使用して状態の完全性を検証し、破損が検出された場合には既知の正常状態にロールバックし、自動アラートと手動承認の要件があることを確認してください。
 #9.11.5    Level: 3    Role: D/V
 エージェントの永続化メカニズムが、エージェントごとのAES-256キーを用いて機密状態データを暗号化し、最大90日間の設定可能なスケジュールでゼロダウンタイムのデプロイメントによる安全なキーのローテーションを実装していることを検証してください。

---

### 9.12 ツール統合セキュリティフレームワーク

定義されたリスク評価および承認プロセスを伴う、動的ツールの読み込み、実行、および結果検証のためのセキュリティ制御。

 #9.12.1    Level: 1    Role: D/V
 ツール記述子に、必要な権限（読み取り/書き込み/実行）、リスクレベル（低/中/高）、リソース制限（CPU、メモリ、ネットワーク）、およびツールマニフェストに文書化された検証要件を指定するセキュリティメタデータが含まれていることを確認してください。
 #9.12.2    Level: 1    Role: D/V
 ツールの実行結果が、タイムアウト制限およびエラー処理手順と統合される前に、期待されるスキーマ（JSONスキーマ、XMLスキーマ）およびセキュリティポリシー（出力のサニタイズ、データ分類）に対して検証されていることを確認してください。
 #9.12.3    Level: 2    Role: D/V
 ツールの操作ログに、特権使用状況、データアクセスパターン、実行時間、リソース消費、および戻りコードを含む詳細なセキュリティコンテキストが含まれていることを確認し、SIEM統合のために構造化ログを使用してください。
 #9.12.4    Level: 2    Role: D/V
 動的ツール読み込みメカニズムがPKIインフラストラクチャを使用してデジタル署名を検証し、実行前にサンドボックス分離と権限確認を伴う安全な読み込みプロトコルを実装していることを確認してください。
 #9.12.5    Level: 3    Role: D/V
 新しいバージョンに対して、静的解析、動的テスト、および文書化された承認基準とSLA要件を含むセキュリティチームのレビューを含む必須承認ゲートを設けたツールのセキュリティ評価が自動的にトリガーされることを検証してください。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 敵対的ロバストネスとプライバシー防御

### 管理目標

回避、推論、抽出、または毒性攻撃に直面した際に、AIモデルが信頼性を維持し、プライバシーを保護し、悪用に強いことを保証する。

---

### 10.1 モデル整合性と安全性

有害またはポリシー違反の出力を防止する。

 #10.1.1    Level: 1    Role: D/V
 アライメントテストスイート（レッドチームプロンプト、ジェイルブレイクプローブ、不許可コンテンツ）がバージョン管理されており、すべてのモデルリリースで実行されていることを確認してください。
 #10.1.2    Level: 1    Role: D
 拒否と安全完了ガードレールが適用されていることを確認してください。
 #10.1.3    Level: 2    Role: D/V
 自動評価者が有害コンテンツ率を測定し、設定された閾値を超えるリグレッションを検出することを確認してください。
 #10.1.4    Level: 2    Role: D
 カウンタージェイルブレイクトレーニングが文書化され、再現可能であることを確認してください。
 #10.1.5    Level: 3    Role: V
 正式なポリシー遵守の証明または認定された監視が重要なドメインをカバーしていることを確認してください。

---

### 10.2 敵対的サンプルの耐性強化

操作された入力に対するレジリエンスを高める。堅牢な敵対的トレーニングとベンチマークスコアリングが現在の最良の方法である。

 #10.2.1    Level: 1    Role: D
 プロジェクトのリポジトリに再現可能なシードを用いた敵対的トレーニングの設定が含まれていることを確認してください。
 #10.2.2    Level: 2    Role: D/V
 本番パイプラインにおいて、敵対的サンプル検出がブロッキングアラートを発生させることを検証してください。
 #10.2.4    Level: 3    Role: V
 認証された堅牢性証明または区間境界証明が、少なくとも最も重要なクラスをカバーしていることを確認してください。
 #10.2.5    Level: 3    Role: V
 回帰テストが適応攻撃を用いて測定可能なロバスト性の低下がないことを確認していることを検証する。

---

### 10.3 メンバーシップ推論緩和

レコードがトレーニングデータに含まれているかどうかを判断する能力を制限する。差分プライバシーおよび信頼度スコアのマスキングが、最も効果的な既知の防御策のままである。

 #10.3.1    Level: 1    Role: D
 クエリごとのエントロピー正則化または温度スケーリングが過度に自信のある予測を減少させることを検証する。
 #10.3.2    Level: 2    Role: D
 機密データセットに対しては、ε-制限付き差分プライバシー最適化を使用していることを検証してください。
 #10.3.3    Level: 2    Role: V
 攻撃シミュレーション（シャドーモデルまたはブラックボックス）が保留データに対して攻撃AUC ≤ 0.60を示すことを確認してください。

---

### 10.4 モデル反転耐性

プライベート属性の再構築を防ぐ。最近の調査では、実用的な防御策として出力の切り捨てと差分プライバシー（DP）保証が強調されている。

 #10.4.1    Level: 1    Role: D
 機密属性が直接出力されることがないことを確認してください。必要に応じて、バケットや一方向変換を使用してください。
 #10.4.2    Level: 1    Role: D/V
 同じ主体からの繰り返しの適応クエリがクエリレート制限によって制御されていることを検証してください。
 #10.4.3    Level: 2    Role: D
 モデルがプライバシー保護ノイズでトレーニングされていることを検証してください。

---

### 10.5 モデル抽出防御

不正なクローン作成を検出し抑止します。ウォーターマーキングとクエリパターン分析が推奨されます。

 #10.5.1    Level: 1    Role: D
 推論ゲートウェイがモデルの記憶閾値に調整されたグローバルおよびAPIキーごとのレート制限を適用していることを確認してください。
 #10.5.2    Level: 2    Role: D/V
 クエリエントロピーと入力複数性の統計が自動抽出検出器に入力されていることを確認してください。
 #10.5.3    Level: 2    Role: V
 疑わしいクローンに対して最大1,000回の問い合わせで、p < 0.01の確率で壊れやすい、または確率的透かしの証明が可能であることを検証してください。
 #10.5.4    Level: 3    Role: D
 ウォーターマークキーとトリガーセットがハードウェアセキュリティモジュールに保存され、毎年ローテーションされていることを確認してください。
 #10.5.5    Level: 3    Role: V
 抽出アラートイベントに問題のあるクエリが含まれており、インシデント対応プレイブックと統合されていることを確認してください。

---

### 10.6 推論時の毒物データ検出

バックドアや毒入り入力を検出して無効化します。

 #10.6.1    Level: 1    Role: D
 モデル推論の前に、入力が異常検知器（例：STRIP、一貫性スコアリング）を通過することを確認してください。
 #10.6.2    Level: 1    Role: V
 検出器のしきい値が、5%未満の誤検知を達成するために、クリーンおよび汚染された検証セットで調整されていることを確認してください。
 #10.6.3    Level: 2    Role: D
 毒されたとフラグ付けされた入力がソフトブロッキングおよび人間のレビューのワークフローをトリガーすることを確認してください。
 #10.6.4    Level: 2    Role: V
 検出器が適応的でトリガーレスのバックドア攻撃によってストレステストされていることを確認してください。
 #10.6.5    Level: 3    Role: D
 検出効果指標が記録され、新しい脅威インテリジェンスとともに定期的に再評価されていることを確認してください。

---

### 10.7 動的セキュリティポリシー適応

脅威インテリジェンスと行動分析に基づくリアルタイムのセキュリティポリシー更新。

 #10.7.1    Level: 1    Role: D/V
 エージェントの再起動なしにセキュリティポリシーを動的に更新でき、ポリシーバージョンの整合性が保たれていることを確認してください。
 #10.7.2    Level: 2    Role: D/V
 ポリシーの更新が認可されたセキュリティ担当者によって暗号的に署名され、適用前に検証されていることを確認してください。
 #10.7.3    Level: 2    Role: D/V
 動的ポリシーの変更が、正当化、承認チェーン、およびロールバック手順を含む完全な監査証跡とともに記録されていることを確認してください。
 #10.7.4    Level: 3    Role: D/V
 適応型セキュリティ機構がリスクの状況や行動パターンに基づいて脅威検知感度を調整することを検証してください。
 #10.7.5    Level: 3    Role: D/V
 ポリシー適応の決定が説明可能であり、セキュリティチームのレビューのために証拠のトレイルを含むことを確認してください。

---

### 10.8 リフレクションベースのセキュリティ分析

エージェントの自己反省とメタ認知分析によるセキュリティ検証。

 #10.8.1    Level: 1    Role: D/V
 エージェントの反省メカニズムには、決定と行動のセキュリティに焦点を当てた自己評価が含まれていることを確認する。
 #10.8.2    Level: 2    Role: D/V
 反射出力が検証され、不正な入力による自己評価メカニズムの操作を防止することを確認してください。
 #10.8.3    Level: 2    Role: D/V
 メタ認知的セキュリティ分析が、エージェントの推論プロセスにおける潜在的なバイアス、操作、または妥協を特定することを検証する。
 #10.8.4    Level: 3    Role: D/V
 リフレクションベースのセキュリティ警告が高度な監視および潜在的な人間の介入ワークフローを引き起こすことを確認してください。
 #10.8.5    Level: 3    Role: D/V
 セキュリティ反省からの継続的学習が、正当な機能を損なうことなく脅威検出を向上させることを検証する。

---

### 10.9 進化と自己改善のセキュリティ

自己改変および進化が可能なエージェントシステムのためのセキュリティ制御。

 #10.9.1    Level: 1    Role: D/V
 自己修正機能が指定された安全領域内に制限されていることを、形式的検証の境界で確認してください。
 #10.9.2    Level: 2    Role: D/V
 進化提案が実装される前に、セキュリティ影響評価を受けることを確認してください。
 #10.9.3    Level: 2    Role: D/V
 自己改善メカニズムには、整合性検証を伴うロールバック機能が含まれていることを確認してください。
 #10.9.4    Level: 3    Role: D/V
 メタラーニングのセキュリティが改善アルゴリズムの敵対的操作を防止することを検証してください。
 #10.9.5    Level: 3    Role: D/V
 再帰的な自己改良が収束の数学的証明とともに形式的な安全制約によって制限されていることを検証する。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 プライバシー保護と個人データ管理

### 管理目標

AIのライフサイクル全体（収集、学習、推論、インシデント対応）にわたって厳格なプライバシー保証を維持し、個人データは明確な同意、最小限必要な範囲、証明可能な消去、および正式なプライバシー保証のもとでのみ処理されるようにします。

---

### 11.1 匿名化とデータ最小化

 #11.1.1    Level: 1    Role: D/V
 直接識別子および準識別子が削除またはハッシュ化されていることを確認してください。
 #11.1.2    Level: 2    Role: D/V
 自動監査がk匿名性/l多様性を測定し、しきい値がポリシーを下回った場合に警告を出すことを確認してください。
 #11.1.3    Level: 2    Role: V
 モデルの特徴重要度レポートが、ε = 0.01の相互情報量を超える識別子リーケージを証明しないことを検証する。
 #11.1.4    Level: 3    Role: V
 形式的証明または合成データの認証により、連結攻撃下でも再識別リスクが0.05以下であることを検証する。

---

### 11.2 忘れられる権利と削除の実施

 #11.2.1    Level: 1    Role: D/V
 データ主体の削除リクエストが、生データセット、チェックポイント、埋め込み、ログ、およびバックアップに対して、30日未満のサービスレベルアグリーメント内で伝播することを検証します。
 #11.2.2    Level: 2    Role: D
 「マシンアンラーニング」手法が、認定されたアンラーニングアルゴリズムを用いて物理的に再学習または近似的な除去を実施していることを検証する。
 #11.2.3    Level: 2    Role: V
 シャドーモデル評価により、忘却後の出力に影響を与える忘れられたレコードが1％未満であることを検証する。
 #11.2.4    Level: 3    Role: V
 削除イベントが不変に記録され、規制当局によって監査可能であることを確認してください。

---

### 11.3 差分プライバシーの保護措置

 #11.3.1    Level: 2    Role: D/V
 累積εがポリシーの閾値を超えた場合に、プライバシー損失会計ダッシュボードが警告を出すことを確認してください。
 #11.3.2    Level: 2    Role: V
 ブラックボックスプライバシー監査が宣言された値の10％以内でε̂を推定していることを検証する。
 #11.3.3    Level: 3    Role: V
 正式な証明が、トレーニング後のすべてのファインチューンおよび埋め込みを網羅していることを確認する。

---

### 11.4 目的制限およびスコープクリープ防止

 #11.4.1    Level: 1    Role: D
 すべてのデータセットおよびモデルチェックポイントが、元の同意に沿った機械可読の目的タグを持っていることを確認してください。
 #11.4.2    Level: 1    Role: D/V
 ランタイムモニターが、宣言された目的と矛盾するクエリを検出し、ソフト拒否をトリガーすることを検証してください。
 #11.4.3    Level: 3    Role: D
 ポリシー・アズ・コードのゲートが、DPIA（データ保護影響評価）のレビューなしにモデルの新しいドメインへの再展開をブロックすることを検証してください。
 #11.4.4    Level: 3    Role: V
 形式的なトレーサビリティ証明が、すべての個人データのライフサイクルが同意された範囲内に留まっていることを示すことを検証してください。

---

### 11.5 同意管理と合法的根拠の追跡

 #11.5.1    Level: 1    Role: D/V
 同意管理プラットフォーム（CMP）が、データ主体ごとにオプトインの状態、目的、および保持期間を記録していることを確認してください。
 #11.5.2    Level: 2    Role: D
 APIが同意トークンを公開していることを確認し、モデルは推論前にトークンのスコープを検証する必要があります。
 #11.5.3    Level: 2    Role: D/V
 同意が拒否または取り消された場合、24時間以内に処理パイプラインが停止することを確認してください。

---

### 11.6 プライバシー制御を備えたフェデレーテッドラーニング

 #11.6.1    Level: 1    Role: D
 クライアントの更新が集約前に局所差分プライバシーのノイズ付加を使用していることを確認してください。
 #11.6.2    Level: 2    Role: D/V
 トレーニングメトリクスが差分プライバシーを保持し、単一クライアントの損失を決して明らかにしないことを検証してください。
 #11.6.3    Level: 2    Role: V
 毒性に強い集約（例：Krum/Trimmed-Mean）が有効になっていることを確認してください。
 #11.6.4    Level: 3    Role: V
 正式な証明が5未満の効用損失で全体のε予算を示すことを検証する。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 監視、ログ記録、および異常検知

### 管理目標

このセクションでは、モデルやその他のAIコンポーネントが何を見て、何を行い、何を返すかについてのリアルタイムおよびフォレンジックの可視性を提供するための要件を示しており、これにより脅威を検出、分類、学習できるようにします。

### C12.1 リクエストおよびレスポンスのログ記録

 #12.1.1    Level: 1    Role: D/V
 すべてのユーザープロンプトとモデルの応答が、適切なメタデータ（例：タイムスタンプ、ユーザーID、セッションID、モデルバージョン）とともに記録されていることを確認してください。
 #12.1.2    Level: 1    Role: D/V
 ログが適切な保存期間ポリシーとバックアップ手順を備えた、安全でアクセス制御されたリポジトリに保存されていることを確認してください。
 #12.1.3    Level: 1    Role: D/V
 ログストレージシステムが、ログに含まれる機密情報を保護するために、保存時および転送時の暗号化を実装していることを確認してください。
 #12.1.4    Level: 1    Role: D/V
 プロンプトおよび出力内の機密データがログ記録前に自動的に検閲またはマスクされることを確認し、PII、認証情報、および機密情報に対する設定可能な検閲ルールを適用してください。
 #12.1.5    Level: 2    Role: D/V
 ポリシー決定および安全フィルタリングの操作が、コンテンツモデレーションシステムの監査およびデバッグを可能にする十分な詳細で記録されていることを確認してください。
 #12.1.6    Level: 2    Role: D/V
 ログの完全性が暗号署名や書き込み専用ストレージなどを通じて保護されていることを確認してください。

---

### C12.2 悪用検出とアラート通知

 #12.2.1    Level: 1    Role: D/V
 既知の脱獄パターン、プロンプトインジェクションの試み、および敵対的入力に対して、シグネチャベースの検出を用いてシステムが検出および警告を行うことを確認してください。
 #12.2.2    Level: 1    Role: D/V
 システムが標準的なログフォーマットおよびプロトコルを使用して、既存のセキュリティ情報およびイベント管理（SIEM）プラットフォームと統合されていることを確認してください。
 #12.2.3    Level: 2    Role: D/V
 強化されたセキュリティイベントに、モデル識別子、信頼度スコア、安全フィルターの決定などのAI固有のコンテキストが含まれていることを確認してください。
 #12.2.4    Level: 2    Role: D/V
 行動異常検知が異常な会話パターン、過剰な再試行回数、または体系的なプロービング行動を識別することを確認してください。
 #12.2.5    Level: 2    Role: D/V
 リアルタイムのアラート機構が、潜在的なポリシー違反や攻撃試行が検出された際にセキュリティチームに通知することを確認してください。
 #12.2.6    Level: 2    Role: D/V
 カスタムルールが、協調的なジャイルブレイク試行、プロンプトインジェクションキャンペーン、およびモデル抽出攻撃を含むAI固有の脅威パターンを検出するために組み込まれていることを確認してください。
 #12.2.7    Level: 3    Role: D/V
 自動化されたインシデント対応ワークフローが、侵害されたモデルを隔離し、悪意のあるユーザーをブロックし、重大なセキュリティイベントをエスカレーションできることを検証してください。

---

### C12.3 モデルドリフト検出

 #12.3.1    Level: 1    Role: D/V
 システムが、モデルのバージョンや期間にわたって、精度、信頼度スコア、遅延、エラー率などの基本的なパフォーマンス指標を追跡していることを確認してください。
 #12.3.2    Level: 2    Role: D/V
 パフォーマンス指標が事前に定義された劣化閾値を超えるか、ベースラインから大幅に逸脱した場合に自動アラートが発動することを確認する。
 #12.3.3    Level: 2    Role: D/V
 モデルの出力に事実誤認、不整合、または捏造された情報が含まれている場合に、幻覚検出モニターがそれを特定しフラグを立てることを検証してください。

---

### C12.4 パフォーマンスおよび動作テレメトリ

 #12.4.1    Level: 1    Role: D/V
 リクエスト遅延、トークン消費量、メモリ使用量、およびスループットを含む運用指標が継続的に収集および監視されていることを確認してください。
 #12.4.2    Level: 1    Role: D/V
 成功率と失敗率が、エラータイプとその根本原因の分類を伴って追跡されていることを確認してください。
 #12.4.3    Level: 2    Role: D/V
 リソース利用状況の監視にGPU/CPU使用率、メモリ消費、およびストレージ要件が含まれていることを確認し、しきい値を超えた場合にアラートが発生するようにしてください。

---

### C12.5 AIインシデント対応計画と実行

 #12.5.1    Level: 1    Role: D/V
 インシデント対応計画が、モデルの侵害、データポイズニング、および敵対的攻撃を含むAI関連のセキュリティイベントに具体的に対応していることを確認してください。
 #12.5.2    Level: 2    Role: D/V
 インシデント対応チームが、モデルの挙動や攻撃ベクトルを調査するために、AI専用のフォレンジックツールおよび専門知識にアクセスできることを確認する。
 #12.5.3    Level: 3    Role: D/V
 事後分析にモデルの再訓練の考慮、安全性フィルターの更新、そして得られた教訓のセキュリティ管理への統合が含まれていることを確認してください。

---

### C12.5 AI性能劣化検知

AIモデルのパフォーマンスおよび品質の劣化を時間の経過とともに監視・検出する。

 #12.5.1    Level: 1    Role: D/V
 モデルの精度、適合率、再現率、およびF1スコアが継続的に監視され、ベースラインの閾値と比較されていることを確認してください。
 #12.5.2    Level: 1    Role: D/V
 データドリフト検出が、モデルの性能に影響を与える可能性のある入力分布の変化を監視することを確認してください。
 #12.5.3    Level: 2    Role: D/V
 概念ドリフト検出が入力と期待される出力との関係の変化を特定することを検証する。
 #12.5.4    Level: 2    Role: D/V
 パフォーマンスの低下が自動アラートをトリガーし、モデルの再トレーニングまたは置換ワークフローを開始することを確認してください。
 #12.5.5    Level: 3    Role: V
 劣化の根本原因分析が、パフォーマンスの低下をデータの変化、インフラ問題、または外的要因と関連付けていることを確認する。

---

### C12.6 DAGの可視化とワークフローのセキュリティ

ワークフロー可視化システムを情報漏洩および改ざん攻撃から保護する。

 #12.6.1    Level: 1    Role: D/V
 保存または送信の前に、DAGの可視化データが機微な情報を取り除くようにサニタイズされていることを確認してください。
 #12.6.2    Level: 1    Role: D/V
 ワークフローの可視化アクセス制御が、権限のあるユーザーのみがエージェントの意思決定経路と推論のトレースを閲覧できることを確認してください。
 #12.6.3    Level: 2    Role: D/V
 DAGのデータ整合性が暗号署名と改ざん検知可能なストレージメカニズムによって保護されていることを検証してください。
 #12.6.4    Level: 2    Role: D/V
 ワークフロー可視化システムが、巧妙に作成されたノードやエッジのデータを通じたインジェクション攻撃を防ぐために、入力検証を実装していることを確認してください。
 #12.6.5    Level: 3    Role: D/V
 リアルタイムDAG更新がレート制限され、検証されていることを確認し、可視化システムへのサービス拒否攻撃を防止してください。

---

### C12.7 プロアクティブなセキュリティ行動モニタリング

プロアクティブなエージェント行動分析を通じたセキュリティ脅威の検出と防止。

 #12.7.1    Level: 1    Role: D/V
 リスク評価の統合を伴い、プロアクティブなエージェントの動作が実行前にセキュリティ検証されていることを確認する。
 #12.7.2    Level: 2    Role: D/V
 自律的なイニシアティブのトリガーには、セキュリティコンテキストの評価と脅威状況の評価が含まれていることを確認してください。
 #12.7.3    Level: 2    Role: D/V
 積極的な行動パターンが潜在的なセキュリティへの影響や予期せぬ結果について分析されていることを確認する。
 #12.7.4    Level: 3    Role: D/V
 セキュリティに重要な事前対応は、監査記録のある明示的な承認連鎖を必要とすることを確認してください。
 #12.7.5    Level: 3    Role: D/V
 行動異常検知が、侵害を示す可能性のあるプロアクティブエージェントのパターンの逸脱を特定することを検証する。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人間の監督、説明責任、及びガバナンス

### 管理目標

この章は、AIシステムにおける人間の監視と明確な責任の連鎖を維持するための要件を提供し、AIライフサイクル全体にわたって説明可能性、透明性、および倫理的管理を確保します。

---

### C13.1 キルスイッチおよびオーバーライドメカニズム

AIシステムの安全でない動作が観察された場合に備え、シャットダウンまたはロールバックの手順を設けてください。

 #13.1.1    Level: 1    Role: D/V
 AIモデルの推論と出力を即座に停止するための手動キルスイッチ機構が存在することを確認してください。
 #13.1.2    Level: 1    Role: D
 オーバーライド制御が認可された担当者のみがアクセスできることを確認してください。
 #13.1.3    Level: 3    Role: D/V
 ロールバック手順が以前のモデルバージョンまたはセーフモード操作に戻すことができることを検証してください。
 #13.1.4    Level: 3    Role: V
 オーバーライド機構が定期的にテストされていることを確認してください。

---

### C13.2 ヒューマンインザループ意思決定チェックポイント

リスクの事前定義された閾値を超える場合、人間の承認を必要とする。

 #13.2.1    Level: 1    Role: D/V
 高リスクAIの決定は実行前に明示的な人間の承認を必要とすることを確認してください。
 #13.2.2    Level: 1    Role: D
 リスク閾値が明確に定義されており、自動的に人間のレビュー作業フローを起動することを確認してください。
 #13.2.3    Level: 2    Role: D
 人間の承認が必要な時間内に得られない場合に備え、時間的に敏感な意思決定にはフォールバック手順があることを確認してください。
 #13.2.4    Level: 3    Role: D/V
 該当する場合は、エスカレーション手順が異なる意思決定タイプまたはリスクカテゴリに対して明確な権限レベルを定義していることを確認してください。

---

### C13.3 責任の連鎖と監査可能性

演算子の操作とモデルの決定を記録する。

 #13.3.1    Level: 1    Role: D/V
 すべてのAIシステムの意思決定および人間の介入が、タイムスタンプ、ユーザー識別情報、および意思決定の理由とともにログに記録されていることを確認してください。
 #13.3.2    Level: 2    Role: D
 監査ログが改ざんできないこと、および完全性検証メカニズムを含むことを確認してください。

---

### C13.4 説明可能なAI（Explainable AI）技術

表面特徴の重要性、反事実、および局所的説明。

 #13.4.1    Level: 1    Role: D/V
 AIシステムが人間に理解可能な形式でその意思決定の基本的な説明を提供していることを確認してください。
 #13.4.2    Level: 2    Role: V
 説明の品質が人間の評価研究および指標を通じて検証されていることを確認してください。
 #13.4.3    Level: 3    Role: D/V
 重要な意思決定に対して、特徴量重要度スコアやアトリビューション手法（SHAP、LIMEなど）が利用可能であることを確認してください。
 #13.4.4    Level: 3    Role: V
 反事実説明が、利用ケースおよびドメインに適用可能な場合に、結果を変えるために入力をどのように修正できるかを示していることを確認してください。

---

### C13.5 モデルカードと使用開示

意図された使用目的、性能指標、および倫理的考慮事項に関するモデルカードを維持してください。

 #13.5.1    Level: 1    Role: D
 モデルカードが意図された使用例、制限、および既知の故障モードを文書化していることを確認してください。
 #13.5.2    Level: 1    Role: D/V
 異なる適用可能なユースケースにおけるパフォーマンス指標が開示されていることを確認してください。
 #13.5.3    Level: 2    Role: D
 倫理的配慮、バイアス評価、公平性評価、訓練データの特徴、および既知の訓練データの制限が文書化され、定期的に更新されていることを確認する。
 #13.5.4    Level: 2    Role: D/V
 モデルカードがバージョン管理され、変更追跡とともにモデルのライフサイクル全体を通じて維持されていることを確認してください。

---

### C13.6 不確実性の定量化

回答において信頼度スコアやエントロピー指標を伝播させる。

 #13.6.1    Level: 1    Role: D
 AIシステムが出力とともに信頼度スコアや不確実性の測定値を提供していることを確認してください。
 #13.6.2    Level: 2    Role: D/V
 不確実性の閾値が追加の人間による審査や代替の意思決定経路を引き起こすことを検証してください。
 #13.6.3    Level: 2    Role: V
 不確実性定量化手法が基準真実データに対して較正および検証されていることを確認する。
 #13.6.4    Level: 3    Role: D/V
 不確実性の伝播が複数段階のAIワークフローを通じて維持されていることを検証する。

---

### C13.7 ユーザ向け透明性レポート

インシデント、ドリフト、およびデータ使用に関する定期的な開示を提供する。

 #13.7.1    Level: 1    Role: D/V
 データ使用ポリシーおよびユーザー同意管理の実践が利害関係者に明確に伝えられていることを確認してください。
 #13.7.2    Level: 2    Role: D/V
 AIの影響評価が実施され、その結果が報告に含まれていることを確認する。
 #13.7.3    Level: 2    Role: D/V
 定期的に公開される透明性レポートが、AIのインシデントおよび運用指標を妥当な詳細で開示していることを確認してください。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 付録A：用語集

この包括的な用語集は、AISVS全体で使用される主要なAI、機械学習（ML）、およびセキュリティ用語の定義を提供し、明確性と共通理解を確保します。
​
敵対的サンプル：人間には知覚できない微細な摂動を加えることで、AIモデルに誤りを起こさせるよう意図的に作成された入力。
​
敵対的堅牢性 – AIにおける敵対的堅牢性とは、モデルがその性能を維持し、意図的に作成された悪意ある入力によって誤動作や誤りを引き起こされるのを防ぐ能力を指します。
​
エージェント – AIエージェントは、ユーザーの代わりに目標を追求しタスクを完了するためにAIを利用するソフトウェアシステムです。これらは推論、計画、記憶を示し、意思決定、学習、適応を行う一定の自律性を持っています。
​
エージェンティックAI：目標達成のためにある程度自律的に動作できるAIシステムであり、多くの場合、直接的な人間の介入なしに意思決定や行動を行う。
​
属性ベースアクセス制御（ABAC）：ユーザー、リソース、アクション、および環境の属性に基づいて認可判断が行われ、クエリ時に評価されるアクセス制御のパラダイム。
​
バックドア攻撃：モデルが特定のトリガーに対して特定の反応をするように訓練され、それ以外の場合は通常通りに動作するデータポイズニング攻撃の一種。
​
バイアス：特定のグループや特定の文脈において不公平または差別的な結果をもたらす可能性のある、AIモデルの出力における系統的な誤り。
​
バイアス悪用：AIモデルに存在する既知のバイアスを利用して、出力や結果を操作する攻撃手法。
​
Cedar：AIシステムのABAC実装に使用される、細粒度の権限のためのAmazonのポリシー言語およびエンジン。
​
思考の連鎖（Chain of Thought）：最終的な回答を出す前に中間的な推論ステップを生成することで、言語モデルの推論能力を向上させる手法。
​
サーキットブレーカー：特定のリスクしきい値を超えた場合に、AIシステムの動作を自動的に停止するメカニズム。
​
データ漏洩：AIモデルの出力や挙動を通じて機密情報が意図せずに公開されること。
​
データポイズニング：モデルの完全性を損なうために訓練データを意図的に改ざんすることで、バックドアを仕込んだり、性能を低下させたりする行為。
​
差分プライバシー – 差分プライバシーは、個々のデータ主体のプライバシーを保護しながら、データセットに関する統計情報を公開するための数学的に厳密な枠組みです。これにより、データ保持者は特定の個人に関する情報漏洩を制限しつつ、グループの集約的なパターンを共有することが可能になります。
​
埋め込み（Embeddings）：データ（テキスト、画像など）の意味を高次元空間で捉える密ベクトル表現。
​
説明可能性 — AIにおける説明可能性とは、AIシステムがその決定や予測に対して人間が理解できる理由を提供し、内部の動作に関する洞察を示す能力のことです。
​
説明可能なAI（XAI）：その決定や行動について、人間が理解できる説明を様々な技術やフレームワークを通じて提供するように設計されたAIシステム。
​
フェデレーテッドラーニング：モデルがデータ自体を交換することなく、複数の分散したデバイス上でローカルデータサンプルを保持したまま学習される機械学習の手法。
​
ガードレール：AIシステムが有害、偏った、またはその他望ましくない出力を生成するのを防ぐために実装される制約。
​
幻覚（ハルシネーション）とは、AIモデルがトレーニングデータや事実に基づかない誤った情報や誤解を招く情報を生成する現象を指します。
​
ヒューマン・イン・ザ・ループ（HITL）：重要な意思決定のポイントで人間による監視、検証、または介入を必要とするように設計されたシステム。
​
インフラストラクチャ as Code (IaC): 手動プロセスの代わりにコードを通じてインフラストラクチャを管理およびプロビジョニングし、セキュリティスキャンと一貫したデプロイメントを可能にすること。
​
脱獄（ジェイルブレイク）：AIシステム、特に大規模言語モデルにおいて、安全ガードレールを回避し、禁止されたコンテンツを生成するために使用される技術。
​
最小権限: ユーザーおよびプロセスに対して必要最小限のアクセス権のみを付与するセキュリティ原則。
​
LIME（局所的解釈可能なモデル非依存の説明）：任意の機械学習分類器の予測を解釈可能なモデルで局所的に近似することで説明する手法。
​
メンバーシップ推論攻撃：特定のデータポイントが機械学習モデルの訓練に使用されたかどうかを判別することを目的とした攻撃。
​
MITRE ATLAS：人工知能システムに対する敵対的脅威の全景。AIシステムに対する敵対的戦術と技術の知識ベース。
​
モデルカード – モデルカードとは、AIモデルの性能、制限、意図された使用用途、および倫理的考慮事項に関する標準化された情報を提供し、透明性と責任あるAI開発を促進するための文書です。
​
モデル抽出：攻撃者が対象モデルに繰り返し問い合わせを行い、許可なく機能的に類似したコピーを作成する攻撃。
​
モデル反転攻撃：モデルの出力を分析することでトレーニングデータの再構築を試みる攻撃。
​
モデルライフサイクル管理 – AIモデルライフサイクル管理は、AIモデルの設計、開発、展開、監視、保守、そして最終的な廃止に至るまでのすべての段階を監督し、モデルが効果的で目的に合致していることを確保するプロセスです。
​
モデルポイズニング：トレーニングプロセス中にモデルに脆弱性やバックドアを直接導入すること。
​
モデル窃盗/盗用：繰り返しのクエリを通じて、独自モデルのコピーまたは近似を抽出すること。
​
マルチエージェントシステム：異なる能力や目標を持つ複数の相互作用するAIエージェントで構成されるシステム。
​
OPA（Open Policy Agent）：スタック全体で統一されたポリシーの適用を可能にするオープンソースのポリシーエンジン。
​
プライバシー保護機械学習（PPML）：トレーニングデータのプライバシーを保護しながら、機械学習モデルをトレーニングおよび展開するための技術と方法。
​
プロンプトインジェクション：モデルの本来の動作を上書きするために悪意のある命令が入力に埋め込まれる攻撃。
​
RAG（検索補強生成）：生成する前に外部の知識源から関連情報を検索して大型言語モデルの応答を強化する技術。
​
レッドチーミング：脆弱性を特定するために、敵対的攻撃を模擬してAIシステムを積極的にテストする手法。
​
SBOM（ソフトウェア部品表）：ソフトウェアやAIモデルの構築に使用されるさまざまなコンポーネントの詳細とサプライチェーン関係を含む正式な記録。
​
SHAP（SHapley Additive exPlanations）：各特徴量が予測にどの程度寄与しているかを計算することで、あらゆる機械学習モデルの出力を説明するゲーム理論に基づく手法。
​
サプライチェーン攻撃：サードパーティのライブラリ、データセット、または事前学習済みモデルなど、供給チェーン内のセキュリティが低い要素を標的にしてシステムを侵害すること。
​
転移学習：あるタスクのために開発されたモデルを、別のタスクのモデルの出発点として再利用する技術。
​
ベクターデータベース：高次元ベクトル（埋め込み）を格納し、効率的な類似検索を実行するために設計された専門データベース。
​
脆弱性スキャン：AIフレームワークや依存関係を含むソフトウェアコンポーネントの既知のセキュリティ脆弱性を特定する自動化ツール。
​
ウォーターマーキング：AI生成コンテンツの起源を追跡したりAI生成を検出したりするために、知覚できないマーカーを埋め込む技術。
​
ゼロデイ脆弱性：開発者がパッチを作成・展開する前に攻撃者が悪用可能な、これまでに知られていなかった脆弱性。

## 付録B：参考文献

### TODO

## 付録C: AIセキュリティガバナンスとドキュメンテーション

### 目的

この付録は、システムライフサイクル全体にわたってAIセキュリティを管理するための組織構造、方針、およびプロセスを確立するための基本的な要件を提供します。

---

### AC.1 AIリスク管理フレームワークの導入

システムライフサイクル全体にわたってAI特有のリスクを特定、評価、および軽減するための正式な枠組みを提供する。

 #AC.1.1    Level: 1    Role: D/V
 AI特有のリスク評価手法が文書化され、実施されていることを確認する。
 #AC.1.2    Level: 2    Role: D
 AIライフサイクルの重要なポイントおよび重大な変更の前に、リスク評価が実施されていることを確認してください。
 #AC.1.3    Level: 3    Role: D/V
 リスク管理フレームワークが確立された基準（例：NIST AI RMF）に準拠していることを確認してください。

---

### AC.2 AI セキュリティ方針および手順

安全なAIの開発、展開、および運用のための組織標準を定義し、実施してください。

 #AC.2.1    Level: 1    Role: D/V
 文書化されたAIセキュリティポリシーが存在することを確認してください。
 #AC.2.2    Level: 2    Role: D
 ポリシーが少なくとも年に一度、および重大な脅威状況の変化後に見直され、更新されていることを確認してください。
 #AC.2.3    Level: 3    Role: D/V
 ポリシーがすべてのAISVSカテゴリおよび適用される規制要件に対応していることを確認してください。

---

### AC.3 AIセキュリティの役割と責任

組織全体でAIセキュリティに対する明確な責任体制を確立すること。

 #AC.3.1    Level: 1    Role: D/V
 AIのセキュリティに関する役割と責任が文書化されていることを確認してください。
 #AC.3.2    Level: 2    Role: D
 責任者が適切なセキュリティ専門知識を有していることを確認する。
 #AC.3.3    Level: 3    Role: D/V
 高リスクのAIシステムに対して、AI倫理委員会またはガバナンス委員会が設置されていることを確認してください。

---

### AC.4 倫理的AIガイドラインの実施

AIシステムが確立された倫理原則に従って運用されることを確保する。

 #AC.4.1    Level: 1    Role: D/V
 AI開発と展開に関する倫理ガイドラインが存在することを確認する。
 #AC.4.2    Level: 2    Role: D
 倫理違反を検知し報告するための仕組みが整っていることを確認してください。
 #AC.4.3    Level: 3    Role: D/V
 展開されたAIシステムに対して定期的な倫理審査が実施されていることを確認してください。

---

### AC.5 AI規制遵守モニタリング

進化するAI規制に対する認識と遵守を維持すること。

 #AC.5.1    Level: 1    Role: D/V
 適用されるAI規制を特定するためのプロセスが存在することを確認してください。
 #AC.5.2    Level: 2    Role: D
 すべての規制要件への準拠が評価されていることを確認してください。
 #AC.5.3    Level: 3    Role: D/V
 規制の変更がAIシステムの適時なレビューと更新を引き起こすことを確認する。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 付録D：AI支援によるセキュアコーディング管理と検証

### 目的

この章は、ソフトウェア開発中にAI支援コーディングツールを安全かつ効果的に使用するための基準となる組織的管理策を定義し、ソフトウェア開発ライフサイクル（SDLC）全体でのセキュリティと追跡可能性を確保します。

---

### AD.1 AI支援セキュアコーディングワークフロー

既存のセキュリティゲートを弱体化させることなく、組織のセキュアソフトウェア開発ライフサイクル（SSDLC）にAIツールを統合する。

 #AD.1.1    Level: 1    Role: D/V
 文書化されたワークフローが、AIツールがコードを生成、リファクタリング、またはレビューするタイミングと方法を説明していることを確認してください。
 #AD.1.2    Level: 2    Role: D
 ワークフローが各SSDLCフェーズ（設計、実装、コードレビュー、テスト、展開）に対応していることを確認してください。
 #AD.1.3    Level: 3    Role: D/V
 AI生成コードに対しても指標（例：脆弱性密度、検出までの平均時間）が収集され、人間のみのベースラインと比較されていることを確認してください。

---

### AD.2 AIツールの適格性評価と脅威モデリング

AIコーディングツールは、採用前にセキュリティ機能、リスク、およびサプライチェーンへの影響を評価することを確実にしてください。

 #AD.2.1    Level: 1    Role: D/V
 各AIツールの脅威モデルが、誤用、モデル反転、データ漏洩、および依存チェーンのリスクを特定していることを確認してください。
 #AD.2.2    Level: 2    Role: D
 ツール評価に、ローカルコンポーネントの静的/動的解析およびSaaSエンドポイント（TLS、認証/認可、ログ記録）の評価が含まれていることを確認してください。
 #AD.2.3    Level: 3    Role: D/V
 評価が認識されたフレームワークに従っていることを確認し、主要なバージョン変更後に再実施されることを確認してください。

---

### AD.3 セキュアなプロンプトおよびコンテキスト管理

AIモデルのプロンプトやコンテキストを構築する際に、秘密情報、専有コード、個人データの漏洩を防止してください。

 #AD.3.1    Level: 1    Role: D/V
 書面によるガイダンスで、プロンプトに秘密情報、認証情報、または機密データを送信することを禁止していることを確認してください。
 #AD.3.2    Level: 2    Role: D
 技術的な制御（クライアント側の編集、承認されたコンテキストフィルター）が自動的に機密情報を除去することを確認してください。
 #AD.3.3    Level: 3    Role: D/V
 プロンプトと応答がトークン化され、転送中および保存時に暗号化されていること、および保持期間がデータ分類ポリシーに準拠していることを確認してください。

---

### AD.4 AI生成コードの検証

コードがマージまたはデプロイされる前に、AI出力によって導入された脆弱性を検出し修正します。

 #AD.4.1    Level: 1    Role: D/V
 AI生成コードは常に人間のコードレビューを受けることを確認してください。
 #AD.4.2    Level: 2    Role: D
 AI生成コードを含むすべてのプルリクエストに対して自動スキャナー（SAST/IAST/DAST）が実行され、重要な問題が検出された場合はマージをブロックすることを確認してください。
 #AD.4.3    Level: 3    Role: D/V
 差分ファズテストまたはプロパティベースのテストが、セキュリティに重要な動作（例：入力検証、認可ロジック）を証明していることを確認してください。

---

### AD.5 コード提案の説明性と追跡可能性

監査人や開発者に対して、提案がなされた理由とその進化過程に関する洞察を提供する。

 #AD.5.1    Level: 1    Role: D/V
 プロンプト／レスポンスのペアがコミットIDと共に記録されていることを確認してください。
 #AD.5.2    Level: 2    Role: D
 開発者が提案を裏付けるモデルの引用（トレーニングスニペット、ドキュメント）を表示できることを確認してください。
 #AD.5.3    Level: 3    Role: D/V
 説明可能性レポートが設計成果物と共に保存され、セキュリティレビューで参照されていることを確認し、ISO/IEC 42001のトレーサビリティ原則を満たしていることを確認します。

---

### AD.6 継続的フィードバックとモデルの微調整

負のドリフトを防ぎながら、時間の経過とともにモデルのセキュリティ性能を向上させる。

 #AD.6.1    Level: 1    Role: D/V
 開発者が安全でないまたは非準拠の提案にフラグを立てることができ、そのフラグが追跡されることを確認してください。
 #AD.6.2    Level: 2    Role: D
 集約されたフィードバックが、定期的なファインチューニングや、検証済みのセキュアコーディングコーパス（例：OWASPチートシート）を用いたリトリーバル強化生成に反映されていることを確認してください。
 #AD.6.3    Level: 3    Role: D/V
 閉ループ評価ハーネスがファインチューニング後に回帰テストを実行することを確認してください。セキュリティ指標は、展開前に前回の基準を満たすかそれを上回る必要があります。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 付録E：ツールおよびフレームワークの例

### 目的

この章では、特定のAISVS要件の実装や達成を支援するためのツールおよびフレームワークの例を示します。これらは、AISVSチームやOWASP GenAIセキュリティプロジェクトによる推奨や支持とみなすべきものではありません。

---

### AE.1 トレーニングデータガバナンスとバイアスマネジメント

データ分析、ガバナンス、およびバイアスマネジメントに使用されるツール。

 #AE.1.1    Section: 1.1
 データインベントリツール：...のようなデータインベントリ管理ツール
 #AE.1.2    Section: 1.2
 転送中暗号化 HTTPSベースのアプリケーションにはTLSを使用し、openSSLやPythonのツールを活用してください`ssl`ライブラリ。

---

### AE.2 ユーザー入力検証

ユーザー入力を処理し検証するためのツール。

 #AE.2.1    Section: 2.1
 プロンプトインジェクション防御ツール：NVIDIAのNeMoやGuardrails AIのようなガードレールツールを使用する。

---

