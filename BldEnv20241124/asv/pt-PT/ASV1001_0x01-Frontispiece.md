# Frontispício

## Sobre o Padrão

O Padrão de Verificação de Segurança em Inteligência Artificial (AISVS) é um catálogo orientado pela comunidade de requisitos de segurança que cientistas de dados, engenheiros de MLOps, arquitetos de software, desenvolvedores, testadores, profissionais de segurança, fornecedores de ferramentas, reguladores e consumidores podem utilizar para projetar, construir, testar e verificar sistemas e aplicações confiáveis habilitados por IA. Ele fornece uma linguagem comum para especificar controles de segurança ao longo do ciclo de vida da IA — desde a coleta de dados e o desenvolvimento de modelos até a implantação e o monitoramento contínuo — para que as organizações possam medir e melhorar a resiliência, a privacidade e a segurança de suas soluções de IA.

## Direitos Autorais e Licença

Versão 0.1 (Primeiro Rascunho Público - Trabalho em Andamento), 2025  

![license](../images/license.png)

Direitos autorais © 2025 O Projeto AISVS.  

Lançado sob a[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Para qualquer reutilização ou distribuição, você deve comunicar claramente os termos de licença deste trabalho para os outros.

## Líderes de Projeto

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Contribuidores e Revisores

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS é um novo padrão criado especificamente para enfrentar os desafios únicos de segurança dos sistemas de inteligência artificial. Embora se baseie em melhores práticas gerais de segurança, cada requisito do AISVS foi desenvolvido do zero para refletir o panorama de ameaças da IA e ajudar as organizações a construir soluções de IA mais seguras e resilientes.

