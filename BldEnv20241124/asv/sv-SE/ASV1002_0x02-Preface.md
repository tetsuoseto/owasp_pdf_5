# Förord

Välkommen till standarden för verifiering av artificiell intelligenssäkerhet (AISVS) version 1.0!

## Introduktion

AISVS, grundat 2025 genom ett kollaborativt samhällsarbete, definierar säkerhetskraven att beakta vid design, utveckling, implementering och drift av moderna AI-modeller, pipelines och AI-aktiverade tjänster.

AISVS v1.0 representerar det samlade arbetet från dess projektledare, arbetsgrupp och bredare samhällsbidragsgivare för att skapa en pragmatisk och testbar grundlinje för att säkra AI-system.

Vårt mål med denna version är att göra AISVS enkel att använda samtidigt som vi håller ett skarpt fokus på dess definierade omfattning och hanterar det snabbt föränderliga risklandskapet som är unikt för AI.

## Nyckelmål för AISVS Version 1.0

Version 1.0 kommer att skapas med flera vägledande principer.

### Väl definierad omfattning

Varje krav måste vara i linje med AISVS:s namn och uppdrag:

* Artificiell intelligens – Kontroller fungerar på AI/ML-nivån (data, modell, pipeline eller inferens) och är AI-specialisternas ansvar.
* Säkerhet – Krav som direkt motverkar identifierade risker för säkerhet, integritet eller säkerhet.
* Verifiering – Språket är skrivet så att överensstämmelse kan objektivt valideras.
* Standard – Sektionerna följer en konsekvent struktur och terminologi för att bilda en sammanhängande referens.
  ​
---

Genom att följa AISVS kan organisationer systematiskt utvärdera och stärka säkerhetsställningen för sina AI-lösningar, vilket främjar en kultur av säker AI-arkitektur.

