# Försättsblad

## Om standarden

Artificial Intelligence Security Verification Standard (AISVS) är en community-driven katalog över säkerhetskrav som dataforskare, MLOps-ingenjörer, mjukvaruarkitekter, utvecklare, testare, säkerhetsexperter, verktygsleverantörer, tillsynsmyndigheter och användare kan använda för att designa, bygga, testa och verifiera pålitliga AI-baserade system och applikationer. Den tillhandahåller ett gemensamt språk för att specificera säkerhetskontroller över AI-livscykeln — från datainsamling och modellutveckling till distribution och kontinuerlig övervakning — så att organisationer kan mäta och förbättra motståndskraft, integritet och säkerhet i sina AI-lösningar.

## Upphovsrätt och licens

Version 0.1 (Första offentliga utkast - Pågående arbete), 2025  

![license](../images/license.png)

Upphovsrätt © 2025 The AISVS Project.  

Släppt under[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
För all återanvändning eller distribution måste du tydligt kommunicera licensvillkoren för detta arbete till andra.

## Projektledare

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Bidragsgivare och granskare

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS är en helt ny standard skapad specifikt för att hantera de unika säkerhetsutmaningarna för artificiella intelligenssystem. Även om den inspireras av bredare säkerhetsbästa praxis, har varje krav i AISVS utvecklats från grunden för att spegla AI-hotlandskapet och hjälpa organisationer att bygga säkrare och mer motståndskraftiga AI-lösningar.

