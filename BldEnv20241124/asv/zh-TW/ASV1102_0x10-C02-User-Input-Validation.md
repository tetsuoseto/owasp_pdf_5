# C2 用戶輸入驗證

## 控制目標

對用戶輸入進行強健的驗證是防範針對人工智慧系統最具破壞性攻擊的第一道防線。提示注入攻擊能夠覆寫系統指令、洩露敏感資料，或引導模型執行不被允許的行為。除非設置專用的過濾器和指令層級，研究顯示利用極長上下文窗口的「多次注入」越獄攻擊將會有效。此外，細微的對抗性擾動攻擊——例如同形字元替換或「Leetspeak」——能悄無聲息地改變模型的決策。

---

## C2.1 提示注入防禦

提示注入是人工智慧系統的主要風險之一。針對此策略的防禦措施結合了靜態模式過濾器、動態分類器以及指令層級的強制執行。

|   #   | Description                                                               | Level | Role |
| :---: | ------------------------------------------------------------------------- | :---: | :--: |
| 2.1.1 | 驗證使用者輸入是否經過篩選，並與持續更新的已知提示注入模式庫（越獄關鍵詞、「忽略之前指令」、角色扮演鏈條、間接 HTML/URL 攻擊）進行比對。 |   1   | D/V  |
| 2.1.2 | 驗證系統是否強制執行指令層級，其中系統或開發者訊息優先於使用者指示，即使在擴展上下文視窗後亦然。                          |   1   | D/V  |
| 2.1.3 | 確保在每次模型或提示模板發布之前，都會進行對抗性評估測試（例如，紅隊「多次示範」提示），並設有成功率門檻及自動阻止回歸的機制。           |   2   | D/V  |
| 2.1.4 | 驗證來自第三方內容（網頁、PDF、電子郵件）的提示是否在合併到主要提示之前，已在隔離的解析環境中進行清理。                     |   2   |  D   |
| 2.1.5 | 確認所有提示過濾規則更新、分類器模型版本及封鎖清單變更均受版本控制並可進行審核。                                  |   3   | D/V  |

---

## C2.2 對抗樣本抗性

自然語言處理（NLP）模型仍然容易受到人類經常忽略但模型容易誤分類的細微字元或詞彙層級擾動的影響。

|   #   | Description                                       | Level | Role |
| :---: | ------------------------------------------------- | :---: | :--: |
| 2.2.1 | 確認基本的輸入正規化步驟（Unicode NFC，同形字映射，空白修剪）在分詞之前執行。      |   1   |  D   |
| 2.2.2 | 驗證統計異常檢測是否能標記出與語言規範有異常高編輯距離、過度重複的詞元，或不正常嵌入距離的輸入。  |   2   | D/V  |
| 2.2.3 | 驗證推論流程是否支援適用於高風險端點的可選對抗訓練加固模型變體或防禦層（例如，隨機化、防禦蒸餾）。 |   2   |  D   |
| 2.2.4 | 驗證疑似對抗性輸入是否已被隔離，並在刪除個人身份資訊(PII)後，完整記錄其有效負載。       |   2   |  V   |
| 2.2.5 | 確認魯棒性指標（已知攻擊套件的成功率）隨時間被追蹤，且回歸問題會觸發發行阻擋。           |   3   | D/V  |

---

## C2.3 架構、型別與長度驗證

包含格式錯誤或過大輸入的 AI 攻擊可能導致解析錯誤、提示內容跨欄位溢出及資源耗盡。嚴格的架構規範也是執行確定性工具調用的先決條件。

|   #   | Description                                                                 | Level | Role |
| :---: | --------------------------------------------------------------------------- | :---: | :--: |
| 2.3.1 | 確認每個 API 或函數呼叫端點都定義了明確的輸入結構（JSON Schema、Protobuf 或多模態等效格式），並且在組裝提示前對輸入進行驗證。 |   1   |  D   |
| 2.3.2 | 驗證超過最大標記數或字節限制的輸入是否會被安全地拒絕並顯示錯誤，而不會被靜默截斷。                                   |   1   | D/V  |
| 2.3.3 | 驗證類型檢查（例如，數值範圍、列舉值、圖像/音頻的 MIME 類型）是否在伺服器端強制執行，而不僅僅是在客戶端代碼中。                 |   2   | D/V  |
| 2.3.4 | 驗證語義驗證器（例如 JSON Schema）是否以常數時間運行，以防止演算法拒絕服務攻擊（DoS）。                         |   2   |  D   |
| 2.3.5 | 驗證失敗時，請確認其以遮蔽的內容片段和明確的錯誤代碼記錄，以協助安全分級。                                       |   3   |  V   |

---

## C2.4 內容與政策審查

開發人員應能夠檢測語法上有效但請求不允許內容（例如非法指令、仇恨言論及受版權保護的文本）的提示，並防止其擴散。

|   #   | Description                                               | Level | Role |
| :---: | --------------------------------------------------------- | :---: | :--: |
| 2.4.1 | 驗證內容分類器（零次學習或微調）對每個輸入進行暴力、自我傷害、仇恨、性內容和非法請求的評分，並且具有可配置的閾值。 |   1   |  D   |
| 2.4.2 | 驗證違反政策的輸入將收到標準化的拒絕或安全完成，確保其不會傳播到下游的大型語言模型調用。              |   1   | D/V  |
| 2.4.3 | 確認篩選模型或規則集至少每季度重新訓練/更新一次，並納入新觀察到的越獄或政策繞過模式。               |   2   |  D   |
| 2.4.4 | 透過在請求時解析的基於屬性的規則，驗證篩選是否遵守用戶特定的政策（年齡、區域法律限制）。              |   2   |  D   |
| 2.4.5 | 確認篩選日誌包含分類器置信度分數和政策類別標籤，以用於SOC關聯和未來紅隊回放。                  |   3   |  V   |

---

## C2.5 輸入速率限制與濫用防止

開發人員應透過限制輸入速率及偵測異常使用模式，防止對 AI 系統的濫用、資源耗盡及自動化攻擊。

|   #   | Description                             | Level | Role |
| :---: | --------------------------------------- | :---: | :--: |
| 2.5.1 | 驗證所有輸入端點是否強制執行每用戶、每IP及每API金鑰的速率限制。      |   1   | D/V  |
| 2.5.2 | 確認突發和持續速率限制已調整以防止拒絕服務（DoS）和暴力破解攻擊。      |   2   | D/V  |
| 2.5.3 | 驗證異常使用模式（例如，快速連續請求、輸入洪水）是否會觸發自動封鎖或升級處理。 |   2   | D/V  |
| 2.5.4 | 驗證濫用預防日誌是否被保留並審查以識別新興的攻擊模式。             |   3   |  V   |

---

## C2.6 多模態輸入驗證

人工智慧系統應包含對非文字輸入（圖片、音訊、檔案）進行強健的驗證，以防止注入、規避或資源濫用。

|   #   | Description                                | Level | Role |
| :---: | ------------------------------------------ | :---: | :--: |
| 2.6.1 | 在處理之前，請確認所有非文字輸入（圖像、音訊、檔案）均已依類型、大小與格式進行驗證。 |   1   |  D   |
| 2.6.2 | 確認文件在擷取之前已掃描惡意軟體和隱寫負載。                     |   2   | D/V  |
| 2.6.3 | 驗證影像/音訊輸入是否經過對抗擾動或已知攻擊模式的檢查。               |   2   | D/V  |
| 2.6.4 | 驗證多模態輸入驗證失敗是否有被記錄並觸發警報以供調查。                |   3   |  V   |

---

## C2.7 輸入來源與歸屬

AI 系統應透過監控並標記所有用戶輸入的來源，以支持審計、濫用追蹤和合規性。

|   #   | Description                               | Level | Role |
| :---: | ----------------------------------------- | :---: | :--: |
| 2.7.1 | 驗證所有用戶輸入在接收時均附有元資料（用戶ID、會話、來源、時間戳記、IP地址）。 |   1   | D/V  |
| 2.7.2 | 驗證所有處理過的輸入均保留且可審計其來源元資料。                  |   2   | D/V  |
| 2.7.3 | 確認異常或不受信任的輸入來源被標記，並受到加強審查或阻擋。             |   2   | D/V  |

---

## C2.8 即時自適應威脅檢測

開發人員應該採用先進的威脅檢測系統，該系統能夠針對人工智慧的新攻擊模式進行自我調整，並透過編譯的模式匹配提供即時防護。

|   #   | Description                                    | Level | Role |
| :---: | ---------------------------------------------- | :---: | :--: |
| 2.8.1 | 驗證威脅檢測模式已編譯成優化的正則表達式引擎，以實現高效能的即時過濾並將延遲影響降到最低。  |   1   | D/V  |
| 2.8.2 | 確認威脅偵測系統為不同的威脅類別（提示注入、有害內容、敏感資料、系統指令）維護分開的模式庫。 |   1   | D/V  |
| 2.8.3 | 確認自適應威脅檢測包含能根據攻擊頻率和成功率更新威脅敏感度的機器學習模型。          |   2   | D/V  |
| 2.8.4 | 驗證即時威脅情報來源會自動使用新的攻擊特徵和妥協指標（IOCs）更新模式庫。         |   2   | D/V  |
| 2.8.5 | 確認威脅檢測的誤報率持續被監控，且模式特異性自動調整以最小化合法用例的干擾。         |   3   | D/V  |
| 2.8.6 | 確認上下文威脅分析考慮了輸入來源、用戶行為模式和會話歷史，以提升檢測準確性。         |   3   | D/V  |
| 2.8.7 | 驗證威脅偵測效能指標（偵測率、處理延遲、資源使用率）是否被實時監控和優化。          |   3   | D/V  |

---

## C2.9 多模態安全驗證流程

開發人員應針對文字、影像、音訊及其他 AI 輸入模式，提供具特定威脅檢測和資源隔離的安全驗證。

|   #   | Description                                                               | Level | Role |
| :---: | ------------------------------------------------------------------------- | :---: | :--: |
| 2.9.1 | 驗證每種輸入模態是否具有專門的安全驗證器，並附有文檔記錄的威脅模式（文字：提示注入，圖像：隱寫術，音頻：頻譜圖攻擊）及偵測閾值。          |   1   | D/V  |
| 2.9.2 | 驗證多模態輸入是否在隔離的沙盒中處理，並對每種類型的模態設定具體的資源限制（記憶體、CPU、處理時間），且這些限制已記錄於安全政策中。       |   2   | D/V  |
| 2.9.3 | 驗證跨模態攻擊檢測能夠識別跨多種輸入類型（例如，圖像中的隱寫負載與文本中的提示注入相結合）的協調攻擊，並利用相關規則進行警示生成。         |   2   | D/V  |
| 2.9.4 | 驗證多模態驗證失敗是否觸發詳細日誌記錄，包括所有輸入模態、驗證結果、威脅評分以及與結構化日誌格式進行的關聯分析，以便整合至 SIEM。       |   3   | D/V  |
| 2.9.5 | 確認特定模態的內容分類器是否根據文件化的排程（至少每季一次）進行更新，並且持續維護包含新威脅模式、對抗性範例及性能基準，且性能保持在基準門檻以上。 |   3   | D/V  |

---

## 參考文獻

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

