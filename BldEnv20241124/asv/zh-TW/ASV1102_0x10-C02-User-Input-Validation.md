# C2 使用者輸入驗證

## 控制目標

對用戶輸入進行強健的驗證是防禦對人工智慧系統造成重大損害攻擊的第一道防線。提示注入攻擊可能會覆蓋系統指令、洩露敏感資料，或引導模型採取不被允許的行為。除非設置專用的過濾器和指令層級結構，研究顯示利用非常長的上下文窗口進行的「多次注入」越獄攻擊將會有效。此外，微妙的對抗性擾動攻擊——例如同形字替換或「駭客語」(leetspeak) ——能悄無聲息地改變模型的決策。

---

## C2.1 提示注入防禦

提示注入是人工智慧系統的主要風險之一。針對此策略的防禦方法結合了靜態模式過濾器、動態分類器以及指令層級強制執行。

|   #   | Description                                                          | Level | Role |
| :---: | -------------------------------------------------------------------- | :---: | :--: |
| 2.1.1 | 驗證使用者輸入是否經過篩選，針對持續更新的已知提示注入模式庫（越獄關鍵字、「忽略先前內容」、角色扮演鏈、間接 HTML/URL 攻擊）。 |   1   | D/V  |
| 2.1.2 | 驗證系統是否強制執行指令層級，其中系統或開發者訊息會覆蓋使用者指令，即使在擴展上下文視窗後亦是如此。                   |   1   | D/V  |
| 2.1.3 | 確認在每次模型或提示模板發布之前，均執行對抗性評估測試（例如，紅隊「多次嘗試」提示），並設定成功率門檻及針對退步的自動阻擋機制。     |   2   | D/V  |
| 2.1.4 | 驗證來自第三方內容（網頁、PDF、電子郵件）的提示，在被串接到主要提示之前，是否先在隔離的解析環境中進行清理。              |   2   |  D   |
| 2.1.5 | 確認所有提示過濾規則更新、分類器模型版本及封鎖清單變更均受版本控制並可審核。                               |   3   | D/V  |

---

## C2.2 對抗性範例抵抗能力

自然語言處理（NLP）模型仍然容易受到人類經常忽略但模型容易誤分類的微妙字符或詞彙層級擾動的影響。

|   #   | Description                                       | Level | Role |
| :---: | ------------------------------------------------- | :---: | :--: |
| 2.2.1 | 確保基本的輸入正規化步驟（Unicode NFC，同形字映射，空白字符裁剪）在分詞之前執行。    |   1   |  D   |
| 2.2.2 | 驗證統計異常檢測是否標記了與語言標準編輯距離異常高、重複標記過多或嵌入距離異常的輸入。       |   2   | D/V  |
| 2.2.3 | 驗證推理流程是否支援可選的對抗訓練強化模型變體或防禦層（例如隨機化、防禦蒸餾），以保護高風險端點。 |   2   |  D   |
| 2.2.4 | 確認疑似對抗性輸入已被隔離，並在進行個人識別資訊(PII)遮蔽後，完整記錄其有效負載。       |   2   |  V   |
| 2.2.5 | 確認健壯性指標（已知攻擊套件的成功率）隨時間被追蹤，且回歸問題會觸發版本發佈阻擋。         |   3   | D/V  |

---

## C2.3 架構、類型與長度驗證

帶有格式錯誤或過大輸入的 AI 攻擊可能導致解析錯誤、提示溢出到不同欄位以及資源耗盡。在執行確定性工具調用時，嚴格的結構驗證也是必要條件。

|   #   | Description                                                                 | Level | Role |
| :---: | --------------------------------------------------------------------------- | :---: | :--: |
| 2.3.1 | 確認每個 API 或函數呼叫端點都定義明確的輸入結構（JSON Schema、Protobuf 或多模態等效結構），並且在提示組合之前先進行輸入驗證。 |   1   |  D   |
| 2.3.2 | 驗證超過最大標記數或位元組限制的輸入是否會被安全地拒絕並回傳錯誤，而不會被默默截斷。                                  |   1   | D/V  |
| 2.3.3 | 確認型別檢查（例如數值範圍、枚舉值、圖片/音訊的 MIME 類型）是在伺服器端強制執行，而不僅僅是在客戶端程式碼中。                  |   2   | D/V  |
| 2.3.4 | 驗證語意檢查器（例如 JSON Schema）確保其在常數時間內執行，以防止演算法式拒絕服務攻擊（DoS）。                      |   2   |  D   |
| 2.3.5 | 確認驗證失敗事件已使用經過遮蔽的有效負載片段和明確的錯誤代碼記錄，以協助安全分流。                                   |   3   |  V   |

---

## C2.4 內容與政策篩選

開發人員應該能夠偵測出語法上有效但請求不允許內容的提示（例如非法指令、仇恨言論和受版權保護的文本），並防止這些提示傳播。

|   #   | Description                                          | Level | Role |
| :---: | ---------------------------------------------------- | :---: | :--: |
| 2.4.1 | 驗證內容分類器（零樣本或微調）是否對每個輸入進行暴力、自殘、仇恨、性內容和非法請求的評分，並可配置閾值。 |   1   |  D   |
| 2.4.2 | 驗證違反政策的輸入將收到標準化的拒絕或安全完成，確保它們不會傳遞到下游的大型語言模型呼叫中。       |   1   | D/V  |
| 2.4.3 | 確認篩選模型或規則集至少每季度重新訓練/更新，並納入新觀察到的繞過監控或政策的模式。           |   2   |  D   |
| 2.4.4 | 透過在請求時解析的基於屬性的規則，驗證篩選是否遵守用戶特定的政策（年齡、區域法律限制）。         |   2   |  D   |
| 2.4.5 | 確認篩選日誌包含分類器信心分數和政策類別標籤，以便進行SOC關聯和未來紅隊重播。             |   3   |  V   |

---

## C2.5 輸入速率限制與濫用防止

開發人員應該透過限制輸入速率和偵測異常使用模式，防止對人工智慧系統的濫用、資源耗盡及自動化攻擊。

|   #   | Description                                              | Level | Role |
| :---: | -------------------------------------------------------- | :---: | :--: |
| 2.5.1 | 驗證所有輸入端點是否對每位使用者、每個IP以及每個API金鑰執行速率限制。                    |   1   | D/V  |
| 2.5.2 | 確認突發（burst）和持續（sustained）速率限制已被調整，以防止拒絕服務攻擊（DoS）和暴力破解攻擊。 |   2   | D/V  |
| 2.5.3 | 驗證異常使用模式（例如快速連發請求、輸入洪水）是否會觸發自動封鎖或升級處理。                   |   2   | D/V  |
| 2.5.4 | 確認濫用防範日誌已被保留並審查，以辨識新興的攻擊模式。                              |   3   |  V   |

---

## C2.6 多模態輸入驗證

人工智慧系統應包含對非文字輸入（影像、音訊、檔案）的強健驗證機制，以防止注入、規避或資源濫用。

|   #   | Description                           | Level | Role |
| :---: | ------------------------------------- | :---: | :--: |
| 2.6.1 | 確認所有非文字輸入（影像、音訊、檔案）在處理前皆已驗證其類型、大小及格式。 |   1   |  D   |
| 2.6.2 | 確認在資料引入之前，檔案已被掃描以檢測惡意軟體和隱寫負載。         |   2   | D/V  |
| 2.6.3 | 確認影像/音訊輸入是否有受到對抗性擾動或已知攻擊模式的檢查。        |   2   | D/V  |
| 2.6.4 | 確認多模態輸入驗證失敗已被記錄並觸發警報以進行調查。            |   3   |  V   |

---

## C2.7 輸入來源與歸屬

AI 系統應透過監控並標記所有使用者輸入的來源，來支持審計、濫用追蹤與合規性。

|   #   | Description                               | Level | Role |
| :---: | ----------------------------------------- | :---: | :--: |
| 2.7.1 | 確認所有用戶輸入在接收時均已標記元數據（用戶ID、會話、來源、時間戳、IP地址）。 |   1   | D/V  |
| 2.7.2 | 驗證所有處理過的輸入均保留並可審計其來源元資料。                  |   2   | D/V  |
| 2.7.3 | 驗證異常或不受信任的輸入來源是否被標記，並接受加強審查或封鎖。           |   2   | D/V  |

---

## C2.8 即時自適應威脅檢測

開發者應該採用先進的人工智慧威脅偵測系統，該系統能適應新的攻擊模式，並透過已編譯的模式匹配提供即時保護。

|   #   | Description                                      | Level | Role |
| :---: | ------------------------------------------------ | :---: | :--: |
| 2.8.1 | 驗證威脅檢測模式是否已編譯成優化的正則表達式引擎，以實現高效能的即時過濾，並將延遲影響降至最低。 |   1   | D/V  |
| 2.8.2 | 確認威脅檢測系統為不同的威脅類別（提示注入、有害內容、敏感數據、系統命令）維護獨立的模式庫。   |   1   | D/V  |
| 2.8.3 | 確認自適應威脅檢測包含機器學習模型，該模型根據攻擊頻率和成功率更新威脅敏感度。          |   2   | D/V  |
| 2.8.4 | 確認即時威脅情報源會自動使用新的攻擊特徵和妥協指標（IOC）更新模式庫。             |   2   | D/V  |
| 2.8.5 | 確認持續監控威脅檢測的誤報率，並自動調整模式特異性以最小化對合法使用情境的干擾。         |   3   | D/V  |
| 2.8.6 | 確認上下文威脅分析考慮輸入來源、用戶行為模式和會話歷史，以提高檢測準確性。            |   3   | D/V  |
| 2.8.7 | 確認威脅檢測效能指標（檢測率、處理延遲、資源使用率）是否被即時監控並優化。            |   3   | D/V  |

---

## C2.9 多模態安全驗證流程

開發人員應針對文字、影像、音訊及其他人工智慧輸入模態，提供具體類型的威脅檢測與資源隔離的安全驗證。

|   #   | Description                                                         | Level | Role |
| :---: | ------------------------------------------------------------------- | :---: | :--: |
| 2.9.1 | 確認每個輸入模態皆具專用的安全驗證器，並有文件記錄的威脅模式（文字：提示注入，影像：隱寫術，音頻：頻譜圖攻擊）及檢測閾值。       |   1   | D/V  |
| 2.9.2 | 驗證多模態輸入是否在獨立沙盒中處理，並對每種模態類型設定明確的資源限制（記憶體、CPU、處理時間），且這些限制應記錄於安全政策中。   |   2   | D/V  |
| 2.9.3 | 驗證跨模態攻擊偵測是否能透過關聯規則與警示產生，識別涵蓋多種輸入類型的協同攻擊（例如，圖片中的隱寫載荷結合文本中的提示注入）。     |   2   | D/V  |
| 2.9.4 | 驗證多模態驗證失敗是否觸發詳細的日誌記錄，包括所有輸入模態、驗證結果、威脅分數以及用於SIEM整合的結構化日誌格式中的關聯分析。    |   3   | D/V  |
| 2.9.5 | 驗證特定模態內容分類器是否按照文件規定的時間表（至少每季一次）更新，包括新增的威脅模式、對抗樣本，並確保其效能指標保持在基準閾值以上。 |   3   | D/V  |

---

## 參考文獻

* [LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
* [Generative AI's Biggest Security Flaw Is Not Easy to Fix](https://www.wired.com/story/generative-ai-prompt-injection-hacking)
* [Many-shot jailbreaking \ Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking)
* [$PDF$ OpenAI GPT-4.5 System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
* [Notebook for the CheckThat Lab at CLEF 2024](https://ceur-ws.org/Vol-3740/paper-53.pdf)
* [Mitigate jailbreaks and prompt injections – Anthropic](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/mitigate-jailbreaks)
* [Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis](https://ama.drwhy.ai/mitre-attck.html)
* [OWASP Top 10 for LLM Applications 2025 – WorldTech IT](https://wtit.com/blog/2025/04/17/owasp-top-10-for-llm-applications-2025/)
* [OWASP Machine Learning Security Top Ten](https://owasp.org/www-project-machine-learning-security-top-10/)
* [Few words about AI Security – Jussi Metso](https://www.jussimetso.com/index.php/2024/09/28/few-words-about-ai-security/)
* [How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry](https://modelmetry.com/blog/how-to-ensure-llm-output-adheres-to-a-json-schema)
* [Easily enforcing valid JSON schema following – API](https://community.openai.com/t/feature-request-function-calling-easily-enforcing-valid-json-schema-following/263515?utm_source)
* [AI Safety + Cybersecurity R\&D Tracker – Fairly AI](https://www.fairly.ai/blog/ai-cybersecurity-tracker)
* [Anthropic makes 'jailbreak' advance to stop AI models producing harmful results](https://www.ft.com/content/cf11ebd8-aa0b-4ed4-945b-a5d4401d186e)
* [Pattern matching filter rules - IBM](https://www.ibm.com/docs/ssw_aix_71/security/intrusion_pattern_matching_filter_rules.html)
* [Real-time Threat Detection](https://www.darktrace.com/cyber-ai-glossary/real-time-threat-detection)

