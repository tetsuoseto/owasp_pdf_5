# Přední obálka

## O standardu

Standard pro ověřování bezpečnosti umělé inteligence (AISVS) je katalog bezpečnostních požadavků vytvářený komunitou, který mohou využít datoví vědci, inženýři MLOps, softwaroví architekti, vývojáři, testeři, bezpečnostní odborníci, dodavatelé nástrojů, regulátoři a uživatelé k navrhování, vytváření, testování a ověřování důvěryhodných systémů a aplikací využívajících umělou inteligenci. Poskytuje společný jazyk pro specifikaci bezpečnostních kontrol v celém životním cyklu AI — od sběru dat a vývoje modelů po nasazení a průběžné monitorování — aby organizace mohly měřit a zlepšovat odolnost, ochranu soukromí a bezpečnost svých AI řešení.

## Autorská práva a licence

Verze 0.1 (První veřejná verze - Práce v průběhu), 2025  

![license](../images/license.png)

Autorská práva © 2025 Projekt AISVS.  

Uvolněno pod[Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
Pro jakékoli opětovné použití nebo distribuci musíte jasně sdělit podmínky licence této práce ostatním.

## Vedoucí projektů

|            |                         |
| ---------- | ----------------------- |
| Jim Manico | Aras “Russ” Memisyazici |

## Přispěvatelé a recenzenti

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS je zbrusu nový standard vytvořený speciálně k řešení jedinečných bezpečnostních výzev systémů umělé inteligence. I když čerpá inspiraci z obecnějších osvědčených bezpečnostních postupů, každý požadavek v AISVS byl vyvinut od základu tak, aby odpovídal bezpečnostnímu prostředí umělé inteligence a pomáhal organizacím budovat bezpečnější a odolnější AI řešení.

