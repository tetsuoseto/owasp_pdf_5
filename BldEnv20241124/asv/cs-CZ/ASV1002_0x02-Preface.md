# Předmluva

Vítejte u normy pro ověřování bezpečnosti umělé inteligence (AISVS) verze 1.0!

## Úvod

Založena v roce 2025 díky společnému úsilí komunity, AISVS definuje bezpečnostní požadavky, které je třeba zohlednit při navrhování, vývoji, nasazování a provozu moderních AI modelů, pipeline a služeb podporovaných umělou inteligencí.

AISVS verze 1.0 představuje společnou práci vedoucích projektu, pracovní skupiny a širší komunity přispěvatelů s cílem vytvořit pragmatický, testovatelný základ pro zabezpečení AI systémů.

Naším cílem s tímto vydáním je učinit AISVS snadno přijatelným při zachování ostré zaměřenosti na jeho definovaný rozsah a řešení rychle se vyvíjejícího rizikového prostředí jedinečného pro AI.

## Klíčové cíle pro AISVS Verze 1.0

Verze 1.0 bude vytvořena na základě několika základních principů.

### Dobře definovaný rozsah

Každý požadavek musí být v souladu s názvem a posláním AISVS:

* Umělá inteligence – Kontroly fungují na vrstvě AI/ML (data, model, pipeline nebo inference) a jsou odpovědností odborníků na AI.
* Bezpečnost – Požadavky přímo zmírňují identifikovaná rizika v oblasti bezpečnosti, ochrany soukromí nebo bezpečnosti uživatelů.
* Ověření – Jazyk je napsán tak, aby byla shoda objektivně ověřitelná.
* Standard – Oddíly následují konzistentní strukturu a terminologii, aby vytvořily soudržný referenční rámec.
  ​
---

Dodržováním AISVS mohou organizace systematicky hodnotit a posilovat bezpečnostní postoj svých AI řešení, čímž podporují kulturu bezpečného inženýrství AI.

