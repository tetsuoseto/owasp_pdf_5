# 扉页

## 关于标准

人工智能安全验证标准（AISVS）是一个由社区推动的安全需求目录，供数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专家、工具供应商、监管机构和用户用于设计、构建、测试和验证可信赖的AI驱动系统和应用。它提供了一种通用语言，用于在AI生命周期中规范安全控制——从数据收集和模型开发到部署及持续监控——以便组织能够衡量和提升其AI解决方案的弹性、隐私和安全性。

## 版权与许可

版本 0.1（首次公开草案 - 进行中），2025年  

![license](../images/license.png)

版权 © 2025 AISVS 项目。  

根据 [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
对于任何再利用或分发，您必须向他人清晰传达此作品的许可条款。

## 项目负责人

|        |                         |
| ------ | ----------------------- |
| 吉姆·马尼科 | Aras “Russ” Memisyazici |

## 贡献者和审稿人

|                                    |                             |
| ---------------------------------- | --------------------------- |
| https://github.com/ottosulin       | https://github.com/mbhatt1  |
| https://github.com/vineethsai      | https://github.com/cciprofm |
| https://github.com/deepakrpandey12 |                             |

---

AISVS 是一个全新的标准，专门为应对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但 AISVS 中的每一项要求都是从零开始开发的，旨在反映人工智能的威胁格局，帮助组织构建更安全、更具弹性的人工智能解决方案。

