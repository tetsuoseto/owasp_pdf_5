## 封面页

### 关于标准

人工智能安全验证标准（AISVS）是一个由社区推动的安全需求目录，数据科学家、MLOps工程师、软件架构师、开发人员、测试人员、安全专家、工具供应商、监管机构和用户可以使用该目录来设计、构建、测试和验证可信赖的人工智能系统和应用。它为人工智能生命周期中的安全控制规范提供了统一的语言——从数据收集和模型开发到部署及持续监控——使组织能够衡量和提升其人工智能解决方案的韧性、隐私和安全性。

### 版权和许可

版本 0.1（首个公开草案 - 进行中），2025  

![license](images/license.png)
版权所有 © 2025 AISVS项目。  

根据 Creative Commons Attribution‑ShareAlike 4.0 International License.
对于任何再利用或分发，您必须明确向他人传达本作品的许可条款。

### 项目负责人

吉姆·马尼科
Aras “Russ” Memisyazici

### 贡献者和审稿人

https://github.com/ottosulin
https://github.com/mbhatt1
https://github.com/vineethsai
https://github.com/cciprofm
https://github.com/deepakrpandey12


---

AISVS 是一个全新的标准，专门针对人工智能系统的独特安全挑战而创建。虽然它借鉴了更广泛的安全最佳实践，但 AISVS 中的每一项要求都是从零开始开发，以反映人工智能的威胁环境，并帮助组织构建更安全、更具韧性的人工智能解决方案。

## 前言

欢迎使用人工智能安全验证标准（AISVS）1.0版！

### 介绍

AISVS成立于2025年，是通过社区协作努力制定的，旨在定义在设计、开发、部署和运营现代人工智能模型、流程及人工智能支持服务时需要考虑的安全要求。

AISVS v1.0 代表了其项目负责人、工作组及更广泛的社区贡献者的共同努力，旨在制定一个务实且可测试的 AI 系统安全基准。

我们此次发布的目标是使AISVS易于采用，同时保持对其定义范围的高度专注，并应对AI特有的快速变化的风险环境。

### AISVS 版本 1.0 的关键目标

版本1.0将基于若干指导原则创建。

#### 明确的范围

每个需求必须与AISVS的名称和使命保持一致：

人工智能——控制措施在AI/机器学习层（数据、模型、流水线或推理）运行，由AI从业人员负责。
安全性——需求直接缓解已识别的安全、隐私或安全风险。
验证 – 语言的编写方式使一致性能够被客观验证。
标准 – 各章节遵循一致的结构和术语，形成连贯的参考资料。
​
---

通过遵循AISVS，组织可以系统地评估和强化其人工智能解决方案的安全态势，促进安全人工智能工程文化的形成。

## 使用AISVS

人工智能安全验证标准（AISVS）定义了现代人工智能应用和服务的安全要求，重点关注应用开发人员可控的方面。

AISVS旨在为任何开发或评估人工智能应用安全性的人员提供指导，包括开发人员、架构师、安全工程师和审计员。本章介绍了AISVS的结构及其使用方法，包括其验证级别和预期使用案例。

### 人工智能安全验证级别

AISVS定义了三个逐级递增的安全验证级别。每个级别都增加了深度和复杂性，使组织能够根据其人工智能系统的风险级别定制安全防护措施。

组织可以从第1级开始，随着安全成熟度和威胁暴露的增加，逐步采用更高的级别。

#### 级别定义

AISVS v1.0中的每个需求被分配到以下级别之一：

 一级要求

第一级包含最关键和基础的安全要求。这些要求侧重于防止不依赖其他先决条件或漏洞的常见攻击。大多数第一级控制措施要么实现简单，要么足够重要，值得付出努力。

 二级要求

第2级处理更高级或不太常见的攻击，以及针对广泛威胁的分层防御。这些需求可能涉及更复杂的逻辑或针对特定攻击前提条件。

 三级要求

第三级包括通常较难实施或适用于特定情境的控制措施。这些通常代表纵深防御机制或针对小众、定向或高复杂度攻击的缓解措施。

#### 角色（D/V）

每个AISVS需求都根据主要受众进行标记：

D – 面向开发者的需求
V – 面向验证者/审计员的需求
D/V – 既适用于开发者，也适用于验证者

## C1 训练数据治理与偏差管理

### 控制目标

训练数据必须以保护来源、安全性、质量和公平性的方式进行采集、处理和维护。这样做既履行了法律责任，也减少了在整个人工智能生命周期中出现偏见、投毒或隐私泄露的风险。

---

### C1.1 训练数据来源

保持所有数据集的可验证清单，仅接受可信来源，并记录所有变更以确保可审计性。

 #1.1.1    Level: 1    Role: D/V
 确保维护每个训练数据源的最新清单（包括来源、管理员/所有者、许可、收集方法、预期使用限制和处理历史）。
 #1.1.2    Level: 1    Role: D/V
 确保仅允许经过质量、代表性、伦理来源和许可合规性审核的数据集，降低中毒、内嵌偏见和知识产权侵权的风险。
 #1.1.3    Level: 1    Role: D/V
 验证是否执行了数据最小化，以排除不必要或敏感的属性。
 #1.1.4    Level: 2    Role: D/V
 确保所有数据集的更改都必须经过记录的审批流程。
 #1.1.5    Level: 2    Role: D/V
 通过审阅者的交叉检查或共识，确保标签/标注质量。
 #1.1.6    Level: 2    Role: D/V
 确认为重要的训练数据集维护“数据卡”或“数据集数据表”，详细说明其特征、动机、组成、收集过程、预处理以及推荐/不推荐的使用方法。

---

### C1.2 训练数据安全性与完整性

限制访问，对静态数据和传输中的数据进行加密，并验证完整性以防止篡改或盗窃。

 #1.2.1    Level: 1    Role: D/V
 验证存储和数据管道受到访问控制的保护。
 #1.2.2    Level: 2    Role: D/V
 验证数据集在传输过程中是否加密，并且对于所有敏感或个人身份信息（PII），在静止状态下是否使用行业标准的加密算法和密钥管理实践进行加密。
 #1.2.3    Level: 2    Role: D/V
 验证在存储和传输过程中使用加密哈希或数字签名以确保数据完整性，并应用自动异常检测技术以防止未经授权的修改或损坏，包括针对性的数据信息投毒尝试。
 #1.2.4    Level: 3    Role: D/V
 验证数据集版本是否被跟踪以支持回滚。
 #1.2.5    Level: 2    Role: D/V
 核实过时数据是否按照数据保留政策、监管要求安全清除或匿名化，以缩小攻击面。

---

### C1.3 表示的完整性与公平性

检测人口统计偏差并采取缓解措施，以确保模型在各组之间的错误率公平。

 #1.3.1    Level: 1    Role: D/V
 验证数据集是否针对具有法律保护的属性（例如种族、性别、年龄）以及与模型应用领域相关的其他伦理敏感特征（例如社会经济状况、地理位置）进行了代表性不平衡和潜在偏差的分析。
 #1.3.2    Level: 2    Role: D/V
 验证已识别的偏差是否通过文档化的策略得到缓解，例如重新平衡、有针对性的数据增强、算法调整（例如预处理、中间处理、后处理技术）或重新加权，并评估缓解措施对公平性和整体模型性能的影响。
 #1.3.3    Level: 2    Role: D/V
 验证已评估并记录训练后公平性指标。
 #1.3.4    Level: 3    Role: D/V
 验证生命周期偏差管理策略是否分配了责任人和审核周期。

---

### C1.4 训练数据标注的质量、完整性与安全性

通过加密保护标签，并对关键类别要求双重审核。

 #1.4.1    Level: 2    Role: D/V
 确保通过明确的指导方针、复审员交叉检查、一致性机制（例如，监控标注者间一致性），以及定义的差异解决流程，来保证标注/注释质量。
 #1.4.2    Level: 2    Role: D/V
 验证是否对标签工件应用了加密哈希或数字签名，以确保其完整性和真实性。
 #1.4.3    Level: 2    Role: D/V
 验证标注接口和平台是否实施强访问控制，维护所有标注活动的防篡改审计日志，并防止未经授权的修改。
 #1.4.4    Level: 3    Role: D/V
 验证对安全性、保密性或公平性至关重要的标签（例如，识别有害内容、关键医疗发现）是否接受了强制性的独立双重审核或等效的严格验证。
 #1.4.5    Level: 2    Role: D/V
 验证是否根据数据最小化原则，对标签中无意捕获或必然存在的敏感信息（包括个人身份信息）在静态和传输过程中进行了脱敏、假名化、匿名化或加密处理。
 #1.4.6    Level: 2    Role: D/V
 确保标签指南和说明全面，具有版本控制，并经过同行评审。
 #1.4.7    Level: 2    Role: D/V
 确保数据架构（包括标签的架构）定义清晰，并进行版本控制。
 #1.8.2    Level: 2    Role: D/V
 验证外包或众包标注工作流程中是否包含技术/程序保障措施，以确保数据的机密性、完整性、标签质量，并防止数据泄露。

---

### C1.5 训练数据质量保证

结合自动验证、人工抽查和记录的补救措施，以确保数据集的可靠性。

 #1.5.1    Level: 1    Role: D
 验证自动化测试是否能够捕捉每次摄取或重大转换中的格式错误、空值和标签偏差。
 #1.5.2    Level: 1    Role: D/V
 验证失败的数据集是否被隔离并有审计跟踪。
 #1.5.3    Level: 2    Role: V
 验证领域专家的手动抽查覆盖了具有统计显著性的样本（例如，≥1%或1000个样本，以较大者为准，或根据风险评估确定），以识别自动化未检测出的细微质量问题。
 #1.5.4    Level: 2    Role: D/V
 验证补救步骤是否已附加到溯源记录中。
 #1.5.5    Level: 2    Role: D/V
 确保质量门禁阻止不合格的数据集，除非获得例外批准。

---

### C1.6 数据投毒检测

应用统计异常检测和隔离工作流程以阻止对抗性插入。

 #1.6.1    Level: 2    Role: D/V
 验证异常检测技术（例如，统计方法、异常值检测、嵌入分析）是否在数据摄取阶段及主要训练运行之前应用于训练数据，以识别潜在的投毒攻击或无意的数据损坏。
 #1.6.2    Level: 2    Role: D/V
 验证被标记的样本在训练前会触发人工审核。
 #1.6.3    Level: 2    Role: V
 验证结果是否反馈到模型的安全档案中，并为持续的威胁情报提供信息。
 #1.6.4    Level: 3    Role: D/V
 验证检测逻辑是否已使用新的威胁情报进行了刷新。
 #1.6.5    Level: 3    Role: D/V
 验证在线学习管道是否监控分布漂移。
 #1.6.6    Level: 3    Role: D/V
 验证是否根据系统的风险状况和数据来源，考虑并实施了针对已知数据投毒攻击类型（例如标签翻转、后门触发器插入、影响实例攻击）的特定防御措施。

---

### C1.7 用户数据删除与同意执行

尊重所有数据集、备份和派生产物中的删除和撤回同意请求。

 #1.7.1    Level: 1    Role: D/V
 验证删除工作流程是否清除主数据和派生数据，并评估对模型的影响；同时评估受影响模型的影响，并在必要时进行处理（例如，通过重新训练或重新校准）。
 #1.7.2    Level: 2    Role: D
 验证已建立机制以跟踪和遵守用户对用于训练数据的同意范围和状态（包括撤回），并且在将数据纳入新的训练过程或重要模型更新之前，必须确认同意的有效性。
 #1.7.3    Level: 2    Role: V
 验证工作流程是否每年进行测试并记录。

---

### C1.8 供应链安全

审查外部数据提供商，并通过认证的加密通道验证数据完整性。

 #1.8.1    Level: 2    Role: D/V
 确保第三方数据供应商，包括预训练模型提供者和外部数据集提供者，在其数据或模型被集成之前，经过安全、隐私、伦理来源和数据质量的尽职调查。
 #1.8.2    Level: 1    Role: D
 验证外部传输是否使用TLS/身份验证和完整性检查。
 #1.8.3    Level: 2    Role: D/V
 验证高风险数据源（例如，来源不明的开源数据集、未经审核的供应商）在用于敏感应用之前，是否经过加强审查，如沙盒分析、广泛的质量/偏差检查及针对性中毒检测。
 #1.8.4    Level: 3    Role: D/V
 在微调或部署之前，确认从第三方获得的预训练模型已进行嵌入偏差、潜在后门、架构完整性及其原始训练数据来源的评估。

---

### C1.9 对抗样本检测

在训练阶段实施措施，例如对抗训练，以增强模型对对抗样本的抵抗力。

 #1.9.1    Level: 3    Role: D/V
 根据风险评估，验证是否为相关模型实施并调优了适当的防御措施，如对抗训练（使用生成的对抗样本）、带扰动输入的数据增强或鲁棒优化技术。
 #1.9.2    Level: 2    Role: D/V
 验证如使用对抗性训练，是否对抗性数据集的生成、管理和版本控制都有记录和控制。
 #1.9.3    Level: 3    Role: D/V
 验证对抗鲁棒性训练对模型性能（针对干净和对抗输入）及公平性指标的影响是否进行了评估、记录和监控。
 #1.9.4    Level: 3    Role: D/V
 确保针对对抗训练和鲁棒性的策略定期进行审查和更新，以应对不断演变的对抗攻击技术。

---

### C1.10 数据血缘和可追溯性

跟踪每个数据点从来源到模型输入的完整过程，以便审计和事件响应。

 #1.10.1    Level: 2    Role: D/V
 验证每个数据点的血统，包括所有的转换、增强和合并，是否已被记录并且可以重建。
 #1.10.2    Level: 2    Role: D/V
 验证血统记录是不可更改的，安全存储的，并且可以用于审计或调查。
 #1.10.3    Level: 2    Role: D/V
 验证血统追踪是否涵盖原始数据和合成数据。

---

### C1.11 合成数据管理

确保合成数据得到妥善管理、标注和风险评估。

 #1.11.1    Level: 2    Role: D/V
 确保在整个流程中所有合成数据均被明确标注，且可与真实数据区分开来。
 #1.11.2    Level: 2    Role: D/V
 验证合成数据的生成过程、参数和预期用途是否有文档记录。
 #1.11.3    Level: 2    Role: D/V
 在用于训练之前，确保对合成数据进行偏差、隐私泄露和表现性问题的风险评估。

---

### C1.12 数据访问监控与异常检测

监控并警报对训练数据的异常访问，以检测内部威胁或数据泄露。

 #1.12.1    Level: 2    Role: D/V
 验证所有对训练数据的访问都被记录，包括用户、时间和操作。
 #1.12.2    Level: 2    Role: D/V
 验证访问日志是否定期审查异常模式，例如大规模导出或来自新地点的访问。
 #1.12.3    Level: 2    Role: D/V
 验证可疑访问事件是否生成了警报并及时进行调查。

---

### C1.13 数据保留与过期政策

定义并执行数据保留期限，以尽量减少不必要的数据存储。

 #1.13.1    Level: 1    Role: D/V
 验证所有训练数据集是否定义了明确的保留期限。
 #1.13.2    Level: 2    Role: D/V
 验证数据集在其生命周期结束时是否自动到期、删除或进行删除审核。
 #1.13.3    Level: 2    Role: D/V
 验证保留和删除操作是否被记录和可审计。

---

### C1.14 监管与司法合规

确保所有训练数据符合适用的法律法规。

 #1.14.1    Level: 2    Role: D/V
 验证所有数据集是否已识别并执行数据驻留和跨境传输要求。
 #1.14.2    Level: 2    Role: D/V
 验证行业特定法规（例如，医疗保健、金融）是否已被识别并在数据处理过程中得到遵守。
 #1.14.3    Level: 2    Role: D/V
 确认相关隐私法律（例如 GDPR、CCPA）的合规性已被记录并定期审查。

---

### C1.15 数据水印与指纹识别

检测未经授权的专有或敏感数据的重用或泄露。

 #1.15.1    Level: 3    Role: D/V
 确保在可行的情况下，对数据集或子集进行水印或指纹标记。
 #1.15.2    Level: 3    Role: D/V
 验证水印/指纹识别方法不会引入偏见或隐私风险。
 #1.15.3    Level: 3    Role: D/V
 验证是否定期进行检查以检测水印数据的未授权重用或泄露。

---

### C1.16 数据主体权利管理

支持数据主体权利，如访问、更正、限制和反对。

 #1.16.1    Level: 2    Role: D/V
 验证是否存在响应数据主体请求访问、纠正、限制或反对的机制。
 #1.16.2    Level: 2    Role: D/V
 验证请求是否在法律规定的时间范围内被记录、跟踪和完成。
 #1.16.3    Level: 2    Role: D/V
 验证数据主体权利流程是否定期进行测试和审查以确保其有效性。

---

### C1.17 数据集版本影响分析

在更新或替换版本之前，评估数据集变化的影响。

 #1.17.1    Level: 2    Role: D/V
 在更新或替换数据集版本之前，确保进行影响分析，涵盖模型性能、公平性和合规性。
 #1.17.2    Level: 2    Role: D/V
 验证影响分析的结果已被相关利益相关者记录并审查。
 #1.17.3    Level: 2    Role: D/V
 验证是否存在回滚计划，以防新版本带来不可接受的风险或回退问题。

---

### C1.18 数据标注人员安全

确保参与数据标注的人员的安全和完整性。

 #1.18.1    Level: 2    Role: D/V
 确认所有参与数据标注的人员都经过背景调查并接受过数据安全和隐私方面的培训。
 #1.18.2    Level: 2    Role: D/V
 确保所有标注人员签署保密和不披露协议。
 #1.18.3    Level: 2    Role: D/V
 验证注释平台是否实施访问控制并监控内部威胁。

---

### 参考文献

NIST AI Risk Management Framework
EU AI Act – Article 10: Data & Data Governance
MITRE ATLAS: Adversary Tactics for AI
Survey of ML Bias Mitigation Techniques – MDPI
Data Provenance & Lineage Best Practices – Nightfall AI
Data Labeling Quality Standards – LabelYourData
Training Data Poisoning Guide – Lakera.ai
CISA Advisory: Securing Data for AI Systems
ISO/IEC 23053: AI Management Systems Framework
IBM: What is AI Governance?
Google AI Principles
GDPR & AI Training Data – DataProtectionReport
Supply-Chain Security for AI Data – AppSOC
OpenAI Privacy Center – Data Deletion Controls
Adversarial ML Dataset – Kaggle

## C2 用户输入验证

### 控制目标

对用户输入的强健验证是防御针对人工智能系统一些最具破坏性攻击的第一道防线。提示注入攻击可以覆盖系统指令、泄露敏感数据或引导模型执行不被允许的行为。研究表明，除非配备专门的过滤器和指令层级，否则利用超长上下文窗口的“多次注入”越狱攻击将是有效的。此外，细微的对抗性扰动攻击——例如同形异义字符替换或“互联网黑话”（leetspeak）——能够悄无声息地改变模型的决策。

---

### C2.1 提示注入防御

提示注入是人工智能系统面临的主要风险之一。针对这一策略的防御措施结合了静态模式过滤器、动态分类器和指令层级执行。

 #2.1.1    Level: 1    Role: D/V
 验证用户输入是否经过筛查，针对不断更新的已知提示注入模式库（越狱关键词、“忽略之前内容”、角色扮演链条、间接HTML/URL攻击）。
 #2.1.2    Level: 1    Role: D/V
 验证系统是否强制执行指令层级，其中系统或开发者消息优先于用户指令，即使在上下文窗口扩展后也是如此。
 #2.1.3    Level: 2    Role: D/V
 验证在每次模型或提示模板发布之前，都会进行对抗性评估测试（例如，红队“多次示例”提示），并设定成功率阈值和用于回归的自动阻断机制。
 #2.1.4    Level: 2    Role: D
 验证来自第三方内容（网页、PDF、电子邮件）的提示在被连接到主提示之前，是否在隔离的解析环境中进行了清洗。
 #2.1.5    Level: 3    Role: D/V
 验证所有提示过滤规则更新、分类器模型版本和阻止列表更改均受版本控制且可审计。

---

### C2.2 对抗样本抗性

自然语言处理（NLP）模型仍然容易受到细微的字符或单词级扰动的影响，这些扰动人类常常忽视，但模型往往会错误分类。

 #2.2.1    Level: 1    Role: D
 验证基本输入规范化步骤（Unicode NFC，同形异义字映射，空白字符修剪）是否在分词之前执行。
 #2.2.2    Level: 2    Role: D/V
 验证统计异常检测是否能标记出与语言规范编辑距离异常高、重复令牌过多或嵌入距离异常的输入。
 #2.2.3    Level: 2    Role: D
 验证推理流程是否支持可选的对抗训练加固模型变体或防御层（例如，随机化、防御性蒸馏），以用于高风险端点。
 #2.2.4    Level: 2    Role: V
 验证疑似对抗性输入已被隔离，并在去除个人身份信息（PII）后，完整的负载被记录在案。
 #2.2.5    Level: 3    Role: D/V
 验证鲁棒性指标（已知攻击套件的成功率）是否随时间跟踪，并且回归问题是否会触发发布阻止。

---

### C2.3 架构、类型与长度验证

包含格式错误或超大输入的AI攻击可能导致解析错误、提示内容跨字段泄漏以及资源耗尽。在执行确定性工具调用时，严格的模式强制也是前提条件。

 #2.3.1    Level: 1    Role: D
 验证每个 API 或函数调用端点是否定义了明确的输入模式（JSON Schema、Protobuf 或多模态等效模式），并确保在提示组装之前对输入进行验证。
 #2.3.2    Level: 1    Role: D/V
 验证超出最大令牌或字节限制的输入是否被安全地拒绝，并且绝不会被静默截断。
 #2.3.3    Level: 2    Role: D/V
 验证类型检查（例如，数值范围、枚举值、图像/音频的MIME类型）是否在服务器端强制执行，而不仅仅是在客户端代码中。
 #2.3.4    Level: 2    Role: D
 验证语义验证器（例如 JSON Schema）是否以常数时间运行，以防止算法拒绝服务（DoS）攻击。
 #2.3.5    Level: 3    Role: V
 验证确保验证失败时记录的负载片段已脱敏，并且错误代码明确，以帮助安全分级。

---

### C2.4 内容与政策审查

开发人员应能够检测请求不允许内容的语法上有效的提示（例如非法指令、仇恨言论和受版权保护的文本），并阻止其传播。

 #2.4.1    Level: 1    Role: D
 验证内容分类器（零样本或微调）是否对每个输入进行暴力、自残、仇恨、色情内容和非法请求的评分，并支持可配置的阈值。
 #2.4.2    Level: 1    Role: D/V
 验证违反政策的输入将收到标准化拒绝或安全完成，以确保它们不会传播到下游的大型语言模型调用。
 #2.4.3    Level: 2    Role: D
 验证筛选模型或规则集是否至少每季度重新训练/更新一次，纳入新观察到的越狱或策略绕过模式。
 #2.4.4    Level: 2    Role: D
 通过基于属性的规则在请求时解析，验证筛选是否遵守用户特定的政策（年龄、地区法律限制）。
 #2.4.5    Level: 3    Role: V
 确认筛查日志包含分类器置信度分数和策略类别标签，以便进行SOC关联和未来的红队回放。

---

### C2.5 输入速率限制与滥用防范

开发人员应通过限制输入速率和检测异常使用模式，防止对人工智能系统的滥用、资源耗尽和自动化攻击。

 #2.5.1    Level: 1    Role: D/V
 验证所有输入端点是否执行了每用户、每IP和每API密钥的速率限制。
 #2.5.2    Level: 2    Role: D/V
 验证突发和持续速率限制是否已调整，以防止拒绝服务（DoS）和暴力破解攻击。
 #2.5.3    Level: 2    Role: D/V
 验证异常使用模式（例如，快速请求、输入泛滥）是否会触发自动阻断或升级。
 #2.5.4    Level: 3    Role: V
 验证滥用防范日志是否被保留并审查以发现新出现的攻击模式。

---

### C2.6 多模态输入验证

人工智能系统应包含对非文本输入（图像、音频、文件）的强健验证，以防止注入、规避或资源滥用。

 #2.6.1    Level: 1    Role: D
 确保所有非文本输入（图片、音频、文件）在处理前均经过类型、大小和格式的验证。
 #2.6.2    Level: 2    Role: D/V
 确认文件在导入前已扫描恶意软件和隐写载荷。
 #2.6.3    Level: 2    Role: D/V
 验证图像/音频输入是否经过对抗扰动或已知攻击模式的检查。
 #2.6.4    Level: 3    Role: V
 验证多模态输入验证失败是否被记录并触发警报以进行调查。

---

### C2.7 输入来源与归属

AI系统应通过监控和标记所有用户输入的来源来支持审计、滥用跟踪和合规。

 #2.7.1    Level: 1    Role: D/V
 验证所有用户输入在摄取时均附有元数据（用户ID、会话、来源、时间戳、IP地址）。
 #2.7.2    Level: 2    Role: D/V
 验证所有处理的输入的来源元数据是否被保留且可审计。
 #2.7.3    Level: 2    Role: D/V
 验证异常或不可信的输入源是否被标记，并接受增强的审查或阻止。

---

### C2.8 实时自适应威胁检测

开发人员应采用先进的AI威胁检测系统，这些系统能适应新的攻击模式，并通过编译的模式匹配提供实时保护。

 #2.8.1    Level: 1    Role: D/V
 验证威胁检测模式是否已编译为优化的正则表达式引擎，以实现高性能的实时过滤并将延迟影响降至最低。
 #2.8.2    Level: 1    Role: D/V
 验证威胁检测系统是否为不同的威胁类别（提示注入、有害内容、敏感数据、系统命令）维护独立的模式库。
 #2.8.3    Level: 2    Role: D/V
 验证自适应威胁检测是否包含基于攻击频率和成功率更新威胁敏感性的机器学习模型。
 #2.8.4    Level: 2    Role: D/V
 验证实时威胁情报馈送是否自动使用新的攻击特征和妥协指标（IOCs）更新模式库。
 #2.8.5    Level: 3    Role: D/V
 验证威胁检测的误报率是否被持续监控，并且模式特异性是否被自动调整以最小化对合法用例的干扰。
 #2.8.6    Level: 3    Role: D/V
 验证上下文威胁分析是否考虑了输入来源、用户行为模式和会话历史，以提高检测准确性。
 #2.8.7    Level: 3    Role: D/V
 验证威胁检测性能指标（检测率、处理延迟、资源利用率）是否被实时监控和优化。

---

### C2.9 多模态安全验证流程

开发人员应针对文本、图像、音频及其他AI输入模态，提供特定类型的威胁检测和资源隔离的安全验证。

 #2.9.1    Level: 1    Role: D/V
 验证每种输入模态是否具备专用的安全验证器，并附有文档化的威胁模式（文本：提示注入，图像：隐写术，音频：频谱图攻击）及检测阈值。
 #2.9.2    Level: 2    Role: D/V
 验证多模态输入是否在具有定义资源限制（内存、CPU、处理时间）的隔离沙箱中处理，这些限制针对每种模态类型具体制定，并在安全策略中有所记录。
 #2.9.3    Level: 2    Role: D/V
 验证跨模态攻击检测是否能够通过相关性规则和警报生成，识别跨越多种输入类型的协同攻击（例如图像中的隐写载荷与文本中的提示注入结合）。
 #2.9.4    Level: 3    Role: D/V
 验证多模态验证失败是否触发详细日志记录，包括所有输入模态、验证结果、威胁评分以及用于SIEM集成的结构化日志格式的关联分析。
 #2.9.5    Level: 3    Role: D/V
 验证特定模态内容分类器是否按照记录的时间表（至少每季度一次）更新，更新内容包括新的威胁模式、对抗样本，并确保性能基准维持在基线阈值以上。

---

### 参考文献

LLM01:2025 Prompt Injection – OWASP Top 10 for LLM & Generative AI Security
Generative AI's Biggest Security Flaw Is Not Easy to Fix
Many-shot jailbreaking \ Anthropic
$PDF$ OpenAI GPT-4.5 System Card
Notebook for the CheckThat Lab at CLEF 2024
Mitigate jailbreaks and prompt injections – Anthropic
Chapter 3 MITRE ATT\&CK – Adversarial Model Analysis
OWASP Top 10 for LLM Applications 2025 – WorldTech IT
OWASP Machine Learning Security Top Ten
Few words about AI Security – Jussi Metso
How To Ensure LLM Output Adheres to a JSON Schema | Modelmetry
Easily enforcing valid JSON schema following – API
AI Safety + Cybersecurity R\&D Tracker – Fairly AI
Anthropic makes 'jailbreak' advance to stop AI models producing harmful results
Pattern matching filter rules - IBM
Real-time Threat Detection

## C3 模型生命周期管理与变更控制

### 控制目标

人工智能系统必须实施变更控制流程，以防止未经授权或不安全的模型修改进入生产环境。该控制确保模型在整个生命周期内的完整性——从开发、部署到退役——从而实现快速的事件响应并维护对所有变更的责任追踪。

核心安全目标：仅通过受控流程使经过授权和验证的模型投入生产，这些流程保持完整性、可追溯性和可恢复性。

---

### C3.1 模型授权与完整性

只有经过验证完整性的授权模型才能进入生产环境。

 #3.1.1    Level: 1    Role: D/V
 在部署之前，验证所有模型工件（权重、配置、分词器）是否由授权实体进行过加密签名。
 #3.1.2    Level: 1    Role: D/V
 验证模型完整性在部署时得到确认，并且签名验证失败会阻止模型加载。
 #3.1.3    Level: 2    Role: D/V
 验证模型溯源记录是否包含授权实体的身份信息、训练数据校验和、带有通过/失败状态的验证测试结果以及创建时间戳。
 #3.1.4    Level: 2    Role: D/V
 验证所有模型工件是否使用语义化版本控制（主版本号.次版本号.修订号），并有文档说明每个版本组件递增的具体标准。
 #3.1.5    Level: 2    Role: V
 验证依赖关系跟踪是否维持了一个实时库存，从而能够快速识别所有使用该依赖的系统。

---

### C3.2 模型验证与测试

模型必须在部署前通过定义的安全性和安全验证。

 #3.2.1    Level: 1    Role: D/V
 验证模型在部署前接受自动化安全测试，包括输入验证、输出清理和安全评估，并符合预先商定的组织通过/失败阈值。
 #3.2.2    Level: 1    Role: D/V
 验证验证失败是否在预先指定的授权人员明确覆盖批准且有书面业务理由的情况下自动阻止模型部署。
 #3.2.3    Level: 2    Role: V
 验证测试结果是否经过加密签名，并且不可篡改地链接到被验证的特定模型版本哈希。
 #3.2.4    Level: 2    Role: D/V
 确认紧急部署需要在预先商定的时间范围内，经过文档化的安全风险评估和预先指定的安全权限的批准。

---

### C3.3 受控部署与回滚

模型部署必须受到控制、监控并且可逆。

 #3.3.1    Level: 1    Role: D
 验证生产部署是否实施了渐进式发布机制（金丝雀发布、蓝绿发布），并基于预先商定的错误率、延迟阈值或安全警报标准设置了自动回滚触发器。
 #3.3.2    Level: 1    Role: D/V
 验证回滚功能是否能够在预定义的组织时间窗口内原子性地恢复完整的模型状态（权重、配置、依赖关系）。
 #3.3.3    Level: 2    Role: D/V
 验证部署流程在模型激活前校验加密签名并计算完整性校验和，若不匹配则部署失败。
 #3.3.4    Level: 2    Role: D/V
 验证紧急模型关闭功能是否能够通过自动断路器或手动杀死开关，在预定义的响应时间内禁用模型端点。
 #3.3.5    Level: 2    Role: V
 验证回滚工件（先前的模型版本、配置、依赖项）是否根据组织政策保留，并采用不可变存储以应对事件响应。

---

### C3.4 变更问责与审计

所有模型生命周期的变更必须可追溯且可审计。

 #3.4.1    Level: 1    Role: V
 验证所有模型更改（部署、配置、退役）是否生成不可变的审计记录，包括时间戳、经过身份验证的操作人员身份、变更类型以及变更前后状态。
 #3.4.2    Level: 2    Role: D/V
 验证审计日志访问是否需要适当的授权，并确保所有访问尝试均记录用户身份和时间戳。
 #3.4.3    Level: 2    Role: D/V
 验证提示模板和系统消息是否在 git 仓库中进行版本控制，并在部署前经过指定审核人员的强制代码审查和批准。
 #3.4.4    Level: 2    Role: V
 验证审计记录是否包含足够的详细信息（模型哈希、配置快照、依赖版本），以便能够在保留期内的任何时间戳完整重建模型状态。

---

### C3.5 安全开发实践

模型开发和训练过程必须遵循安全操作规范，以防止被破坏。

 #3.5.1    Level: 1    Role: D
 验证模型开发、测试和生产环境在物理上或逻辑上是分离的。它们没有共享的基础设施，具有不同的访问控制，并且数据存储是隔离的。
 #3.5.2    Level: 1    Role: D
 验证模型训练和微调是否在隔离环境中进行，并且网络访问受到控制。
 #3.5.3    Level: 1    Role: D/V
 在模型开发使用之前，验证训练数据来源通过完整性检查并通过可信来源进行身份验证，且具备记录在案的监管链。
 #3.5.4    Level: 2    Role: D
 验证模型开发工件（超参数、训练脚本、配置文件）是否存储在版本控制中，并且在用于训练前是否需要同行评审批准。

---

### C3.6 模型退役与报废

模型在不再需要或发现安全问题时，必须安全退役。

 #3.6.1    Level: 1    Role: D
 验证模型退役流程是否自动扫描依赖图，识别所有使用系统，并在退役前提供预先商定的通知期限。
 #3.6.2    Level: 1    Role: D/V
 根据已验证的销毁证明，按照记录的数据保留政策，使用加密抹除或多次覆盖的方法验证已退休模型工件被安全删除。
 #3.6.3    Level: 2    Role: V
 验证模型退役事件是否带有时间戳和操作人员身份的日志记录，并且模型签名已被撤销以防止重复使用。
 #3.6.4    Level: 2    Role: D/V
 验证紧急模型退役功能是否能够通过自动关闭开关，在发现关键安全漏洞时，在预先设定的紧急响应时间内禁用模型访问。

---

### 参考文献

MLOps Principles
Securing AI/ML Ops – Cisco.com
Audit logs security: cryptographically signed tamper-proof logs
Machine Learning Model Versioning: Top Tools & Best Practices
AI Hygiene Starts with Models and Data Loaders – SEI Blog
How to handle versioning and rollback of a deployed ML model?
Reinforcement fine-tuning – OpenAI API
Auditing Machine Learning models: Governance, Data Security and …
Adversarial Training to Improve Model Robustness
What is AI adversarial robustness? – IBM Research
Exploring Data Provenance: Ensuring Data Integrity and Authenticity
MITRE ATLAS
AWS Prescriptive Guidance – Best practices for retiring applications …

## C4 基础设施、配置与部署安全

### 控制目标

AI基础设施必须通过安全配置、运行时隔离、可信部署管道和全面监控来防止特权提升、供应链篡改和横向移动。只有经过授权和验证的基础设施组件及配置，才能通过受控流程进入生产环境，以确保安全性、完整性和可审计性。

核心安全目标：只有经过加密签名、漏洞扫描的基础设施组件，通过执行安全策略并保持不可变审计轨迹的自动化验证管道，才能进入生产环境。

---

### C4.1 运行时环境隔离

通过内核级隔离原语和强制访问控制来防止容器逃逸和权限提升。

 #4.1.1    Level: 1    Role: D/V
 验证所有 AI 容器均剥夺除 CAP_SETUID、CAP_SETGID 以及安全基线中明确要求的权限之外的所有 Linux 能力。
 #4.1.2    Level: 1    Role: D/V
 验证 seccomp 配置文件是否阻止所有系统调用，除了预先批准的允许列表中的系统调用，违规行为将终止容器并生成安全警报。
 #4.1.3    Level: 2    Role: D/V
 验证AI工作负载是否以只读根文件系统运行，临时数据使用tmpfs，持久数据使用命名卷，并强制执行noexec挂载选项。
 #4.1.4    Level: 2    Role: D/V
 验证基于eBPF的运行时监控（如Falco、Tetragon或同类工具）是否能够检测特权提升尝试，并在组织响应时间要求内自动终止违规进程。
 #4.1.5    Level: 3    Role: D/V
 验证高风险 AI 工作负载是否在硬件隔离环境中执行（如 Intel TXT、AMD SVM 或专用裸机节点），并进行认证验证。

---

### C4.2 安全构建与部署流水线

通过可重现构建和签名制品确保加密完整性和供应链安全。

 #4.2.1    Level: 1    Role: D/V
 验证基础设施即代码在每次提交时均使用工具（tfsec、Checkov 或 Terrascan）进行扫描，且对于存在严重（CRITICAL）或高（HIGH）严重性问题的提交阻止合并。
 #4.2.2    Level: 1    Role: D/V
 验证容器构建是否具有可复现性，即跨构建具有相同的 SHA256 哈希值，并生成由 Sigstore 签名的 SLSA 三级来源证明。
 #4.2.3    Level: 2    Role: D/V
 验证容器镜像在推送到镜像仓库之前嵌入了 CycloneDX 或 SPDX SBOM，并且使用 Cosign 签名，未经签名的镜像在部署时将被拒绝。
 #4.2.4    Level: 2    Role: D/V
 验证CI/CD管道使用来自HashiCorp Vault、AWS IAM角色或Azure托管身份的OIDC令牌，其有效期不超过组织安全策略的限制。
 #4.2.5    Level: 2    Role: D/V
 验证在容器执行前的部署过程中，Cosign 签名和 SLSA 证明已被验证，并且验证错误会导致部署失败。
 #4.2.6    Level: 2    Role: D/V
 验证构建环境是否运行在临时容器或虚拟机中，且没有持久存储，并且与生产VPC网络隔离。

---

### C4.3 网络安全与访问控制

通过默认拒绝策略和加密通信实现零信任网络。

 #4.3.1    Level: 1    Role: D/V
 验证 Kubernetes NetworkPolicies 或任何等效方案是否实现了默认拒绝入站/出站流量，并对所需端口（443、8080 等）设置了显式允许规则。
 #4.3.2    Level: 1    Role: D/V
 验证SSH（端口22）、RDP（端口3389）和云元数据端点（169.254.169.254）是否被阻止或需要基于证书的身份验证。
 #4.3.3    Level: 2    Role: D/V
 验证出口流量是否通过带有域名允许列表的 HTTP/HTTPS 代理（如 Squid、Istio 或云 NAT 网关）进行过滤，并记录被阻止的请求。
 #4.3.4    Level: 2    Role: D/V
 验证服务间通信使用双向 TLS，证书根据组织策略进行轮换，并强制执行证书验证（不允许跳过验证标志）。
 #4.3.5    Level: 2    Role: D/V
 验证人工智能基础设施运行在专用的VPC/VNet中，且无直接互联网访问，仅通过NAT网关或堡垒主机进行通信。

---

### C4.4 密钥与加密密钥管理

通过硬件支持的存储和零信任访问实现凭证的保护与自动轮换。

 #4.4.1    Level: 1    Role: D/V
 验证机密是否存储在 HashiCorp Vault、AWS Secrets Manager、Azure Key Vault 或 Google Secret Manager 中，并且使用 AES-256 进行静态数据加密。
 #4.4.2    Level: 1    Role: D/V
 验证加密密钥是否在符合FIPS 140-2 2级标准的硬件安全模块（HSM）（如AWS CloudHSM、Azure Dedicated HSM）中生成，并根据组织的加密策略执行密钥轮换。
 #4.4.3    Level: 2    Role: D/V
 验证密码轮换是否实现了零停机部署自动化，并且在人员变动或安全事件触发时能够立即轮换。
 #4.4.4    Level: 2    Role: D/V
 验证容器镜像是否使用工具（GitLeaks、TruffleHog 或 detect-secrets）进行扫描，阻止包含 API 密钥、密码或证书的构建。
 #4.4.5    Level: 2    Role: D/V
 验证生产环境的秘密访问是否需要使用硬件令牌（如 YubiKey、FIDO2）的多因素认证（MFA），并且通过包含用户身份和时间戳的不可篡改审计日志进行记录。
 #4.4.6    Level: 2    Role: D/V
 验证机密信息是通过 Kubernetes 机密、挂载卷或初始化容器注入的，并确保机密信息绝不嵌入环境变量或镜像中。

---

### C4.5 AI 工作负载沙箱与验证

将不受信任的人工智能模型隔离在安全的沙箱中，并进行全面的行为分析。

 #4.5.1    Level: 1    Role: D/V
 验证外部 AI 模型是否在 gVisor、microVM（如 Firecracker、CrossVM）或带有 --security-opt=no-new-privileges 和 --read-only 标志的 Docker 容器中执行。
 #4.5.2    Level: 1    Role: D/V
 验证沙箱环境无网络连接（--network=none）或仅限本地主机访问，并通过iptables规则阻止所有外部请求。
 #4.5.3    Level: 2    Role: D/V
 验证人工智能模型的验证过程是否包括具有组织定义的测试覆盖范围和行为分析的自动化红队测试，以检测后门。
 #4.5.4    Level: 2    Role: D/V
 确认在AI模型投产前，其沙箱测试结果已由授权安全人员进行密码签名，并存储在不可篡改的审计日志中。
 #4.5.5    Level: 2    Role: D/V
 验证沙箱环境在每次评估之间是否被销毁并从黄金镜像重新创建，确保完整的文件系统和内存清理。

---

### C4.6 基础设施安全监控

通过自动修复和实时警报，持续扫描和监控基础设施。

 #4.6.1    Level: 1    Role: D/V
 验证容器镜像是否按照组织的计划进行扫描，并根据组织风险阈值，将存在关键漏洞的镜像阻止部署。
 #4.6.2    Level: 1    Role: D/V
 验证基础设施是否符合CIS基准或NIST 800-53控制，依据组织定义的合规阈值，并对失败的检查进行自动修复。
 #4.6.3    Level: 2    Role: D/V
 验证高严重性漏洞是否根据组织的风险管理时间表进行了修补，并针对已被主动利用的CVE实施紧急处理程序。
 #4.6.4    Level: 2    Role: V
 验证安全警报是否通过CEF或STIX/TAXII格式与SIEM平台（Splunk、Elastic或Sentinel）集成，并支持自动丰富功能。
 #4.6.5    Level: 3    Role: V
 验证基础设施指标是否已导出到监控系统（Prometheus、DataDog），并具备SLA仪表板和高管报告。
 #4.6.6    Level: 2    Role: D/V
 根据组织监控要求，使用工具（Chef InSpec、AWS Config）验证配置漂移是否被检测到，并对未经授权的更改进行自动回滚。

---

### C4.7 AI 基础设施资源管理

通过配额和监控防止资源耗尽攻击，确保资源公平分配。

 #4.7.1    Level: 1    Role: D/V
 验证GPU/TPU的利用率是否被监控，并在组织定义的阈值触发警报，同时根据容量管理策略启动自动扩展或负载均衡。
 #4.7.2    Level: 1    Role: D/V
 验证是否按照组织的监控要求收集了 AI 工作负载指标（推理延迟、吞吐量、错误率），并将其与基础设施利用率相关联。
 #4.7.3    Level: 2    Role: D/V
 验证 Kubernetes ResourceQuotas 或等效机制是否根据组织的资源分配策略限制单个工作负载，并强制执行硬性限制。
 #4.7.4    Level: 2    Role: V
 验证成本监控是否根据组织预算阈值跟踪每个工作负载/租户的支出，并基于预算超支设置警报和自动控制。
 #4.7.5    Level: 3    Role: V
 验证容量规划是否使用具有组织定义的预测周期的历史数据，并根据需求模式进行自动化资源配置。
 #4.7.6    Level: 2    Role: D/V
 验证资源耗尽是否按照组织响应要求触发断路器，包括基于容量策略的速率限制和工作负载隔离。

---

### C4.8 环境隔离与发布控制

通过自动化推广门控和安全验证强制执行严格的环境边界。

 #4.8.1    Level: 1    Role: D/V
 验证开发/测试/生产环境是否在独立的VPC/VNet中运行，且没有共享的IAM角色、安全组或网络连接。
 #4.8.2    Level: 1    Role: D/V
 验证环境晋升是否需要经过组织定义的授权人员使用加密签名和不可篡改的审计跟踪的批准。
 #4.8.3    Level: 2    Role: D/V
 确认生产环境阻止 SSH 访问，禁用调试端点，并要求变更请求符合组织的提前通知要求，紧急情况除外。
 #4.8.4    Level: 2    Role: D/V
 验证基础设施即代码更改在合并到主分支前需经过同行评审，并进行自动化测试和安全扫描。
 #4.8.5    Level: 2    Role: D/V
 验证非生产数据是否根据组织的隐私要求进行了匿名处理，经过合成数据生成，或通过完全的数据掩码并验证了个人身份信息（PII）的移除。
 #4.8.6    Level: 2    Role: D/V
 确认晋升门包括自动化安全测试（SAST、DAST、容器扫描），且要求无关键漏洞（CRITICAL）才能批准。

---

### C4.9 基础设施备份与恢复

通过自动备份、测试恢复程序和灾难恢复能力，确保基础设施的弹性。

 #4.9.1    Level: 1    Role: D/V
 验证基础设施配置是否根据组织的备份计划备份到地理上分隔的区域，并实施3-2-1备份策略。
 #4.9.2    Level: 2    Role: D/V
 验证备份系统在隔离网络中运行，使用独立凭据和物理隔离的存储，以防止勒索软件攻击。
 #4.9.3    Level: 2    Role: V
 确保根据组织计划，通过自动化测试验证恢复程序的测试和有效性，恢复时间目标（RTO）和恢复点目标（RPO）符合组织要求。
 #4.9.4    Level: 3    Role: V
 验证灾难恢复是否包含针对AI的运行手册，包括模型权重恢复、GPU集群重建和服务依赖映射。

---

### C4.10 基础设施合规性与治理

通过持续评估、文档记录和自动化控制来保持法规合规性。

 #4.10.1    Level: 2    Role: D/V
 验证基础设施合规性是否按照组织的时间表，针对SOC 2、ISO 27001或FedRAMP控制进行评估，并通过自动化证据收集完成。
 #4.10.2    Level: 2    Role: V
 验证基础设施文档是否包含根据组织变更管理要求更新的网络图、数据流图和威胁模型。
 #4.10.3    Level: 3    Role: D/V
 验证基础设施变更通过自动化合规影响评估，并对高风险修改实施监管审批流程。

---

### C4.11 人工智能硬件安全

保护专门用于人工智能的硬件组件，包括GPU、TPU和专用的AI加速器。

 #4.11.1    Level: 2    Role: D/V
 验证AI加速器固件（GPU BIOS、TPU固件）是否经过加密签名验证，并按照组织的补丁管理时间表进行更新。
 #4.11.2    Level: 2    Role: D/V
 验证在工作负载执行之前，AI加速器的完整性通过使用TPM 2.0、Intel TXT或AMD SVM的硬件证明进行验证。
 #4.11.3    Level: 2    Role: D/V
 验证使用 SR-IOV、MIG（多实例 GPU）或等效硬件分区时，工作负载之间的 GPU 内存是否隔离，并确保作业间的内存清理。
 #4.11.4    Level: 3    Role: V
 验证AI硬件供应链是否包含制造商证书的来源验证和防篡改包装的验证。
 #4.11.5    Level: 3    Role: D/V
 验证硬件安全模块（HSM）是否通过了 FIPS 140-2 三级或通用准则 EAL4+ 认证，以保护 AI 模型权重和加密密钥。

---

### C4.12 边缘与分布式人工智能基础设施

包括边缘计算、联邦学习和多站点架构在内的安全分布式人工智能部署。

 #4.12.1    Level: 2    Role: D/V
 验证边缘人工智能设备是否使用基于设备证书的双向TLS认证连接中央基础设施，且设备证书按照组织的证书管理政策进行轮换。
 #4.12.2    Level: 2    Role: D/V
 验证边缘设备是否实现了带有验证签名和防回滚保护的安全启动，以防止固件降级攻击。
 #4.12.3    Level: 3    Role: D/V
 验证分布式人工智能协调是否使用拜占庭容错共识算法，并包含参与者验证和恶意节点检测。
 #4.12.4    Level: 3    Role: D/V
 验证边缘到云的通信包含带宽限制、数据压缩及具备安全本地存储的离线操作能力。

---

### C4.13 多云与混合基础设施安全

在多个云服务提供商和混合云本地部署中保护 AI 工作负载的安全。

 #4.13.1    Level: 2    Role: D/V
 验证多云 AI 部署是否使用云无关的身份联合（OIDC，SAML），并在各供应商之间实现集中式策略管理。
 #4.13.2    Level: 2    Role: D/V
 验证跨云数据传输使用端到端加密，采用客户管理的密钥，并根据各司法管辖区强制执行数据驻留控制。
 #4.13.3    Level: 2    Role: D/V
 验证混合云人工智能工作负载在本地和云环境中实施一致的安全策略，并实现统一的监控和告警。
 #4.13.4    Level: 3    Role: V
 验证防止云供应商锁定的方法包括可移植的基础设施即代码、标准化的API以及带有格式转换工具的数据导出功能。
 #4.13.5    Level: 3    Role: V
 验证多云成本优化是否包括防止资源泛滥的安全控制以及防止未经授权的跨云数据传输费用。

---

### C4.14 基础设施自动化与 GitOps 安全

为人工智能基础设施管理保障安全的基础设施自动化流水线和GitOps工作流。

 #4.14.1    Level: 2    Role: D/V
 验证GitOps仓库是否要求使用GPG密钥进行签名提交，并且通过分支保护规则防止直接推送到主分支。
 #4.14.2    Level: 2    Role: D/V
 验证基础设施自动化是否包括漂移检测，并根据组织响应要求针对未经授权的更改触发自动修复和回滚功能。
 #4.14.3    Level: 2    Role: D/V
 验证自动化基础设施配置过程中包含安全策略验证，并对不合规配置阻止部署。
 #4.14.4    Level: 2    Role: D/V
 验证基础设施自动化的密钥是否通过外部密钥操作器（External Secrets Operator，Bank-Vaults）进行管理，并支持自动轮换。
 #4.14.5    Level: 3    Role: V
 验证自愈基础设施是否包括带有自动事故响应和利益相关者通知工作流的安全事件关联。

---

### C4.15 量子抗性基础设施安全

通过后量子密码学和量子安全协议，为量子计算威胁准备人工智能基础设施。

 #4.15.1    Level: 3    Role: D/V
 验证人工智能基础设施是否实施了NIST批准的后量子密码算法（CRYSTALS-Kyber、CRYSTALS-Dilithium、SPHINCS+）用于密钥交换和数字签名。
 #4.15.2    Level: 3    Role: D/V
 验证量子密钥分发（QKD）系统的实施，以确保高安全性的人工智能通信，并采用量子安全密钥管理协议。
 #4.15.3    Level: 3    Role: D/V
 验证加密灵活性框架是否通过自动证书和密钥轮换，实现对新后量子算法的快速迁移。
 #4.15.4    Level: 3    Role: V
 验证量子威胁建模是否评估了人工智能基础设施对量子攻击的脆弱性，并包含有文档化的迁移时间表和风险评估。
 #4.15.5    Level: 3    Role: D/V
 验证混合经典-量子密码系统在量子过渡期间通过性能监控提供纵深防御。

---

### C4.16 机密计算与安全隔区

使用基于硬件的可信执行环境和机密计算技术保护人工智能工作负载和模型权重。

 #4.16.1    Level: 3    Role: D/V
 验证敏感的人工智能模型是否在配备加密内存和验证证明的Intel SGX隔离区、AMD SEV-SNP或ARM TrustZone中执行。
 #4.16.2    Level: 3    Role: D/V
 验证机密容器（如 Kata 容器、配备机密计算的 gVisor）是否通过硬件强制的内存加密隔离 AI 工作负载。
 #4.16.3    Level: 3    Role: D/V
 验证远程证明在加载AI模型之前通过加密证明执行环境的真实性来确认安全环境的完整性。
 #4.16.4    Level: 3    Role: D/V
 验证机密AI推理服务通过带密封模型权重的加密计算和受保护执行防止模型提取。
 #4.16.5    Level: 3    Role: D/V
 验证可信执行环境编排通过远程证明和加密通信通道管理安全隔离区的生命周期。
 #4.16.6    Level: 3    Role: D/V
 验证安全多方计算（SMPC）是否能够在不暴露个人数据集或模型参数的情况下，实现协作式人工智能训练。

---

### C4.17 零知识基础设施

实现零知识证明系统，用于隐私保护的人工智能验证和认证，且不泄露敏感信息。

 #4.17.1    Level: 3    Role: D/V
 验证零知识证明（ZK-SNARKs，ZK-STARKs）在不暴露模型权重或训练数据的情况下，验证AI模型完整性和训练来源。
 #4.17.2    Level: 3    Role: D/V
 验证基于零知识（ZK）的认证系统是否能够在不泄露身份相关信息的情况下，实现对人工智能服务的隐私保护用户验证。
 #4.17.3    Level: 3    Role: D/V
 验证私有集合交集（PSI）协议在联邦人工智能中实现安全数据匹配且不暴露各自数据集。
 #4.17.4    Level: 3    Role: D/V
 验证零知识机器学习（ZKML）系统能够通过密码学证明正确计算，实现可验证的人工智能推理。
 #4.17.5    Level: 3    Role: D/V
 验证ZK-rollups通过批量验证和降低计算开销，实现可扩展且保护隐私的AI交易处理。

---

### C4.18 侧信道攻击预防

保护人工智能基础设施，防止通过时间、功率、电磁和缓存侧信道攻击泄露敏感信息。

 #4.18.1    Level: 3    Role: D/V
 验证AI推理时间是否通过使用常数时间算法和填充进行了归一化，以防止基于时间的模型提取攻击。
 #4.18.2    Level: 3    Role: D/V
 验证功率分析防护是否包含噪声注入、电源线滤波和随机执行模式，以保护人工智能硬件。
 #4.18.3    Level: 3    Role: D/V
 验证基于缓存的侧信道缓解是否使用缓存分区、随机化和刷新指令来防止信息泄露。
 #4.18.4    Level: 3    Role: D/V
 确认电磁辐射防护包括屏蔽、信号滤波和随机化处理，以防止类似TEMPEST的攻击。
 #4.18.5    Level: 3    Role: D/V
 验证微架构侧信道防御措施是否包括推测执行控制和内存访问模式混淆。

---

### C4.19 神经形态与专用人工智能硬件安全

保障新兴的人工智能硬件架构安全，包括神经形态芯片、FPGA、定制ASIC和光学计算系统。

 #4.19.1    Level: 3    Role: D/V
 验证神经形态芯片安全性包括脉冲模式加密、突触权重保护和基于硬件的学习规则验证。
 #4.19.2    Level: 3    Role: D/V
 验证基于FPGA的人工智能加速器是否实现了比特流加密、防篡改机制以及带有认证更新的安全配置加载。
 #4.19.3    Level: 3    Role: D/V
 验证定制ASIC安全性是否包括片上安全处理器、硬件根信任和带防篡改检测的安全密钥存储。
 #4.19.4    Level: 3    Role: D/V
 验证光计算系统是否实现了量子安全的光学加密、安全的光子交换和受保护的光信号处理。
 #4.19.5    Level: 3    Role: D/V
 验证混合模拟-数字人工智能芯片包括安全的模拟计算、受保护的权重存储以及经过认证的模拟到数字转换。

---

### C4.20 隐私保护计算基础设施

为隐私保护计算实施基础设施控制，以在人工智能处理和分析过程中保护敏感数据。

 #4.20.1    Level: 3    Role: D/V
 验证同态加密基础设施支持对敏感AI工作负载进行加密计算，同时具备密码完整性验证和性能监控功能。
 #4.20.2    Level: 3    Role: D/V
 验证私有信息检索系统是否通过加密保护访问模式，实现无需泄露查询模式的数据库查询。
 #4.20.3    Level: 3    Role: D/V
 验证安全多方计算协议能够实现隐私保护的人工智能推理，而不会暴露单个输入或中间计算过程。
 #4.20.4    Level: 3    Role: D/V
 验证隐私保护密钥管理包括分布式密钥生成、门限密码学和带有硬件支持保护的安全密钥轮换。
 #4.20.5    Level: 3    Role: D/V
 通过批处理、缓存和硬件加速验证隐私保护计算性能的优化，同时保持密码学安全保证。

---

### C4.15 代理框架云集成安全与混合部署

具有混合本地/云架构的云集成代理框架的安全控制。

 #4.15.1    Level: 1    Role: D/V
 验证云存储集成是否使用端到端加密，并且密钥管理由代理控制。
 #4.15.2    Level: 2    Role: D/V
 验证混合部署的安全边界是否明确定义，并使用加密通信通道。
 #4.15.3    Level: 2    Role: D/V
 验证云资源访问是否包含零信任验证和持续身份验证。
 #4.15.4    Level: 3    Role: D/V
 通过对存储位置进行加密证明，验证数据驻留要求的执行情况。
 #4.15.5    Level: 3    Role: D/V
 验证云提供商的安全评估是否包括针对代理的威胁建模和风险评估。

---

### 参考文献

NIST Cybersecurity Framework 2.0
CIS Controls v8
OWASP Container Security Verification Standard
Kubernetes Security Best Practices
SLSA Supply Chain Security Framework
NIST SP 800-190: Application Container Security Guide
Cloud Security Alliance: Cloud Controls Matrix
ENISA: Secure Infrastructure Design
NIST SP 800-53: Security Controls for Federal Information Systems
ISO 27001:2022 Information Security Management
NIST AI Risk Management Framework
CIS Kubernetes Benchmark
FIPS 140-2 Security Requirements
NIST SP 800-207: Zero Trust Architecture
IEEE 2857: Privacy Engineering for AI Systems
NIST SP 800-161: Cybersecurity Supply Chain Risk Management
NIST Post-Quantum Cryptography Standards
Intel SGX Developer Guide
AMD SEV-SNP White Paper
ARM TrustZone Technology
ZK-SNARKs: A Gentle Introduction
NIST SP 800-57: Cryptographic Key Management
Side-Channel Attack Countermeasures
Neuromorphic Computing Security Challenges
FPGA Security: Fundamentals, Evaluation, and Countermeasures
Microsoft SEAL: Homomorphic Encryption Library
HElib: Homomorphic Encryption Library
PALISADE Lattice Cryptography Library
Differential Privacy: A Survey of Results
Secure Aggregation for Federated Learning
Private Information Retrieval: Concepts and Constructions

## C5 人工智能组件与用户的访问控制与身份管理

### 控制目标

针对 AI 系统的有效访问控制需要强大的身份管理、上下文感知的授权以及遵循零信任原则的运行时执行。这些控制措施确保人类、服务和自主代理仅在明确授予的范围内与模型、数据和计算资源交互，并具备持续的验证和审计能力。

---

### C5.1 身份管理与身份验证

为所有实体建立基于加密的身份，并对特权操作实施多因素身份验证。

 #5.1.1    Level: 1    Role: D/V
 验证所有人类用户和服务主体均通过集中式企业身份提供者（IdP）使用 OIDC/SAML 协议进行身份验证，并采用唯一的身份到令牌映射（禁止共享账户或凭据）。
 #5.1.2    Level: 1    Role: D/V
 验证高风险操作（模型部署、权重导出、训练数据访问、生产配置更改）是否需要多因素认证或带有会话重新验证的升级认证。
 #5.1.3    Level: 2    Role: D
 在新任负责人获得生产系统访问权限之前，确保其身份验证符合 NIST 800-63-3 IAL-2 或同等标准。
 #5.1.4    Level: 2    Role: V
 验证访问审查是否按季度进行，并具备自动检测休眠账户、强制凭证轮换及停用工作流程。
 #5.1.5    Level: 3    Role: D/V
 验证联合AI代理通过签名的JWT断言进行身份验证，该断言的最大有效期为24小时并包含来源的加密证明。

---

### C5.2 资源授权与最小权限原则

为所有人工智能资源实施细粒度访问控制，采用明确的权限模型和审计追踪。

 #5.2.1    Level: 1    Role: D/V
 验证每个 AI 资源（数据集、模型、端点、向量集合、嵌入索引、计算实例）是否实施基于角色的访问控制，且具有显式的允许列表和默认拒绝策略。
 #5.2.2    Level: 1    Role: D/V
 验证服务账户默认执行最小权限原则，初始为只读权限，且写权限需有书面业务理由。
 #5.2.3    Level: 1    Role: V
 验证所有访问控制修改均与已批准的变更请求相关联，并以不可篡改的方式记录，包括时间戳、执行者身份、资源标识符和权限差异。
 #5.2.4    Level: 2    Role: D
 验证数据分类标签（PII、PHI、出口管制、专有）能否自动传播到派生资源（嵌入、提示缓存、模型输出），并确保策略执行一致。
 #5.2.5    Level: 2    Role: D/V
 验证未授权访问尝试和权限升级事件是否在5分钟内通过上下文元数据触发实时警报到SIEM系统。

---

### C5.3 动态策略评估

部署基于属性的访问控制（ABAC）引擎，以实现具有审计能力的上下文感知授权决策。

 #5.3.1    Level: 1    Role: D/V
 验证授权决策是否外部化到通过加密完整性保护的认证 API 可访问的专用策略引擎（如 OPA、Cedar 或同等引擎）。
 #5.3.2    Level: 1    Role: D/V
 验证策略在运行时评估动态属性，包括用户安全等级、资源敏感性分类、请求上下文、租户隔离和时间限制。
 #5.3.3    Level: 2    Role: D
 验证策略定义在生产部署前已通过版本控制、同行评审，并通过CI/CD流水线中的自动化测试进行验证。
 #5.3.4    Level: 2    Role: V
 验证策略评估结果包含结构化的决策依据，并传输到SIEM系统以进行关联分析和合规报告。
 #5.3.5    Level: 3    Role: D/V
 验证策略缓存的生存时间（TTL）值，对于高敏感性资源不超过5分钟，对于具有缓存失效功能的标准资源不超过1小时。

---

### C5.4 查询时安全执行

通过强制过滤和行级安全策略实施数据库层的安全控制。

 #5.4.1    Level: 1    Role: D/V
 验证所有向量数据库和SQL查询均包含强制性安全过滤器（租户ID、敏感性标签、用户范围），且这些过滤器在数据库引擎层面强制执行，而非在应用代码中。
 #5.4.2    Level: 1    Role: D/V
 验证所有向量数据库、搜索索引和训练数据集中是否启用了行级安全（RLS）策略和字段级掩码，并且支持策略继承。
 #5.4.3    Level: 2    Role: D
 验证失败的授权评估将通过立即中止查询并返回明确的授权错误代码，而不是返回空结果集，从而防止“混淆代理攻击”。
 #5.4.4    Level: 2    Role: V
 验证策略评估延迟是否被持续监控，并针对可能导致授权绕过的超时条件设置了自动警报。
 #5.4.5    Level: 3    Role: D/V
 验证查询重试机制是否重新评估授权策略，以考虑活动用户会话中的动态权限变更。

---

### C5.5 输出过滤与数据丢失防护

部署后处理控制措施，以防止AI生成内容中的未经授权数据泄露。

 #5.5.1    Level: 1    Role: D/V
 验证推理后过滤机制是否扫描并编辑未经授权的个人身份信息（PII）、机密信息和专有数据，然后再将内容交付给请求者。
 #5.5.2    Level: 1    Role: D/V
 验证模型输出中的引用、参考文献和来源归属是否符合调用者权限，并在检测到未授权访问时将其移除。
 #5.5.3    Level: 2    Role: D
 根据用户权限级别和数据分类，验证是否强制执行输出格式限制（经过清理的PDF、去元数据的图像、批准的文件类型）。
 #5.5.4    Level: 2    Role: V
 验证润色算法是否具有确定性，受版本控制，并保持审计日志以支持合规调查和取证分析。
 #5.5.5    Level: 3    Role: V
 验证高风险涂黑事件是否生成包含原始内容加密哈希的自适应日志，以便进行取证检索且不泄露数据。

---

### C5.6 多租户隔离

确保共享人工智能基础设施中租户之间的加密和逻辑隔离。

 #5.6.1    Level: 1    Role: D/V
 验证内存空间、嵌入存储、缓存条目和临时文件是否按租户进行命名空间隔离，并在租户删除或会话终止时进行安全清除。
 #5.6.2    Level: 1    Role: D/V
 验证每个API请求是否包含经身份验证的租户标识符，并通过加密方式根据会话上下文和用户权限进行验证。
 #5.6.3    Level: 2    Role: D
 验证网络策略是否在服务网格和容器编排平台中对跨租户通信实施默认拒绝规则。
 #5.6.4    Level: 3    Role: D
 验证每个租户的加密密钥是否唯一，支持客户管理密钥（CMK），并确保租户数据存储之间的密码学隔离。

---

### C5.7 自主代理授权

通过作用域能力令牌和持续授权控制 AI 代理和自主系统的权限。

 #5.7.1    Level: 1    Role: D/V
 验证自主代理是否接收到明确定义允许操作、可访问资源、时间限制和操作约束范围的能力令牌。
 #5.7.2    Level: 1    Role: D/V
 验证高风险功能（文件系统访问、代码执行、外部 API 调用、金融交易）默认被禁用，并且激活这些功能需要有明确的业务理由和授权。
 #5.7.3    Level: 2    Role: D
 验证能力令牌是否绑定到用户会话，包含加密完整性保护，并确保它们不能在离线场景中被持久化或重用。
 #5.7.4    Level: 2    Role: V
 验证代理启动的操作通过ABAC策略引擎进行二次授权，包含完整的上下文评估和审计日志记录。
 #5.7.5    Level: 3    Role: V
 验证代理错误条件和异常处理是否包含能力范围信息，以支持事件分析和取证调查。

---

### 参考文献

#### 标准与框架

NIST SP 800-63-3: Digital Identity Guidelines
Zero Trust Architecture – NIST SP 800-207
OWASP Application Security Verification Standard (AISVS)
​
#### 实施指南

Identity and Access Management in the AI Era: 2025 Guide – IDSA
Attribute-Based Access Control with OPA – Permify
How We Designed Cedar to Be Intuitive, Fast, and Safe – AWS
​
#### 人工智能专项安全

Row Level Security in Vector DBs for RAG – Bluetuple.ai
Tenant Isolation in Multi-Tenant Systems – WorkOS
Handling AI Agent Permissions – Stytch
OWASP Top 10 for Large Language Model Applications

## C6 模型、框架与数据的供应链安全

### 控制目标

人工智能供应链攻击利用第三方模型、框架或数据集植入后门、偏见或可利用的代码。这些控制措施提供端到端的溯源、漏洞管理和监控，以保护整个模型生命周期。

---

### C6.1 预训练模型审查与出处

在进行任何微调或部署之前，评估并验证第三方模型的来源、许可证及隐藏行为。

 #6.1.1    Level: 1    Role: D/V
 确认每个第三方模型工件都包含一个签名的来源记录，标明源代码仓库和提交哈希。
 #6.1.2    Level: 1    Role: D/V
 确保在导入模型之前，使用自动化工具扫描模型中的恶意层或特洛伊触发器。
 #6.1.3    Level: 2    Role: D
 验证迁移学习微调是否通过对抗性评估来检测隐藏行为。
 #6.1.4    Level: 2    Role: V
 验证模型许可、出口控制标签和数据来源声明是否已记录在 ML-BOM 条目中。
 #6.1.5    Level: 3    Role: D/V
 验证高风险模型（公开上传的权重、未经验证的创建者）在人工审查和批准之前保持隔离状态。

---

### C6.2 框架与库扫描

持续扫描机器学习框架和库中的公共漏洞（CVE）及恶意代码，以保持运行时堆栈的安全。

 #6.2.1    Level: 1    Role: D/V
 确认持续集成（CI）流水线对人工智能框架和关键库运行依赖扫描器。
 #6.2.2    Level: 1    Role: D/V
 验证关键漏洞（CVSS ≥ 7.0）是否会阻止推广到生产镜像。
 #6.2.3    Level: 2    Role: D
 验证静态代码分析是否在分叉或供应商提供的机器学习库上运行。
 #6.2.4    Level: 2    Role: V
 验证框架升级提案是否包含引用公共CVE源的安全影响评估。
 #6.2.5    Level: 3    Role: V
 验证运行时传感器是否会对偏离签名软件物料清单（SBOM）的意外动态库加载发出警报。

---

### C6.3 依赖固定与验证

将每个依赖固定到不可变的摘要，并复现构建以保证产物一致且未被篡改。

 #6.3.1    Level: 1    Role: D/V
 验证所有包管理器通过锁文件强制执行版本固定。
 #6.3.2    Level: 1    Role: D/V
 验证容器引用中使用的是不可变摘要而非可变标签。
 #6.3.3    Level: 2    Role: D
 验证可复现构建检查是否在持续集成运行之间比较哈希值以确保输出一致。
 #6.3.4    Level: 2    Role: V
 验证构建证明是否存储了18个月以确保审计可追溯性。
 #6.3.5    Level: 3    Role: D
 验证过期的依赖项是否会触发自动拉取请求，以更新或分叉固定版本。

---

### C6.4 可信来源执行

仅允许从经过密码学验证的、组织批准的来源下载工件，阻止所有其他来源。

 #6.4.1    Level: 1    Role: D/V
 验证模型权重、数据集和容器是否仅从批准的域名或内部注册中心下载。
 #6.4.2    Level: 1    Role: D/V
 验证 Sigstore/Cosign 签名以确认发布者身份，然后再将工件缓存到本地。
 #6.4.3    Level: 2    Role: D
 验证出口代理阻止未经身份验证的工件下载，以执行可信源策略。
 #6.4.4    Level: 2    Role: V
 验证仓库允许列表是否每季度审核一次，并附有每个条目的业务合理性证据。
 #6.4.5    Level: 3    Role: V
 验证策略违规是否会触发对工件的隔离以及依赖流水线运行的回滚。

---

### C6.5 第三方数据集风险评估

评估外部数据集的投毒、偏见和法律合规性，并在其整个生命周期内进行监控。

 #6.5.1    Level: 1    Role: D/V
 验证外部数据集是否经过投毒风险评分（例如，数据指纹识别、异常值检测）。
 #6.5.2    Level: 1    Role: D
 确认在数据集批准之前已计算偏差指标（人口统计平等、机会均等）。
 #6.5.3    Level: 2    Role: V
 验证数据集的来源和许可条款是否已记录在ML-BOM条目中。
 #6.5.4    Level: 2    Role: V
 验证定期监控是否能检测托管数据集中的漂移或损坏。
 #6.5.5    Level: 3    Role: D
 确保在训练之前通过自动清理移除禁止内容（版权信息、个人身份信息）。

---

### C6.6 供应链攻击监控

通过CVE信息源、审计日志分析和红队模拟，及早检测供应链威胁。

 #6.6.1    Level: 1    Role: V
 验证 CI/CD 审计日志是否传输到 SIEM，用于检测异常的软件包拉取或被篡改的构建步骤。
 #6.6.2    Level: 2    Role: D
 确认事件响应剧本包含被攻破模型或库的回滚程序。
 #6.6.3    Level: 3    Role: V
 验证威胁情报增强是否在警报分类中标记了特定于机器学习的指标（例如，模型中毒的IoC）。

---

### C6.7 模型工件的机器学习构件清单 (ML-BOM)

生成并签署详细的特定于机器学习的软件物料清单（ML-BOM），以便下游消费者在部署时能够验证组件的完整性。

 #6.7.1    Level: 1    Role: D/V
 验证每个模型工件是否发布了 ML-BOM，列出了数据集、权重、超参数和许可。
 #6.7.2    Level: 1    Role: D/V
 验证在持续集成（CI）中 ML-BOM 生成和 Cosign 签名是自动化的，并且是合并所必需的。
 #6.7.3    Level: 2    Role: D
 验证如果任何组件元数据（哈希值、许可证）缺失，ML-BOM 完整性检查是否会导致构建失败。
 #6.7.4    Level: 2    Role: V
 验证下游使用者是否可以通过API查询ML-BOM，以在部署时验证导入的模型。
 #6.7.5    Level: 3    Role: V
 验证机器学习物料清单（ML-BOMs）是否进行了版本控制和差异比较，以检测未经授权的修改。

---

### 参考文献

ML Supply Chain Compromise – MITRE ATLAS
Supply‑chain Levels for Software Artifacts (SLSA)
CycloneDX – Machine Learning Bill of Materials
What is Data Poisoning? – SentinelOne
Transfer Learning Attack – OWASP ML Security Top 10
AI Data Security Best Practices – CISA
Secure CI/CD Supply Chain – Sumo Logic
AI & Transparency: Protect ML Models – ReversingLabs
SBOM Overview – CISA
Training Data Poisoning Guide – Lakera.ai
Dependency Pinning for Reproducible Python – Medium

## C7 模型行为、输出控制与安全保障

### 控制目标

模型输出必须具备结构化、可靠、安全、可解释且在生产环境中持续监控。这样做可以减少幻觉现象、隐私泄露、有害内容和失控行为，同时提升用户信任度和合规性。

---

### C7.1 输出格式强制执行

严格的模式、受限的解码和下游验证在内容传播前阻止格式错误或恶意内容。

 #7.1.1    Level: 1    Role: D/V
 验证系统提示中是否提供了响应模式（例如，JSON模式），并且每个输出都自动进行验证；不符合规范的输出将触发修复或拒绝。
 #7.1.2    Level: 1    Role: D/V
 验证已启用约束解码（停止标记、正则表达式、最大令牌数）以防止溢出或提示注入侧信道。
 #7.1.3    Level: 2    Role: D/V
 验证下游组件将输出视为不可信，并根据模式或注入安全的反序列化器对其进行验证。
 #7.1.4    Level: 3    Role: V
 验证不当输出事件是否被记录、速率限制并显示在监控中。

---

### C7.2 幻觉检测与缓解

不确定性估计和后备策略遏制了虚构答案。

 #7.2.1    Level: 1    Role: D/V
 确认基于单词级别的对数概率、集成自洽性或微调的幻觉检测器为每个答案分配置信度评分。
 #7.2.2    Level: 1    Role: D/V
 验证低于可配置置信度阈值的响应是否触发回退工作流（例如，检索增强生成、二级模型或人工审核）。
 #7.2.3    Level: 2    Role: D/V
 确认幻觉事件已标记根本原因元数据，并被送入事后分析和微调流程。
 #7.2.4    Level: 3    Role: D/V
 确认在重大模型或知识库更新后阈值和检测器已重新校准。
 #7.2.5    Level: 3    Role: V
 验证仪表盘可视化是否跟踪幻觉率。

---

### C7.3 输出安全与隐私过滤

策略过滤器和红队覆盖保护用户及机密数据。

 #7.3.1    Level: 1    Role: D/V
 验证生成前和生成后分类器是否阻止符合政策的仇恨、骚扰、自残、极端主义和性露骨内容。
 #7.3.2    Level: 1    Role: D/V
 验证在每个响应中是否运行了PII/PCI检测和自动编辑；违规情况将引发隐私事件。
 #7.3.3    Level: 2    Role: D
 验证机密性标签（例如，商业秘密）是否在多模态间传播，以防止在文本、图像或代码中泄露。
 #7.3.4    Level: 3    Role: D/V
 验证过滤器绕过尝试或高风险分类是否需要二次审批或用户重新认证。
 #7.3.5    Level: 3    Role: D/V
 验证过滤阈值是否反映法律管辖区及用户年龄/角色上下文。

---

### C7.4 输出与操作限制

速率限制和审批关卡防止滥用和过度自治。

 #7.4.1    Level: 1    Role: D
 验证每个用户和每个 API 密钥的配额是否限制请求、令牌和费用，并在遇到 429 错误时采用指数退避。
 #7.4.2    Level: 1    Role: D/V
 验证特权操作（文件写入、代码执行、网络调用）是否需要基于策略的批准或人工介入。
 #7.4.3    Level: 2    Role: D/V
 验证跨模态一致性检查确保为同一请求生成的图像、代码和文本不能被用于走私恶意内容。
 #7.4.4    Level: 2    Role: D
 验证代理委托深度、递归限制和允许的工具列表是否被明确配置。
 #7.4.5    Level: 3    Role: V
 验证限制违反是否触发结构化安全事件以供SIEM摄取。

---

### C7.5 输出可解释性

透明信号提高用户信任和内部调试能力。

 #7.5.1    Level: 2    Role: D/V
 确认在风险评估认为合适时，向用户展示置信度评分或简要推理摘要。
 #7.5.2    Level: 2    Role: D/V
 验证生成的解释避免泄露敏感的系统提示或专有数据。
 #7.5.3    Level: 3    Role: D
 验证系统是否捕获了令牌级别的对数概率或注意力图，并将其存储以供授权检查。
 #7.5.4    Level: 3    Role: V
 确保可解释性工件与模型发布一起进行版本控制，以便审计。

---

### C7.6 监控集成

实时可观测性实现了开发与生产之间的闭环。

 #7.6.1    Level: 1    Role: D
 验证指标（模式违规、幻觉率、毒性、个人身份信息泄露、延迟、成本）是否流向中央监控平台。
 #7.6.2    Level: 1    Role: V
 验证每个安全指标是否定义了警报阈值，并且具有值班升级路径。
 #7.6.3    Level: 2    Role: V
 验证仪表板是否将输出异常与模型/版本、功能标志和上游数据变化相关联。
 #7.6.4    Level: 2    Role: D/V
 验证监控数据是否反馈回文档化的MLOps工作流中，用于重新训练、微调或规则更新。
 #7.6.5    Level: 3    Role: V
 确保对监控管道进行渗透测试并实施访问控制，以避免敏感日志泄露。

---

### 7.7 生成媒体安全措施

通过执行政策约束、输出验证和可追溯性，确保人工智能系统不生成非法、有害或未经授权的媒体内容。

 #7.7.1    Level: 1    Role: D/V
 验证系统提示和用户指令是否明确禁止生成非法、有害或未经同意的深度伪造媒体（例如，图像、视频、音频）。
 #7.7.2    Level: 2    Role: D/V
 验证提示是否经过筛选，以防止生成冒充、性露骨的深度伪造内容或未经同意描绘真实个人的媒体。
 #7.7.3    Level: 2    Role: V
 验证系统是否使用感知哈希、水印检测或指纹识别来防止未经授权的版权所有媒体复制。
 #7.7.4    Level: 3    Role: D/V
 验证所有生成的媒体是否经过加密签名、水印处理，或嵌入防篡改的溯源元数据，以实现下游可追溯性。
 #7.7.5    Level: 3    Role: V
 验证绕过尝试（例如，提示混淆、俚语、对抗性措辞）是否被检测、记录并限速；重复滥用情况应向监控系统报告。

### 参考文献

NIST AI Risk Management Framework
ISO/IEC 42001:2023 – AI Management System
OWASP Top-10 for Large Language Model Applications (2025)
Improper Output Handling – OWASP LLM05:2025
Practical Techniques to Constrain LLM Output
Dataiku – Structured Text Generation Guide
VL-Uncertainty: Detecting Hallucinations
HaDeMiF: Hallucination Detection & Mitigation
Building Confidence in LLM Outputs
Explainable AI & LLMs
LLM Red-Teaming Guide
Sensitive Information Disclosure in LLMs
LangChain – Chat Model Rate Limiting
OpenAI Rate-Limit & Exponential Back-off
Arize AI – LLM Observability Platform

## C8 存储、嵌入和向量数据库安全

### 控制目标

嵌入和向量存储作为现代人工智能系统的“实时记忆”，持续接收用户提供的数据，并通过检索增强生成（RAG）将其呈现在模型上下文中。如果不加以管理，这种记忆可能泄露个人身份信息（PII）、违反用户同意，或被逆向推断以还原原始文本。本控制类别的目标是加强记忆管道和向量数据库的安全，使访问权限遵循最小特权原则，嵌入具有隐私保护功能，存储的向量能够根据需求过期或被撤销，并确保每个用户的记忆不污染其他用户的提示或生成内容。

---

### C8.1 内存和RAG索引的访问控制

对每个向量集合实施细粒度访问控制。

 #8.1.1    Level: 1    Role: D/V
 验证行级/命名空间级访问控制规则是否限制了每个租户、集合或文档标签的插入、删除和查询操作。
 #8.1.2    Level: 1    Role: D/V
 验证 API 密钥或 JWT 是否包含范围限定的声明（例如，集合 ID、操作动词），并且至少每季度进行一次轮换。
 #8.1.3    Level: 2    Role: D/V
 验证特权升级尝试（例如，跨命名空间相似性查询）是否在5分钟内被检测到并记录到SIEM中。
 #8.1.4    Level: 2    Role: D/V
 验证向量数据库审计日志是否包含主体标识符、操作、向量ID/命名空间、相似度阈值和结果数量。
 #8.1.5    Level: 3    Role: V
 确保在引擎升级或索引分片规则更改时，对访问决策进行绕过缺陷测试。

---

### C8.2 嵌入清理与验证

在向量化之前，对文本进行个人身份信息（PII）预筛查，进行编辑或假名化，并可选择性地对嵌入向量进行后处理，以去除残留信号。

 #8.2.1    Level: 1    Role: D/V
 验证通过自动分类器检测到的个人身份信息（PII）和受监管数据，并在嵌入之前进行掩码处理、标记化或丢弃。
 #8.2.2    Level: 1    Role: D
 验证嵌入管道是否会拒绝或隔离包含可执行代码或非 UTF-8 文本的输入，这些内容可能会污染索引。
 #8.2.3    Level: 2    Role: D/V
 验证是否对距离任何已知个人身份信息（PII）标记低于可配置阈值的句子嵌入应用了局部或度量差分隐私净化。
 #8.2.4    Level: 2    Role: V
 验证清理效果（例如，个人身份信息去除的召回率、语义漂移）至少每半年通过基准语料库进行验证。
 #8.2.5    Level: 3    Role: D/V
 验证清理配置是否受版本控制，并且更改经过同伴审查。

---

### C8.3 内存过期、撤销与删除

GDPR“被遗忘权”及类似法律要求及时删除；因此，向量存储必须支持TTL、硬删除和墓碑机制，以确保被撤销的向量无法被恢复或重新索引。

 #8.3.1    Level: 1    Role: D/V
 验证每个向量和元数据记录是否携带由自动清理任务执行的TTL或显式保留标签。
 #8.3.2    Level: 1    Role: D/V
 验证用户发起的删除请求是否在30天内清除向量、元数据、缓存副本和衍生索引。
 #8.3.3    Level: 2    Role: D
 验证在硬件支持的情况下，逻辑删除是否紧随存储块的加密销毁，或者通过密钥库密钥销毁进行。
 #8.3.4    Level: 3    Role: D/V
 验证过期向量在过期后500毫秒内被排除在最近邻搜索结果之外。

---

### C8.4 防止嵌入反演与泄露

最近的防御方法——噪声叠加、投影网络、隐私神经元扰动和应用层加密——可以将令牌级别的反演率降低到5%以下。

 #8.4.1    Level: 1    Role: V
 验证是否存在涵盖反演攻击、成员身份攻击和属性推断攻击的正式威胁模型，并确保该模型每年进行审核。
 #8.4.2    Level: 2    Role: D/V
 验证应用层加密或可搜索加密是否能防止基础设施管理员或云工作人员直接读取向量。
 #8.4.3    Level: 3    Role: V
 验证防御参数（DP的ε，噪声σ，投影维度k）是否在隐私保护≥99%令牌保护和效用损失≤3%准确率之间达到平衡。
 #8.4.4    Level: 3    Role: D/V
 验证反转鲁棒性指标是否作为模型更新发布门控的一部分，并定义了回归预算。

---

### C8.5 用户特定内存的范围强制执行

跨租户泄露仍然是RAG的主要风险：过滤不当的相似性查询可能暴露其他客户的私有文档。

 #8.5.1    Level: 1    Role: D/V
 在传递给大语言模型（LLM）提示之前，验证每个检索查询是否经过租户/用户ID的后过滤。
 #8.5.2    Level: 1    Role: D
 验证集合名称或命名空间 ID 是否针对每个用户或租户进行了加盐处理，以防止向量跨范围发生冲突。
 #8.5.3    Level: 2    Role: D/V
 验证超过可配置距离阈值但在调用者作用域之外的相似性结果是否被丢弃并触发安全警报。
 #8.5.4    Level: 2    Role: V
 验证多租户压力测试是否模拟了试图检索超出范围文档的对抗性查询，并证明没有信息泄露。
 #8.5.5    Level: 3    Role: D/V
 验证加密密钥是否按租户隔离，确保即使物理存储共享也实现密码学隔离。

---

### C8.6 高级内存系统安全

针对复杂内存架构（包括情节记忆、语义记忆和工作记忆）制定的安全控制措施，涵盖具体的隔离和验证要求。

 #8.6.1    Level: 1    Role: D/V
 验证不同类型的记忆（情景记忆、语义记忆、工作记忆）是否具有独立的安全上下文，包括基于角色的访问控制、独立的加密密钥以及针对每种记忆类型的访问模式文档。
 #8.6.2    Level: 2    Role: D/V
 验证记忆合并过程是否包含安全验证，通过内容清理、来源验证和完整性检查，防止恶意记忆的注入，然后再存储。
 #8.6.3    Level: 2    Role: D/V
 验证内存检索查询是否经过验证和清理，以通过查询模式分析、访问控制执行和结果过滤防止未经授权的信息提取。
 #8.6.4    Level: 3    Role: D/V
 验证内存遗忘机制通过密钥删除、多次覆盖或带有验证证书的硬件安全删除，具备加密擦除保证，安全地删除敏感信息。
 #8.6.5    Level: 3    Role: D/V
 验证内存系统完整性是否通过校验和、审计日志以及当内存内容在正常操作之外发生变化时的自动警报，持续监控是否存在未经授权的修改或损坏。

---

### 参考文献

Vector database security: Pinecone – IronCore Labs
Securing the Backbone of AI: Safeguarding Vector Databases and Embeddings – Privacera
Enhancing Data Security with RBAC of Qdrant Vector Database – AI Advances
Mitigating Privacy Risks in LLM Embeddings from Embedding Inversion – arXiv
DPPN: Detecting and Perturbing Privacy-Sensitive Neurons – OpenReview
Art. 17 GDPR – Right to Erasure
Sensitive Data in Text Embeddings Is Recoverable – Tonic.ai
PII Identification and Removal – NVIDIA NeMo Docs
De-identifying Sensitive Data – Google Cloud DLP
Remove PII from Conversations Using Sensitive Information Filters – AWS Bedrock Guardrails
Think Your RAG Is Secure? Think Again – Medium
Design a Secure Multitenant RAG Inferencing Solution – Microsoft Learn
Best Practices for Multi-Tenancy RAG with Milvus – Milvus Blog

## 9 自主编排与代理行为安全

### 控制目标

确保自主或多智能体AI系统只能执行明确意图的、经过认证的、可审计的、且在限定成本和风险阈值内的操作。这可以防止自主系统被攻破、工具滥用、智能体循环检测、通信劫持、身份伪造、群体操纵及意图篡改等威胁。

---

### 9.1 代理任务规划与递归预算

限制递归计划并强制对特权操作设置人工检查点。

 #9.1.1    Level: 1    Role: D/V
 验证最大递归深度、宽度、实际运行时间、令牌数和每个代理执行的货币成本是否集中配置且版本控制。
 #9.1.2    Level: 1    Role: D/V
 验证特权或不可逆操作（例如，代码提交、资金转移）在执行前需通过可审计渠道获得明确的人类批准。
 #9.1.3    Level: 2    Role: D
 验证实时资源监控器在任何预算阈值被超出时触发断路器中断，停止任务的进一步扩展。
 #9.1.4    Level: 2    Role: D/V
 验证断路器事件是否记录了代理ID、触发条件以及捕获的计划状态以便取证审查。
 #9.1.5    Level: 3    Role: V
 验证安全测试是否涵盖预算耗尽和计划失控场景，确认在不丢失数据的情况下安全停止。
 #9.1.6    Level: 3    Role: D
 验证预算策略是否以策略即代码（policy-as-code）的形式表达，并在CI/CD中执行，以阻止配置漂移。

---

### 9.2 工具插件沙箱机制

隔离工具交互以防止未经授权的系统访问或代码执行。

 #9.2.1    Level: 1    Role: D/V
 验证每个工具/插件是否在操作系统、容器或WASM级沙箱内执行，并采用最小权限的文件系统、网络和系统调用策略。
 #9.2.2    Level: 1    Role: D/V
 验证沙箱资源配额（CPU、内存、磁盘、网络出口）和执行超时是否被强制执行并记录。
 #9.2.3    Level: 2    Role: D/V
 验证工具二进制文件或描述符是否经过数字签名；在加载之前验证签名。
 #9.2.4    Level: 2    Role: V
 验证沙箱遥测数据流向SIEM；异常情况（例如，尝试的出站连接）触发警报。
 #9.2.5    Level: 3    Role: V
 确保高风险插件在投入生产部署前经过安全审核和渗透测试。
 #9.2.6    Level: 3    Role: D/V
 验证沙箱逃逸尝试是否被自动阻止，并且涉嫌违规的插件已被隔离以待调查。

---

### 9.3 自主循环与成本边界

检测并阻止无控制的代理间递归和成本爆炸。

 #9.3.1    Level: 1    Role: D/V
 验证代理间调用是否包含跳数限制或TTL，运行时会递减并执行该限制。
 #9.3.2    Level: 2    Role: D
 验证代理是否维护唯一的调用图 ID，以识别自调用或循环模式。
 #9.3.3    Level: 2    Role: D/V
 验证累积的计算单元和支出计数器是否按请求链进行跟踪；超过限制则中止该链。
 #9.3.4    Level: 3    Role: V
 验证形式分析或模型检测是否证明了代理协议中不存在无界递归。
 #9.3.5    Level: 3    Role: D
 验证循环中断事件是否生成警报并输入持续改进指标。

---

### 9.4 协议级误用防护

在代理与外部系统之间建立安全通信通道，以防止劫持或篡改。

 #9.4.1    Level: 1    Role: D/V
 验证所有代理到工具及代理之间的消息均经过身份验证（例如，双向TLS或JWT）并端到端加密。
 #9.4.2    Level: 1    Role: D
 验证模式是否严格校验；未知字段或格式错误的消息应被拒绝。
 #9.4.3    Level: 2    Role: D/V
 验证完整性检查（MAC 或数字签名）是否涵盖了整个消息负载，包括工具参数。
 #9.4.4    Level: 2    Role: D
 验证协议层是否强制执行重放保护（随机数或时间戳窗口）。
 #9.4.5    Level: 3    Role: V
 验证协议实现是否经过模糊测试和静态分析，以检测注入或反序列化漏洞。

---

### 9.5 代理身份与防篡改性

确保操作可追溯且修改可检测。

 #9.5.1    Level: 1    Role: D/V
 验证每个代理实例是否具有唯一的加密身份（密钥对或硬件根凭证）。
 #9.5.2    Level: 2    Role: D/V
 验证所有代理操作均已签名和时间戳记录；日志包含签名以保证不可否认性。
 #9.5.3    Level: 2    Role: V
 验证防篡改日志是否存储在仅追加或一次写入的介质中。
 #9.5.4    Level: 3    Role: D
 验证身份密钥是否按照预定的计划和在发生泄露指标时进行轮换。
 #9.5.5    Level: 3    Role: D/V
 验证欺骗或密钥冲突尝试是否会立即触发受影响代理的隔离。

---

### 9.6 多智能体群体风险降低

通过隔离和正式安全建模来减轻集体行为风险。

 #9.6.1    Level: 1    Role: D/V
 验证在不同安全域中运行的代理是否在隔离的运行时沙箱或网络分段中执行。
 #9.6.2    Level: 3    Role: V
 确保群体行为在部署前经过建模，并对其活性和安全性进行形式化验证。
 #9.6.3    Level: 3    Role: D
 验证运行时监视器是否能够检测出新出现的不安全模式（例如，振荡、死锁）并启动纠正措施。

---

### 9.7 用户与工具认证/授权

为每个代理触发的操作实施强有力的访问控制。

 #9.7.1    Level: 1    Role: D/V
 验证代理作为一流主体向下游系统进行身份验证，绝不重复使用终端用户凭据。
 #9.7.2    Level: 2    Role: D
 验证细粒度授权策略是否限制代理可以调用的工具以及其可以提供的参数。
 #9.7.3    Level: 2    Role: V
 验证特权检查是否在每次调用时重新评估（持续授权），而不仅仅是在会话开始时。
 #9.7.4    Level: 3    Role: D
 验证委托权限是否会自动过期，并在超时或作用域更改后需要重新授权同意。

---

### 9.8 代理间通信安全

加密并完整性保护所有代理间消息，以防止窃听和篡改。

 #9.8.1    Level: 1    Role: D/V
 验证代理通道必须使用相互认证和完美前向保密加密（例如 TLS 1.3）。
 #9.8.2    Level: 1    Role: D
 在处理之前验证消息的完整性和来源；失败时触发警报并丢弃消息。
 #9.8.3    Level: 2    Role: D/V
 验证通信元数据（时间戳、序列号）是否已记录，以支持取证重构。
 #9.8.4    Level: 3    Role: V
 验证形式化验证或模型检查是否确认协议状态机无法被驱动进入不安全状态。

---

### 9.9 意图验证与约束执行

验证代理的行动是否符合用户的陈述意图和系统约束。

 #9.9.1    Level: 1    Role: D
 验证预执行约束求解器是否根据硬编码的安全和政策规则检查所提议的行动。
 #9.9.2    Level: 2    Role: D/V
 验证高影响操作（财务、破坏性、隐私敏感）是否需要发起用户的明确意图确认。
 #9.9.3    Level: 2    Role: V
 验证后置条件检查，确保已完成的操作达到预期效果且无副作用；若出现差异则触发回滚。
 #9.9.4    Level: 3    Role: V
 验证形式方法（例如，模型检查、定理证明）或基于属性的测试能够证明代理计划满足所有声明的约束条件。
 #9.9.5    Level: 3    Role: D
 验证意图不匹配或约束违规事件是否用于持续改进循环和威胁情报共享。

---

### 9.10 代理推理策略安全

安全选择和执行包括ReAct、链式思维和思维树方法在内的不同推理策略。

 #9.10.1    Level: 1    Role: D/V
 验证推理策略选择是否使用确定性标准（输入复杂度、任务类型、安全上下文），并确保在相同安全上下文中，输入相同会产生相同的策略选择。
 #9.10.2    Level: 1    Role: D/V
 验证每种推理策略（ReAct、Chain-of-Thought、Tree-of-Thoughts）是否具有专门的输入验证、输出净化和针对其认知方法的执行时间限制。
 #9.10.3    Level: 2    Role: D/V
 验证推理策略转换是否记录了完整的上下文，包括输入特征、选择标准值和执行元数据，以便审计追踪重建。
 #9.10.4    Level: 2    Role: D/V
 验证思维树推理包含分支剪枝机制，当检测到策略违规、资源限制或安全边界时终止探索。
 #9.10.5    Level: 2    Role: D/V
 确认ReAct（推理-行动-观察）循环在每个阶段都包含验证检查点：推理步骤验证、行动授权以及观察清理，然后才能继续进行。
 #9.10.6    Level: 3    Role: D/V
 验证推理策略的性能指标（执行时间、资源使用、输出质量）是否通过自动警报进行监控，当指标偏离配置的阈值时触发警报。
 #9.10.7    Level: 3    Role: D/V
 验证结合多种策略的混合推理方法是否保持所有组成策略的输入验证和输出约束，且不绕过任何安全控制。
 #9.10.8    Level: 3    Role: D/V
 验证推理策略的安全测试包括使用格式错误的输入进行模糊测试，设计用以强制策略切换的对抗性提示，以及对每种认知方法进行边界条件测试。

---

### 9.11 代理生命周期状态管理与安全

使用密码学审计轨迹和定义的恢复程序，实现安全代理初始化、状态转换和终止。

 #9.11.1    Level: 1    Role: D/V
 验证代理初始化是否包括使用硬件支持的凭证建立加密身份，以及包含代理ID、时间戳、配置哈希和初始化参数的不可变启动审计日志。
 #9.11.2    Level: 2    Role: D/V
 验证代理状态转换是否经过加密签名、时间戳记录，并完整记录上下文，包括触发事件、前一状态哈希、新状态哈希以及执行的安全验证。
 #9.11.3    Level: 2    Role: D/V
 验证代理关闭程序包括使用密码擦除或多遍覆盖进行安全内存擦除、凭证吊销并通知证书颁发机构，以及生成防篡改终止证书。
 #9.11.4    Level: 3    Role: D/V
 验证代理恢复机制使用加密校验和（至少SHA-256）来验证状态完整性，并在检测到损坏时回滚到已知的良好状态，同时配备自动警报和人工批准要求。
 #9.11.5    Level: 3    Role: D/V
 验证代理持久机制是否使用每个代理的 AES-256 密钥对敏感状态数据进行加密，并在可配置的计划（最长90天）上实施安全密钥轮换，同时实现零停机部署。

---

### 9.12 工具集成安全框架

针对动态工具加载、执行和结果验证的安全控制，包含明确的风险评估和审批流程。

 #9.12.1    Level: 1    Role: D/V
 验证工具描述符是否包含指定所需权限（读/写/执行）、风险等级（低/中/高）、资源限制（CPU、内存、网络）和验证要求的安全元数据，并在工具清单中进行记录。
 #9.12.2    Level: 1    Role: D/V
 验证工具执行结果是否符合预期的模式（JSON Schema，XML Schema）和安全策略（输出清理，数据分类），并在超时限制和错误处理程序中进行集成前进行校验。
 #9.12.3    Level: 2    Role: D/V
 验证工具交互日志是否包含详细的安全上下文，包括权限使用情况、数据访问模式、执行时间、资源消耗和返回代码，并采用结构化日志记录以便于SIEM集成。
 #9.12.4    Level: 2    Role: D/V
 验证动态工具加载机制是否使用公钥基础设施 (PKI) 验证数字签名，并在执行前实现带有沙箱隔离和权限验证的安全加载协议。
 #9.12.5    Level: 3    Role: D/V
 验证工具安全评估能否自动触发针对新版本，且包含必需的审批关卡，包括静态分析、动态测试和安全团队审核，并具备有文档记录的审批标准和服务水平协议（SLA）要求。

---

#### 参考文献

MITRE ATLAS tactics ML09
Circuit-breaker research for AI agents — Zou et al., 2024
Trend Micro analysis of sandbox escapes in AI agents — Park, 2025
Auth0 guidance on human-in-the-loop authorization for agents — Martinez, 2025
Medium deep-dive on MCP & A2A protocol hijacking — ForAISec, 2025
Rapid7 fundamentals on spoofing attack prevention — 2024
Imperial College verification of swarm systems — Lomuscio et al.
NIST AI Risk Management Framework 1.0, 2023
WIRED security briefing on encryption best practices, 2024
OWASP Top 10 for LLM Applications, 2025
Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS
[How Is LLM Reasoning Distracted by Irrelevant Context?
An Analysis Using a Controlled Benchmark](https://www.arxiv.org/pdf/2505.18761)
Large Language Model Sentinel: LLM Agent for Adversarial Purification
Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents

## 10 对抗鲁棒性与隐私防护

### 控制目标

确保人工智能模型在面对规避、推断、提取或投毒攻击时，保持可靠性、隐私保护和抗滥用能力。

---

### 10.1 模型对齐与安全

防止产生有害或违反政策的输出。

 #10.1.1    Level: 1    Role: D/V
 验证对齐测试套件（红队提示、越狱探测器、不允许的内容）是否进行版本控制，并在每次模型发布时运行。
 #10.1.2    Level: 1    Role: D
 验证拒绝和安全完成防护栏是否被执行。
 #10.1.3    Level: 2    Role: D/V
 验证自动评估器是否测量有害内容率并标记超过设定阈值的回归。
 #10.1.4    Level: 2    Role: D
 验证反绕过训练是否有文档记录且可复现。
 #10.1.5    Level: 3    Role: V
 验证正式的政策合规性证明或认证监控是否涵盖关键领域。

---

### 10.2 对抗样本加固

提高对被操控输入的抗干扰能力。强健的对抗训练和基准评分是当前的最佳实践。

 #10.2.1    Level: 1    Role: D
 验证项目代码库中是否包含具有可复现种子的对抗训练配置。
 #10.2.2    Level: 2    Role: D/V
 验证对抗样本检测是否在生产管道中触发阻断警报。
 #10.2.4    Level: 3    Role: V
 验证经过认证的鲁棒性证明或区间界限证书是否涵盖至少最重要的关键类别。
 #10.2.5    Level: 3    Role: V
 验证回归测试使用自适应攻击确认没有可测量的鲁棒性损失。

---

### 10.3 成员推断缓解措施

限制判断某条记录是否在训练数据中的能力。差分隐私和置信度评分遮蔽仍然是已知最有效的防御方法。

 #10.3.1    Level: 1    Role: D
 验证每次查询的熵正则化或温度缩放是否减少过度自信的预测。
 #10.3.2    Level: 2    Role: D
 验证训练过程中针对敏感数据集采用了ε界限的差分隐私优化。
 #10.3.3    Level: 2    Role: V
 验证攻击模拟（影子模型或黑盒）在保留数据上的攻击AUC是否≤0.60。

---

### 10.4 模型反演抵抗

防止重建私有属性。近期调查强调输出截断和差分隐私保障作为实际防护措施。

 #10.4.1    Level: 1    Role: D
 验证敏感属性绝不直接输出；必要时，使用分桶或单向变换。
 #10.4.2    Level: 1    Role: D/V
 验证查询速率限制是否限制来自同一主体的重复自适应查询。
 #10.4.3    Level: 2    Role: D
 验证模型是否经过隐私保护噪声训练。

---

### 10.5 模型提取防御

检测和阻止未经授权的克隆。建议使用水印和查询模式分析。

 #10.5.1    Level: 1    Role: D
 验证推理网关是否执行了针对模型记忆阈值调整的全局和每个 API 密钥的速率限制。
 #10.5.2    Level: 2    Role: D/V
 验证查询熵和输入复数性统计数据是否输入到自动提取检测器中。
 #10.5.3    Level: 2    Role: V
 验证脆弱或概率性水印在针对疑似克隆体的最多1000次查询中，能够以 p < 0.01 的显著性水平被证明。
 #10.5.4    Level: 3    Role: D
 验证水印密钥和触发集是否存储在硬件安全模块中，并每年轮换。
 #10.5.5    Level: 3    Role: V
 验证提取警报事件是否包含违规查询，并且已与事件响应剧本集成。

---

### 10.6 推理时的中毒数据检测

识别并中和带有后门或被投毒的输入。

 #10.6.1    Level: 1    Role: D
 验证输入通过异常检测器（例如，STRIP、一致性评分）后再进行模型推理。
 #10.6.2    Level: 1    Role: V
 验证检测器阈值是否在干净/中毒的验证集上调整，以实现低于5%的假阳性率。
 #10.6.3    Level: 2    Role: D
 验证被标记为中毒的输入是否会触发软阻断和人工审核流程。
 #10.6.4    Level: 2    Role: V
 验证检测器是否通过自适应、无触发器后门攻击进行了压力测试。
 #10.6.5    Level: 3    Role: D
 验证检测效能指标是否已记录，并定期使用最新的威胁情报重新评估。

---

### 10.7 动态安全策略适应

基于威胁情报和行为分析的实时安全策略更新。

 #10.7.1    Level: 1    Role: D/V
 验证安全策略可以在不重启代理的情况下动态更新，同时保持策略版本的完整性。
 #10.7.2    Level: 2    Role: D/V
 验证策略更新是否由授权的安全人员进行加密签名，并在应用前进行验证。
 #10.7.3    Level: 2    Role: D/V
 验证动态策略变更是否记录了完整的审计轨迹，包括变更理由、审批链和回滚程序。
 #10.7.4    Level: 3    Role: D/V
 验证自适应安全机制是否基于风险环境和行为模式调整威胁检测的敏感度。
 #10.7.5    Level: 3    Role: D/V
 确保策略调整决策具有可解释性，并包含供安全团队审查的证据链。

---

### 10.8 基于反射的安全分析

通过代理自我反思和元认知分析进行安全验证。

 #10.8.1    Level: 1    Role: D/V
 验证代理反思机制是否包括对决策和行为的安全性自我评估。
 #10.8.2    Level: 2    Role: D/V
 验证反射输出的有效性，以防止对抗性输入操纵自我评估机制。
 #10.8.3    Level: 2    Role: D/V
 验证元认知安全分析是否识别出代理推理过程中的潜在偏见、操控或妥协。
 #10.8.4    Level: 3    Role: D/V
 验证基于反射的安全警告是否触发了增强监控和潜在的人为干预工作流程。
 #10.8.5    Level: 3    Role: D/V
 验证从安全反馈中进行的持续学习能够提升威胁检测能力，同时不降低合法功能的性能。

---

### 10.9 演化与自我改进安全

具备自我修改和进化能力的代理系统的安全控制。

 #10.9.1    Level: 1    Role: D/V
 验证自我修改能力是否仅限于具有正式验证边界的指定安全区域。
 #10.9.2    Level: 2    Role: D/V
 确保演进提案在实施前经过安全影响评估。
 #10.9.3    Level: 2    Role: D/V
 验证自我改进机制是否包含具备完整性验证的回滚功能。
 #10.9.4    Level: 3    Role: D/V
 验证元学习安全性防止改进算法的对抗操控。
 #10.9.5    Level: 3    Role: D/V
 验证递归自我改进在形式安全约束下的界限性，并通过数学证明其收敛性。

---

#### 参考文献

MITRE ATLAS adversary tactics for ML
NIST AI Risk Management Framework 1.0, 2023
OWASP Top 10 for LLM Applications, 2025
Adversarial Training: A Survey — Zhao et al., 2024
RobustBench adversarial-robustness benchmark
Membership-Inference & Model-Inversion Risk Survey, 2025
PURIFIER: Confidence-Score Defense against MI Attacks — AAAI 2023
Model-Inversion Attacks & Defenses Survey — AI Review, 2025
Comprehensive Defense Framework Against Model Extraction — IEEE TDSC 2024
Fragile Model Watermarking Survey — 2025
Data Poisoning in Deep Learning: A Survey — Zhao et al., 2025
BDetCLIP: Multimodal Prompting Backdoor Detection — Niu et al., 2024

## 11 隐私保护与个人数据管理

### 控制目标

在整个人工智能生命周期——数据收集、训练、推理和事件响应过程中，保持严格的隐私保障，确保个人数据仅在明确同意、最小必要范围、可证明的擦除以及正式的隐私保障下被处理。

---

### 11.1 匿名化与数据最小化

 #11.1.1    Level: 1    Role: D/V
 确认已删除或哈希处理直接标识符和准标识符。
 #11.1.2    Level: 2    Role: D/V
 验证自动审核是否测量k-匿名性/l-多样性，并在阈值低于策略时发出警报。
 #11.1.3    Level: 2    Role: V
 验证模型特征重要性报告，确保标识符泄露的互信息不超过ε = 0.01。
 #11.1.4    Level: 3    Role: V
 验证形式证明或合成数据认证即使在关联攻击下，重新识别风险也 ≤ 0.05。

---

### 11.2 被遗忘权与删除执行

 #11.2.1    Level: 1    Role: D/V
 验证数据主体删除请求是否在少于30天的服务级别协议内传递到原始数据集、检查点、嵌入、日志和备份。
 #11.2.2    Level: 2    Role: D
 验证“机器遗忘”流程是否通过认证的遗忘算法来物理重新训练或近似移除。
 #11.2.3    Level: 2    Role: V
 验证影子模型评估证明遗忘记录在反学习后对输出的影响少于1%。
 #11.2.4    Level: 3    Role: V
 验证删除事件是否被不可篡改地记录并且可供监管机构审计。

---

### 11.3 差分隐私保护措施

 #11.3.1    Level: 2    Role: D/V
 验证当累积 ε 超过政策阈值时，隐私损失统计仪表盘是否发出警报。
 #11.3.2    Level: 2    Role: V
 验证黑盒隐私审计估计的 ε̂ 在声明值的 10% 以内。
 #11.3.3    Level: 3    Role: V
 验证形式证明覆盖所有训练后微调和嵌入。

---

### 11.4 目的限制与范围膨胀防护

 #11.4.1    Level: 1    Role: D
 验证每个数据集和模型检查点是否携带与原始同意相符的机器可读目的标签。
 #11.4.2    Level: 1    Role: D/V
 验证运行时监视器是否检测到与声明用途不一致的查询并触发软拒绝。
 #11.4.3    Level: 3    Role: D
 验证策略即代码门控是否阻止在未经过DPIA审核的情况下将模型重新部署到新领域。
 #11.4.4    Level: 3    Role: V
 验证正式的可追溯性证明以确保每个个人数据生命周期都在获得同意的范围内。

---

### 11.5 同意管理与合法依据追踪

 #11.5.1    Level: 1    Role: D/V
 验证同意管理平台（CMP）是否记录每个数据主体的选择加入状态、用途和保留期限。
 #11.5.2    Level: 2    Role: D
 验证API是否公开了同意令牌；模型必须在推理前验证令牌范围。
 #11.5.3    Level: 2    Role: D/V
 验证被拒绝或撤回的同意在24小时内停止处理流程。

---

### 11.6 带隐私控制的联邦学习

 #11.6.1    Level: 1    Role: D
 验证客户端更新在聚合前是否采用了局部差分隐私噪声添加。
 #11.6.2    Level: 2    Role: D/V
 验证训练指标具有差分隐私，且永远不会泄露单个客户的损失。
 #11.6.3    Level: 2    Role: V
 确认启用了抗投毒聚合（例如，Krum/Trimmed-Mean）。
 #11.6.4    Level: 3    Role: V
 验证形式证明表明整体 ε 预算的效用损失小于 5。

---

#### 参考文献

GDPR & AI Compliance Best Practices
EU Parliament Study on GDPR & AI, 2020
ISO 31700-1:2023 — Privacy by Design for Consumer Products
NIST Privacy Framework 1.1 (2025 Draft)
Machine Unlearning: Right-to-Be-Forgotten Techniques
A Survey of Machine Unlearning, 2024
Auditing DP-SGD — ArXiv 2024
DP-SGD Explained — PyTorch Blog
Purpose-Limitation for AI — IJLIT 2025
Data-Protection Considerations for AI — URM Consulting
Top Consent-Management Platforms, 2025
Secure Aggregation in DP Federated Learning — ArXiv 2024

## C12 监控、日志记录与异常检测

### 控制目标

本节提供了实现对模型及其他人工智能组件所观察、执行和返回内容的实时及取证可视化的要求，以便能够检测、分类和从威胁中学习。

### C12.1 请求与响应日志记录

 #12.1.1    Level: 1    Role: D/V
 验证所有用户提示和模型响应是否都已记录适当的元数据（例如时间戳、用户ID、会话ID、模型版本）。
 #12.1.2    Level: 1    Role: D/V
 验证日志是否存储在安全的、受访问控制的存储库中，并具有适当的保留策略和备份程序。
 #12.1.3    Level: 1    Role: D/V
 验证日志存储系统是否实现了静态加密和传输加密，以保护日志中包含的敏感信息。
 #12.1.4    Level: 1    Role: D/V
 验证提示和输出中的敏感数据在记录前是否被自动删除或屏蔽，并且具有可配置的个人身份信息（PII）、凭证和专有信息的删除规则。
 #12.1.5    Level: 2    Role: D/V
 验证策略决策和安全过滤操作已被详细记录，以便对内容审核系统进行审计和调试。
 #12.1.6    Level: 2    Role: D/V
 验证日志完整性是否通过例如加密签名或只写存储得以保护。

---

### C12.2 滥用检测和报警

 #12.2.1    Level: 1    Role: D/V
 验证系统是否能够通过基于签名的检测，识别并报警已知的越狱模式、提示注入尝试和对抗性输入。
 #12.2.2    Level: 1    Role: D/V
 验证系统是否使用标准日志格式和协议与现有的安全信息与事件管理 (SIEM) 平台集成。
 #12.2.3    Level: 2    Role: D/V
 验证丰富的安全事件是否包含特定于人工智能的上下文，例如模型标识符、置信度得分和安全过滤器决策。
 #12.2.4    Level: 2    Role: D/V
 验证行为异常检测是否能识别出异常的对话模式、过度重试尝试或系统性探测行为。
 #12.2.5    Level: 2    Role: D/V
 验证实时警报机制是否在检测到潜在的政策违规或攻击尝试时通知安全团队。
 #12.2.6    Level: 2    Role: D/V
 验证是否包含自定义规则，以检测特定于人工智能的威胁模式，包括协调的越狱尝试、提示注入活动和模型提取攻击。
 #12.2.7    Level: 3    Role: D/V
 验证自动化事件响应工作流是否能够隔离被攻破的模型、阻止恶意用户，并升级处理关键安全事件。

---

### C12.3 模型漂移检测

 #12.3.1    Level: 1    Role: D/V
 验证系统是否跟踪基本性能指标，如准确率、置信度分数、延迟和错误率，涵盖模型版本和时间段。
 #12.3.2    Level: 2    Role: D/V
 验证当性能指标超过预定义的退化阈值或显著偏离基线时，自动警报是否触发。
 #12.3.3    Level: 2    Role: D/V
 验证幻觉检测监控是否能够识别并标记模型输出中包含事实错误、不一致或虚构信息的实例。

---

### C12.4 性能与行为遥测

 #12.4.1    Level: 1    Role: D/V
 验证包括请求延迟、令牌消耗、内存使用和吞吐量在内的操作指标是否被持续收集和监控。
 #12.4.2    Level: 1    Role: D/V
 验证成功率和失败率是否按错误类型及其根本原因进行分类跟踪。
 #12.4.3    Level: 2    Role: D/V
 验证资源利用监控包括GPU/CPU使用率、内存消耗和存储需求，并在阈值超限时发出警报。

---

### C12.5 人工智能事件响应计划与执行

 #12.5.1    Level: 1    Role: D/V
 验证事件响应计划是否特别针对AI相关的安全事件，包括模型受损、数据中毒和对抗性攻击。
 #12.5.2    Level: 2    Role: D/V
 确保事件响应团队能够使用专门针对人工智能的取证工具和具备相关专业知识，以调查模型行为和攻击路径。
 #12.5.3    Level: 3    Role: D/V
 验证事故后分析是否包括模型重新训练的考虑、安全过滤器的更新以及将经验教训整合到安全控制中。

---

### C12.5 人工智能性能退化检测

监控并检测人工智能模型性能和质量随时间的下降。

 #12.5.1    Level: 1    Role: D/V
 验证模型的准确率、精确率、召回率和F1分数是否持续监控并与基线阈值进行比较。
 #12.5.2    Level: 1    Role: D/V
 验证数据漂移检测是否监控可能影响模型性能的输入分布变化。
 #12.5.3    Level: 2    Role: D/V
 验证概念漂移检测是否识别输入与预期输出之间关系的变化。
 #12.5.4    Level: 2    Role: D/V
 验证性能下降是否触发自动警报并启动模型重新训练或更换工作流程。
 #12.5.5    Level: 3    Role: V
 验证性能下降的根本原因分析是否将性能下降与数据变化、基础设施问题或外部因素相关联。

---

### C12.6 有向无环图（DAG）可视化与工作流安全

保护工作流程可视化系统，防止信息泄露和篡改攻击。

 #12.6.1    Level: 1    Role: D/V
 验证DAG可视化数据在存储或传输前已被清理，以删除敏感信息。
 #12.6.2    Level: 1    Role: D/V
 验证工作流可视化访问控制，确保只有授权用户才能查看代理决策路径和推理轨迹。
 #12.6.3    Level: 2    Role: D/V
 验证DAG数据完整性通过加密签名和防篡改存储机制得到保护。
 #12.6.4    Level: 2    Role: D/V
 验证工作流可视化系统是否实现了输入验证，以防止通过精心构造的节点或边数据进行注入攻击。
 #12.6.5    Level: 3    Role: D/V
 验证实时DAG更新是否受到速率限制和验证，以防止对可视化系统的拒绝服务攻击。

---

### C12.7 主动安全行为监控

通过主动代理行为分析进行安全威胁的检测和防范。

 #12.7.1    Level: 1    Role: D/V
 验证主动代理行为在执行前通过安全验证，并集成风险评估。
 #12.7.2    Level: 2    Role: D/V
 验证自主主动触发因素是否包括安全上下文评估和威胁态势评估。
 #12.7.3    Level: 2    Role: D/V
 验证主动行为模式是否被分析，以识别潜在的安全隐患和意外后果。
 #12.7.4    Level: 3    Role: D/V
 验证安全关键的主动措施需要明确的审批链和审计跟踪。
 #12.7.5    Level: 3    Role: D/V
 验证行为异常检测是否识别可能表明受损的主动代理模式偏差。

---

### 参考文献

NIST AI Risk Management Framework 1.0 - Manage 4.1 and 4.3
ISO/IEC 42001:2023 — AI Management Systems Requirements - Annex B 6.2.6
EU AI Act — Article 12, 13, 16 and 19 on Logging and Record-keeping

## C13 人类监督、问责与治理

### 控制目标

本章节提供了维护人工监督和明确责任链的要求，确保在人工智能系统的整个生命周期中实现可解释性、透明性和伦理管理。

---

### C13.1 终止开关与覆盖机制

当观察到人工智能系统的不安全行为时，应提供关闭或回滚路径。

 #13.1.1    Level: 1    Role: D/V
 确认存在手动紧急停止机制，以立即终止AI模型推理和输出。
 #13.1.2    Level: 1    Role: D
 核实覆盖控制仅限授权人员访问。
 #13.1.3    Level: 3    Role: D/V
 验证回滚流程能够恢复到之前的模型版本或安全模式操作。
 #13.1.4    Level: 3    Role: V
 确保覆盖机制定期接受测试。

---

### C13.2 人工参与决策检查点

当风险超过预设阈值时，需人工审批。

 #13.2.1    Level: 1    Role: D/V
 验证高风险的人工智能决策在执行前需要明确的人类批准。
 #13.2.2    Level: 1    Role: D
 验证风险阈值是否明确定义并能够自动触发人工审核流程。
 #13.2.3    Level: 2    Role: D
 确认在无法在规定时间内获得人工批准时，时间敏感的决策有备用程序。
 #13.2.4    Level: 3    Role: D/V
 如果适用，请验证升级程序是否为不同的决策类型或风险类别定义了明确的权限等级。

---

### C13.3 责任链与可审计性

记录操作员行为和模型决策。

 #13.3.1    Level: 1    Role: D/V
 验证所有人工智能系统的决策和人工干预均有时间戳、用户身份和决策理由的日志记录。
 #13.3.2    Level: 2    Role: D
 验证审计日志不可被篡改，并包含完整性验证机制。

---

### C13.4 可解释性人工智能技术

表面特征重要性、反事实和局部解释。

 #13.4.1    Level: 1    Role: D/V
 验证人工智能系统是否以人类可读的格式提供其决策的基本解释。
 #13.4.2    Level: 2    Role: V
 通过人工评估研究和指标验证解释质量。
 #13.4.3    Level: 3    Role: D/V
 确认关键决策是否提供特征重要性评分或归因方法（如 SHAP、LIME 等）。
 #13.4.4    Level: 3    Role: V
 验证反事实解释是否展示了如何修改输入以改变结果（如果适用于使用案例和领域）。

---

### C13.5 模型卡与使用披露

维护模型卡，包含预期用途、性能指标和伦理考量。

 #13.5.1    Level: 1    Role: D
 验证模型卡是否记录了预期的使用场景、限制和已知的失败模式。
 #13.5.2    Level: 1    Role: D/V
 验证已披露适用于不同用例的性能指标。
 #13.5.3    Level: 2    Role: D
 验证伦理考量、偏见评估、公平性评价、训练数据特征和已知训练数据限制是否有记录并定期更新。
 #13.5.4    Level: 2    Role: D/V
 确保模型卡在整个模型生命周期中进行版本控制和维护，并具有变更跟踪功能。

---

### C13.6 不确定性量化

在响应中传递置信度分数或熵度量。

 #13.6.1    Level: 1    Role: D
 验证人工智能系统是否在其输出结果中提供置信度评分或不确定性度量。
 #13.6.2    Level: 2    Role: D/V
 验证不确定性阈值是否触发额外的人类审核或替代决策路径。
 #13.6.3    Level: 2    Role: V
 验证不确定性量化方法是否经过校准并以真实数据进行验证。
 #13.6.4    Level: 3    Role: D/V
 验证不确定性传播在多步骤人工智能工作流程中的保持情况。

---

### C13.7 面向用户的透明度报告

定期披露事件、漂移和数据使用情况。

 #13.7.1    Level: 1    Role: D/V
 确保数据使用政策和用户同意管理实践清晰传达给利益相关者。
 #13.7.2    Level: 2    Role: D/V
 确认已进行人工智能影响评估，并将结果纳入报告中。
 #13.7.3    Level: 2    Role: D/V
 核实定期发布的透明度报告是否以合理的细节披露了人工智能事件和运营指标。

#### 参考文献

EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
ISO/IEC 42001:2023 — AI Management Systems Requirements
NIST AI Risk Management Framework 1.0
NIST SP 800-53 Revision 5 — Security and Privacy Controls
A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)
Model Cards for Model Reporting (Mitchell et al., 2018)
Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)
ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods
IEEE 7001-2021 — Transparency of Autonomous Systems
GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)
Human Oversight under Article 14 of the EU AI Act (Fink, 2025)

## 附录 A：术语表

本综合词汇表提供了AISVS中使用的关键人工智能、机器学习和安全术语的定义，以确保清晰和共识。
​
对抗样本：一种故意设计的输入，旨在使人工智能模型犯错，通常通过添加人类难以察觉的微小扰动实现。
​
对抗鲁棒性——AI中的对抗鲁棒性指的是模型在面对故意设计用于引发错误的恶意输入时，依然能够保持其性能并抵抗被欺骗或操纵的能力。
​
智能体 – AI智能体是使用人工智能代表用户追求目标并完成任务的软件系统。它们具备推理、规划和记忆能力，并具有一定的自主性，能够做出决策、学习和适应。
​
代理型人工智能：能够以一定程度的自主性运行以实现目标的人工智能系统，通常在没有直接人类干预的情况下做出决策和采取行动。
​
基于属性的访问控制（ABAC）：一种访问控制范式，其授权决策基于用户、资源、操作和环境的属性，在查询时进行评估。
​
后门攻击：一种数据投毒攻击，模型被训练成在遇到特定触发器时以特定方式响应，而在其他情况下表现正常。
​
偏差：AI模型输出中的系统性错误，可能导致对某些群体或特定情境产生不公平或歧视性的结果。
​
偏见利用：一种利用人工智能模型中已知偏见来操纵输出或结果的攻击技术。
​
Cedar：亚马逊的策略语言和引擎，用于实现 AI 系统的基于属性的访问控制（ABAC）中的细粒度权限管理。
​
链式思维：一种通过在生成最终答案之前产生中间推理步骤来改善语言模型推理能力的技术。
​
断路器：当超过特定风险阈值时，自动停止人工智能系统操作的机制。
​
数据泄露：通过人工智能模型输出或行为无意中暴露敏感信息。
​
数据投毒：故意破坏训练数据以损害模型完整性，通常用于植入后门或降低性能。
​
差分隐私——差分隐私是一种数学上严密的框架，用于在保护个体数据主体隐私的同时发布有关数据集的统计信息。它使数据持有者能够共享群体的总体模式，同时限制泄露关于特定个体的信息。
​
嵌入：数据（文本、图像等）的密集向量表示，在高维空间中捕捉语义意义。
​
可解释性——人工智能中的可解释性是指AI系统能够为其决策和预测提供人类可理解的理由，从而揭示其内部工作机制的能力。
​
可解释人工智能（XAI）：通过各种技术和框架设计的能够为其决策和行为提供人类可理解解释的人工智能系统。
​
联邦学习：一种机器学习方法，模型在多个分散的设备上训练，这些设备持有本地数据样本，但不交换数据本身。
​
安全防护措施：为防止人工智能系统产生有害的、有偏见的或其他不良输出而实施的约束条件。
​
幻觉——AI幻觉指的是一种现象，即AI模型生成不基于其训练数据或事实现实的错误或误导性信息。
​
人机交互（HITL）：设计为在关键决策点需要人工监督、验证或干预的系统。
​
基础设施即代码（IaC）：通过代码而非手动流程管理和配置基础设施，实现安全扫描和一致性部署。
​
越狱技术：用于规避人工智能系统中安全防护措施的技术，特别是在大型语言模型中，以生成被禁止的内容。
​
最小权限原则：为用户和进程授予仅最低必要访问权限的安全原则。
​
LIME（局部可解释模型无关解释）：一种通过局部拟合可解释模型来解释任何机器学习分类器预测的方法。
​
成员推断攻击：一种旨在确定特定数据点是否被用于训练机器学习模型的攻击。
​
MITRE ATLAS：针对人工智能系统的对抗威胁态势；一个针对AI系统的对抗策略和技术的知识库。
​
模型卡——模型卡是一种文档，提供关于人工智能模型的性能、局限性、预期用途和伦理考量的标准化信息，以促进透明度和负责任的人工智能开发。
​
模型提取：一种攻击行为，攻击者通过反复查询目标模型，未授权地创建一个功能上相似的副本。
​
模型反演：一种通过分析模型输出尝试重建训练数据的攻击。
​
模型生命周期管理——AI模型生命周期管理是监督AI模型存在的各个阶段的过程，包括其设计、开发、部署、监控、维护以及最终退役，以确保其保持有效并与目标保持一致。
​
模型中毒：在训练过程中直接向模型引入漏洞或后门。
​
模型盗用/窃取：通过反复查询提取专有模型的复制品或近似模型。
​
多智能体系统：由多个相互作用的人工智能代理组成的系统，每个代理可能具有不同的能力和目标。
​
OPA（开放策略代理）：一个开源的策略引擎，能够实现跨整个技术栈的统一策略执行。
​
隐私保护机器学习（PPML）：在保护训练数据隐私的同时，训练和部署机器学习模型的技术和方法。
​
提示注入：一种攻击手段，通过在输入中嵌入恶意指令以覆盖模型的预期行为。
​
RAG（检索增强生成）：一种通过在生成回答之前从外部知识源检索相关信息来增强大型语言模型的技术。
​
红队演练：通过模拟对抗性攻击主动测试人工智能系统以识别漏洞的实践。
​
SBOM（软件物料清单）：一份包含用于构建软件或AI模型的各个组件详情及供应链关系的正式记录。
​
SHAP（Shapley 加性解释）：一种博弈论方法，通过计算每个特征对预测结果的贡献，来解释任何机器学习模型的输出。
​
供应链攻击：通过针对供应链中安全较弱的环节，如第三方库、数据集或预训练模型，来攻破系统。
​
迁移学习：一种技术，其中为一个任务开发的模型被重新用作第二个任务模型的起点。
​
向量数据库：一种专门设计用于存储高维向量（嵌入）并执行高效相似性搜索的数据库。
​
漏洞扫描：自动化工具，用于识别软件组件中的已知安全漏洞，包括人工智能框架和依赖项。
​
水印技术：在AI生成内容中嵌入不可察觉的标记，以追踪其来源或检测AI生成。
​
零日漏洞：一种先前未知的漏洞，攻击者可以在开发人员创建和部署补丁之前利用该漏洞。

## 附录 B：参考文献

### TODO

## 附录C：人工智能安全治理与文档

### 目标

本附录提供了建立组织结构、政策和流程的基本要求，以在整个系统生命周期内管理人工智能安全。

---

### AC.1 人工智能风险管理框架采纳

提供一个正式框架，以在系统生命周期内识别、评估和缓解特定于人工智能的风险。

 #AC.1.1    Level: 1    Role: D/V
 验证已记录并实施专门针对人工智能的风险评估方法。
 #AC.1.2    Level: 2    Role: D
 确认在人工智能生命周期的关键节点以及重大变更之前进行风险评估。
 #AC.1.3    Level: 3    Role: D/V
 验证风险管理框架是否符合既定标准（例如，NIST AI RMF）。

---

### AC.2 人工智能安全政策与程序

定义并执行组织标准，以确保人工智能的安全开发、部署和运行。

 #AC.2.1    Level: 1    Role: D/V
 验证是否存在已记录的人工智能安全策略。
 #AC.2.2    Level: 2    Role: D
 确保政策至少每年审查和更新一次，并在重大威胁环境变化后进行更新。
 #AC.2.3    Level: 3    Role: D/V
 验证政策是否涵盖所有AISVS类别及适用的监管要求。

---

### AC.3 人工智能安全的角色与职责

在整个组织中建立明确的人工智能安全责任制。

 #AC.3.1    Level: 1    Role: D/V
 验证人工智能安全角色和职责是否有文档记录。
 #AC.3.2    Level: 2    Role: D
 确认相关人员具备适当的安全专业知识。
 #AC.3.3    Level: 3    Role: D/V
 确认已为高风险人工智能系统建立人工智能伦理委员会或治理委员会。

---

### AC.4 伦理人工智能指南执行

确保人工智能系统按照既定的伦理原则运行。

 #AC.4.1    Level: 1    Role: D/V
 验证是否存在人工智能开发和部署的伦理指南。
 #AC.4.2    Level: 2    Role: D
 验证是否已建立机制以检测和报告伦理违规行为。
 #AC.4.3    Level: 3    Role: D/V
 验证已部署的人工智能系统是否定期进行伦理审查。

---

### AC.5 人工智能法规合规监测

保持对不断变化的人工智能法规的关注和遵守。

 #AC.5.1    Level: 1    Role: D/V
 验证是否存在识别适用人工智能法规的流程。
 #AC.5.2    Level: 2    Role: D
 验证是否已评估所有监管要求的合规性。
 #AC.5.3    Level: 3    Role: D/V
 确认监管变化能够及时触发对人工智能系统的审查和更新。

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management
EU Artificial Intelligence Act — Regulation (EU) 2024/1689
ISO/IEC 24029‑2:2023 — Robustness of Neural Networks — Methodology for Formal Methods

## 附录D：AI辅助的安全编码治理与验证

### 目标

本章定义了在软件开发过程中安全有效使用AI辅助编码工具的基础组织控制，确保软件开发生命周期（SDLC）中的安全性和可追溯性。

---

### AD.1 AI辅助安全编码工作流程

将人工智能工具集成到组织的安全软件开发生命周期（SSDLC）中，同时不削弱现有的安全关卡。

 #AD.1.1    Level: 1    Role: D/V
 验证已记录的工作流程是否描述了何时以及如何使用 AI 工具生成、重构或审查代码。
 #AD.1.2    Level: 2    Role: D
 验证该工作流程是否映射到每个SSDLC阶段（设计、实施、代码审查、测试、部署）。
 #AD.1.3    Level: 3    Role: D/V
 验证是否收集了针对AI生成代码的指标（例如，漏洞密度、平均检测时间），并将其与仅由人工编写的基线进行比较。

---

### AD.2 AI 工具资格认证与威胁建模

确保在采用前对人工智能编码工具的安全能力、风险及供应链影响进行评估。

 #AD.2.1    Level: 1    Role: D/V
 验证每个 AI 工具的威胁模型是否识别了滥用、模型反演、数据泄露和依赖链风险。
 #AD.2.2    Level: 2    Role: D
 验证工具评估是否包括对任何本地组件的静态/动态分析以及对SaaS端点（TLS、身份验证/授权、日志记录）的评估。
 #AD.2.3    Level: 3    Role: D/V
 验证评估是否遵循公认的框架，并在重大版本更改后重新执行评估。

---

### AD.3 安全提示与上下文管理

在构建用于AI模型的提示或上下文时，防止机密信息、专有代码和个人数据泄露。

 #AD.3.1    Level: 1    Role: D/V
 确认书面指导禁止在提示中发送机密信息、凭证或机密数据。
 #AD.3.2    Level: 2    Role: D
 验证技术控制措施（客户端编辑、已批准的上下文过滤器）是否自动剥离敏感信息。
 #AD.3.3    Level: 3    Role: D/V
 验证提示和响应在传输和静止时均被分词和加密，且保留期限符合数据分类政策。

---

### AD.4 AI生成代码的验证

在代码合并或部署之前，检测并修复由AI生成内容引入的漏洞。

 #AD.4.1    Level: 1    Role: D/V
 确保人工智能生成的代码始终经过人工代码审查。
 #AD.4.2    Level: 2    Role: D
 验证所有包含 AI 生成代码的拉取请求是否运行自动扫描工具（SAST/IAST/DAST），并在发现关键问题时阻止合并。
 #AD.4.3    Level: 3    Role: D/V
 验证差分模糊测试或基于属性的测试能证明安全关键行为（例如，输入验证、授权逻辑）。

---

### AD.5 代码建议的可解释性与可追溯性

为审计员和开发人员提供关于建议为何被提出以及其演变过程的见解。

 #AD.5.1    Level: 1    Role: D/V
 验证提示/响应对是否已使用提交ID进行记录。
 #AD.5.2    Level: 2    Role: D
 验证开发人员是否能够展示支持建议的模型引用（训练片段、文档）。
 #AD.5.3    Level: 3    Role: D/V
 验证可解释性报告是否与设计工件一起存储，并在安全审查中引用，以满足 ISO/IEC 42001 可追溯性原则。

---

### AD.6 持续反馈与模型微调

随着时间的推移提高模型的安全性能，同时防止负面漂移。

 #AD.6.1    Level: 1    Role: D/V
 验证开发者能否标记不安全或不合规的建议，并且确保这些标记被追踪。
 #AD.6.2    Level: 2    Role: D
 验证汇总反馈是否用于定期微调或基于检索增强生成，且所用语料来自经过审核的安全编码库（例如，OWASP备忘单）。
 #AD.6.3    Level: 3    Role: D/V
 验证闭环评估系统在每次微调后运行回归测试；安全指标必须达到或超过之前的基线才能部署。

---

#### 参考文献

NIST AI Risk Management Framework 1.0
ISO/IEC 42001:2023 — AI Management Systems Requirements
OWASP Secure Coding Practices — Quick Reference Guide

## 附录 E：示例工具和框架

### 目标

本章提供了可支持实现或满足特定AISVS需求的工具和框架示例。这些示例不应被视为AISVS团队或OWASP GenAI安全项目的推荐或认可。

---

### AE.1 训练数据治理与偏差管理

用于数据分析、治理和偏见管理的工具。

 #AE.1.1    Section: 1.1
 数据清单工具：数据清单管理工具如...
 #AE.1.2    Section: 1.2
 传输中的加密 使用TLS用于基于HTTPS的应用程序，结合openSSL和Python的工具`ssl`库。

---

### AE.2 用户输入验证

处理和验证用户输入的工具。

 #AE.2.1    Section: 2.1
 提示注入防御工具：使用如NVIDIA的NeMo或Guardrails AI等防护工具。

---

