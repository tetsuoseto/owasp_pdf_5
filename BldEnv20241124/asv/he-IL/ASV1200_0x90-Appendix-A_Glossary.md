# נספח א': מילון מונחים

> המונחיה המקיפה הזו מספקת הגדרות למונחים מרכזיים בתחום ה-AI, ML ואבטחה המשמשים לאורך כל ה-AISVS במטרה להבטיח בהירות והבנה משותפת.
> ​
* דוגמה עוינת: קלט שנוצר במכוון כדי לגרום למודל בינה מלאכותית לעשות טעות, לעיתים על ידי הוספת הפרעות עדינות שלא ניתנות לזיהוי על ידי בני אדם.
  ​
* חוסן אדברסרי – חוסן אדברסרי בבינה מלאכותית מתייחס ליכולת של מודל לשמור על ביצועיו ולהתנגד להונות או למניפולציות הנעשיות באמצעות קלטים עוינים ומכוונים שנוצרו בכוונה לגרום לשגיאות.
  ​
* סוכן – סוכני בינה מלאכותית (AI) הם מערכות תוכנה המשתמשות ב-AI כדי לרדוף אחר מטרות ולהשלים משימות מטעם המשתמשים. הם מציגים יכולות של היסק, תכנון וזיכרון, ונהנים מרמת עצמאות לקבלת החלטות, ללמוד ולהסתגל.
  ​
* בינה מלאכותית סוכנת: מערכות בינה מלאכותית שיכולות לפעול עם מידה מסוימת של אוטונומיה להשגת מטרות, לעיתים מקבלות החלטות ונוקטות בפעולות ללא התערבות ישירה של אדם.
  ​
* בקרת גישה מבוססת תכונות (ABAC): פרדיגמת בקרת גישה שבה החלטות האישור מבוססות על תכונות של המשתמש, המשאב, הפעולה והסביבה, המוערכות בזמן השאילתה.
  ​
* התקפת דלת אחורית: סוג של התקפת הרעלה של נתונים שבה המודל מאומן להגיב בצורה ספציפית לטריגרים מסוימים תוך התנהגות רגילה אחרת.
  ​
* הטיה: שגיאות שיטתיות בתוצאות של מודל בינה מלאכותית היכולות להוביל לתוצאות לא הוגנות או מפלות כלפי קבוצות מסוימות או בהקשרים מסוימים.
  ​
* ניצול הטיה: טכניקת התקפה המנצלת הטיות ידועות במודלים של בינה מלאכותית כדי למניפול פלטים או תוצאות.
  ​
* Cedar: שפת המדיניות ומנוע של אמזון להענקת הרשאות מדויקות המשמשים ליישום ABAC במערכות בינה מלאכותית.
  ​
* רצף חשיבה: טכניקה לשיפור ההיסק במודלי שפה על ידי יצירת שלבי היסק ביניים לפני הפקת תשובה סופית.
  ​
* מתגי הפסקה: מנגנונים שמפסיקים באופן אוטומטי את פעולת מערכת ה-AI כאשר נעשים חריגות מסוימות בסף הסיכון.
  ​
* דליפת נתונים: חשיפת מידע רגיש שלא בכוונה דרך תוצרי מודל בינה מלאכותית או התנהגותו.
  ​
* הרעלת נתונים: השחתה מכוונת של נתוני האימון לפגוע בשלמות המודל, לעיתים להתקנת דלתות אחוריות או להורדת הביצועים.
  ​
* פרטיות דיפרנציאלית – פרטיות דיפרנציאלית היא מסגרת מתמטית קשיחה לשחרור מידע סטטיסטי על מערכי נתונים תוך הגנה על פרטיותם של נבדקים בודדים. היא מאפשרת לבעל הנתונים לשתף דפוסים מצטברים של הקבוצה תוך הגבלת המידע שנחשף על פרטים ספציפיים.
  ​
* הטמעות: ייצוגים וקטוריים צפופים של נתונים (טקסט, תמונות, וכו') שמבקשים ללכוד משמעות סמנטית במרחב רב-ממדי.
  ​
* הסבריות – הסבריות בבינה מלאכותית היא היכולת של מערכת בינה מלאכותית לספק סיבות מובנות לאדם להחלטות ולתחזיות שלה, ומציעה תובנות לגבי פעולתה הפנימית.
  ​
* בינה מלאכותית מוסברת (XAI): מערכות בינה מלאכותית המעצבות להסביר באופן מובן לבני אדם את החלטותיהן והתנהגויותיהן באמצעות טכניקות ומסגרות שונות.
  ​
* למידה מבוזרת: גישה ללמידת מכונה שבה מודלים מאומנים על פני מספר מכשירים מבוזרים המחזיקים במדגמי נתונים מקומיים, מבלי להחליף את הנתונים עצמם.
  ​
* מגבלות: אילוצים שמיושמים כדי למנוע ממערכות בינה מלאכותית להפיק תוצאות מזיקות, מוטות או בלתי רצויות באופן אחר.
  ​
* הלוצינציה – הלוצינציה של בינה מלאכותית מתייחסת לתופעה שבה מודל בינה מלאכותית מייצר מידע שגוי או מטעה שאינו מבוסס על נתוני האימון שלו או על המציאות העובדתית.
  ​
* אדם בלולאה (HITL): מערכות שנועדו לדרוש פיקוח, אימות או התערבות אנושית בנקודות החלטה קריטיות.
  ​
* תשתית כקוד (IaC): ניהול והקצאת תשתיות באמצעות קוד במקום תהליכים ידניים, המאפשר סריקות אבטחה ופריסות עקביות.
  ​
* פריצת סורגים: טכניקות המשמשות לעקיפת מכשירי הבטיחות במערכות בינה מלאכותית, במיוחד במודלים גדולים של שפה, כדי לייצר תוכן אסור.
  ​
* זכויות מינימום: עקרון האבטחה של מתן רק את הזכויות ההכרחיות המינימליות למשתמשים ותהליכים.
  ​
* LIME (הסברים מקומיים בלתי תלויים במודל): טכניקה להסברת תחזיות של כל מסווג בלימוד מכונה על ידי הערכה מקומית שלו עם מודל ניתן לפרש.
  ​
* התקפת הסקת חברות: התקפה שמטרתה לקבוע האם נקודת נתונים מסוימת שימשה לאימון מודל למידת מכונה.
  ​
* MITRE ATLAS: נוף האיומים העוינים למערכות בינה מלאכותית; בסיס ידע של טקטיקות וטכניקות עוינות נגד מערכות AI.
  ​
* כרטיס מודל – כרטיס מודל הוא מסמך המספק מידע סטנדרטי על ביצועי מודל בינה מלאכותית, מגבלותיו, השימושים המתוכננים והיבטים אתיים במטרה לקדם שקיפות ופיתוח אחראי של בינה מלאכותית.
  ​
* חילוץ מודל: התקפה שבה מתנגד שואל שוב ושוב מודל יעד כדי ליצור עותק בעל פונקציונליות דומה ללא הרשאה.
  ​
* היפוך מודל: מתקפה שמנסה לשחזר נתוני אימון על ידי ניתוח תוצאות המודל.
  ​
* ניהול מחזור חיי מודל – ניהול מחזור חיי מודל בינה מלאכותית הוא התהליך של פיקוח על כל שלבי קיומו של מודל בינה מלאכותית, כולל עיצובו, פיתוחו, פריסתו, ניטורו, תחזוקתו ופרישתו בסופו של דבר, כדי להבטיח שהוא נשאר יעיל ומתואם עם המטרות.
  ​
* רעלול דגם: הכנסת פרצות אבטחה או דלתות אחוריות ישירות לתוך הדגם במהלך תהליך האימון.
  ​
* גניבת מודל: חילוץ העתק או קירוב של מודל קנייני באמצעות שאילתות חוזרות.
  ​
* מערכת רב-סוכנית: מערכת המורכבת ממספר סוכני בינה מלאכותית פעילים, שלכל אחד מהם יכולות ומטרות שונות פוטנציאלית.
  ​
* OPA (Open Policy Agent): מנוע מדיניות קוד פתוח המאפשר אכיפה אחידה של מדיניות לאורך כל המערכת.
  ​
* למידת מכונה לשמירת פרטיות (PPML): טכניקות ושיטות לאימון והטמעת מודלים של למידת מכונה תוך הגנה על פרטיות נתוני האימון.
  ​
* הזרקת פרומפט: התקפה שבה משולבות הוראות זדוניות בקלטים כדי לעקוף את ההתנהגות המיועדת של המודל.
  ​
* RAG (ייצור משופר באמצעות שליפה): טכניקה שמגבירה את דגמי השפה הגדולים על ידי שליפת מידע רלוונטי ממקורות ידע חיצוניים לפני יצירת תגובה.
  ​
* בדיקת קבוצה אדומה: תהליך של בדיקה פעילה של מערכות בינה מלאכותית על ידי סימולציה של התקפות עוינות כדי לאתר נקודות תורפה.
  ​
* רשימת חומרים לתוכנה (SBOM): רישום רשמי המכיל את הפרטים ויחסי שרשרת האספקה של רכיבים שונים המשמשים בבניית תוכנה או דגמי בינה מלאכותית.
  ​
* SHAP (הסברים מצטברים של שייפלי): גישה תיאורטית משחקית להסבר הפלט של כל מודל למידת מכונה על ידי חישוב התרומה של כל תכונה לחיזוי.
  ​
* מתקפת שרשרת אספקה: פגיעה במערכת על ידי מיקוד ברכיבים פחות מאובטחים בשרשרת האספקה שלה, כגון ספריות צד שלישי, מערכי נתונים או מודלים מאומנים מראש.
  ​
* למידת העברה: טכניקה שבה מודל שפותח למשימה אחת משמש כנקודת התחלה למודל במשימה שנייה.
  ​
* מאגר וקטורים: מאגר נתונים מיוחד שנועד לאחסון וקטורים בעלי מימד גבוה (הטמעות) ולביצוע חיפושי דמיון יעילים.
  ​
* סריקת פרצות: כלים אוטומטיים שמזהים פרצות אבטחה ידועות ברכיבי תוכנה, כולל מסגרות בינה מלאכותית ותלויות.
  ​
* חותמת מים: טכניקות להטמעת סימנים בלתי נראים בתוכן הנוצר על ידי בינה מלאכותית כדי לעקוב אחר מקורו או לזהות יצירה של בינה מלאכותית.
  ​
* פרצת יום אפס: פרצה לא ידועה קודם לכן, שנוצלת על ידי התוקפים לפני שהמפתחים יוצרים ומפיצים תיקון.

