# C13 인간 감독, 책임 및 거버넌스

## 통제 목표

이 장에서는 AI 시스템에서 인간의 감독과 명확한 책임 체계를 유지하는 요구 사항을 제공하며, AI 수명 주기 전반에 걸쳐 설명 가능성, 투명성 및 윤리적 관리성을 보장합니다.

---

## C13.1 킬 스위치 및 오버라이드 메커니즘

AI 시스템의 안전하지 않은 동작이 관찰될 경우 종료 또는 롤백 경로를 제공하십시오.

|   #    | Description                                            | Level | Role |
| :----: | ------------------------------------------------------ | :---: | :--: |
| 13.1.1 | AI 모델 추론 및 출력을 즉시 중단할 수 있는 수동 킬스위치 메커니즘이 존재하는지 확인하십시오. |   1   | D/V  |
| 13.1.2 | 재정의 제어가 권한이 있는 인원만 접근할 수 있는지 확인하십시오.                   |   1   |  D   |
| 13.1.3 | 롤백 절차가 이전 모델 버전 또는 안전 모드 작업으로 되돌릴 수 있는지 확인하십시오.        |   3   | D/V  |
| 13.1.4 | 오버라이드 메커니즘이 정기적으로 테스트되는지 확인하십시오.                       |   3   |  V   |

---

## C13.2 인간 포함 결정 검증 지점

위험 임계값을 초과하는 경우 사람의 승인을 요구하십시오.

|   #    | Description                                                               | Level | Role |
| :----: | ------------------------------------------------------------------------- | :---: | :--: |
| 13.2.1 | 고위험 AI 결정은 실행 전에 명시적인 인간 승인을 받도록 확인하십시오.                                  |   1   | D/V  |
| 13.2.2 | 위험 임계값이 명확하게 정의되어 있으며 자동으로 인간 검토 워크플로를 트리거하는지 확인하십시오.                     |   1   |  D   |
| 13.2.3 | 인간 승인을 필요한 시간 내에 얻을 수 없을 경우를 대비하여, 시간에 민감한 결정에 대한 대체 절차가 마련되어 있는지 확인하십시오. |   2   |  D   |
| 13.2.4 | 적용 가능한 경우, 에스컬레이션 절차가 다양한 의사 결정 유형이나 위험 범주에 대해 명확한 권한 수준을 정의하는지 확인하십시오.   |   3   | D/V  |

---

## C13.3 책임 연쇄 및 감사 가능성

연산자 작업 및 모델 결정을 기록하십시오.

|   #    | Description                                                     | Level | Role |
| :----: | --------------------------------------------------------------- | :---: | :--: |
| 13.3.1 | 모든 AI 시스템 결정과 인간 개입이 타임스탬프, 사용자 식별 정보 및 결정 근거와 함께 기록되는지 확인하십시오. |   1   | D/V  |
| 13.3.2 | 감사 로그가 변조될 수 없으며 무결성 검증 메커니즘을 포함하고 있는지 확인하십시오.                  |   2   |  D   |

---

## C13.4 설명가능한 AI 기법

표면 특징 중요도, 반사실적 설명, 그리고 국소적 설명.

|   #    | Description                                                                    | Level | Role |
| :----: | ------------------------------------------------------------------------------ | :---: | :--: |
| 13.4.1 | AI 시스템이 사람의 이해가 가능한 형식으로 그들의 결정에 대한 기본적인 설명을 제공하는지 확인하십시오.                     |   1   | D/V  |
| 13.4.2 | 설명 품질이 인간 평가 연구 및 지표를 통해 검증되었는지 확인하십시오.                                        |   2   |  V   |
| 13.4.3 | 중요한 결정에 대해 특징 중요도 점수 또는 기여도 방법(SHAP, LIME 등)이 사용 가능한지 확인하십시오.                  |   3   | D/V  |
| 13.4.4 | 카운터팩추얼 설명이 사용 사례 및 도메인에 적용 가능한 경우, 결과를 변경하기 위해 입력을 어떻게 수정할 수 있는지 보여주는지 확인하십시오. |   3   |  V   |

---

## C13.5 모델 카드 및 사용 공개

의도된 사용, 성능 지표 및 윤리적 고려 사항에 대한 모델 카드를 유지하십시오.

|   #    | Description                                                                           | Level | Role |
| :----: | ------------------------------------------------------------------------------------- | :---: | :--: |
| 13.5.1 | 모델 카드가 의도된 사용 사례, 한계 및 알려진 실패 모드를 문서화하는지 확인하십시오.                                      |   1   |  D   |
| 13.5.2 | 다양한 적용 가능한 사용 사례 전반에 걸친 성능 지표가 공개되었는지 확인하십시오.                                         |   1   | D/V  |
| 13.5.3 | 윤리적 고려사항, 편향 평가, 공정성 평가, 훈련 데이터 특성, 그리고 알려진 훈련 데이터 한계가 문서화되어 있고 정기적으로 업데이트되는지 확인하십시오. |   2   |  D   |
| 13.5.4 | 모델 카드가 버전 관리되고 모델 생애 주기 전반에 걸쳐 변경 추적과 함께 유지되는지 확인하십시오.                                |   2   | D/V  |

---

## C13.6 불확실성 정량화

응답에서 신뢰도 점수 또는 엔트로피 측정값을 전파합니다.

|   #    | Description                                       | Level | Role |
| :----: | ------------------------------------------------- | :---: | :--: |
| 13.6.1 | AI 시스템이 출력과 함께 신뢰도 점수 또는 불확실성 측정치를 제공하는지 확인하십시오.  |   1   |  D   |
| 13.6.2 | 불확실성 임계값이 추가적인 인간 검토 또는 대체 의사 결정 경로를 유발하는지 확인합니다. |   2   | D/V  |
| 13.6.3 | 불확실성 정량화 방법이 실제 데이터에 대해 보정되고 검증되었는지 확인하십시오.       |   2   |  V   |
| 13.6.4 | 불확실성 전파가 다단계 AI 워크플로우 전반에 걸쳐 유지되는지 확인하십시오.        |   3   | D/V  |

---

## C13.7 사용자 대상 투명성 보고서

사건, 드리프트, 데이터 사용에 대한 주기적인 공개를 제공하십시오.

|   #    | Description                                              | Level | Role |
| :----: | -------------------------------------------------------- | :---: | :--: |
| 13.7.1 | 데이터 사용 정책 및 사용자 동의 관리 관행이 이해 관계자에게 명확하게 전달되었는지 확인하십시오.   |   1   | D/V  |
| 13.7.2 | AI 영향 평가가 수행되었으며 결과가 보고서에 포함되었는지 확인하십시오.                 |   2   | D/V  |
| 13.7.3 | 투명성 보고서가 정기적으로 AI 사고 및 운영 지표를 합리적인 세부 사항으로 공개하는지 확인하십시오. |   2   | D/V  |

### 참고문헌

* [EU Artificial Intelligence Act — Regulation (EU) 2024/1689 (Official Journal, 12 July 2024)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
* [ISO/IEC 23894:2023 — Artificial Intelligence — Guidance on Risk Management](https://www.iso.org/standard/77304.html)
* [ISO/IEC 42001:2023 — AI Management Systems Requirements](https://www.iso.org/standard/81230.html)
* [NIST AI Risk Management Framework 1.0](https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf)
* [NIST SP 800-53 Revision 5 — Security and Privacy Controls](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf)
* [A Unified Approach to Interpreting Model Predictions (SHAP, ICML 2017)](https://arxiv.org/abs/1705.07874)
* [Model Cards for Model Reporting (Mitchell et al., 2018)](https://arxiv.org/abs/1810.03993)
* [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning (Gal & Ghahramani, 2016)](https://arxiv.org/abs/1506.02142)
* [ISO/IEC 24029-2:2023 — Robustness of Neural Networks — Methodology for Formal Methods](https://www.iso.org/standard/79804.html)
* [IEEE 7001-2021 — Transparency of Autonomous Systems](https://standards.ieee.org/ieee/7001/6929/)
* [GDPR — Article 5 "Transparency Principle" (Regulation (EU) 2016/679)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX%3A32016R0679)
* [Human Oversight under Article 14 of the EU AI Act (Fink, 2025)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5147196)

