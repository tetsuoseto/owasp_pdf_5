# Prefazione

Benvenuti allo Standard di Verifica della Sicurezza dell'Intelligenza Artificiale (AISVS) versione 1.0!

## Introduzione

Fondata nel 2025 tramite uno sforzo collaborativo della comunità, AISVS definisce i requisiti di sicurezza da considerare nella progettazione, sviluppo, distribuzione e gestione di modelli di IA moderni, pipeline e servizi abilitati all'IA.

AISVS v1.0 rappresenta il lavoro combinato dei suoi responsabili di progetto, del gruppo di lavoro e dei contributori della comunità più ampia per produrre una baseline pragmatica e testabile per la sicurezza dei sistemi di IA.

Il nostro obiettivo con questa versione è rendere AISVS facile da adottare, mantenendo al contempo un focus preciso sul suo ambito definito e affrontando il panorama dei rischi in rapida evoluzione, unico per l'IA.

## Obiettivi principali per AISVS Versione 1.0

La versione 1.0 sarà creata seguendo diversi principi guida.

### Ambito Ben Definito

Ogni requisito deve essere allineato con il nome e la missione di AISVS:

* Intelligenza Artificiale – I controlli operano a livello AI/ML (dati, modello, pipeline o inferenza) e sono responsabilità degli operatori AI.
* Sicurezza – I requisiti mitigano direttamente i rischi identificati di sicurezza, privacy o sicurezza operativa.
* Verifica – Il linguaggio è scritto in modo che la conformità possa essere convalidata oggettivamente.
* Standard – Le sezioni seguono una struttura e una terminologia coerenti per formare un riferimento omogeneo.
  ​
---

Seguendo AISVS, le organizzazioni possono valutare sistematicamente e rafforzare la postura di sicurezza delle loro soluzioni di intelligenza artificiale, promuovendo una cultura di ingegneria dell'IA sicura.

